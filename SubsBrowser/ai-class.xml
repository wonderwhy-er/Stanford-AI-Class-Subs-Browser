<videos date="Tue Oct 25 2011">
  <video title="Unit 0w, 1 Introduction" id="BnIJ7Ba5Sr4">
    <transcript>
      <text start="0" dur="4">Welcome to the online introduction to artificial intelligence.</text>
      <text start="4" dur="3">My name is Sebastian Thrun. &amp;gt;&amp;gt;I&amp;#39;m Peter Norvig.</text>
      <text start="7" dur="2">We are teaching this class at Stanford,</text>
      <text start="9" dur="2">and now we are teaching it online for the entire world.</text>
      <text start="11" dur="2">We are really excited about this.</text>
      <text start="13" dur="1">It&amp;#39;s great to have you all here.</text>
      <text start="14" dur="4">It&amp;#39;s exciting to have such a record-breaking number of people.</text>
      <text start="18" dur="4">We think we can deliver a good introduction to artificial intelligence.</text>
      <text start="22" dur="2">We hope you&amp;#39;ll stick with it.</text>
      <text start="24" dur="1">It&amp;#39;s going to be a lot of work,</text>
      <text start="25" dur="2">but we think it&amp;#39;s going to be very rewarding.</text>
      <text start="27" dur="2">The way that it is going to be organized is that</text>
      <text start="29" dur="3">every week there is going to be new videos and with these videos, quizes.</text>
      <text start="32" dur="3">With these quizzes, you can test your knowledge about AI.</text>
      <text start="35" dur="3">We also post for the advanced version of this class, homework assignments and exams</text>
      <text start="38" dur="2">on which you&amp;#39;ll be quizzed.</text>
      <text start="40" dur="4">We&amp;#39;re going to grade those to give you a final score to see</text>
      <text start="44" dur="3">if you can actually master artificial intelligence the same way</text>
      <text start="47" dur="2">any good student at Stanford would do it.</text>
      <text start="49" dur="5">If you do that, then at the end of the class, we&amp;#39;ll sign a letter of accomplishment,</text>
      <text start="54" dur="4">and let you know that you&amp;#39;ve achieved this and what your rank in the class was.</text>
      <text start="58" dur="4">So I hope you have fun.  Watch us on videotape.</text>
      <text start="62" dur="2">We will teach you AI.</text>
      <text start="64" dur="2">Participate in the discussion forum.</text>
      <text start="66" dur="3">Ask your questions, and help others answer questions.</text>
      <text start="69" dur="3">I hope we have a fantastic time ahead of us in the next 10 weeks.</text>
      <text start="72" dur="3">Welcome to the class. We&amp;#39;ll see you online.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 1 Introduction" id="Q7_GQq7cDyM">
    <transcript>
      <text start="0" dur="5">Welcome to the first unit of Online Introduction to Artificial Intelligence.</text>
      <text start="5" dur="4">I will be teaching you the very, very basics today.</text>
      <text start="9" dur="5">This is Unit 1 of Artificial Intelligence.</text>
      <text start="14" dur="2">Welcome.</text>
      <text start="16" dur="4">The purpose of this class is twofold:</text>
      <text start="20" dur="5">Number 1, to teach you the very basics of artificial intelligence</text>
      <text start="25" dur="4">so you&amp;#39;ll be able to talk to people in the field</text>
      <text start="29" dur="3">and understand the basic tools of the trade;</text>
      <text start="32" dur="5">and also, very importantly, to excite you about the field.</text>
      <text start="37" dur="5">I have been in the field of artificial intelligence for about 20 years,</text>
      <text start="42" dur="2">and it&amp;#39;s been truly rewarding.</text>
      <text start="44" dur="4">So I want you to participate in the beauty and the excitement of AI</text>
      <text start="48" dur="4">so you can become a professional who gets the same reward</text>
      <text start="52" dur="3">and excitement out of this field as I do.</text>
      <text start="55" dur="5">The basic structure of this class involves videos</text>
      <text start="60" dur="3">in which Peter or I will teach you something new,</text>
      <text start="63" dur="8">then also quizzes, which we will ask you about your ability to answer AI questions,</text>
      <text start="71" dur="6">and finally, answer videos in which we tell you what the right answer would have been</text>
      <text start="77" dur="5">for the quiz that you might have falsely or incorrectly answered before.</text>
      <text start="82" dur="6">This will all be reiterated, and every so often you get a homework assignment,</text>
      <text start="88" dur="6">also in the form of quizzes but without the answers.</text>
      <text start="94" dur="3">And then we also have video exams.</text>
      <text start="97" dur="2">If you check our website, there&amp;#39;s requirements</text>
      <text start="99" dur="4">on how you have to do assignments and exams.</text>
      <text start="103" dur="5">Please go to ai-class.org in this class.</text>
      <text start="108" dur="10">An AI program is called wetware, a formula, or an intelligent agent.</text>
      <text start="118" dur="2">Pick the one that fits best.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 2 Intelligent Agents" id="cx3lV07w-XE">
    <transcript>
      <text start="0" dur="4">[Thrun] The correct answer is intelligent agent.</text>
      <text start="4" dur="3">Let&amp;#39;s talk about intelligent agents.</text>
      <text start="7" dur="4">Here is my intelligent agent,</text>
      <text start="11" dur="6">and it gets to interact with an environment.</text>
      <text start="17" dur="5">The agent can perceive the state of the environment</text>
      <text start="22" dur="3">through its sensors,</text>
      <text start="25" dur="4">and it can affect its state through its actuators.</text>
      <text start="29" dur="8">The big question of artificial intelligence is the function that maps sensors to actuators.</text>
      <text start="37" dur="4">That is called the control policy for the agent.</text>
      <text start="41" dur="7">So all of this class will deal with how does an agent make decisions</text>
      <text start="48" dur="6">that it can carry out with its actuators based on past sensor data.</text>
      <text start="54" dur="4">Those decisions take place many, many times,</text>
      <text start="58" dur="5">and the loop of environment feedback to sensors, agent decision,</text>
      <text start="63" dur="9">actuator interaction with the environment and so on is called perception action cycle.</text>
      <text start="72" dur="3">So here is my very first quiz for you.</text>
      <text start="75" dur="6">Artificial intelligence, AI, has successfully been used in finance,</text>
      <text start="81" dur="5">robotics, games, medicine, and the Web.</text>
      <text start="86" dur="2">Check any or all of those that apply.</text>
      <text start="88" dur="6">And if none of them applies, check the box down here that says none of them.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 3 Applications of AI" id="N6JW8TQzbX8">
    <transcript>
      <text start="0" dur="3">So the correct answer is all of those--</text>
      <text start="3" dur="5">finance, robotics, games, medicine, the Web, and many more applications.</text>
      <text start="8" dur="2">So let me talk about them in some detail.</text>
      <text start="10" dur="5">There is a huge number of applications of artificial intelligence in finance,</text>
      <text start="15" dur="3">very often in the shape of making trading decisions--</text>
      <text start="18" dur="3">in which case, the agent is called a trading agent.</text>
      <text start="21" dur="6">And the environment might be things like the stock market or the bond market</text>
      <text start="27" dur="2">or the commodities market.</text>
      <text start="29" dur="4">And our trading agent can sense the course of certain things,</text>
      <text start="33" dur="2">like the stock or bonds or commodities.</text>
      <text start="35" dur="5">It can also read the news online and follow certain events.</text>
      <text start="40" dur="8">And its decisions are usually things like buy or sell decisions--trades.</text>
      <text start="48" dur="7">There&amp;#39;s a huge history of artificial intelligence finding methods to look at data over time</text>
      <text start="55" dur="3">and make predictions as to how courses develop over time--</text>
      <text start="58" dur="3">and then put in trades behind those.</text>
      <text start="61" dur="5">And very frequently, people using artificial intelligence trading agents</text>
      <text start="66" dur="4">have made a good amount of money with superior trading decisions.</text>
      <text start="70" dur="4">There&amp;#39;s also a long history of AI in Robotics.</text>
      <text start="74" dur="3">Here is my depiction of a robot.</text>
      <text start="77" dur="3">Of course, there are many different types of robots</text>
      <text start="80" dur="4">and they all interact with their environments through their sensors,</text>
      <text start="84" dur="9">which include things like cameras, microphones, tactile sensor or touch.</text>
      <text start="93" dur="5">And the way they impact their environments is to move motors around,</text>
      <text start="98" dur="5">in particular, their wheels, their legs, their arms, their grippers.</text>
      <text start="103" dur="3">They can also say things to people using voice.</text>
      <text start="106" dur="4">Now there&amp;#39;s a huge history of using artificial intelligence in robotics.</text>
      <text start="110" dur="4">Pretty much, every robot that does something interesting today uses AI.</text>
      <text start="114" dur="4">In fact, often AI has been studied together with robotics, as one discipline.</text>
      <text start="118" dur="5">But because robots are somewhat special in that they use physical actuators</text>
      <text start="123" dur="3">and deal with physical environments, they are a little bit different from</text>
      <text start="126" dur="2">just artificial intelligence, as a whole.</text>
      <text start="128" dur="7">When the Web came out, the early Web crawlers were called robots</text>
      <text start="135" dur="5">and to block a robot from accessing your website, to the present day,</text>
      <text start="140" dur="4">there&amp;#39;s a file called robot.txt, that allows you to deny any Web crawler</text>
      <text start="144" dur="4">to access and retrieve that information from your website.</text>
      <text start="148" dur="4">So historically, robotics played a huge role in artificial intelligence</text>
      <text start="152" dur="4">and a good chunk of this class will be focusing on robotics.</text>
      <text start="156" dur="3">AI has a huge history in games--</text>
      <text start="159" dur="4">to make games smarter or feel more natural.</text>
      <text start="163" dur="4">There are 2 ways in which AI has been used in games, as a game agent.</text>
      <text start="167" dur="3">One is to play against you, as a human user.</text>
      <text start="170" dur="4">So for example, if you play the game of Chess,</text>
      <text start="174" dur="3">then you are the environment to the game agent.</text>
      <text start="177" dur="6">The game agent gets to observe your moves, and it generates its own moves</text>
      <text start="183" dur="4">with the purpose of defeating you in Chess.</text>
      <text start="187" dur="3">So most adversarial games, where you play against an opponent</text>
      <text start="190" dur="3">and the opponent is a computer program,</text>
      <text start="193" dur="7">the game agent is built to play against you--against your own interests--and make you lose.</text>
      <text start="200" dur="2">And of course, your objective is to win.</text>
      <text start="202" dur="3">That&amp;#39;s an AI games-type situation.</text>
      <text start="205" dur="4">The second thing is that games agents in AI</text>
      <text start="209" dur="3">also are used to make games feel more natural.</text>
      <text start="212" dur="4">So very often games have characters inside, and these characters act in some way.</text>
      <text start="216" dur="6">And it&amp;#39;s important for you, as the player, to feel that these characters are believable.</text>
      <text start="222" dur="3">There&amp;#39;s an entire sub-field of artificial intelligence to use AI</text>
      <text start="225" dur="6">to make characters in a game more believable--look smarter, so to speak--</text>
      <text start="231" dur="4">so that you, as a player, think you&amp;#39;re playing a better game.</text>
      <text start="235" dur="5">Artificial intelligence has a long history in medicine as well.</text>
      <text start="240" dur="4">The classic example is that of a diagnostic agent.</text>
      <text start="244" dur="5">So here you are--and you might be sick, and you go to your doctor.</text>
      <text start="249" dur="2">And your doctor wishes to understand</text>
      <text start="251" dur="6">what the reason for your symptoms and your sickness is.</text>
      <text start="257" dur="4">The diagnostic agent will observe you through various measurements--</text>
      <text start="261" dur="4">for example, blood pressure and heart signals, and so on--</text>
      <text start="265" dur="4">and it&amp;#39;ll come up with the hypothesis as to what you might be suffering from.</text>
      <text start="269" dur="5">But rather than intervene directly, in most cases the diagnostic of your disease</text>
      <text start="274" dur="4">is communicated to the doctor, who then takes on the intervention.</text>
      <text start="278" dur="2">This is called a diagnostic agent.</text>
      <text start="280" dur="3">There are many other versions of AI in medicine.</text>
      <text start="283" dur="5">AI is used in intensive care to understand whether there are situations</text>
      <text start="288" dur="2">that need immediate attention.</text>
      <text start="290" dur="4">It&amp;#39;s been used for life-long medicine to monitor signs over long periods of time.</text>
      <text start="294" dur="4">And as medicine becomes more personal, the role of artificial intelligence</text>
      <text start="298" dur="3">will definitely increase.</text>
      <text start="301" dur="4">We already mentioned AI on the Web.</text>
      <text start="305" dur="4">The most generic version of AI is to crawl the Web and understand the Web,</text>
      <text start="309" dur="3">and assist you in answering questions.</text>
      <text start="312" dur="3">So when you have this search box over here</text>
      <text start="315" dur="3">and it says &amp;quot;Search&amp;quot; on the left,</text>
      <text start="318" dur="2">and &amp;quot;I&amp;#39;m Feeling Lucky&amp;quot; on the right,</text>
      <text start="320" dur="1">and you type in the words,</text>
      <text start="321" dur="7">what AI does for you is it understands what words you typed in</text>
      <text start="328" dur="2">and finds the most relevant pages.</text>
      <text start="330" dur="2">That is really co-artificial intelligence.</text>
      <text start="332" dur="4">It&amp;#39;s used by a number of companies, such as Microsoft and Google</text>
      <text start="336" dur="3">and Amazon, Yahoo, and many others.</text>
      <text start="339" dur="4">And the way this works is that there&amp;#39;s a crawling agent that can go</text>
      <text start="343" dur="8">to the World Wide Web and retrieve pages, through just a computer program.</text>
      <text start="351" dur="5">It then sorts these pages into a big database inside the crawler</text>
      <text start="356" dur="5">and also analyzes developments of each page to any possible query.</text>
      <text start="361" dur="3">When you then come and issue a query,</text>
      <text start="364" dur="4">the AI system is able to give you a response--</text>
      <text start="368" dur="4">for example, a collection of 10 best Web links.</text>
      <text start="372" dur="3">In short, every time you try to write a piece of software,</text>
      <text start="375" dur="3">that makes your computer software smart</text>
      <text start="378" dur="2">likely you will need artificial intelligence.</text>
      <text start="380" dur="3">And in this class, Peter and I will teach you</text>
      <text start="383" dur="2">many of the basic tricks of the trade</text>
      <text start="385" dur="3">to make your software really smart.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 4 Terminology" id="5lcLmhsmBnQ">
    <transcript>
      <text start="0" dur="4">It will be good to introduce some basic terminology</text>
      <text start="4" dur="5">that is commonly used in artificial intelligence to distinguish different types of problems.</text>
      <text start="9" dur="7">The very first word I will teach you is  fully versus partially observable.</text>
      <text start="16" dur="3">An environment is called fully observable if what your agent can sense</text>
      <text start="19" dur="7">at any point in time is completely sufficient to make the optimal decision.</text>
      <text start="26" dur="3">So, for example, in many card games,</text>
      <text start="29" dur="7">when all the cards are on the table, the momentary site of all those cards</text>
      <text start="36" dur="4">is really sufficient to make the optimal choice.</text>
      <text start="40" dur="6">That is in contrast to some other environments where you need memory</text>
      <text start="46" dur="4">on the side of the agent to make the best possible decision.</text>
      <text start="50" dur="5">For example, in the game of poker, the cards aren&amp;#39;t openly on the table,</text>
      <text start="55" dur="5">and memorizing past moves will help you make a better decision.</text>
      <text start="60" dur="4">To fully understand the difference, consider the interaction of an agent</text>
      <text start="64" dur="4">with the environment to its sensors and its actuators,</text>
      <text start="68" dur="3">and this interaction takes place over many cycles,</text>
      <text start="71" dur="5">often called the perception-action cycle.</text>
      <text start="76" dur="3">For many environments, it&amp;#39;s convenient to assume</text>
      <text start="79" dur="3">that the environment has some sort of internal state.</text>
      <text start="82" dur="6">For example, in a card game where the cards are not openly on the table,</text>
      <text start="88" dur="5">the state might pertain to the cards in your hand.</text>
      <text start="93" dur="4">An environment is fully observable if the sensors can always see</text>
      <text start="97" dur="4">the entire state of the environment.</text>
      <text start="101" dur="5">It&amp;#39;s partially observable if the sensors can only see a fraction of the state,</text>
      <text start="106" dur="6">yet memorizing past measurements gives us additional information of the state</text>
      <text start="112" dur="3">that is not readily observable right now.</text>
      <text start="115" dur="6">So any game, for example, where past moves have information about</text>
      <text start="121" dur="5">what might be in a person&amp;#39;s hand, those games are partially observable,</text>
      <text start="126" dur="2">and they require different treatment.</text>
      <text start="128" dur="4">Very often agents that deal with partially observable environments</text>
      <text start="132" dur="3">need to acquire internal memory to understand what</text>
      <text start="135" dur="3">the state of the environment is, and we&amp;#39;ll talk extensively</text>
      <text start="138" dur="3">when we talk about hidden Markov models about how this structure</text>
      <text start="141" dur="2">has such internal memory.</text>
      <text start="143" dur="3">A second terminology for environments pertains to whether the environment</text>
      <text start="146" dur="3">is deterministic or stochastic.</text>
      <text start="149" dur="6">Deterministic environment is one where your agent&amp;#39;s actions</text>
      <text start="155" dur="2">uniquely determine the outcome.</text>
      <text start="157" dur="5">So, for example, in chess, there&amp;#39;s really no randomness when you move a piece.</text>
      <text start="162" dur="4">The effect of moving a piece is completely predetermined,</text>
      <text start="166" dur="4">and no matter where I&amp;#39;m going to move the same piece, the outcome is the same.</text>
      <text start="170" dur="2">That we call deterministic.</text>
      <text start="172" dur="4">Games with dice, for example, like backgammon, are stochastic.</text>
      <text start="176" dur="4">While you can still deterministically move your pieces,</text>
      <text start="180" dur="3">the outcome of an action also involves throwing of the dice,</text>
      <text start="183" dur="2">and  you can&amp;#39;t predict those.</text>
      <text start="185" dur="3">There&amp;#39;s a certain amount of randomness involved for the outcome of dice,</text>
      <text start="188" dur="2">and therefore, we call this stochastic.</text>
      <text start="190" dur="4">Let me talk about discrete versus continuous.</text>
      <text start="194" dur="4">A discrete environment is one where you have finitely many action choices,</text>
      <text start="198" dur="3">and finitely many things you can sense.</text>
      <text start="201" dur="4">So, for example, in chess, again, there&amp;#39;s finitely many board positions,</text>
      <text start="205" dur="3">and finitely many things you can do.</text>
      <text start="208" dur="2">That is different from a continuous environment</text>
      <text start="210" dur="5">where the space of possible actions or things you could sense may be infinite.</text>
      <text start="215" dur="6">So, for example, if you throw darts, there&amp;#39;s infinitely many ways to angle the darts</text>
      <text start="221" dur="2">and to accelerate them.</text>
      <text start="223" dur="6">Finally, we distinguish benign versus adversarial environments.</text>
      <text start="229" dur="4">In benign environments, the environment might be random.</text>
      <text start="233" dur="4">It might be stochastic, but it has no objective on its own</text>
      <text start="237" dur="2">that would contradict the own objective.</text>
      <text start="239" dur="3">So, for example, weather is benign.</text>
      <text start="242" dur="4">It might be random. It might affect the outcome of your actions.</text>
      <text start="246" dur="2">But it isn&amp;#39;t really out there to get you.</text>
      <text start="248" dur="6">Contrast this with adversarial environments, such as many games, like chess,</text>
      <text start="254" dur="2">where your opponent is really out there to get you.</text>
      <text start="256" dur="5">It turns out it&amp;#39;s much harder to find good actions in adversarial environments</text>
      <text start="261" dur="5">where the opponent actively observes you and counteracts what you&amp;#39;re trying to achieve</text>
      <text start="266" dur="4">relative to benign environment, where the environment might merely be stochastic</text>
      <text start="270" dur="5">but isn&amp;#39;t really interested in making your life worse.</text>
      <text start="275" dur="3">So, let&amp;#39;s see to what extent these expressions make sense to you</text>
      <text start="278" dur="2">by going to our next quiz.</text>
      <text start="280" dur="5">So here are the 4 concepts again: partially observable versus fully,</text>
      <text start="285" dur="5">stochastic versus deterministic, continuous versus discrete,</text>
      <text start="290" dur="2">adversarial versus benign.</text>
      <text start="292" dur="4">And let me ask you about the game of checkers.</text>
      <text start="296" dur="4">Check one or all of those attributes that apply.</text>
      <text start="300" dur="3">So, if you think checkers is partially observable, check this one.</text>
      <text start="303" dur="2">Otherwise, just don&amp;#39;t check it.</text>
      <text start="305" dur="2">If you think it&amp;#39;s stochastic, check this one,</text>
      <text start="307" dur="4">continuous, check this one, adversarial, check this one.</text>
      <text start="311" dur="4">If you don&amp;#39;t know about checkers, you can check the Web and Google it</text>
      <text start="315" dur="2">to find a little more information about checkers.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 5 Checkers Answer" id="qVppDRbx2kM">
    <transcript>
      <text start="0" dur="4">So, checkers is an interesting game.</text>
      <text start="4" dur="4">Here&amp;#39;s the typical board of the game of checkers.</text>
      <text start="8" dur="3">Your pieces might look like this,</text>
      <text start="11" dur="5">and your opponent&amp;#39;s pieces might look like this.</text>
      <text start="16" dur="3">And apart from some very cryptic rules in checkers,</text>
      <text start="19" dur="4">which I won&amp;#39;t really discuss here, the board basically tells you</text>
      <text start="23" dur="5">everything there is to know about checkers, so it&amp;#39;s clearly fully observable.</text>
      <text start="28" dur="5">It is deterministic because your move and your opponent&amp;#39;s move</text>
      <text start="33" dur="3">very clearly affect the state of the board in ways that have</text>
      <text start="36" dur="3">absolutely no stochasticity.</text>
      <text start="39" dur="6">It is also discrete because there&amp;#39;s finitely many action choices</text>
      <text start="45" dur="2">and finitely many board positions,</text>
      <text start="47" dur="5">and obviously, it is adversarial, since your opponent is out to get you.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 6 Poker" id="M_AdFAazf4k">
    <transcript>
      <text start="0" dur="6">[Male narrator] The game of poker--is this partially observable, stochastic,</text>
      <text start="6" dur="3">continuous, or adversarial?</text>
      <text start="9" dur="3">Please check any or all of those that apply.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 7 Poker Answer" id="DjILhASM3A8">
    <transcript>
      <text start="0" dur="3">[Male narrator] I would argue poker is partially observable</text>
      <text start="3" dur="5">because it can&amp;#39;t be seen what is in your opponent&amp;#39;s hands.</text>
      <text start="8" dur="5">It is stochastic because you&amp;#39;re being dealt cards that are kind of coming at random.</text>
      <text start="13" dur="3">It is not continuous; it&amp;#39;s just finding many cards</text>
      <text start="16" dur="4">and finding many actions you can do, even though you might argue</text>
      <text start="20" dur="4">that there&amp;#39;s a huge number of different monies you can bet.</text>
      <text start="24" dur="3">It&amp;#39;s still finite, and it is clearly adversarial.</text>
      <text start="27" dur="3">If you&amp;#39;ve ever played poker before, you know how brutal it can be.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 8 Robotic Car" id="vz-ERydsKLU">
    <transcript>
      <text start="0" dur="4">[Male narrator] --a favorite, a robotic car.</text>
      <text start="4" dur="2">I wish to know whether it is partially observable,</text>
      <text start="6" dur="5">stochastic, continuous, or adversarial.</text>
      <text start="11" dur="5">That is, is the problem of driving robotically--</text>
      <text start="16" dur="4">say, in a city--subject to any of those 4 categories?</text>
      <text start="20" dur="2">Please check any or all that might apply.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 9 Robotic Car Answer" id="nOWCfVG0xNQ">
    <transcript>
      <text start="0" dur="4">Well, the robotic car clearly deals with a partially observable environment</text>
      <text start="4" dur="6">if you just look at momentary sensing input, you can&amp;#39;t even tell how fast other cars are going.</text>
      <text start="10" dur="2">So, you need to memorize something.</text>
      <text start="12" dur="3">It is stochastic because it&amp;#39;s inherently unpredictable</text>
      <text start="15" dur="2">what&amp;#39;s going to happen next with other cars.</text>
      <text start="17" dur="3">It is continuous.</text>
      <text start="20" dur="3">There&amp;#39;s the infinitely many ways to set your steering</text>
      <text start="23" dur="3">or push your gas pedal or your brake,</text>
      <text start="26" dur="3">and, well, you can argue with adversarial or not.</text>
      <text start="29" dur="2">Depending on where you live, it might be highly adversarial.</text>
      <text start="31" dur="2">Where I live, it isn&amp;#39;t.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 10 AI and Uncertainty" id="ytw6_8a5Wls">
    <transcript>
      <text start="0" dur="3">I&amp;#39;m going to briefly talk of AI as something else,</text>
      <text start="3" dur="7">which is AI is the technique of uncertainty management in computer software.</text>
      <text start="10" dur="7">Put differently, AI is the discipline that you apply when you want to know what to do</text>
      <text start="17" dur="5">when you don&amp;#39;t know what to do.</text>
      <text start="22" dur="5">Now, there&amp;#39;s many reasons why there might be uncertainty in a computer program.</text>
      <text start="27" dur="2">There could be a sensor limit.</text>
      <text start="29" dur="4">That is, your sensors are unable to tell me</text>
      <text start="33" dur="4">what exactly is the case outside the AI system.</text>
      <text start="37" dur="4">There could be adversaries who act in a way that makes it hard for  you</text>
      <text start="41" dur="3">to understand what is the case.</text>
      <text start="44" dur="4">There could be stochastic environments.</text>
      <text start="48" dur="3">Every time you roll the dice in a dice game,</text>
      <text start="51" dur="4">the stochasticity of the dice will make it impossible for you</text>
      <text start="55" dur="2">to be absolutely certain of what&amp;#39;s the situation.</text>
      <text start="57" dur="3">There could be laziness.</text>
      <text start="60" dur="4">So perhaps you can actually compute what the situation is,</text>
      <text start="64" dur="3">but your computer program is just too lazy to do it.</text>
      <text start="67" dur="4">And here&amp;#39;s my favorite: ignorance, plain ignorance.</text>
      <text start="71" dur="3">Many people are just ignorant of what&amp;#39;s going on.</text>
      <text start="74" dur="3">They could know it, but they just don&amp;#39;t care.</text>
      <text start="77" dur="4">All of these things are cause for uncertainty.</text>
      <text start="81" dur="7">AI is the discipline that deals with uncertainty and manages it in decision making.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 11 Examples of AI in Practice" id="sPSN0aI0PgE">
    <transcript>
      <text start="0" dur="3">Now we&amp;#39;ve had an introduction to AI.</text>
      <text start="3" dur="3">We&amp;#39;ve heard about some of the properties of environments,</text>
      <text start="6" dur="4">and we&amp;#39;ve seen some possible architecture for agents.</text>
      <text start="10" dur="3">I&amp;#39;d like next to show you some examples of AI in practice.</text>
      <text start="13" dur="5">And Sebastian and I have some experience personally in things we have done</text>
      <text start="18" dur="3">at Google, at NASA, and at Stanford.</text>
      <text start="21" dur="4">And I want to tell you a little bit about some of those.</text>
      <text start="25" dur="3">One of the best successes of AI technology at Google</text>
      <text start="28" dur="3">has been the machine translation system.</text>
      <text start="31" dur="6">Here we see an example of an article in Italian automatically translated into English.</text>
      <text start="37" dur="4">Now, these systems are built for 50 different languages,</text>
      <text start="41" dur="5">and we can translate from any of the languages into any of the other languages.</text>
      <text start="46" dur="5">So, that&amp;#39;s over 2,500 different systems, and we&amp;#39;ve done this all</text>
      <text start="51" dur="4">using machine learning techniques, using AI techniques,</text>
      <text start="55" dur="3">rather than trying to build them by hand.</text>
      <text start="58" dur="5">And the way it works is that we go out and collect examples of text</text>
      <text start="63" dur="3">that&amp;#39;s a line between the 2 languages.</text>
      <text start="66" dur="5">So we find, say, a newspaper that publishes 2 editions,</text>
      <text start="71" dur="5">an Italian edition and an English edition, and now we have examples of translations.</text>
      <text start="76" dur="6">And if anybody ever asked us for exactly the translation of this one particular article,</text>
      <text start="82" dur="3">then we could just look it up and say &amp;quot;We already know that.&amp;quot;</text>
      <text start="85" dur="2">But of course, we aren&amp;#39;t often going to be asked that.</text>
      <text start="87" dur="3">Rather, we&amp;#39;re going to be asked parts of this.</text>
      <text start="90" dur="4">Here are some words that we&amp;#39;ve seen before, and we have to figure out</text>
      <text start="94" dur="6">which words in this article correspond to which words in the translation article.</text>
      <text start="100" dur="5">And when we do that by examining many, many millions of words of text</text>
      <text start="105" dur="4">in the 2 languages and making the correspondence,</text>
      <text start="109" dur="2">and then we can put that all together.</text>
      <text start="111" dur="3">And then when we see a new example of text that we haven&amp;#39;t seen before,</text>
      <text start="114" dur="4">we can just look up what we&amp;#39;ve seen in the past for that correspondence.</text>
      <text start="118" dur="3">So, the task is really two parts.</text>
      <text start="121" dur="4">Off-line, before we see an example of text we want to translate,</text>
      <text start="125" dur="2">we first build our translation model.</text>
      <text start="127" dur="3">We do that by examining all of the different examples</text>
      <text start="130" dur="4">and figuring out which part aligns to which.</text>
      <text start="134" dur="4">Now, when we&amp;#39;re given a text to translate, we use that model,</text>
      <text start="138" dur="4">and we go through and find the most probable translation.</text>
      <text start="142" dur="2">So, what does it look like?</text>
      <text start="144" dur="2">Well, let&amp;#39;s look at it in some example text.</text>
      <text start="146" dur="3">And rather than look at news articles, I&amp;#39;m going to look at something simpler.</text>
      <text start="149" dur="6">I&amp;#39;m going to switch from Italian to Chinese.</text>
      <text start="155" dur="2">Here&amp;#39;s a bilingual text.</text>
      <text start="157" dur="4">Now, for a large-scale machine translation, examples are found on the Web.</text>
      <text start="161" dur="5">This example was found in a Chinese restaurant by Adam Lopez.</text>
      <text start="166" dur="3">Now, it&amp;#39;s given, for a text of this form,</text>
      <text start="169" dur="6">that a line in Chinese corresponds to a line in English,</text>
      <text start="175" dur="4">and that&amp;#39;s true for each of the individual lines.</text>
      <text start="179" dur="3">But to learn from this text, what we really want to discover</text>
      <text start="182" dur="5">is what individual words in Chinese correspond to individual words</text>
      <text start="187" dur="2">or small phrases in English.</text>
      <text start="189" dur="7">I&amp;#39;ve started that process by highlighting  the word &amp;quot;wonton&amp;quot; in English.</text>
      <text start="196" dur="2">It appears 3 times throughout the text.</text>
      <text start="198" dur="5">Now, in each of those lines, there&amp;#39;s a character that appears,</text>
      <text start="203" dur="4">and that&amp;#39;s the only place in the Chinese text where that character appears.</text>
      <text start="207" dur="6">So, that seems like it&amp;#39;s a high probability that this character in Chinese</text>
      <text start="213" dur="3">corresponds to the word &amp;quot;wonton&amp;quot; in English.</text>
      <text start="216" dur="2">Let&amp;#39;s see if we can go farther.</text>
      <text start="218" dur="6">My question for you is what word or what character or characters in Chinese</text>
      <text start="224" dur="3">correspond to the word &amp;quot;chicken&amp;quot; in English?</text>
      <text start="227" dur="7">And here we see &amp;quot;chicken&amp;quot; appears in these locations.</text>
      <text start="234" dur="6">Click on the character or characters in Chinese that corresponds to &amp;quot;chicken.&amp;quot;</text>
    </transcript>
  </video>
  <video title="Unit 1w, 12 Chinese Translation Answer" id="RWhwKudtixY">
    <transcript>
      <text start="1" dur="3">The answer is that chicken appears here,</text>
      <text start="4" dur="6">here, here, and here.</text>
      <text start="10" dur="4">Now, I don&amp;#39;t know for sure, 100%, that that is the character for chicken in Chinese,</text>
      <text start="14" dur="3">but I do know that there is a good correspondence.</text>
      <text start="17" dur="3">Every place the word chicken appears in English,</text>
      <text start="20" dur="4">this character appears in Chinese and no other place.</text>
      <text start="24" dur="3">Let&amp;#39;s go 1 step farther.</text>
      <text start="27" dur="3">Let&amp;#39;s see if we can work out a phrase in Chinese</text>
      <text start="30" dur="3">and see if it corresponds to a phrase in English.</text>
      <text start="33" dur="4">Here&amp;#39;s the phrase corn cream.</text>
      <text start="38" dur="6">Click on the characters in Chinese that correspond to corn cream.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 13 Chinese Translation Answer 2" id="vvyaXxjsxBU">
    <transcript>
      <text start="0" dur="4">The answer is: these 2 characters here</text>
      <text start="4" dur="3">appear only in these 2 locations</text>
      <text start="7" dur="3">corresponding to the words corn cream</text>
      <text start="10" dur="3">which appear only in these locations in the English text.</text>
      <text start="13" dur="4">Again, we&amp;#39;re not 100% sure that&amp;#39;s the right answer,</text>
      <text start="17" dur="3">but it looks like a strong correlation.</text>
      <text start="20" dur="2">Now, 1 more question.</text>
      <text start="22" dur="4">Tell me what character or characters in Chinese</text>
      <text start="26" dur="3">correspond to the English word soup.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 14 Chinese Translation Answer 3" id="lFJey0tOvBg">
    <transcript>
      <text start="0" dur="5">The answer is that soup occurs in most of these phrases</text>
      <text start="9" dur="2">but not 100% of them.</text>
      <text start="11" dur="2">It&amp;#39;s missing in this phrase.</text>
      <text start="14" dur="3">Equivalently, on the Chinese side</text>
      <text start="17" dur="3">we see this character occurs</text>
      <text start="20" dur="3">in most of the phrases,</text>
      <text start="23" dur="4">but it&amp;#39;s missing here.</text>
      <text start="27" dur="4">So we see that the correspondence doesn&amp;#39;t have to be 100%</text>
      <text start="31" dur="3">to tell us that there is still a good chance of a correlation.</text>
      <text start="34" dur="3">When we&amp;#39;re learning to do machine translation</text>
      <text start="37" dur="4">we use these kinds of alignments to learn probability tables</text>
      <text start="41" dur="4">of what is the probability of one phrase in one language</text>
      <text start="45" dur="3">corresponding to the phrase in another language.</text>
    </transcript>
  </video>
  <video title="Unit 1w, 15 Congratulations" id="mXM38kjzK-M">
    <transcript>
      <text start="0" dur="3">So congratulations, you just finished unit 1.</text>
      <text start="3" dur="4">You just finished unit 1 of this class,</text>
      <text start="7" dur="3">where I told you about key applications</text>
      <text start="10" dur="3">of artificial intelligence,</text>
      <text start="13" dur="5">I told you about the definition of an intelligent agent,</text>
      <text start="18" dur="5">I gave you 4 key attributes of intelligent agents</text>
      <text start="24" dur="6">(partial observability, stochasticity, continuous spaces, and adversarial natures),</text>
      <text start="31" dur="3">I discussed sources and management of uncertainty,</text>
      <text start="34" dur="6">and I briefly mentioned the mathematical concept of rationality.</text>
      <text start="40" dur="5">Obviously, I only touched any of these issues superficially,</text>
      <text start="45" dur="4">but as this class goes on you&amp;#39;re going to dive into any of those</text>
      <text start="49" dur="2">and learn much more about</text>
      <text start="51" dur="4">what it takes to make a truly intelligent AI system.</text>
      <text start="55" dur="1">Thank you.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 1, Introduction" id="ZQmJuHtpGfs">
    <transcript>
      <text start="0" dur="1">[PROBLEM SOLVING]</text>
      <text start="1" dur="3">In this unit we&amp;#39;re going to talk about problem solving.</text>
      <text start="4" dur="2">The theory and technology of building agents</text>
      <text start="6" dur="4">that can plan ahead to solve problems.</text>
      <text start="10" dur="3">In particular, we&amp;#39;re talking about problem solving</text>
      <text start="13" dur="4">where the complexity of the problem comes from the idea that there are many states.</text>
      <text start="17" dur="2">As in this problem here.</text>
      <text start="19" dur="5">A navigation problem where there are many choices to start with.</text>
      <text start="24" dur="5">And the complexity comes from picking the right choice now and picking the right choice at the</text>
      <text start="29" dur="3">next intersection and the intersection after that.</text>
      <text start="32" dur="3">Streaming together a sequence of actions.</text>
      <text start="35" dur="4">This is in contrast to the type of complexity shown in this picture,</text>
      <text start="39" dur="4">where the complexity comes from the partial observability</text>
      <text start="43" dur="3">that we can&amp;#39;t see through the fog where the possible paths are.</text>
      <text start="46" dur="2">We can&amp;#39;t see the results of our actions</text>
      <text start="48" dur="3">and even the actions themselves are not known.</text>
      <text start="51" dur="5">This type of complexity will be covered in a later unit.</text>
      <text start="56" dur="2">Here&amp;#39;s an example of a problem.</text>
      <text start="58" dur="5">This is a route-finding problem where we&amp;#39;re given a start city,</text>
      <text start="63" dur="6">in this case, Arad, and a destination, Bucharest, the capital of Romania,</text>
      <text start="69" dur="2">from which this is a corner of the map.</text>
      <text start="71" dur="5">And the problem then is to find a route from Arad to Bucharest.</text>
      <text start="76" dur="4">The actions that the agent can execute when driving</text>
      <text start="80" dur="3">from one city to the next along one of the roads shown on the map.</text>
      <text start="83" dur="5">The question is, is there a solution that the agent can come up with</text>
      <text start="88" dur="6">given the knowledge shown here to the problem of driving from Arad to Bucharest?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 2, Route Finding Question" id="SIHc9LgMeaU">
    <transcript>
      <text start="0" dur="3">And the answer is no.</text>
      <text start="3" dur="3">There is no solution that the agent can come up with</text>
      <text start="6" dur="2">because Bucharest doesn&amp;#39;t appear on the map,</text>
      <text start="8" dur="4">and so the agent doesn&amp;#39;t know any actions that can arrive there.</text>
      <text start="12" dur="7">So let&amp;#39;s give the agent a better chance.</text>
      <text start="19" dur="4">Now we&amp;#39;ve given the agent the full map of Romania.</text>
      <text start="23" dur="7">To start, he&amp;#39;s in Arad, and the destination--or goal--is in Bucharest.</text>
      <text start="30" dur="5">And the agent is given the problem of coming up with a sequence of actions</text>
      <text start="35" dur="2">that will arrive at the destination.</text>
      <text start="37" dur="6">Now, is it possible for the agent to solve this problem?</text>
      <text start="43" dur="2">And the answer is yes.</text>
      <text start="45" dur="5">There are many routes or steps or sequences of actions that will arrive at the destination.</text>
      <text start="50" dur="3">Here is one of them:</text>
      <text start="53" dur="7">Starting out in Arad, taking this step first, then this one, then this one,</text>
      <text start="60" dur="5">then this one, and then this one to arrive at the destination.</text>
      <text start="65" dur="3">So that would count as a solution to the problem.</text>
      <text start="68" dur="4">So sequence of actions, chained together, that are guaranteed to get us to the goal.</text>
      <text start="72" dur="2">[DEFINITION OF A PROBLEM]</text>
      <text start="74" dur="3">Now let&amp;#39;s formally define what a problem looks like.</text>
      <text start="77" dur="4">A problem can be broken down into a number of components.</text>
      <text start="81" dur="4">First, the initial state that the agent starts out with.</text>
      <text start="85" dur="7">In our route finding problem, the initial state was the agent being in the city of Arad.</text>
      <text start="92" dur="9">Next, a function--Actions--that takes a state as input and returns</text>
      <text start="101" dur="6">a set of possible actions that the agent can execute when the agent is in this state.</text>
      <text start="107" dur="3">[ACTIONS (s)     {a,a2,a3...}]</text>
      <text start="110" dur="4">In some problems, the agent will have the same actions available in all states</text>
      <text start="114" dur="4">and in other problems, he&amp;#39;ll have different actions dependent on the state.</text>
      <text start="118" dur="4">In the route finding problem, the actions are dependent on the state.</text>
      <text start="122" dur="4">When we&amp;#39;re in one city, we can take the routes to the neighboring cities--</text>
      <text start="126" dur="3">but we can&amp;#39;t go to any other cities.</text>
      <text start="129" dur="11">Next we have a function called Result, which takes, as input, a state and an action</text>
      <text start="140" dur="4">and delivers, as its output, a new state.</text>
      <text start="144" dur="9">So, for example, if the agent is in the city of Arad, and takes--that would be the state--</text>
      <text start="153" dur="7">and takes the action of driving along Route E-671 towards Timisoara,</text>
      <text start="160" dur="5">then the result of applying that action in that state would be the new state--</text>
      <text start="165" dur="6">where the agent is in the city of Timisoara.</text>
      <text start="171" dur="7">Next, we need a function called Goal Test,</text>
      <text start="178" dur="6">which takes a state and returns a Boolean value--</text>
      <text start="184" dur="5">true or false--telling us if this state is a goal or not.</text>
      <text start="189" dur="5">In a route-finding problem, the only goal would be being in the destination city--</text>
      <text start="194" dur="5">the city of Bucharest--and all the other states would return false for the Goal Test.</text>
      <text start="199" dur="9">And finally, we need one more thing which is a Path Cost function--</text>
      <text start="208" dur="12">which takes a path, a sequence of state/action transitions,</text>
      <text start="220" dur="4">and returns a number, which is the cost of that path.</text>
      <text start="224" dur="6">Now, for most of the problems we&amp;#39;ll deal with, we&amp;#39;ll make the Path Cost function be additive</text>
      <text start="230" dur="6">so that the cost of the path is just the sum of the costs of the individual steps.</text>
      <text start="236" dur="8">And so we&amp;#39;ll implement this Path Cost function, in terms of a Step Cost function.</text>
      <text start="244" dur="10">The Step Cost function takes a state, an action, and the resulting state from that action</text>
      <text start="254" dur="4">and returns a number--n--which is the cost of that action.</text>
      <text start="258" dur="6">In the route finding example, the cost might be the number of miles traveled</text>
      <text start="264" dur="5">or maybe the number of minutes it takes to get to that destination.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 3, Route Finding" id="bEi73QXP7PA">
    <transcript>
      <text start="0" dur="6">Now lets see how the definition of a problem</text>
      <text start="6" dur="4">maps onto the route finding, the domain.</text>
      <text start="10" dur="2">First, the initial state was given.</text>
      <text start="12" dur="3">Lets say we start off in Arad,</text>
      <text start="15" dur="2">and the goal test,</text>
      <text start="17" dur="5">lets say that the state of being in Bucharest</text>
      <text start="22" dur="2">is the only state that counts as a goal,</text>
      <text start="24" dur="2">and all the other states are not goals.</text>
      <text start="26" dur="3">Now the set of all of the states here</text>
      <text start="29" dur="2">is known as the state space,</text>
      <text start="31" dur="4">and we navigate the state space by applying actions.</text>
      <text start="35" dur="4">The actions are specific to each city,</text>
      <text start="39" dur="3">so when we are in Arad, there are three possible actions,</text>
      <text start="42" dur="4">to follow this road, this one, or this one.</text>
      <text start="46" dur="3">And as we follow them, we build paths</text>
      <text start="49" dur="2">or sequences of actions.</text>
      <text start="51" dur="4">So just being in Arad is the path of length zero,</text>
      <text start="55" dur="3">and now we could start exploring the space</text>
      <text start="58" dur="3">and add in this path of length one,</text>
      <text start="61" dur="2">this path of length one,</text>
      <text start="63" dur="3">and this path of length one.</text>
      <text start="66" dur="5">We could add in another path here of length two</text>
      <text start="71" dur="3">and another path here of length two.</text>
      <text start="74" dur="3">Here is another path of length two.</text>
      <text start="77" dur="4">Here is a path of length three.</text>
      <text start="81" dur="5">Another path of length two, and so on.</text>
      <text start="86" dur="2">Now at ever point,</text>
      <text start="88" dur="6">we want to separate the state out into three parts.</text>
      <text start="94" dur="3">First, the ends of the paths</text>
      <text start="97" dur="3">The farthest paths that have been explored,</text>
      <text start="100" dur="2">we call the frontier.</text>
      <text start="102" dur="4">And so the frontier in this case</text>
      <text start="106" dur="5">consists of these states</text>
      <text start="111" dur="4">that are the farthest out we have explored.</text>
      <text start="115" dur="4">And then to the left of that in this diagram,</text>
      <text start="119" dur="3">we have the explored part of the state.</text>
      <text start="122" dur="2">And then off to the rigtht,</text>
      <text start="124" dur="2">we have the unexplored.</text>
      <text start="126" dur="3">So lets write down those three components.</text>
      <text start="129" dur="6">We have the frontier.</text>
      <text start="135" dur="5">We have the unexplored region,</text>
      <text start="140" dur="5">and we have the explored region.</text>
      <text start="145" dur="2">One more thing,</text>
      <text start="147" dur="3">in this diagram we have labeled the step cost</text>
      <text start="150" dur="3">of each action along the route.</text>
      <text start="153" dur="4">So the step cost of going between Neamt to Iasi</text>
      <text start="157" dur="5">would be 87 corresponding to a distance of 87 kilometers,</text>
      <text start="162" dur="4">and the path cost is just the sum of the step costs.</text>
      <text start="166" dur="2">So the cost of the path</text>
      <text start="168" dur="2">of going from Arad to Oradea</text>
      <text start="170" dur="5">would be 71 plus 75.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 4, Tree Search" id="c0PfWsqtfdo">
    <transcript>
      <text start="0" dur="4">[Narrator] Now let&amp;#39;s define a function for solving problems.</text>
      <text start="4" dur="3">It&amp;#39;s called Tree Search because it superimposes</text>
      <text start="7" dur="3">a search tree over the state space.</text>
      <text start="10" dur="2">Here&amp;#39;s how it works: It starts off by</text>
      <text start="12" dur="2">initializing the frontier to be the path</text>
      <text start="14" dur="2">consisting of only the initial states,</text>
      <text start="16" dur="2">and then it goes into a loop</text>
      <text start="18" dur="3">in which it first checks to see</text>
      <text start="21" dur="2">do we still have anything left in the frontier?</text>
      <text start="23" dur="2">If not we fail, there can be no solution.</text>
      <text start="25" dur="3">If we do have something, then we make a choice.</text>
      <text start="28" dur="3">Tree Search is really a family of functions</text>
      <text start="31" dur="2">not a single algorithm which</text>
      <text start="33" dur="2">depends on how we make that choice,</text>
      <text start="35" dur="3">and we&amp;#39;ll see some of the options later.</text>
      <text start="38" dur="3">If we go ahead and make a choice of one of</text>
      <text start="41" dur="2">the paths on the frontier and remove that</text>
      <text start="43" dur="2">path from the frontier, we find the state</text>
      <text start="45" dur="2">which is at the end of the path, and if that</text>
      <text start="47" dur="2">state&amp;#39;s a go then we&amp;#39;re done.</text>
      <text start="49" dur="2">We found a path to the goal; otherwise,</text>
      <text start="51" dur="3">we do what&amp;#39;s called expanding that path.</text>
      <text start="54" dur="3">We look at all the actions from that state,</text>
      <text start="57" dur="3">and we add to the path the actions</text>
      <text start="60" dur="3">and the result of that state; so we get</text>
      <text start="63" dur="3">a new path that has the old path, the action</text>
      <text start="66" dur="3">and the result of that action, and we</text>
      <text start="69" dur="4">stick all of those paths back onto the frontier.</text>
      <text start="77" dur="2">Now Tree Search represents a whole family</text>
      <text start="79" dur="3">of algorithms, and where you get the family</text>
      <text start="82" dur="2">resemblance is that they&amp;#39;re all looking</text>
      <text start="84" dur="2">at the frontier, copying items off and</text>
      <text start="86" dur="3">and looking to see if their goal tests,</text>
      <text start="89" dur="2">but where you get the difference is right here,</text>
      <text start="91" dur="3">in the choice of how you&amp;#39;re going to expand</text>
      <text start="94" dur="2">the next item on the frontier, which</text>
      <text start="96" dur="3">path do we look at first, and we&amp;#39;ll go through</text>
      <text start="99" dur="3">different sets of algorithms that make</text>
      <text start="102" dur="3">different choices for which path to look at first.</text>
      <text start="107" dur="2">The first algorithm I want to consider</text>
      <text start="109" dur="2">is called Breadth-First Search.</text>
      <text start="111" dur="3">Now it could be called shortest-first search</text>
      <text start="114" dur="2">because what it does is always choose</text>
      <text start="116" dur="3">of the frontier one of the paths that hadn&amp;#39;t been</text>
      <text start="119" dur="3">considered yet that&amp;#39;s the shortest possible.</text>
      <text start="122" dur="2">So how does it work?</text>
      <text start="124" dur="2">Well we start off with the path of</text>
      <text start="126" dur="4">length 0, starting in the start state, and</text>
      <text start="130" dur="3">that&amp;#39;s the only path in the frontier so</text>
      <text start="133" dur="2">it&amp;#39;s the shortest one so we pick it,</text>
      <text start="135" dur="2">and then we expand it, and we add in</text>
      <text start="137" dur="3">all the paths that result from</text>
      <text start="140" dur="2">applying all the possible actions.</text>
      <text start="142" dur="3">So now we&amp;#39;ve removed</text>
      <text start="145" dur="3">this path from the frontier,</text>
      <text start="148" dur="3">but we&amp;#39;ve added in 3 new paths.</text>
      <text start="151" dur="2">This one,</text>
      <text start="153" dur="4">this one, and this one.</text>
      <text start="157" dur="2">Now we&amp;#39;re in a position where</text>
      <text start="159" dur="3">we have 3 paths on the frontier, and</text>
      <text start="162" dur="3">we have to pick the shortest one.</text>
      <text start="165" dur="2">Now in this case all 3 paths</text>
      <text start="167" dur="3">have the same length, length 1, so we</text>
      <text start="170" dur="2">break the tie at random or using some</text>
      <text start="172" dur="4">other technique, and let&amp;#39;s suppose that</text>
      <text start="176" dur="2">in this case we choose this path</text>
      <text start="178" dur="2">from Arad to Sibiu.</text>
      <text start="180" dur="3">Now the question I want you to answer</text>
      <text start="183" dur="6">is once we remove that from the frontier,</text>
      <text start="189" dur="2">what paths are we going to add next?</text>
      <text start="191" dur="3">So show me by checking off the cities</text>
      <text start="194" dur="2">that ends the paths, which paths</text>
      <text start="196" dur="3">are going to be added to the frontier?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 5, Tree Search Answer" id="GKKQyJLee84">
    <transcript>
      <text start="0" dur="6">[Male narrator] The answer is that in Sibiu, the action function gives us 4 actions</text>
      <text start="6" dur="3">corresponding to traveling along these 4 roads,</text>
      <text start="9" dur="6">so we have to add in paths for each of those actions.</text>
      <text start="15" dur="2">One of those paths goes here,</text>
      <text start="17" dur="4">the other path continues from Arad and goes out here.</text>
      <text start="21" dur="4">The third path continues out here</text>
      <text start="25" dur="6">and then the fourth path goes from here--from Arad to Sibiu</text>
      <text start="31" dur="5">and then backtracks back to Arad.</text>
      <text start="36" dur="5">Now, it may seem silly and redundant to have a path that starts in Arad,</text>
      <text start="41" dur="3">goes to Sibiu and returns to Arad.</text>
      <text start="44" dur="5">How can that help us get to our destination in Bucharest?</text>
      <text start="49" dur="3">But we can see if we&amp;#39;re dealing with a tree search,</text>
      <text start="52" dur="4">why it&amp;#39;s natural to have this type of formulation</text>
      <text start="56" dur="4">and why the tree search doesn&amp;#39;t even notice that it&amp;#39;s backtracked.</text>
      <text start="60" dur="5">What the tree search does is superimpose on top of the state space</text>
      <text start="65" dur="4">a tree of searches, and the tree looks like this.</text>
      <text start="69" dur="6">We start off in state A, and in state A, there were 3 actions,</text>
      <text start="75" dur="6">so we gave those paths going to Z, S, and T.</text>
      <text start="81" dur="13">And from S, there were 4 actions, so that gave us paths going from O, F, R, and A,</text>
      <text start="94" dur="3">and then the tree would continue on from here.</text>
      <text start="97" dur="3">We&amp;#39;d take one of the next items</text>
      <text start="100" dur="8">and we&amp;#39;d move it and continue on, but notice that we returned to the A state</text>
      <text start="108" dur="3">in the state space, but in the tree,</text>
      <text start="111" dur="4">it&amp;#39;s just another item in the tree.</text>
      <text start="115" dur="2">Now, here&amp;#39;s another representation of the search space</text>
      <text start="117" dur="4">and what&amp;#39;s happening is as we start to explore the state,</text>
      <text start="121" dur="8">we keep track of the frontier, which is the set of states that are at the end of the paths</text>
      <text start="129" dur="4">that we haven&amp;#39;t explored yet, and behind that frontier</text>
      <text start="133" dur="6">is the set of explored states, and ahead of the frontier is the unexplored states.</text>
      <text start="139" dur="3">Now the reason we keep track of the explored states</text>
      <text start="142" dur="5">is that when we want to expand and we find a duplicate--</text>
      <text start="147" dur="6">so say when we expand from here, if we pointed back to state T,</text>
      <text start="153" dur="9">if we hadn&amp;#39;t kept track of that, we would have to add in a new state for T down here.</text>
      <text start="162" dur="5">But because we&amp;#39;ve already seen it and we know that this is actually a regressive step</text>
      <text start="167" dur="4">into the already explored state, now, because we kept track of that,</text>
      <text start="171" dur="3">we don&amp;#39;t need it anymore.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 6, Graph Search" id="mtbfvJuOV_U">
    <transcript>
      <text start="0" dur="4">Now we see how to modify the Tree Search Function</text>
      <text start="4" dur="2">to make it be a Graph Search Function</text>
      <text start="6" dur="3">to avoid those repeated paths.</text>
      <text start="9" dur="4">What we do, is we start off and initialize a set</text>
      <text start="13" dur="3">called the explored set of states that we have already explored.</text>
      <text start="16" dur="3">Then, when we consider a new path,</text>
      <text start="19" dur="4">we add the new state to the set of already explored states,</text>
      <text start="23" dur="3">and then when we are expanding the path</text>
      <text start="26" dur="3">and adding in new states to the end of it,</text>
      <text start="29" dur="4">we dont  add that in if we have already seen that new state</text>
      <text start="33" dur="4">in either the frontier or the explored.</text>
      <text start="37" dur="2">Now back to Breadth First Search.</text>
      <text start="39" dur="2">Lets assume we are using the Graph Search</text>
      <text start="41" dur="3">so that we have eliminated the duplicate paths.</text>
      <text start="44" dur="3">Arad is crossed off the list.</text>
      <text start="47" dur="2">The path that goes from Arad to Sibiu</text>
      <text start="49" dur="2">and back to Arad is removed,</text>
      <text start="51" dur="2">and we are left with these one, two, three,</text>
      <text start="53" dur="4">four, five possible paths.</text>
      <text start="57" dur="2">Given these 5 paths,</text>
      <text start="59" dur="3">show me which ones are candidates to be expanded next</text>
      <text start="62" dur="3">by the Breadth First Search Algorithm.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 7, Graph Search Answer" id="HfYXaw56-0w">
    <transcript>
      <text start="0" dur="3">[Male narrator] And the answer is that Breadth - First Search always considers</text>
      <text start="3" dur="5">the shortest paths first, and in this case, there&amp;#39;s 2 paths of length 1,</text>
      <text start="8" dur="4">and 1, the paths from Arad to Zerind and Arad to Timisoara,</text>
      <text start="12" dur="3">so those would be the 2 paths that would be considered.</text>
      <text start="15" dur="3">Now, let&amp;#39;s suppose that the tie is broken in some way</text>
      <text start="18" dur="4">and we chose this path from Arad to Zerind.</text>
      <text start="22" dur="3">Now, we want to expand that node.</text>
      <text start="25" dur="6">We remove it from the frontier and put it in the explored list</text>
      <text start="31" dur="4">and now we say, &amp;quot;What paths are we going to add?&amp;quot;</text>
      <text start="35" dur="7">So check off the ends of the paths the cities that we&amp;#39;re going to add.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 8, Graph Search Answer" id="CUfmOLQi3RM">
    <transcript>
      <text start="0" dur="3">[Male narrator] In this case, there&amp;#39;s nothing to add</text>
      <text start="3" dur="6">because of the 2 neighbors, 1 is in the explored list and 1 is in the frontier,</text>
      <text start="9" dur="4">and if we&amp;#39;re using graph search, then we won&amp;#39;t add either of those.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 9, More Graph Search" id="I3lrnzdgwmI">
    <transcript>
      <text start="0" dur="4">[Male narrator] So we move on, we look for another shortest path.</text>
      <text start="4" dur="7">There&amp;#39;s one path left of length 1, so we look at that path, we expand it,</text>
      <text start="11" dur="5">add in this path, put that one on the explored list,</text>
      <text start="16" dur="4">and now we&amp;#39;ve got 3 paths of length 2.</text>
      <text start="20" dur="3">We choose 1 of them, and let&amp;#39;s say we choose this one.</text>
      <text start="23" dur="7">Now, my question is show me which states we add to the path</text>
      <text start="30" dur="5">and tell me whether we&amp;#39;re going to terminate the algorithm at this point</text>
      <text start="35" dur="3">because we&amp;#39;ve reached the goal or whether we&amp;#39;re going to continue.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 10, Graph Search Answer" id="cr1Ck1Fr60M">
    <transcript>
      <text start="0" dur="8">[Male narrator] The answer is that we add 1 more path, the path to Bucharest.</text>
      <text start="8" dur="3">We don&amp;#39;t add the path going back because it&amp;#39;s in the explored list,</text>
      <text start="11" dur="2">but we don&amp;#39;t terminate it yet.</text>
      <text start="13" dur="3">True, we have added a path that ends in Bucharest,</text>
      <text start="16" dur="6">but the goal test isn&amp;#39;t applied when we add a path to the frontier.</text>
      <text start="22" dur="4">Rather, it&amp;#39;s applied when we remove that path from the frontier,</text>
      <text start="26" dur="3">and we haven&amp;#39;t done that yet.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 11, Graph Search Termination" id="mueRduwpg-U">
    <transcript>
      <text start="0" dur="6">[Male narrator] Now, why doesn&amp;#39;t the general tree search or graph search algorithm stop</text>
      <text start="6" dur="3">when it adds a goal node to the frontier?</text>
      <text start="9" dur="4">The reason is because it might not be the best path to the goal.</text>
      <text start="13" dur="3">Now, here we found a path of length 2</text>
      <text start="16" dur="5">and we added a path of length 3 that reached the goal.</text>
      <text start="21" dur="3">The general graph search or tree search doesn&amp;#39;t know</text>
      <text start="24" dur="3">that there might be some other path that we could expand</text>
      <text start="27" dur="3">that would have a distance of say, 2-1/2,</text>
      <text start="30" dur="3">but there&amp;#39;s an optimization that could be made.</text>
      <text start="33" dur="2">If we know we&amp;#39;re doing Breadth - First Search</text>
      <text start="35" dur="5">and we know there&amp;#39;s no possibility of a path of length 2-1/2.</text>
      <text start="40" dur="4">Then we can change algorithm so that it checks states</text>
      <text start="44" dur="2">as soon as they&amp;#39;re added to the frontier</text>
      <text start="46" dur="3">rather than waiting until they&amp;#39;re expanded</text>
      <text start="49" dur="4">and in that case, we can write a specific Breadth - First Search routine</text>
      <text start="53" dur="8">that terminates early and gives us a result as soon as we add a goal state to the frontier.</text>
      <text start="61" dur="3">Breadth - First Search will find this path</text>
      <text start="64" dur="4">that ends up in Bucharest, and if we&amp;#39;re looking for the shortest path</text>
      <text start="68" dur="2">in terms of number of steps,</text>
      <text start="70" dur="2">Breadth - First Search is guaranteed to find it,</text>
      <text start="72" dur="5">But if we&amp;#39;re looking for the shortest path in terms of total cost</text>
      <text start="77" dur="4">by adding up the step costs, then it turns out</text>
      <text start="81" dur="5">that this path is shorter than the path found by Breadth - First Search.</text>
      <text start="86" dur="4">So let&amp;#39;s look at how we could find that path.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 12, Uniform Cost Search" id="Qrig0mznzG4">
    <transcript>
      <text start="0" dur="5">An algorithm that has traditionally been called uniform-cost search</text>
      <text start="5" dur="3">but could be called cheapest-first search,</text>
      <text start="8" dur="3">is guaranteed to find the path with the cheapest total cost.</text>
      <text start="11" dur="3">Let&amp;#39;s see how it works.</text>
      <text start="14" dur="5">We start out as before in the start state.</text>
      <text start="19" dur="5">And we pop that empty path off.</text>
      <text start="24" dur="4">Move it from the frontier to explored,</text>
      <text start="28" dur="5">and then add in the paths out of that state.</text>
      <text start="33" dur="6">As before, there will be 3 of those paths.</text>
      <text start="39" dur="4">And now, which path are we going to pick next</text>
      <text start="43" dur="8">in order to expand according to the rules of cheapest first?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 13, Uniform Cost Search" id="7MbW6kZ_vb8">
    <transcript>
      <text start="0" dur="3">Cheapest first says that we pick the path with</text>
      <text start="4" dur="2">the lowest total cost.</text>
      <text start="6" dur="1">And that would be this path.</text>
      <text start="7" dur="6">It has a cost of 75 compared to the cost of 118 and 140</text>
      <text start="13" dur="1">for the other paths.</text>
      <text start="14" dur="5">So we get here. We take that path off the frontier,</text>
      <text start="19" dur="4">put it on the explored list, add in its neighbors.</text>
      <text start="23" dur="3">Not going back to Arad,</text>
      <text start="26" dur="4">but adding in this new path.</text>
      <text start="30" dur="3">Summing up the total cost of that path,</text>
      <text start="33" dur="7">71 + 75 is 146 for this path.</text>
      <text start="40" dur="1">And now the question is,</text>
      <text start="41" dur="3">which path gets expanded next?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 14, Uniform Cost Search" id="9vNvrRP0ymw">
    <transcript>
      <text start="0" dur="5">Of the 3 paths on the frontier, we have ones</text>
      <text start="5" dur="5">with a cost of 146, 140, and 118.</text>
      <text start="10" dur="3">And that&amp;#39;s the cheapest, so this one gets expanded.</text>
      <text start="13" dur="3">We take it off the frontier, move it to explored,</text>
      <text start="16" dur="5">add in its successors. In this case it&amp;#39;s only 1.</text>
      <text start="21" dur="8">And that has a path total of 229.</text>
      <text start="29" dur="1">Which path do we expand next?</text>
      <text start="30" dur="3">Well, we&amp;#39;ve got 146, 140, and 229</text>
      <text start="33" dur="5">So 140 is the lowest.</text>
      <text start="38" dur="3">Take it off the frontier. Put it on explored.</text>
      <text start="41" dur="3">Add in this path</text>
      <text start="44" dur="4">for a total cost of 220.</text>
      <text start="48" dur="5">And this path for a total cost of 239.</text>
      <text start="53" dur="3">And now the question is, which path do we expand next?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 15, Uniform Cost Search" id="LVCMMPXaQlE">
    <transcript>
      <text start="0" dur="4">The answer is this one, 146.</text>
      <text start="4" dur="3">Put it on explored.</text>
      <text start="7" dur="5">But there&amp;#39;s nothing to add because</text>
      <text start="12" dur="1">both of its neighbors have already been explored.</text>
      <text start="13" dur="2">Which path do we look at next?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 16, Uniform Cost Termination" id="G-H1AnA8uBI">
    <transcript>
      <text start="0" dur="5">The answer is this one. Two-twenty is less than 229 or 239.</text>
      <text start="5" dur="4">Take it off the frontier. Put it on explored.</text>
      <text start="9" dur="6">Add in 2 more paths and sum them up.</text>
      <text start="15" dur="6">So, 220 plus 146 is 366.</text>
      <text start="21" dur="8">And 220 plus 97 is 317.</text>
      <text start="29" dur="3">Okay, and now, notice that we&amp;#39;re closing in on Bucharest.</text>
      <text start="32" dur="6">We&amp;#39;ve got 2 neighbors almost there, but neither of them is their turn yet.</text>
      <text start="38" dur="5">Instead, the cheapest path is this one over here,</text>
      <text start="43" dur="2">so move it to the explored list.</text>
      <text start="45" dur="5">Add 70 to the path cost so far,</text>
      <text start="50" dur="7">and we get 299.</text>
      <text start="57" dur="4">Now the cheapest node is 239 here,</text>
      <text start="61" dur="8">so we expand, finally, into Bucharest at a cost of 460.</text>
      <text start="69" dur="4">And now the question is are we done? Can we terminate the algorithm?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 17, Uniform Cost Termination Answer" id="NxCUVltVoZ8">
    <transcript>
      <text start="0" dur="3">[Male] And the answer is no, we&amp;#39;re not done yet.</text>
      <text start="3" dur="4">We&amp;#39;ve put Bucharest, the gold state, onto the frontier,</text>
      <text start="7" dur="2">but we haven&amp;#39;t popped it off the frontier yet.</text>
      <text start="9" dur="4">And the reason is because we&amp;#39;ve got to look around and see if there&amp;#39;s a better path</text>
      <text start="13" dur="2">that can reach it, Bucharest.</text>
      <text start="15" dur="3">And so, let&amp;#39;s continue.</text>
      <text start="18" dur="2">Look at everything on the frontier.</text>
      <text start="20" dur="3">Here&amp;#39;s the cheapest one over here.</text>
      <text start="23" dur="3">Expand that.</text>
      <text start="26" dur="4">Now, what&amp;#39;s the cheapest next one?</text>
      <text start="30" dur="3">Well, over here.</text>
      <text start="33" dur="3">Oops, forgot to take this one off the list.</text>
      <text start="36" dur="8">So now, we&amp;#39;re at 317 plus 101 gives us another path into Bucharest,</text>
      <text start="44" dur="2">and this is a better path.</text>
      <text start="46" dur="8">This is 418, gives us another route in.</text>
      <text start="54" dur="5">But we have to keep going.</text>
      <text start="59" dur="7">The best path on the frontier is 366,</text>
      <text start="66" dur="8">so pop that off, and that would give us 2 more routes into here,</text>
      <text start="74" dur="4">and eventually we pop off all of these.</text>
      <text start="78" dur="6">And then we get to the point where 418 was the best path on the frontier.</text>
      <text start="84" dur="5">We pop that off, and then we recognize that we&amp;#39;d reach the goal,</text>
      <text start="89" dur="6">and the reason that uniform cost finds the optimal path, the cheapest cost,</text>
      <text start="95" dur="5">is because it&amp;#39;s guaranteed that it will first pop off this cheapest path,</text>
      <text start="100" dur="6">the 418, before it gets to the more expensive path, like the 460.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 18, Depth First Search" id="Ve-mmCM8TI0">
    <transcript>
      <text start="0" dur="3">So, we&amp;#39;ve looked at 2 search algorithms.</text>
      <text start="3" dur="5">One, breadth-first search, in which we always expand first</text>
      <text start="8" dur="4">the shallowest paths, the shortest paths.</text>
      <text start="12" dur="5">Second, cheapest-first search, in which we always expand first the path</text>
      <text start="17" dur="3">with the lowest total cost.</text>
      <text start="20" dur="5">And I&amp;#39;m going to take this opportunity to introduce a third algorithm, depth-first search,</text>
      <text start="25" dur="3">which is in a way the opposite of breadth-first search.</text>
      <text start="28" dur="5">In depth-first search, we always expand first the longest path,</text>
      <text start="33" dur="3">the path with the most lengths in it.</text>
      <text start="36" dur="6">Now, what I want to ask you to do is for each of these nodes in each of the trees,</text>
      <text start="42" dur="2">tell us in what order they&amp;#39;re expanded,</text>
      <text start="44" dur="5">first, second, third, fourth, fifth and so on by putting a number into the box.</text>
      <text start="49" dur="9">And if there are ties, put that number in and resolve the ties in left to right order.</text>
      <text start="58" dur="5">Then I want you to ask one more question or answer one more question</text>
      <text start="63" dur="3">which is are these searches optimal?</text>
      <text start="66" dur="5">That is, are they guaranteed to find the best solution?</text>
      <text start="71" dur="5">And for breadth-first search, optimal would mean finding the shortest path.</text>
      <text start="76" dur="5">If you think it&amp;#39;s guaranteed to find the shortest path, check here.</text>
      <text start="81" dur="5">For cheapest first, it would mean finding the path with the lowest total path cost.</text>
      <text start="86" dur="4">Check here if you think it&amp;#39;s guaranteed to do that.</text>
      <text start="90" dur="4">And we&amp;#39;ll allow the assumption that all costs have to be positive.</text>
      <text start="94" dur="7">And in depth first, cheapest or optimal would mean, again,</text>
      <text start="101" dur="5">as in breadth first, finding the shortest possible path in terms of number of lengths.</text>
      <text start="106" dur="4">Check here if  you think depth first will always find that.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 19, Search Optimality Answer" id="slLRsFFiiRc">
    <transcript>
      <text start="0" dur="4">Here are the answers.</text>
      <text start="4" dur="6">Breadth-first search, as the name implies, expands nodes in this order.</text>
      <text start="10" dur="7">One, 2, 3, 4, 5, 6, 7.</text>
      <text start="17" dur="6">So, it&amp;#39;s going across a stripe at a time, breadth first.</text>
      <text start="23" dur="2">Is it optimal?</text>
      <text start="25" dur="3">Well, it&amp;#39;s always expanding in the shortest paths first,</text>
      <text start="28" dur="6">and so wherever the goal is hiding, it&amp;#39;s going to find it by examining</text>
      <text start="34" dur="4">no longer paths, so in fact, it is optimal.</text>
      <text start="38" dur="7">Cheapest first, first we expand the path of length zero,</text>
      <text start="45" dur="2">then the path of length 2.</text>
      <text start="47" dur="6">Now there&amp;#39;s a path of length 4, path of length 5,</text>
      <text start="53" dur="9">path of length 6, a path of length 7, and finally, a path of length 8.</text>
      <text start="62" dur="6">And as we&amp;#39;ve seen, it&amp;#39;s guaranteed to find the cheapest path of all,</text>
      <text start="68" dur="6">assuming that all the individual step costs are not negative.</text>
      <text start="74" dur="3">Depth-first search tries to go as deep as it can first,</text>
      <text start="77" dur="7">so it goes 1, 2, 3, then backs up, 4,</text>
      <text start="84" dur="5">then backs up, 5, 6, 7.</text>
      <text start="89" dur="5">And you can see that it doesn&amp;#39;t necessarily find the shortest path of all.</text>
      <text start="94" dur="5">Let&amp;#39;s say that there were goals in position 5 and in position 3.</text>
      <text start="99" dur="4">It would find the longer path to position 3 and find the goal there</text>
      <text start="103" dur="3">and would not find the goal in position 5.</text>
      <text start="106" dur="3">So, it is not optimal.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 20, Storage Requirements, Completeness" id="RntnUP9QRiU">
    <transcript>
      <text start="0" dur="4">Given the non-optimality of depth-first search,</text>
      <text start="4" dur="3">why would anybody choose to use it?</text>
      <text start="7" dur="3">Well, the answer has to do with the storage requirements.</text>
      <text start="10" dur="3">Here I&amp;#39;ve illustrated a state space</text>
      <text start="13" dur="5">consisting of a very large or even infinite binary tree.</text>
      <text start="18" dur="4">As we go to levels 1, 2, 3, down to level n,</text>
      <text start="22" dur="2">the tree gets larger and larger.</text>
      <text start="24" dur="5">Now, let&amp;#39;s consider the frontier for each of these search algorithms.</text>
      <text start="29" dur="6">For breadth-first search, we know a frontier looks like that,</text>
      <text start="35" dur="5">and so when we get down to level n, we&amp;#39;ll require a storage space of</text>
      <text start="40" dur="5">2 to the n of pass in a breadth-first search.</text>
      <text start="45" dur="4">For cheapest first, the frontier is going to be more complicated.</text>
      <text start="49" dur="4">It&amp;#39;s going to sort of work out this contour of cost,</text>
      <text start="53" dur="4">but it&amp;#39;s going to have a similar total number of nodes.</text>
      <text start="57" dur="6">But for depth-first search, as we go down the tree, we start going down this branch,</text>
      <text start="63" dur="5">and then we back up, but at any point, our frontier is only going to have n nodes</text>
      <text start="68" dur="6">rather than 2 to the n nodes, so that&amp;#39;s a substantial savings for depth-first search.</text>
      <text start="74" dur="5">Now, of course, if we&amp;#39;re also keeping track of the explored set,</text>
      <text start="79" dur="2">then we don&amp;#39;t get that much savings.</text>
      <text start="81" dur="4">But without the explored set, depth-first search has a huge advantage</text>
      <text start="85" dur="2">in terms of space saved.</text>
      <text start="87" dur="3">One more property of the algorithms to consider</text>
      <text start="90" dur="5">is the property of completeness, meaning if there is a goal somewhere,</text>
      <text start="95" dur="2">will the algorithm find it?</text>
      <text start="97" dur="4">So, let&amp;#39;s move from very large trees to infinite trees,</text>
      <text start="101" dur="6">and let&amp;#39;s say that there&amp;#39;s some goal hidden somewhere deep down in that tree.</text>
      <text start="107" dur="4">And the question is, are each of these algorithms complete?</text>
      <text start="111" dur="4">That is, are they guaranteed to find a path to the goal?</text>
      <text start="115" dur="7">Mark off the check boxes for the algorithms that you believe are complete in this sense.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 21, Completeness Answer" id="aEZOJ-KazvU">
    <transcript>
      <text start="0" dur="4">The answer is that breadth-first search is complete,</text>
      <text start="4" dur="6">so even if the tree is infinite, if the goal is placed at any finite level,</text>
      <text start="10" dur="6">eventually, we&amp;#39;re going to march down and find that goal.</text>
      <text start="16" dur="2">Same with cheapest first.</text>
      <text start="18" dur="3">No matter where the goal is, if it has a finite cost,</text>
      <text start="21" dur="4">eventually, we&amp;#39;re going to go down and find it.</text>
      <text start="25" dur="3">But not so for depth-first search.</text>
      <text start="28" dur="5">If there&amp;#39;s an infinite path, depth-first search will keep following that,</text>
      <text start="33" dur="4">so it will keep going down and down and down along this path</text>
      <text start="37" dur="5">and never get to the path that the goal consists of</text>
      <text start="42" dur="4">and never get to the path on which the goal sits.</text>
      <text start="46" dur="3">So, depth-first search is not complete.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 22, More on Uniform Cost Search" id="IBAuWgq0ews">
    <transcript>
      <text start="0" dur="5">Let&amp;#39;s try to understand a little better how uniform cost search works.</text>
      <text start="5" dur="3">We start at a start state,</text>
      <text start="8" dur="5">and then we start expanding out from there looking at different paths,</text>
      <text start="13" dur="8">and what we end of doing is expanding in terms of contours like on a topological map,</text>
      <text start="21" dur="7">where first we span out to a certain distance, then to a farther distance,</text>
      <text start="28" dur="3">and then to a farther distance.</text>
      <text start="31" dur="4">Now at some point we meet up with a goal.  Let&amp;#39;s say the goal is here.</text>
      <text start="35" dur="7">Now we found a path from the start to the goal.</text>
      <text start="42" dur="4">But notice that the search really wasn&amp;#39;t directed at any way towards the goal.</text>
      <text start="46" dur="6">It was expanding out everywhere in the space and depending on where the goal is,</text>
      <text start="52" dur="5">we should expect to have to explore half the space, on average, before we find the goal.</text>
      <text start="57" dur="3">If the space is small, that can be fine,</text>
      <text start="60" dur="5">but when spaces are large, that won&amp;#39;t get us to the goal fast enough.</text>
      <text start="65" dur="5">Unfortunately, there is really nothing we can do, with what we know, to do better than that,</text>
      <text start="70" dur="5">and so if we want to improve, if we want to be able to find the goal faster,</text>
      <text start="75" dur="6">we&amp;#39;re going to have to add more knowledge.</text>
      <text start="81" dur="6">The type of knowledge that is proven most useful in search is an estimate of the distance</text>
      <text start="87" dur="5">from the start state to the goal.</text>
      <text start="92" dur="4">So let&amp;#39;s say we&amp;#39;re dealing with a route-finding problem,</text>
      <text start="96" dur="7">and we can move in any direction--up or down, right or left--</text>
      <text start="103" dur="7">and we&amp;#39;ll take as our estimate, the straight line distance between a state and a goal,</text>
      <text start="110" dur="5">and we&amp;#39;ll try to use that estimate to find our way to the goal fastest.</text>
      <text start="115" dur="9">Now an algorithm called greedy best-first search does exactly that.</text>
      <text start="124" dur="5">It expands first the path that&amp;#39;s closest to the goal according to the estimate.</text>
      <text start="129" dur="4">So what do the contours look like in this approach?</text>
      <text start="133" dur="4">Well, we start here, and then we look at all the neighboring states,</text>
      <text start="137" dur="4">and the ones that appear to be closest to the goal we would expand first.</text>
      <text start="141" dur="9">So we&amp;#39;d start expanding like this and like this and like this and like this</text>
      <text start="150" dur="3">and that would lead us directly to the goal.</text>
      <text start="153" dur="5">So now instead of exploring whole circles that go out everywhere with a certain space,</text>
      <text start="158" dur="3">our search is directed towards the goal.</text>
      <text start="161" dur="5">In this case it gets us immediately towards the goal, but that won&amp;#39;t always be the case</text>
      <text start="166" dur="4">if there are obstacles along the way.</text>
      <text start="170" dur="4">Consider this search space.  We have a start state and a goal,</text>
      <text start="174" dur="3">and there&amp;#39;s an impassable barrier.</text>
      <text start="177" dur="5">Now greedy best-first search will start expanding out as before,</text>
      <text start="182" dur="6">trying to get towards the goal,</text>
      <text start="188" dur="3">and when it reaches the barrier, what will it do next?</text>
      <text start="191" dur="4">Well, it will try to increase along a path that&amp;#39;s getting closer and closer to the goal.</text>
      <text start="195" dur="5">So it won&amp;#39;t consider going back this way which is farther from the goal.</text>
      <text start="200" dur="4">Rather it will continue expanding out along these lines</text>
      <text start="204" dur="4">which always get closer and closer to the goal,</text>
      <text start="208" dur="3">and eventually it will find its way towards the goal.</text>
      <text start="211" dur="5">So it does find a path, and it does it by expanding a small number of nodes,</text>
      <text start="216" dur="6">but it&amp;#39;s willing to accept a path which is longer than other paths.</text>
      <text start="222" dur="5">Now if we explored in the other direction, we could have found a much simpler path,</text>
      <text start="227" dur="7">a much shorter path, by just popping over the barrier, and then going directly to the goal.</text>
      <text start="234" dur="2">but greedy best-first search wouldn&amp;#39;t have done that because</text>
      <text start="236" dur="5">that would have involved getting to this point, which is this distance to the goal,</text>
      <text start="241" dur="7">and then considering states which were farther from the goal.</text>
      <text start="248" dur="3">What we would really like is an algorithm that combines the best parts</text>
      <text start="251" dur="6">of greedy search which explores a small number of nodes in many cases</text>
      <text start="257" dur="5">and uniform cost search which is guaranteed to find a shortest path.</text>
      <text start="262" dur="6">We&amp;#39;ll show how to do that next using an algorithm called the A-star algorithm.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 23, A-Star Search" id="_CBhTubi-CU">
    <transcript>
      <text start="0" dur="3">[Male narrator] A* Search works by always expanding the path</text>
      <text start="3" dur="4">that has a minimum value of the function f</text>
      <text start="7" dur="5">which is defined as a sum of the g + h components.</text>
      <text start="12" dur="4">Now, the function g of a path</text>
      <text start="16" dur="3">is just the path cost,</text>
      <text start="19" dur="4">and the function h of a path</text>
      <text start="23" dur="4">is equal to the h value of the state,</text>
      <text start="27" dur="3">which is the final state of the path,</text>
      <text start="30" dur="6">which is equal to the estimated distance to the goal.</text>
      <text start="36" dur="3">Here&amp;#39;s an example of how A* works.</text>
      <text start="39" dur="5">Suppose we found this path through the state&amp;#39;s base to a state x</text>
      <text start="44" dur="4">and we&amp;#39;re trying to give a measure to the value of this path.</text>
      <text start="48" dur="7">The measure f is a sum of g, the path cost so far,</text>
      <text start="55" dur="7">and h, which is the estimated distance that the path will take</text>
      <text start="62" dur="2">to complete its path to the goal.</text>
      <text start="64" dur="4">Now, minimizing g helps us keep the path short</text>
      <text start="68" dur="5">and minimizing h helps us keep focused on finding the goal</text>
      <text start="73" dur="4">and the result is a search strategy that is the best possible</text>
      <text start="77" dur="3">in the sense that it finds the shortest length path</text>
      <text start="80" dur="4">while expanding the minimum number of paths possible.</text>
      <text start="84" dur="4">It could be called &amp;quot;best estimated total path cost first,&amp;quot;</text>
      <text start="88" dur="4">but the name A* is traditional.</text>
      <text start="92" dur="4">Now let&amp;#39;s go back to Romania and apply the A* algorithm</text>
      <text start="96" dur="4">and we&amp;#39;re going to use a heuristic, which is a straight line distance</text>
      <text start="100" dur="2">between a state and the goal.</text>
      <text start="102" dur="2">The goal, again, is Bucharest,</text>
      <text start="104" dur="3">and so the distance from Bucharest to Bucharest is, of course, 0.</text>
      <text start="107" dur="4">And for all the other states, I&amp;#39;ve written in red</text>
      <text start="111" dur="2">the straight line distance.</text>
      <text start="113" dur="2">For example, straight across like that.</text>
      <text start="115" dur="4">Now, I should say that all the roads here I&amp;#39;ve drawn as straight lines,</text>
      <text start="119" dur="4">but actually, roads are going to be curved to some degree,</text>
      <text start="123" dur="3">so the actual distance along the roads is going to be longer</text>
      <text start="126" dur="3">than the straight line distance.</text>
      <text start="129" dur="4">Now, we start out as usual--we&amp;#39;ll start in Arad as a start state--</text>
      <text start="133" dur="8">and we&amp;#39;ll expand out Arad and so we&amp;#39;ll add 3 paths</text>
      <text start="141" dur="5">and the evaluation function, f, will be the sum of the path length,</text>
      <text start="146" dur="3">which is given in black, and the estimated distance,</text>
      <text start="149" dur="3">which is given in red.</text>
      <text start="152" dur="5">And so the path length from this path</text>
      <text start="157" dur="8">will be 140+253 or 393;</text>
      <text start="165" dur="10">for this path, 75+374, or 449;</text>
      <text start="175" dur="10">and for this path, 118+329, or 447.</text>
      <text start="185" dur="4">And now, the question is out of all the paths that are on the frontier,</text>
      <text start="189" dur="5">which path would we expand next under the A* algorithm?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 23, A-Star Search ANSWER" id="yO5Cx5zw8h4">
    <transcript>
      <text start="0" dur="5">The answer is that we select this path first--the one from Arad to Sibiu--</text>
      <text start="5" dur="9">because it has the smallest value--393--of the sum f=g+h.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 24, A-Star Second Question" id="KP8JiOrl5As">
    <transcript>
      <text start="0" dur="3">Let&amp;#39;s go ahead and expand this node now.</text>
      <text start="3" dur="3">So we&amp;#39;re going to add 3 paths.</text>
      <text start="6" dur="4">This one has a path cost of 291</text>
      <text start="10" dur="4">and an estimated distance to the goal of 380,</text>
      <text start="14" dur="4">for a total of 671.</text>
      <text start="18" dur="3">This one has a path cost of 239</text>
      <text start="21" dur="6">and an estimated distance of 176, for a total of 415.</text>
      <text start="27" dur="6">And the final one is 220+193=413.</text>
      <text start="33" dur="6">And now the question is which state to we expand next?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 24, A-Star Second Question ANSWER" id="YOjVW4NKgDQ">
    <transcript>
      <text start="0" dur="3">The answer is we expand this path next</text>
      <text start="3" dur="3">because its total, 413,</text>
      <text start="6" dur="3">is less than all the other ones on the front tier--</text>
      <text start="9" dur="3">although only slightly less than the 415 for this path.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 25, A-Star Third Question" id="u6_Xjgz7MCg">
    <transcript>
      <text start="0" dur="3">So we expand this node,</text>
      <text start="3" dur="3">giving us 2 more paths--</text>
      <text start="6" dur="4">this one with an f-value of 417,</text>
      <text start="10" dur="6">and this one with an f-value of 526.</text>
      <text start="16" dur="4">The question again--which path are we going to expand next?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 25, A-Star Third Question ANSWER" id="BG5V3_MQP54">
    <transcript>
      <text start="0" dur="5">And the answer is that we expand this path, Fagaras, next,</text>
      <text start="5" dur="3">because its f-total, 415,</text>
      <text start="8" dur="3">is less than all the other paths in the front tier.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 26, A-Star Fourth Question" id="i0ExF1xivqc">
    <transcript>
      <text start="1" dur="3">Now we expand Fagaras</text>
      <text start="4" dur="3">and we get a path that reaches the goal</text>
      <text start="7" dur="4">and it has a path length of 450 and an estimated distance of 0</text>
      <text start="11" dur="3">for a total f value of 450,</text>
      <text start="14" dur="3">and now the question is: What do we do next?</text>
      <text start="17" dur="5">Click here if you think we&amp;#39;re at the end of the algorithm</text>
      <text start="22" dur="2">and we don&amp;#39;t need to expand next</text>
      <text start="24" dur="2">or click on the node that you think we will expand next.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 26, A-Star Fourth Question ANSWER" id="qLfsDlLP2SY">
    <transcript>
      <text start="0" dur="3">The answer is that we&amp;#39;re not done yet,</text>
      <text start="3" dur="3">because the algorithm works by doing the goal test,</text>
      <text start="6" dur="2">when we take a path off the front tier,</text>
      <text start="8" dur="3">not when we put a path on the front tier.</text>
      <text start="11" dur="4">Instead, we just continue in the normal way and choose the node</text>
      <text start="15" dur="3">on the front tier which has the lowest value.</text>
      <text start="18" dur="5">That would be this one--the path through Pitesti, with a total of 417.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 27, A-Star Fifth Question" id="pFPqrufkL48">
    <transcript>
      <text start="1" dur="3">So let&amp;#39;s expand the node at Pitesti.</text>
      <text start="4" dur="4">We have to go down this direction, up,</text>
      <text start="8" dur="3">then we reach a path we&amp;#39;ve seen before,</text>
      <text start="11" dur="2">and we go in this direction.</text>
      <text start="13" dur="3">Now we reach Bucharest, which is the goal,</text>
      <text start="16" dur="3">and the h value is going to be 0</text>
      <text start="19" dur="5">because we&amp;#39;re at the goal, and the g value works out to 418.</text>
      <text start="24" dur="7">Again, we don&amp;#39;t stop here just because we put a path onto the front tier,</text>
      <text start="31" dur="4">we put it there, we don&amp;#39;t apply the goal test next,</text>
      <text start="35" dur="3">but, now we go back to the front tier,</text>
      <text start="38" dur="5">and it turns out that this 418 is the lowest-cost path on the front tier.</text>
      <text start="43" dur="2">So now we pull it off, do the goal test,</text>
      <text start="45" dur="4">and now we found our path to the goal,</text>
      <text start="49" dur="3">and it is, in fact, the shortest possible path.</text>
      <text start="55" dur="4">In this case, A-star was able to find the lowest-cost path.</text>
      <text start="59" dur="3">Now the question that you&amp;#39;ll have to think about,</text>
      <text start="62" dur="2">because we haven&amp;#39;t explained it yet,</text>
      <text start="64" dur="2">is whether A-star will always do this.</text>
      <text start="66" dur="6">Answer yes if you think A-star will always find the shortest cost path,</text>
      <text start="72" dur="5">or answer no if you think it depends on the particular problem given,</text>
      <text start="77" dur="7">or answer no if you think it depends on the particular heuristic estimate function, h.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 27, A-Star Fifth Question ANSWER Mandatory" id="z86_jYE6CDA">
    <transcript>
      <text start="2" dur="4">The answer is that it depends on the h function.</text>
      <text start="6" dur="3">A-star will find the lowest-cost path</text>
      <text start="9" dur="7">if the h function for a state is less than the true cost</text>
      <text start="16" dur="4">of the path to the goal through that state.</text>
      <text start="20" dur="6">In other words, we want the h to never overestimate the distance to the goal.</text>
      <text start="26" dur="5">We also say that h is optimistic.</text>
      <text start="31" dur="3">Another way of stating that</text>
      <text start="34" dur="3">is that h is admissible,</text>
      <text start="37" dur="4">meaning is it admissible to use it to find the lowest-cost path.</text>
      <text start="41" dur="4">Think of all of these of being the same way</text>
      <text start="45" dur="4">of stating the conditions under which A-star finds the lowest-cost path.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 28, Optimistic Heuristics" id="3Vmn9Rn-lDM">
    <transcript>
      <text start="1" dur="2">Here we give you an intuition as to why</text>
      <text start="3" dur="4">an optimistic heuristic function, h, finds the lowest-cost path.</text>
      <text start="8" dur="7">When A-star ends, it returns a path, p, with estimated cost, c.</text>
      <text start="15" dur="5">It turns out that c is also the actual cost,</text>
      <text start="20" dur="3">because at the goal the h component is 0,</text>
      <text start="23" dur="4">and so the path cost is the total cost as estimated by the function.</text>
      <text start="28" dur="3">Now, all the paths on the front tier</text>
      <text start="31" dur="4">have an estimated cost that&amp;#39;s greater than c,</text>
      <text start="35" dur="5">and we know that because the front tier is explored in cheapest-first order.</text>
      <text start="40" dur="4">If h is optimistic, then the estimated cost</text>
      <text start="44" dur="3">is less than the true cost,</text>
      <text start="47" dur="4">so the path p must have a cost that&amp;#39;s less than the true cost</text>
      <text start="51" dur="3">of any of the paths on the front tier.</text>
      <text start="54" dur="3">Any paths that go beyond the front tier</text>
      <text start="57" dur="2">must have a cost that&amp;#39;s greater than that</text>
      <text start="59" dur="5">because we agree that the step cost is always 0 or more.</text>
      <text start="64" dur="5">So that means that this path, p, must be the minimal cost path.</text>
      <text start="69" dur="4">Now, this argument, I should say, only goes through</text>
      <text start="73" dur="3">as is for tree search.</text>
      <text start="76" dur="3">For graph search the argument is slightly more complicated,</text>
      <text start="79" dur="3">but the general intuitions hold the same.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 29, State Spaces" id="8dXgwOvQYVE">
    <transcript>
      <text start="1" dur="4">So far we&amp;#39;ve looked at the state space of cities in Romania--</text>
      <text start="5" dur="2">a 2-dimensional, physical space.</text>
      <text start="7" dur="3">But the technology for problem solving through search</text>
      <text start="10" dur="2">can deal with many types of state spaces,</text>
      <text start="12" dur="5">dealing with abstract properties, not just x-y position in a plane.</text>
      <text start="17" dur="4">Here I introduce another state space--the vacuum world.</text>
      <text start="21" dur="4">It&amp;#39;s a very simple world in which there are only 2 positions</text>
      <text start="25" dur="5">as opposed to the many positions in the Romania state space.</text>
      <text start="30" dur="3">But there are additional properties to deal with as well.</text>
      <text start="33" dur="3">The robot vacuum cleaner can be in either of the 2 conditions,</text>
      <text start="36" dur="4">but as well as that each of the positions</text>
      <text start="40" dur="3">can either have dirt in it or not have dirt in it.</text>
      <text start="43" dur="4">Now the question is to represent this as a state space</text>
      <text start="47" dur="4">how many states do we need?</text>
      <text start="51" dur="8">The number of states can fill in this box here.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 29, State Spaces ANSWER" id="6KTjn8LpbZM">
    <transcript>
      <text start="1" dur="3">And the answer is there are 8 states.</text>
      <text start="4" dur="6">There are 2 physical states that the robot vacuum cleaner can be in--</text>
      <text start="10" dur="2">either in state A or in state B.</text>
      <text start="12" dur="5">But in addition to that, there are states about how the world is</text>
      <text start="17" dur="2">as well as where the robot is in the world.</text>
      <text start="19" dur="5">So state A can be dirty or not.</text>
      <text start="24" dur="2">That&amp;#39;s 2 possibilities.</text>
      <text start="26" dur="2">And B can be dirty or not.</text>
      <text start="28" dur="3">That&amp;#39;s 2 more possibilities.</text>
      <text start="31" dur="4">We multiply those together.                                 We get 8 possible states.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 30, State Space Diagram and More Complexity" id="NCfWMf9lL5I">
    <transcript>
      <text start="1" dur="4">Here is a diagram of the state space for the vacuum world.</text>
      <text start="5" dur="4">Note that there are 8 states, and we have the actions connecting the states</text>
      <text start="9" dur="3">just as we did in the Romania problem.</text>
      <text start="12" dur="3">Now let&amp;#39;s look at a path through this state.</text>
      <text start="15" dur="4">Let&amp;#39;s say we start out in this position,</text>
      <text start="19" dur="4">and then we apply the action of moving right.</text>
      <text start="23" dur="4">Then we end up in a position where the state of the world looks the same,</text>
      <text start="27" dur="5">except the robot has moved from position &amp;#39;A&amp;#39; to position &amp;#39;B&amp;#39;.</text>
      <text start="32" dur="5">Now if we turn on the sucking action,</text>
      <text start="37" dur="5">then we end up in a state where the robot is in the same position</text>
      <text start="42" dur="4">but that position is no longer dirty.</text>
      <text start="47" dur="3">Let&amp;#39;s take this very simple vacuum world</text>
      <text start="50" dur="3">and make a slightly more complicated one.</text>
      <text start="53" dur="3">First, we&amp;#39;ll say that the robot has a power switch,</text>
      <text start="56" dur="8">which can be in one of three conditions:                     on, off, or sleep.</text>
      <text start="64" dur="5">Next, we&amp;#39;ll say that the robot has a dirt-sensing camera,</text>
      <text start="69" dur="4">and that camera can either be on or off.</text>
      <text start="73" dur="3">Third, this is the deluxe model of robot</text>
      <text start="76" dur="3">in which the brushes that clean up the dust</text>
      <text start="79" dur="3">can be set at 1 of 5 different heights</text>
      <text start="82" dur="5">to be appropriate for whatever level of carpeting you have.</text>
      <text start="87" dur="3">Finally, rather that just having the 2 positions,</text>
      <text start="90" dur="7">we&amp;#39;ll extend that out and have 10 positions.</text>
      <text start="97" dur="7">Now the question is how many states are in this state space?</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 30, State Space Diagram and More Complexity ANSWER" id="ATEXTIBgH4o">
    <transcript>
      <text start="1" dur="4">The answer is that the number of states is the cross product</text>
      <text start="5" dur="3">of the numbers of all the variables, since they&amp;#39;re each independent,</text>
      <text start="8" dur="2">and any combination can occur.</text>
      <text start="10" dur="4">For the power we have 3 possible positions.</text>
      <text start="14" dur="4">The camera has 2.</text>
      <text start="18" dur="5">The brush height has 5.</text>
      <text start="23" dur="5">The dirt has 2 for each of the 10 positions.</text>
      <text start="28" dur="5">That&amp;#39;s 2^10 or 1024.</text>
      <text start="33" dur="6">Then the robot&amp;#39;s position can be any of those 10 positions as well.</text>
      <text start="39" dur="5">That works out to 307,200 states in the state space.</text>
      <text start="44" dur="2">Notice how a fairly trivial problem--</text>
      <text start="46" dur="4">we&amp;#39;re only modeling a few variables and only 10 positions--</text>
      <text start="50" dur="2">works out to a large number of state spaces.</text>
      <text start="52" dur="5">That&amp;#39;s why we need efficient algorithms for searching through states spaces.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 31, Sliding Blocks Puzzle" id="-HvDwJAM2y4">
    <transcript>
      <text start="1" dur="4">I want to introduce one more problem that can be solved with search techniques.</text>
      <text start="5" dur="3">This is a sliding blocks puzzle, called a 15 puzzle.</text>
      <text start="8" dur="2">You may have seen something like this.</text>
      <text start="10" dur="4">So there are a bunch of little squares or blocks or tiles</text>
      <text start="14" dur="2">and you can slide them around.</text>
      <text start="19" dur="2">and the goal is to get into a certain configuration.</text>
      <text start="21" dur="6">So we&amp;#39;ll say that this is the goal state, where the numbers 1-15 are in order</text>
      <text start="27" dur="2">left to right, top to bottom.</text>
      <text start="29" dur="5">The starting state would be some state where all the positions are messed up.</text>
      <text start="34" dur="4">Now the question is: Can we come up with a good heuristic for this?</text>
      <text start="38" dur="4">Let&amp;#39;s examine that as a way of thinking about where heuristics come from.</text>
      <text start="42" dur="4">The first heuristic we&amp;#39;re going to consider</text>
      <text start="46" dur="8">we&amp;#39;ll call h1, and that is equal to the number of misplaced blocks.</text>
      <text start="54" dur="5">So here 10 and 11 are misplaced because they should be there and there, respectively,</text>
      <text start="59" dur="3">12 is in the right place, 13 is in the right place,</text>
      <text start="62" dur="2">and 14 and 15 are misplaced.</text>
      <text start="64" dur="3">That&amp;#39;s a total of 4 misplaced blocks.</text>
      <text start="67" dur="6">The 2nd heuristic, h2, is equal to</text>
      <text start="73" dur="6">the sum of the distances that each block would have to move to get to the right position.</text>
      <text start="79" dur="7">For this position, 10 would have to move 1 space to get to the right position,</text>
      <text start="86" dur="4">11 would have to move 1, so that&amp;#39;s a total of 2 so far,</text>
      <text start="90" dur="1">13 is in the right place,</text>
      <text start="91" dur="2">14 is 1 displaced,</text>
      <text start="93" dur="2">and 15 is 1 displaced,</text>
      <text start="95" dur="3">so that would also be a total of 4.</text>
      <text start="98" dur="6">Now, the question is: Which, if any, of these heuristics are admissible?</text>
      <text start="104" dur="3">Check the boxes next to the heuristics that you think</text>
      <text start="107" dur="2">are admissible.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 31, Sliding Blocks Puzzle ANSWER" id="lviKMjofhZ0">
    <transcript>
      <text start="2" dur="5">H1 is admissible, because every tile that&amp;#39;s in the wrong position</text>
      <text start="7" dur="3">must be moved at least once to get into the right position.</text>
      <text start="10" dur="3">So h1 never overestimates.</text>
      <text start="13" dur="2">How about h2?</text>
      <text start="15" dur="5">H2 is also admissible, because every tile in the wrong position</text>
      <text start="20" dur="6">can be moved closer to the correct position no faster than 1 space per move.</text>
      <text start="26" dur="2">Therefore, both are admissible.</text>
      <text start="28" dur="5">But notice that h2 is always greater than or equal to h1.</text>
      <text start="33" dur="2">That means that, with the exception of breaking ties,</text>
      <text start="35" dur="4">an A* search using h2 will always expand</text>
      <text start="39" dur="3">fewer paths than one using h1</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 32, Where is the Intelligence" id="lL-8KGXehNY">
    <transcript>
      <text start="1" dur="3">Now, we&amp;#39;re trying to build an artificial intelligence</text>
      <text start="4" dur="3">that can solve problems like this all on its own.</text>
      <text start="8" dur="4">You can see that the search algorithms do a great job</text>
      <text start="12" dur="3">of finding solutions to problems like this.</text>
      <text start="15" dur="4">But, you might complain that in order for the search algorithms to work,</text>
      <text start="19" dur="3">we had to provide it with a heurstic function.</text>
      <text start="22" dur="3">A heurstic function came from the outside.</text>
      <text start="25" dur="5">You might think that coming up with a good heurstic function is really where all the intelligence is.</text>
      <text start="30" dur="4">So, a problem solver that uses an heurstic function given to it</text>
      <text start="34" dur="2">really isn&amp;#39;t intelligent at all.</text>
      <text start="36" dur="3">So let&amp;#39;s think about where the intelligence could come from</text>
      <text start="39" dur="4">and can we automatically come up with good heurstic functions.</text>
      <text start="45" dur="2">I&amp;#39;m going to sketch a description of</text>
      <text start="47" dur="3">a program that can automatically come up with good heurstics</text>
      <text start="50" dur="2">given a description of a problem.</text>
      <text start="52" dur="5">Suppose this program is given a description of the sliding blocks puzzle</text>
      <text start="57" dur="5">where we say that a block can move from square A to square B</text>
      <text start="62" dur="4">if A is adjacent to B and B is blank.</text>
      <text start="66" dur="4">Now, imagine that we try to loosen this restriction.</text>
      <text start="70" dur="4">We cross out &amp;quot;B is blank,&amp;quot;</text>
      <text start="74" dur="2">and then we get the rule</text>
      <text start="76" dur="4">&amp;quot;a block can move from A to B if A is adjacent to B,&amp;quot;</text>
      <text start="80" dur="3">and that&amp;#39;s equal to our heurstic h2</text>
      <text start="83" dur="4">because a block can move anywhere to an adjacent state.</text>
      <text start="87" dur="4">Now, we could also cross out the other part of the rule,</text>
      <text start="91" dur="5">and we now get &amp;quot;a block can move from any square A</text>
      <text start="96" dur="4">to any square B regardless of any condition.</text>
      <text start="100" dur="3">That gives us heurstic h1.</text>
      <text start="103" dur="5">So we see that both of our heurstics can be derived</text>
      <text start="108" dur="2">from a simple mechanical manipulation</text>
      <text start="110" dur="3">of the formal description of the problem.</text>
      <text start="113" dur="5">Once we&amp;#39;ve generated automatically these candidate heuristics,</text>
      <text start="118" dur="4">another way to come up with a good heurstic is to say</text>
      <text start="122" dur="2">that a new heurstic, h,</text>
      <text start="124" dur="6">is equal to the maximum of h1 and h2,</text>
      <text start="130" dur="3">and that&amp;#39;s guaranteed to be admissible as long as</text>
      <text start="133" dur="3">h1 and h2 are admissible</text>
      <text start="136" dur="2">because it still never overestimates,</text>
      <text start="138" dur="4">and it&amp;#39;s guaranteed to be better because its getting closer to the true value.</text>
      <text start="142" dur="5">The only problem with combining multiple heuristics like this</text>
      <text start="147" dur="2">is that there is some cause to compute the heuristic</text>
      <text start="149" dur="2">and it could take longer to compute</text>
      <text start="151" dur="4">even if we end up expanding pure paths.</text>
      <text start="155" dur="3">Crossing out parts of the rules like this</text>
      <text start="158" dur="3">is called &amp;quot;generating a relaxed problem.&amp;quot;</text>
      <text start="161" dur="3">What we&amp;#39;ve done is we&amp;#39;ve taken the original problem,</text>
      <text start="164" dur="2">where it&amp;#39;s hard to move squares around,</text>
      <text start="166" dur="3">and made it easier by relaxing one of the constraints.</text>
      <text start="169" dur="5">You can see that as adding new links in the state space,</text>
      <text start="174" dur="5">so if we have a state space in which there are only particular links,</text>
      <text start="179" dur="6">by relaxing the problem it&amp;#39;s as if we are adding new operators</text>
      <text start="185" dur="2">that traverse the state in new ways.</text>
      <text start="187" dur="4">So adding new operators only makes the problem easier,</text>
      <text start="191" dur="5">and thus never overestimates, and thus is admissible.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 33, What Can't Search Do" id="UbqrrN4wbqQ">
    <transcript>
      <text start="0" dur="3">We&amp;#39;ve seen what search can do for problem solving.</text>
      <text start="3" dur="3">It can find the lowest-cost path to a goal,</text>
      <text start="6" dur="6">and it can do that in a way in which we never generate more paths than we have to.</text>
      <text start="12" dur="3">We can find the optimal number of paths to generate,</text>
      <text start="15" dur="4">and we can do that with a heuristic function that we generate on our own</text>
      <text start="19" dur="3">by relaxing the existing problem definition.</text>
      <text start="22" dur="3">But let&amp;#39;s be clear on what search can&amp;#39;t do.</text>
      <text start="25" dur="6">All the solutions that we have found consist of a fixed sequence of actions.</text>
      <text start="31" dur="7">In other words, the agent Hirin Arad, thinks, comes up with a plan that it wants to execute</text>
      <text start="38" dur="4">and then essentially closes his eyes and starts driving,</text>
      <text start="42" dur="4">never considering along the way if something has gone wrong.</text>
      <text start="46" dur="3">That works fine for this type of problem,</text>
      <text start="49" dur="4">but it only works when we satisfy the following conditions.</text>
      <text start="53" dur="2">[Problem solving works when:]</text>
      <text start="55" dur="4">Problem-solving technology works when the following set of conditions is true:</text>
      <text start="59" dur="4">First, the domain must be fully observable.</text>
      <text start="63" dur="5">In other words, we must be able to see what initial state we start out with.</text>
      <text start="68" dur="4">Second, the domain must be known.</text>
      <text start="72" dur="4">That is, we have to know the set of available actions to us.</text>
      <text start="76" dur="4">Third, the domain must be discrete.</text>
      <text start="80" dur="4">There must be a finite number of actions to chose from.</text>
      <text start="84" dur="4">Fourth, the domain must be deterministic.</text>
      <text start="88" dur="4">We have to know the result of taking an action.</text>
      <text start="92" dur="4">Finally, the domain must be static.</text>
      <text start="96" dur="5">There must be nothing else in the world that can change the world except our own actions.</text>
      <text start="101" dur="3">If all these conditions are true, then we can search for a plan</text>
      <text start="104" dur="3">which solves the problem and is guaranteed to work.</text>
      <text start="107" dur="5">In later units, we will see what to do if any of these conditions fail to hold.</text>
    </transcript>
  </video>
  <video title="Unit 2, Topic 34, Note on Implementation" id="3muiVUU0sys">
    <transcript>
      <text start="1" dur="7">Our description of the algorithm has talked about paths in the state space.</text>
      <text start="8" dur="7">I want to say a little bit now about how to implement that in terms of a computer algorithm.</text>
      <text start="15" dur="4">We talk about paths, but we want to implement that in some ways.</text>
      <text start="19" dur="3">In the implementation we talk about nodes.</text>
      <text start="22" dur="5">A node is a data structure, and it has four fields.</text>
      <text start="27" dur="8">The state field indicates the state at the end of the path.</text>
      <text start="35" dur="5">The action was the action it took to get there.</text>
      <text start="40" dur="5">The cost is the total cost,</text>
      <text start="45" dur="5">and the parent is a pointer to another node.</text>
      <text start="50" dur="6">In this case, the node that has state &amp;quot;S&amp;quot;,</text>
      <text start="56" dur="10">and it will have a parent which points to the node that has state &amp;quot;A&amp;quot;,</text>
      <text start="66" dur="4">and that will have a parent pointer that&amp;#39;s null.</text>
      <text start="70" dur="5">So we have a linked list of nodes representing the path.</text>
      <text start="75" dur="3">We&amp;#39;ll use the word &amp;quot;path&amp;quot; for the abstract idea,</text>
      <text start="78" dur="4">and the word &amp;quot;node&amp;quot; for the representation in the computer memory.</text>
      <text start="82" dur="4">But otherwise, you can think of those two terms as being synonyms,</text>
      <text start="86" dur="5">because they&amp;#39;re in a one-to-one correspondence.</text>
      <text start="91" dur="4">Now there are two main data structures that deal with nodes.</text>
      <text start="95" dur="6">We have the &amp;quot;frontier&amp;quot; and we have the &amp;quot;explored&amp;quot; list.</text>
      <text start="101" dur="3">Let&amp;#39;s talk about how to implement them.</text>
      <text start="104" dur="4">In the frontier the operations we have to deal with</text>
      <text start="108" dur="4">are removing the best item from the frontier and adding in new ones.</text>
      <text start="112" dur="3">And that suggests we should implement it as a priority queue,</text>
      <text start="115" dur="4">which knows how to keep track of the best items in proper order.</text>
      <text start="119" dur="4">But we also need to have an additional operation</text>
      <text start="123" dur="4">of a membership test as a new item in the frontier.</text>
      <text start="127" dur="3">And that suggests representing it as a set,</text>
      <text start="130" dur="4">which can be built from a hash table or a tree.</text>
      <text start="134" dur="6">So the most efficient implementations of search actually have both representations.</text>
      <text start="140" dur="3">The explored set, on the other hand, is easier.</text>
      <text start="143" dur="5">All we have to do there is be able to add new members and check for membership.</text>
      <text start="148" dur="3">So we represent that as a single set,</text>
      <text start="151" dur="4">which again can be done with either a hash table or tree.</text>
    </transcript>
  </video>
  <video title="Homework 1, Congratulations!" id="IXVOQEFTvb4">
    <transcript>
      <text start="0" dur="2">Congratulations.</text>
      <text start="2" dur="3">You just made assignment 1.</text>
    </transcript>
  </video>
  <video title="Homework 1, Introduction" id="dnnGEYjD9wo">
    <transcript>
      <text start="0" dur="5">This is homework assignment #1.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 1, Peg Solitaire" id="CxjV8H50xfU">
    <transcript>
      <text start="1" dur="3">This is a question about peg solitaire.</text>
      <text start="4" dur="4">In peg solitaire, a single player faces</text>
      <text start="8" dur="2">the following kind of board.</text>
      <text start="13" dur="6">Initially, all pieces are occupied except for the center piece.</text>
      <text start="22" dur="4">You can find more information on peg solitare at the following URL.</text>
      <text start="26" dur="9">[http://en.wikipedia.org/wiki/peg_solitaire]</text>
      <text start="36" dur="4">I wish to know whether this game is partially observable,</text>
      <text start="40" dur="3">Please say yes or no.</text>
      <text start="43" dur="3">I wish to know whether it is stochastic.</text>
      <text start="46" dur="4">Please say yes if it is and no if it&amp;#39;s deterministic.</text>
      <text start="50" dur="5">Let me know if it&amp;#39;s continuous, yes or no,</text>
      <text start="55" dur="5">and let me know if it&amp;#39;s adversarial, yes or no.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 1, Peg Solitaire ANSWER" id="YOfAe4Xo_P4">
    <transcript>
      <text start="0" dur="6">&amp;gt;&amp;gt;Peg Solitaire is not partially observable because you can see the board at all times.</text>
      <text start="6" dur="3">It is not stochastic because you just make all the moves,</text>
      <text start="9" dur="2">and they have very different mystic effects.</text>
      <text start="11" dur="4">It is not continuous.  It&amp;#39;s just finding many choices of actions</text>
      <text start="15" dur="3">and finding many board positions, so therefore, it is not continuous.</text>
      <text start="18" dur="4">and it&amp;#39;s not adversarial because there is no adversaries--just you playing.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 2, Loaded Coin" id="ZmVLMZ5Fwcg">
    <transcript>
      <text start="1" dur="4">I am going to ask you about the problem to learn about a loaded coin.</text>
      <text start="5" dur="2">A loaded coin is a coin,</text>
      <text start="7" dur="2">that if you flip it,</text>
      <text start="9" dur="4">might have a non 0.5 chance</text>
      <text start="13" dur="2">of coming up heads or tails.</text>
      <text start="16" dur="4">Fair coins always come up 50% heads or tails.</text>
      <text start="20" dur="3">Loaded coins might come up, for example,</text>
      <text start="23" dur="4">0.9 chance heads and 0.1 chance tails.</text>
      <text start="27" dur="3">Your task will be to understand,</text>
      <text start="30" dur="1">from coin flips,</text>
      <text start="31" dur="2">whether a coin is loaded,</text>
      <text start="33" dur="2">and if so, at what probability.</text>
      <text start="35" dur="2">I don&amp;#39;t want you to solve the problem,</text>
      <text start="37" dur="3">but I want you to answer the following questions:</text>
      <text start="40" dur="2">Is it partially observable?</text>
      <text start="42" dur="2">Yes or no.</text>
      <text start="44" dur="2">Is it stochastic?</text>
      <text start="46" dur="2">Yes or no.</text>
      <text start="48" dur="3">Is it continuous?  [Yes or no.]</text>
      <text start="51" dur="2">And finally, is it adversarial?</text>
      <text start="53" dur="1">Yes or no.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 2, Loaded Coin ANSWER" id="GsKZT-aAZFI">
    <transcript>
      <text start="0" dur="6">[Thrun] So the loaded coin example is clearly partially observable,</text>
      <text start="6" dur="3">and the reason is it is actually used for the memory</text>
      <text start="9" dur="5">if you flip it more than 1 time so you can learn more about what the actual probability is.</text>
      <text start="14" dur="6">Therefore, looking at the most recent coin flip is insufficient to make your choice.</text>
      <text start="20" dur="5">It is stochastic because you flip a coin.</text>
      <text start="25" dur="6">It is not continuous because there&amp;#39;s only 1 action--a flip--and 2 outcomes.</text>
      <text start="31" dur="5">And it isn&amp;#39;t really adversarial because while you do your learning task</text>
      <text start="36" dur="2">no adversary interferes.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 3, Path Through Maze" id="dj6jEEU-jZc">
    <transcript>
      <text start="0" dur="5">Let&amp;#39;s talk about the problem of finding a path through a maze.</text>
      <text start="5" dur="5">Let me draw you a maze.</text>
      <text start="10" dur="5">Suppose you wish to find the path from the start to your goal.</text>
      <text start="15" dur="4">I don&amp;#39;t want to you to solve this problem.</text>
      <text start="19" dur="4">Rather I want you to tell me whether it&amp;#39;s partially observable.</text>
      <text start="23" dur="2">Yes or no.</text>
      <text start="25" dur="2">It is stochastic?</text>
      <text start="27" dur="2">Yes or no.</text>
      <text start="29" dur="2">Is it continuous?</text>
      <text start="31" dur="1">Yes or no.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 3, Path Through Maze ANSWER" id="TskS2qHzi90">
    <transcript>
      <text start="0" dur="3">[Thrun] The path through the maze is clearly not partially observable</text>
      <text start="3" dur="3">because you can see the maze entirely at all times.</text>
      <text start="6" dur="4">It is not stochastic. There is no randomness involved.</text>
      <text start="10" dur="2">It isn&amp;#39;t really continuous.</text>
      <text start="12" dur="3">There&amp;#39;s typically just finitely many choices--go left or right.</text>
      <text start="15" dur="3">And it isn&amp;#39;t adversarial because there&amp;#39;s no real adversary involved.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 4, Search Tree" id="qsxMRW2SOqI">
    <transcript>
      <text start="0" dur="2">This is a search question.</text>
      <text start="2" dur="3">Suppose we are given the following search tree.</text>
      <text start="5" dur="3">We are searching from the top, the start node,</text>
      <text start="8" dur="4">to the goal, which is over here.</text>
      <text start="12" dur="5">Assume we expand from left to right.</text>
      <text start="17" dur="3">Tell me how many nodes are expanded</text>
      <text start="20" dur="3">if we expand from left to right,</text>
      <text start="23" dur="4">counting the start node and the goal node in your answer.</text>
      <text start="27" dur="5">And give me the same answer for Depth First Search.</text>
      <text start="32" dur="3">Now, let&amp;#39;s assume you&amp;#39;re going to search from right to left.</text>
      <text start="35" dur="4">How many nodes would we now expand in Breadth First Search,</text>
      <text start="39" dur="4">and how many do we expand in Depth First Search?</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 4, Search Tree ANSWER" id="FDTlQfGb9SY">
    <transcript>
      <text start="0" dur="3">[Thrun] Breadth first from left to right is 6--</text>
      <text start="3" dur="4">1, 2, 3, 4, 5, 6.</text>
      <text start="7" dur="8">Depth first from left to right is 4--1, 2, 3, 4.</text>
      <text start="15" dur="4">Breadth first searched from right to left is 9--</text>
      <text start="19" dur="6">1, 2, 3, 4, 5, 6, 7, 8, 9.</text>
      <text start="25" dur="3">And depth first from right to left is 9--</text>
      <text start="28" dur="10">1, 2, 3, 4, 5, 6, 7, 8, 9.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 5, Another Search Tree" id="vWNEaVcK2gU">
    <transcript>
      <text start="0" dur="3">Another search problem--</text>
      <text start="3" dur="5">Consider the following search tree,</text>
      <text start="8" dur="4">where this is the start node.</text>
      <text start="12" dur="3">Now, assume we search from left to right.</text>
      <text start="15" dur="4">I would like you to tell me the number of nodes expanded from Breadth-First Search</text>
      <text start="19" dur="3">and Depth-First Search.</text>
      <text start="22" dur="3">Please do count the start and the goal node,</text>
      <text start="25" dur="3">and please give me the same numbers for Right-to-Left Search,</text>
      <text start="28" dur="3">for Breadth-First, and Depth-First.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 5, Another Search Tree ANSWER" id="V_eXNj-LA9E">
    <transcript>
      <text start="0" dur="5">[Thrun] The correct answer for breadth first left to right is 13--</text>
      <text start="5" dur="8">1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13.</text>
      <text start="13" dur="4">And for depth first it is 10--</text>
      <text start="17" dur="11">1, 2, 3, 4, 5, 6, 7, 8, 9, and 10.</text>
      <text start="28" dur="4">For right to left search, the right answer for breadth first is 11--</text>
      <text start="32" dur="6">1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11.</text>
      <text start="38" dur="4">And for depth first the right answer is 7--</text>
      <text start="42" dur="6">1, 2, 3, 4, 5, 6, 7.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 6, Search Network" id="IQhUlwJaBqc">
    <transcript>
      <text start="0" dur="4">This is another search problem.</text>
      <text start="4" dur="3">Let&amp;#39;s assume we have a search graph.</text>
      <text start="7" dur="6">It isn&amp;#39;t quite a tree but looks like this.</text>
      <text start="13" dur="5">Obviously in the structure we can reach nodes through multiple paths.</text>
      <text start="18" dur="4">So let&amp;#39;s assume that our search never expands the same node twice.</text>
      <text start="22" dur="5">Let&amp;#39;s also assume this start node is on top. We search down.</text>
      <text start="27" dur="3">And this over here is our goal node.</text>
      <text start="30" dur="5">So left-to-right search, tell me how many nodes</text>
      <text start="35" dur="8">breadth first would expand--do count the start and goal node in the final answer.</text>
      <text start="43" dur="5">Give me the same result for a depth-first search.</text>
      <text start="48" dur="3">Again counting the start and the goal node in your answer.</text>
      <text start="51" dur="3">And again give me your answer for breadth-first</text>
      <text start="54" dur="6">and for depth-first in the right-to-left search paradigm.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 6, Search Network ANSWER" id="mXT-9-K5OtU">
    <transcript>
      <text start="0" dur="5">[Thrun] The right answer over here is 10 for breadth first from left to right--</text>
      <text start="5" dur="6">1, 2, 3, 4, 5, 6, 7, 8, 9, 10.</text>
      <text start="11" dur="4">Depth first is 16, or all nodes--</text>
      <text start="15" dur="15">1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16.</text>
      <text start="30" dur="4">And notice how I never expanded a node twice.</text>
      <text start="34" dur="4">Correct answer for breadth first right to left is 7--</text>
      <text start="38" dur="5">1, 2, 3, 4, 5, 6, 7.</text>
      <text start="43" dur="6">And the correct answer for depth first from right to left is 4--1, 2, 3, and 4.</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 7, A* Search" id="V4h2H0jpGsg">
    <transcript>
      <text start="0" dur="3">Let&amp;#39;s talk about a star search.</text>
      <text start="3" dur="5">Let&amp;#39;s assume we have the following grid.</text>
      <text start="8" dur="5">The start state is right here.</text>
      <text start="13" dur="3">And the goal state is right here.</text>
      <text start="16" dur="6">And just for convenience, I will give each here a little number.</text>
      <text start="22" dur="4">A. B. C. D.</text>
      <text start="26" dur="4">Let me draw a heuristic function.</text>
      <text start="30" dur="2">Please take a look for a moment</text>
      <text start="32" dur="6">and tell me whether this heuristic function is admissable.</text>
      <text start="38" dur="3">Check here if yes and here if no.</text>
      <text start="41" dur="5">Which one is the first node a star would expand?</text>
      <text start="46" dur="5">B1 or A2?</text>
      <text start="51" dur="5">What&amp;#39;s the second node to expand?</text>
      <text start="56" dur="10">B1, C1, A2, A3, or B2?</text>
      <text start="66" dur="4">And finally, what is the third node to expand?</text>
      <text start="70" dur="6">D1, C2, B3, or A4?</text>
    </transcript>
  </video>
  <video title="Homework 1, Question 7, A* Search ANSWER" id="forv6djwNWM">
    <transcript>
      <text start="0" dur="5">[Thrun] Clearly this is an admissable heuristic because the distance to the goal</text>
      <text start="5" dur="2">is strictly underestimated.</text>
      <text start="7" dur="2">From here it would take 1 step,</text>
      <text start="9" dur="6">from here it will take 1, 2 steps, so the answer is yes.</text>
      <text start="15" dur="7">Now, to understand A*, let me also draw the g function</text>
      <text start="22" dur="2">for development part of this table.</text>
      <text start="24" dur="3">Clearly g is 0 over here.</text>
      <text start="27" dur="4">To understand which node to expand, this one or this one,</text>
      <text start="31" dur="3">let&amp;#39;s project the g function, which is 1,</text>
      <text start="34" dur="6">and we will see that 3 plus 1 is smaller than 4 plus 1;</text>
      <text start="40" dur="7">therefore, this is the second node to expand, which is b1.</text>
      <text start="47" dur="8">Now let me for the next step explain the g function from this guy here, 2 and 2.</text>
      <text start="55" dur="13">So 2 plus 2 is 4 versus 3 plus 2 is 5, so we expand this node next, which is c1.</text>
      <text start="68" dur="6">And finally, the g function from here would go 3 and 3.</text>
      <text start="74" dur="10">3 plus 1 is better than 3 plus 2, so we would expand d1 next.</text>
      <text start="84" dur="5">And notice how in the sum of g and h,</text>
      <text start="89" dur="6">this node over here, which has a total of 4, is better than any other node that is unexpanded.</text>
      <text start="95" dur="5">So in particular, 4 plus 1 is 5, and 3 plus 2 is 5 as well,</text>
      <text start="100" dur="4">and 2 plus 3 is 5 as well, so this is the next one to expand.</text>
    </transcript>
  </video>
  <video title="Unit 3 1 Introduction" id="-8DyY8_IuA0">
    <transcript>
      <text start="0" dur="3">So the next units will be concerned with probabilities</text>
      <text start="3" dur="5">and particularly with structured probabilities using Bayes networks.</text>
      <text start="8" dur="4">This is some of the most involved material in this class.</text>
      <text start="12" dur="2">And since this is a Stanford level class,</text>
      <text start="14" dur="4">you will find out that some of the quizzes are actually really hard.</text>
      <text start="18" dur="5">So as you go through the material, I hope the hardness of the quizzes won&amp;#39;t discourage you;</text>
      <text start="23" dur="7">it&amp;#39;ll really entice you to take a piece of paper and a pen and work them out.</text>
      <text start="30" dur="5">Let me give you a flavor of a Bayes network using an example.</text>
      <text start="35" dur="4">Suppose you find in the morning that your car won&amp;#39;t start.</text>
      <text start="39" dur="4">Well, there&amp;#39;s many causes why your car might not start.</text>
      <text start="43" dur="3">One is that your battery is flat.</text>
      <text start="46" dur="4">Even for a flat battery there is multiple causes.</text>
      <text start="50" dur="2">One, it&amp;#39;s just plain dead,</text>
      <text start="52" dur="3">and one is that the battery is okay but it&amp;#39;s not charging.</text>
      <text start="55" dur="6">The reason why a battery might not charge is that the alternator might be broken</text>
      <text start="61" dur="2">or the fan belt might be broken.</text>
      <text start="63" dur="4">If you look at this influence diagram, also called a Bayes network,</text>
      <text start="67" dur="5">you&amp;#39;ll find there&amp;#39;s many different ways to explain that the car won&amp;#39;t start.</text>
      <text start="72" dur="5">And a natural question you might have is, &amp;quot;Can we diagnose the problem?&amp;quot;</text>
      <text start="77" dur="3">One diagnostic tool is a battery meter,</text>
      <text start="80" dur="6">which may increase or decrease your belief that the battery may cause your car failure.</text>
      <text start="86" dur="3">You might also know your battery age.</text>
      <text start="89" dur="2">Older batteries tend to go dead more often.</text>
      <text start="91" dur="6">And there&amp;#39;s many other ways to look at reasons why the car might not start.</text>
      <text start="97" dur="6">You might inspect the lights, the oil light, the gas gauge.</text>
      <text start="103" dur="5">You might even dip into the engine to see what the oil level is with a dipstick.</text>
      <text start="108" dur="4">All of those relate to alternative reasons why the car might not be starting,</text>
      <text start="112" dur="7">like no oil, no gas, the fuel line might be blocked, or the starter may be broken.</text>
      <text start="119" dur="5">And all of these can influence your measurements,</text>
      <text start="124" dur="3">like the oil light or the gas gauge, in different ways.</text>
      <text start="127" dur="5">For example, the battery flat would have an effect on the lights.</text>
      <text start="132" dur="4">It might have an effect on the oil light and on the gas gauge,</text>
      <text start="136" dur="4">but it won&amp;#39;t really affect the oil you measure with the dipstick.</text>
      <text start="140" dur="6">That is affected by the actual oil level, which also affects the oil light.</text>
      <text start="146" dur="6">Gas will affect the gas gauge, and of course without gas the car doesn&amp;#39;t start.</text>
      <text start="152" dur="7">So this is a complicated structure that really describes one way to understand</text>
      <text start="159" dur="2">how a car doesn&amp;#39;t start.</text>
      <text start="161" dur="2">A car is a complex system.</text>
      <text start="163" dur="3">It has lots of variables you can&amp;#39;t really measure immediately,</text>
      <text start="166" dur="6">and it has sensors which allow you to understand a little bit about the state of the car.</text>
      <text start="172" dur="2">What the Bayes network does,</text>
      <text start="174" dur="7">it really assists you in reasoning from observable variables, like the car won&amp;#39;t start</text>
      <text start="181" dur="5">and the value of the dipstick, to hidden causes, like is the fan belt broken</text>
      <text start="186" dur="3">or is the battery dead.</text>
      <text start="189" dur="4">What you have here is a Bayes network.</text>
      <text start="193" dur="2">A Bayes network is composed of nodes.</text>
      <text start="195" dur="6">These nodes correspond to events that you might or might not know</text>
      <text start="201" dur="3">that are typically called random variables.</text>
      <text start="204" dur="7">These nodes are linked by arcs, and the arcs suggest that a child of an arc</text>
      <text start="211" dur="4">is influenced by its parent but not in a deterministic way.</text>
      <text start="215" dur="6">It might be influenced in a probabilistic way, which means an older battery, for example,</text>
      <text start="221" dur="4">has a higher chance of causing the battery to be dead,</text>
      <text start="225" dur="3">but it&amp;#39;s not clear that every old battery is dead.</text>
      <text start="228" dur="5">There is a total of 16 variables in this Bayes network.</text>
      <text start="233" dur="6">What the graph structure and associated probabilities specify</text>
      <text start="239" dur="7">is a huge probability distribution in the space of all of these 16 variables.</text>
      <text start="246" dur="4">If they are all binary, which we&amp;#39;ll assume throughout this unit,</text>
      <text start="250" dur="5">they can take 2 to the 16th different values, which is a lot.</text>
      <text start="255" dur="3">The Bayes network, as we find out, is a complex representation</text>
      <text start="258" dur="8">of a distribution over this very, very large joint probability distribution of all of these variables.</text>
      <text start="266" dur="3">Further, once we specify the Bayes network,</text>
      <text start="269" dur="4">we can observe, for example, the car won&amp;#39;t start.</text>
      <text start="273" dur="4">We can observe things like the oil light and the lights and the battery meter</text>
      <text start="277" dur="4">and then compute probabilities of the hypothesis, like the alternator is broken</text>
      <text start="281" dur="4">or the fan belt is broken or the battery is dead.</text>
      <text start="285" dur="5">So in this class we&amp;#39;re going to talk about how to construct this Bayes network,</text>
      <text start="290" dur="6">what the semantics are, and how to reason in this Bayes network</text>
      <text start="296" dur="6">to find out about variables we can&amp;#39;t observe, like whether the fan belt is broken or not.</text>
      <text start="302" dur="2">That&amp;#39;s an overview.</text>
      <text start="304" dur="4">Throughout this unit I am going to assume that every event is discrete--</text>
      <text start="308" dur="2">in fact, it&amp;#39;s binary.</text>
      <text start="310" dur="4">We&amp;#39;ll start with some consideration of basic probability,</text>
      <text start="314" dur="5">we&amp;#39;ll work our way into some simple Bayes networks,</text>
      <text start="319" dur="4">we&amp;#39;ll talk about concepts like conditional independence</text>
      <text start="323" dur="3">and then define Bayes networks more generally,</text>
      <text start="326" dur="6">move into concepts like D-separation and start doing parameter counts.</text>
      <text start="332" dur="4">Later on, Peter will tell you about inference in Bayes networks.</text>
      <text start="336" dur="2">So we won&amp;#39;t do this in this class.</text>
      <text start="338" dur="5">I can&amp;#39;t overemphasize how important this class is.</text>
      <text start="343" dur="6">Bayes networks are used extensively in almost all fields of smart computer system,</text>
      <text start="349" dur="8">in diagnostics, for prediction, for machine learning, and fields like finance,</text>
      <text start="357" dur="3">inside Google, in robotics.</text>
      <text start="360" dur="5">Bayes networks are also the building blocks of more advanced AI techniques</text>
      <text start="365" dur="7">such as particle filters, hidden Markov models, MDPs and POMDPs,</text>
      <text start="372" dur="2">Kalman filters, and many others.</text>
      <text start="374" dur="4">These are words that don&amp;#39;t sound familiar quite yet,</text>
      <text start="378" dur="4">but as you go through the class, I can promise you you will get to know what they mean.</text>
      <text start="382" dur="4">So let&amp;#39;s start now at the very, very basics.</text>
    </transcript>
  </video>
  <video title="Unit 3 2 Probabilities" id="EdONkI3RNKg">
    <transcript>
      <text start="0" dur="2">[Thrun] So let&amp;#39;s talk about probabilities.</text>
      <text start="2" dur="3">Probabilities are the cornerstone of artificial intelligence.</text>
      <text start="5" dur="3">They are used to express uncertainty,</text>
      <text start="8" dur="4">and the management of uncertainty is really key to many, many things in AI</text>
      <text start="12" dur="4">such as machine learning and Bayes network inference</text>
      <text start="16" dur="5">and filtering and robotics and computer vision and so on.</text>
      <text start="21" dur="3">So I&amp;#39;m going to start with some very basic questions,</text>
      <text start="24" dur="2">and we&amp;#39;re going to work our way up from there.</text>
      <text start="26" dur="2">Here is a coin.</text>
      <text start="28" dur="4">The coin can come up heads or tails, and my question is the following:</text>
      <text start="32" dur="6">Suppose the probability for heads is 0.5.</text>
      <text start="38" dur="2">What&amp;#39;s the probability for it coming up tails?</text>
    </transcript>
  </video>
  <video title="Unit 3 2a Answer" id="orhhEZGH_Es">
    <transcript>
      <text start="0" dur="3">[Thrun] So the right answer is a half, or 0.5,</text>
      <text start="3" dur="4">and the reason is the coin can only come up heads or tails.</text>
      <text start="7" dur="3">We know that it has to be either one.</text>
      <text start="10" dur="4">Therefore, the total probability of both coming up is 1.</text>
      <text start="14" dur="5">So if half of the probability is assigned to heads, then the other half is assigned to tail.</text>
    </transcript>
  </video>
  <video title="Unit 3 2b Question" id="Ee9g6dhDL9A">
    <transcript>
      <text start="0" dur="2">[Thrun] Let me ask my next quiz.</text>
      <text start="2" dur="4">Suppose the probability of heads is a quarter, 0.25.</text>
      <text start="6" dur="2">What&amp;#39;s the probability of tail?</text>
    </transcript>
  </video>
  <video title="Unit 3 2c Answer" id="84KcxfggKRg">
    <transcript>
      <text start="0" dur="2">[Thrun] And the answer is 3/4.</text>
      <text start="2" dur="3">It&amp;#39;s a loaded coin, and the reason is, well,</text>
      <text start="5" dur="3">each of them come up with a certain probability.</text>
      <text start="8" dur="4">The total of those is 1. The quarter is claimed by heads.</text>
      <text start="12" dur="5">Therefore, 3/4 remain for tail, which is the answer over here.</text>
    </transcript>
  </video>
  <video title="Unit 3 2d Question" id="koOpSPz-voY">
    <transcript>
      <text start="0" dur="2">[Thrun] Here&amp;#39;s another quiz.</text>
      <text start="2" dur="6">What&amp;#39;s the probability that the coin comes up heads, heads, heads, three times in a row,</text>
      <text start="8" dur="4">assuming that each one of those has a probability of a half</text>
      <text start="12" dur="2">and that these coin flips are independent?</text>
    </transcript>
  </video>
  <video title="Unit 3 2e Answer" id="7pZQS5inJXs">
    <transcript>
      <text start="0" dur="4">[Thrun] And the answer is 0.125.</text>
      <text start="4" dur="2">Each head has a probability of a half.</text>
      <text start="6" dur="4">We can multiply those probabilities because they are independent events,</text>
      <text start="10" dur="4">and that gives us 1 over 8 or 0.125.</text>
    </transcript>
  </video>
  <video title="Unit 3 2f Question" id="KatS5xl7vn8">
    <transcript>
      <text start="0" dur="11">[Thrun] Now let&amp;#39;s flip the coin 4 times, and let&amp;#39;s call Xi the result of the i-th coin flip.</text>
      <text start="11" dur="5">So each Xi is going to be drawn from heads or tail.</text>
      <text start="16" dur="6">What&amp;#39;s the probability that all 4 of those flips give us the same result,</text>
      <text start="22" dur="4">no matter what it is, assuming that each one of those has identically</text>
      <text start="26" dur="6">an equally distributed probability of coming up heads of the half?</text>
    </transcript>
  </video>
  <video title="Unit 3 2g Answer" id="g_M3o3QXBjo">
    <transcript>
      <text start="0" dur="4">[Thrun] And the answer is, well, there&amp;#39;s 2 ways that we can achieve this.</text>
      <text start="4" dur="2">One is the all heads and one is all tails.</text>
      <text start="6" dur="4">You already know that 4 times heads is 1/16,</text>
      <text start="10" dur="3">and we know that 4 times tail is also 1/16.</text>
      <text start="13" dur="2">These are completely independent events.</text>
      <text start="15" dur="8">The probability of either one occurring is 1/16 plus 1/16, which is 1/8, which is 0.125.</text>
    </transcript>
  </video>
  <video title="Unit 3 2h Question" id="hdQER9u46yU">
    <transcript>
      <text start="0" dur="2">[Thrun] So here&amp;#39;s another one.</text>
      <text start="2" dur="5">What&amp;#39;s the probability that within the set of X1, X2, X3, and X4</text>
      <text start="7" dur="3">there are at least three heads?</text>
    </transcript>
  </video>
  <video title="Unit 3 2i Answer" id="FEqiaraw3GE">
    <transcript>
      <text start="0" dur="3">[Thrun] And the solution is let&amp;#39;s look at different sequences</text>
      <text start="3" dur="3">in which head occurs at least 3 times.</text>
      <text start="6" dur="4">It could be head, head, head, head, in which it comes 4 times.</text>
      <text start="10" dur="6">It could be head, head, head, tail and so on, all the way to tail, head, head, head.</text>
      <text start="16" dur="3">There&amp;#39;s 1, 2, 3, 4, 5 of those outcomes.</text>
      <text start="19" dur="9">Each of them has a 16th for probability, so it&amp;#39;s 5 times a 16th, which is 0.3125.</text>
    </transcript>
  </video>
  <video title="Unit 3 2j Summary" id="Xblzy61pBDQ">
    <transcript>
      <text start="0" dur="2">[Thrun] So we just learned a number of things.</text>
      <text start="2" dur="3">One is about complementary probability.</text>
      <text start="5" dur="3">If an event has a certain probability, p,</text>
      <text start="8" dur="5">the complementary event has the probability 1-p.</text>
      <text start="13" dur="2">We also learned about independence.</text>
      <text start="15" dur="4">If 2 random variables, X and Y, are independent,</text>
      <text start="19" dur="2">which you&amp;#39;re going to write like this,</text>
      <text start="21" dur="5">that means the probability of the joint that any 2 variables can assume</text>
      <text start="26" dur="4">is the product of the marginals.</text>
      <text start="30" dur="4">So rather than asking the question, &amp;quot;What is the probability</text>
      <text start="34" dur="6">&amp;quot;for any combination that these 2 coins or maybe 5 coins could have taken?&amp;quot;</text>
      <text start="40" dur="2">we can now look at the probability of each coin individually,</text>
      <text start="42" dur="3">look at its probability and just multiply them up.</text>
    </transcript>
  </video>
  <video title="Unit 3 3 Dependence" id="uy0sL0DGV7o">
    <transcript>
      <text start="0" dur="3">[Thrun] So let me ask you about dependence.</text>
      <text start="3" dur="2">Suppose we flip 2 coins.</text>
      <text start="5" dur="7">Our first coin is a fair coin, and we&amp;#39;re going to denote the outcome by X1.</text>
      <text start="12" dur="3">So the chance of X1 coming up heads is half.</text>
      <text start="15" dur="5">But now we branch into picking a coin based on the first outcome.</text>
      <text start="20" dur="3">So if the first outcome was heads,</text>
      <text start="23" dur="5">you pick a coin whose probability of coming up heads is going to be 0.9.</text>
      <text start="28" dur="4">The way I word this is by conditional probability,</text>
      <text start="32" dur="3">probability of the second coin flip coming up heads</text>
      <text start="35" dur="6">provided that or given that X1, the first coin flip, was heads, is 0.9.</text>
      <text start="41" dur="3">The first coin flip might also come up tails,</text>
      <text start="44" dur="3">in which case I pick a very different coin.</text>
      <text start="47" dur="7">In this case I pick a coin which with 0.8 probability will once again give me tails,</text>
      <text start="54" dur="3">conditioned on the first coin flip coming up tails.</text>
      <text start="57" dur="2">So my question for you is,</text>
      <text start="59" dur="5">what&amp;#39;s the probability of the second coin flip coming up heads?</text>
    </transcript>
  </video>
  <video title="Unit 3 3a Answer" id="kpdV5I5WHW8">
    <transcript>
      <text start="0" dur="4">[Thrun] The answer is 0.55.</text>
      <text start="4" dur="4">The way to compute this is by the theorem of total probability.</text>
      <text start="8" dur="4">Probability of X2 equals heads.</text>
      <text start="12" dur="3">There&amp;#39;s 2 ways I can get to this outcome.</text>
      <text start="15" dur="3">One is via this path over here, and one is via this path over here.</text>
      <text start="18" dur="2">Let me just write both of them down.</text>
      <text start="20" dur="6">So first of all, it could be the probability of X2 equals heads</text>
      <text start="26" dur="4">given that and I will assume X1 was head already.</text>
      <text start="30" dur="2">Now I have to add the complementary event.</text>
      <text start="32" dur="3">Suppose X1 came up tails.</text>
      <text start="35" dur="5">Then I can ask the question, what is the probability that X2 comes up heads regardless,</text>
      <text start="40" dur="2">even though X1 was tails?</text>
      <text start="42" dur="2">Plugging in the numbers gives us the following.</text>
      <text start="44" dur="5">This one over here is 0.9 times a half.</text>
      <text start="49" dur="2">The probability of tails is 0.8,</text>
      <text start="51" dur="7">thereby my head probability becomes 1 minus 0.8, which is 0.2.</text>
      <text start="58" dur="5">Adding all of this together gives me 0.45 plus 0.1,</text>
      <text start="63" dur="3">which is exactly 0.55.</text>
    </transcript>
  </video>
  <video title="Unit 3 4 What We Learned" id="9fxuibvkZ9g">
    <transcript>
      <text start="0" dur="2">So, we actually just learned some interesting lessons.</text>
      <text start="2" dur="6">The probability of any random variable Y can be written as</text>
      <text start="8" dur="5">probability of Y given that some other random variable X assumes value i</text>
      <text start="13" dur="4">times probability of X equals i,</text>
      <text start="17" dur="5">sums over all possible outcomes i for the (inaudible) variable X.</text>
      <text start="22" dur="2">This is called total probability.</text>
      <text start="24" dur="3">The second thing we learned has to do with negation of probabilities.</text>
      <text start="27" dur="10">We found that probability of not X given Y is 1 minus probability of X given Y.</text>
      <text start="37" dur="6">Now, you might be tempted to say &amp;quot;What about the probability of X given not Y?&amp;quot;</text>
      <text start="43" dur="8">&amp;quot;Is this the same as 1 minus probability of X given Y?&amp;quot;</text>
      <text start="51" dur="3">And the answer is absolutely no.</text>
      <text start="54" dur="2">That&amp;#39;s not the case.</text>
      <text start="56" dur="4">If you condition on something that has a certain probability value,</text>
      <text start="60" dur="3">you can take the event you&amp;#39;re looking at and negate this,</text>
      <text start="63" dur="2">but you can never negate your conditional variable</text>
      <text start="65" dur="2">and assume these values add up to 1.</text>
    </transcript>
  </video>
  <video title="Unit 3 5 Weather Quiz" id="RRYo6jVL6ao">
    <transcript>
      <text start="0" dur="6">We assume there is sometimes sunny days and sometimes rainy days,</text>
      <text start="6" dur="3">and on day 1, which we&amp;#39;re going to call D1,</text>
      <text start="9" dur="4">the probability of sunny is 0.9.</text>
      <text start="13" dur="7">And then let&amp;#39;s assume that a sunny day follows a sunny day with 0.8 chance,</text>
      <text start="20" dur="5">and a rainy day follows a sunny day with--well--</text>
    </transcript>
  </video>
  <video title="Unit 3 5a Answer" id="GqCNDJhZQnc">
    <transcript>
      <text start="0" dur="5">Well, the correct answer is 0.2, which is a negation of this event over here.</text>
    </transcript>
  </video>
  <video title="Unit 3 5b Question" id="ASgU5Ekoz-A">
    <transcript>
      <text start="0" dur="6">A sunny day follows a rainy day with 0.6 chance,</text>
      <text start="6" dur="5">and a rainy day follows a rainy day--</text>
      <text start="11" dur="2">please give me your number.</text>
    </transcript>
  </video>
  <video title="Unit 3 5c Answer" id="KgEX10LtY8Y">
    <transcript>
      <text start="0" dur="3">0.4</text>
    </transcript>
  </video>
  <video title="Unit 3 5d Question" id="aEVUaEK84UQ">
    <transcript>
      <text start="0" dur="3">So, what are the chances that D2 is sunny?</text>
      <text start="3" dur="3">Suppose the same dynamics apply from D2 to D3,</text>
      <text start="6" dur="4">so just replace D3 over here with D2s over there.</text>
      <text start="10" dur="4">That means the transition probabilities from one day to the next remain the same.</text>
      <text start="14" dur="4">Tell me, what&amp;#39;s the probability that D3 is sunny?</text>
    </transcript>
  </video>
  <video title="Unit 3 5e Answer" id="tn9chzKS9sM">
    <transcript>
      <text start="0" dur="4">So, the correct answer over here is 0.78,</text>
      <text start="4" dur="6">and over here it&amp;#39;s 0.756.</text>
      <text start="10" dur="3">To get there, let&amp;#39;s complete this one first.</text>
      <text start="13" dur="3">The probability of D2 = sunny.</text>
      <text start="16" dur="5">Well, we know there&amp;#39;s a 0.9 chance it&amp;#39;s sunny on D1,</text>
      <text start="21" dur="4">and then if it is sunny, we know it stays sunny with a 0.8 chance.</text>
      <text start="25" dur="4">So, we multiply these 2 things together, and we get 0.72.</text>
      <text start="29" dur="4">We know there&amp;#39;s a 0.1 chance of it being rainy on day 1, which is the complement,</text>
      <text start="33" dur="4">but if it&amp;#39;s rainy, we know it switches to sunny with 0.6 chance,</text>
      <text start="37" dur="4">so you multiply these 2 things, and you get 0.06.</text>
      <text start="41" dur="5">Adding those two up equals 0.78.</text>
      <text start="46" dur="5">Now, for the next day, we know our prior for sunny is 0.78.</text>
      <text start="51" dur="4">If it is sunny, it stays sunny with 0.8 probability.</text>
      <text start="55" dur="6">Multiplying these 2 things gives us 0.624.</text>
      <text start="61" dur="6">We know it&amp;#39;s rainy with 0.2 chance, which is the complement of 0.78,</text>
      <text start="67" dur="3">but a 0.6 chance if it was (inaudible) sunny.</text>
      <text start="70" dur="4">But if you multiply those, 0.132.</text>
      <text start="74" dur="5">Adding those 2 things up gives us 0.756.</text>
      <text start="79" dur="4">So, to some extents, it&amp;#39;s tedious to compute these values,</text>
      <text start="83" dur="2">but they can be perfectly computed, as shown here.</text>
    </transcript>
  </video>
  <video title="Unit 3 6 Cancer Quiz" id="nhIDr-yogzg">
    <transcript>
      <text start="0" dur="5">Next example is a cancer example.</text>
      <text start="5" dur="6">Suppose there&amp;#39;s a specific type of cancer which exists for 1% of the population.</text>
      <text start="11" dur="2">I&amp;#39;m going to write this as follows.</text>
      <text start="13" dur="6">You can probably tell me now what the probability of not having this cancer is.</text>
    </transcript>
  </video>
  <video title="Unit 3 6a Answer and Cancer Test" id="_NRpTjkvWv0">
    <transcript>
      <text start="0" dur="4">And yes, the answer is 0.99.</text>
      <text start="4" dur="3">Let&amp;#39;s assume there&amp;#39;s a test for this cancer,</text>
      <text start="7" dur="5">which gives us probabilistically an answer whether we have this cancer or not.</text>
      <text start="12" dur="6">So, let&amp;#39;s say the probability of a test being positive, as indicated by this + sign,</text>
      <text start="18" dur="4">given that we have cancer, is 0.9.</text>
      <text start="22" dur="6">The probability of the test coming out negative if we have the cancer is--you name it.</text>
    </transcript>
  </video>
  <video title="Unit 3 6b Answer" id="sAnyHLFbiXg">
    <transcript>
      <text start="0" dur="6">0.1, which is the difference between 1 and 0.9.</text>
      <text start="6" dur="5">Let&amp;#39;s assume the probability of the test coming out positive</text>
      <text start="11" dur="4">given that we don&amp;#39;t have this cancer is 0.2.</text>
      <text start="15" dur="4">In other words, the probability of the test correctly saying</text>
      <text start="19" dur="5">we don&amp;#39;t have the cancer if we&amp;#39;re cancer free is 0.8.</text>
      <text start="24" dur="4">Now, ultimately, I&amp;#39;d like to know what&amp;#39;s the probability</text>
      <text start="28" dur="7">they have this cancer given they just received a single, positive test?</text>
      <text start="35" dur="4">Before I do this, please help me filling out some other probabilities</text>
      <text start="39" dur="2">that are actually important.</text>
      <text start="41" dur="4">Specifically, the joint probabilities.</text>
      <text start="45" dur="6">The probability of a positive test and having cancer.</text>
      <text start="51" dur="2">The probability of a negative test and having cancer,</text>
      <text start="53" dur="2">and this is not conditional anymore.</text>
      <text start="55" dur="2">It&amp;#39;s now a joint probability.</text>
      <text start="57" dur="4">So, please give me those 4 values over here.</text>
    </transcript>
  </video>
  <video title="Unit 3 6c Answer" id="PCKlid_iMNo">
    <transcript>
      <text start="0" dur="5">And here the correct answer is 0.009,</text>
      <text start="5" dur="7">which is the product of your prior, 0.01, times the conditional, 0.9.</text>
      <text start="12" dur="9">Over here we get 0.001, the probability of our prior cancer times 0.1.</text>
      <text start="21" dur="5">Over here we get 0.198,</text>
      <text start="26" dur="3">the probability of not having cancer is 0.99</text>
      <text start="29" dur="3">times still getting a positive reading, which is 0.2.</text>
      <text start="32" dur="5">And finally, we get 0.792,</text>
      <text start="37" dur="3">which is the probability of this guy over here, and this guy over here.</text>
    </transcript>
  </video>
  <video title="Unit 3 6d Question" id="BX_uy8rCS5k">
    <transcript>
      <text start="0" dur="4">Now, our next quiz, I want you to fill in the probability of</text>
      <text start="4" dur="3">the cancer given that we just received a positive test.</text>
    </transcript>
  </video>
  <video title="Unit 3 6e Answer" id="JgYH7UEcA6c">
    <transcript>
      <text start="0" dur="6">And the correct answer is 0.043.</text>
      <text start="6" dur="3">So, even though I received a positive test,</text>
      <text start="9" dur="5">my probability of having cancer is just 4.3%,</text>
      <text start="14" dur="4">which is not very much given that the test itself is quite sensitive.</text>
      <text start="18" dur="8">It really gives me a 0.8 chance of getting a negative result if I don&amp;#39;t have cancer.</text>
      <text start="26" dur="6">It gives me a 0.9 chance of detecting cancer given that I have cancer.</text>
      <text start="32" dur="3">Now, what comes (inaudible) small?</text>
      <text start="35" dur="3">Well, let&amp;#39;s just put all the cases together.</text>
      <text start="38" dur="3">You already know that we received a positive test.</text>
      <text start="41" dur="6">Therefore, this entry over here, and this entry over here are relevant.</text>
      <text start="47" dur="9">Now, the chance of having a positive test and having cancer is 0.009.</text>
      <text start="56" dur="5">Well, I might--when I receive a positive test--have cancer or not cancer,</text>
      <text start="61" dur="5">so we will just normalize by these 2 possible causes for the positive test,</text>
      <text start="66" dur="5">which is 0.009 + 0.198.</text>
      <text start="71" dur="9">We know both these 2 things together gets 0.009 over 0.207,</text>
      <text start="80" dur="3">which is approximately 0.043.</text>
      <text start="83" dur="5">Now, the interesting thing in this equation is that the chances</text>
      <text start="88" dur="4">of having seen a positive test result in the absence of cancers</text>
      <text start="92" dur="3">are still much, much higher than the chance of seeing a positive result</text>
      <text start="95" dur="4">in the presence of cancer, and that&amp;#39;s because our prior for cancer</text>
      <text start="99" dur="5">is so small in the population that it&amp;#39;s just very unlikely to have cancer.</text>
      <text start="104" dur="3">So, the additional information of a positive test</text>
      <text start="107" dur="5">only erased my posterior probability to 0.043.</text>
    </transcript>
  </video>
  <video title="Unit 3 7 Bayes Rule" id="OWCRop639TA">
    <transcript>
      <text start="0" dur="3">So, we&amp;#39;ve just learned about what&amp;#39;s probably the most important</text>
      <text start="3" dur="6">piece of math for this class in statistics called Bayes Rule.</text>
      <text start="9" dur="6">It was invented by Reverend Thomas Bayes, who was a British mathematician</text>
      <text start="15" dur="3">and a Presbyterian minister in the 18th century.</text>
      <text start="18" dur="9">Bayes Rule is usually stated as follows: P of A given B where B is the evidence</text>
      <text start="27" dur="9">and A is the variable we care about is P of B given A times P of A over P of B.</text>
      <text start="36" dur="4">This expression is called the likelihood.</text>
      <text start="40" dur="6">This is called the prior, and this is called marginal likelihood.</text>
      <text start="46" dur="4">The expression over here is called the posterior.</text>
      <text start="50" dur="5">The interesting thing here is the way the probabilities are reworded.</text>
      <text start="55" dur="2">Say we have evidence B.</text>
      <text start="57" dur="4">We know about B, but we really care about the variable A.</text>
      <text start="61" dur="2">So, for example, B is a test result.</text>
      <text start="63" dur="3">We don&amp;#39;t care about the test result as much as we care about the fact</text>
      <text start="66" dur="2">whether we have cancer or not.</text>
      <text start="68" dur="8">This diagnostic reasoning--which is from evidence to its causes--</text>
      <text start="76" dur="6">is turned upside down by Bayes Rule into a causal reasoning,</text>
      <text start="82" dur="5">which is given--hypothetically, if we knew the cause,</text>
      <text start="87" dur="4">what would be the probability of the evidence we just observed.</text>
      <text start="91" dur="5">But to correct for this inversion, we have to multiply</text>
      <text start="96" dur="4">by the prior of the cause to be the case in the first place,</text>
      <text start="100" dur="2">in this case, having cancer or not,</text>
      <text start="102" dur="5">and divide it by the probability of the evidence, P(B),</text>
      <text start="107" dur="5">which often is expanded using the theorem of total probability as follows.</text>
      <text start="112" dur="6">The probability of B is a sum over all probabilities of B</text>
      <text start="118" dur="6">conditional on A, lower caps a, times the probability of A equals lower caps a.</text>
      <text start="124" dur="4">This is total probability as we already encountered it.</text>
      <text start="128" dur="2">So, let&amp;#39;s apply this to the cancer case</text>
      <text start="130" dur="3">and say we really care about whether you have cancer,</text>
      <text start="133" dur="4">which is our cause, conditioned on the evidence</text>
      <text start="137" dur="6">that is the result of this hidden cause, in this case, a positive test result.</text>
      <text start="143" dur="2">Let&amp;#39;s just plug in the numbers.</text>
      <text start="145" dur="5">Our likelihood is the probability of seeing a positive test result</text>
      <text start="150" dur="3">given that you have cancer multiplied by the prior probability</text>
      <text start="153" dur="5">of having cancer over the probability of the positive test result,</text>
      <text start="158" dur="5">and that is--according to the tables we looked at before--</text>
      <text start="163" dur="7">0.9 times a prior of 0.01 over--</text>
      <text start="170" dur="5">now we&amp;#39;re going to expand this right over here according to total probability</text>
      <text start="175" dur="6">which gives us 0.9 times 0.01.</text>
      <text start="181" dur="5">That&amp;#39;s the probability of + given that we do have cancer.</text>
      <text start="186" dur="5">So, the probability of + given that we don&amp;#39;t have cancer is 0.2,</text>
      <text start="191" dur="4">but the prior here is 0.99.</text>
      <text start="195" dur="5">So, if we plug in the numbers we know about, we get 0.009</text>
      <text start="200" dur="7">over 0.009 + 0.198.</text>
      <text start="207" dur="7">That is approximately 0.0434, which is the number we saw before.</text>
    </transcript>
  </video>
  <video title="Unit 3 7a Bayes Rule Graphically" id="1DhY4Cs_qEs">
    <transcript>
      <text start="0" dur="3">So, if you want to draw Bayes rule graphically,</text>
      <text start="3" dur="5">we have a situation where we have an internal variable A,</text>
      <text start="8" dur="5">like whether I&amp;#39;m going to die of cancer, but we can&amp;#39;t sense A.</text>
      <text start="13" dur="3">Instead, we have a second variable, called B,</text>
      <text start="16" dur="5">which is our test, and B is observable, but A isn&amp;#39;t.</text>
      <text start="21" dur="5">This is a classical example of a Bayes network.</text>
      <text start="26" dur="4">The Bayes network is composed of 2 variables, A and B.</text>
      <text start="30" dur="3">We know the prior probability for A,</text>
      <text start="33" dur="2">and we know the conditional.</text>
      <text start="35" dur="3">A causes B--whether or not we have cancer,</text>
      <text start="38" dur="3">causes the test result to be positive or not,</text>
      <text start="41" dur="3">although there was some randomness involved.</text>
      <text start="44" dur="5">So, we know what the probability of B given the different values for A,</text>
      <text start="49" dur="5">and what we care about in this specific instance is called diagnostic reasoning,</text>
      <text start="54" dur="4">which is the inverse of the causal reasoning,</text>
      <text start="58" dur="8">the probability of A given B or similarly, probability of A given not B.</text>
      <text start="66" dur="5">This is our very first Bayes network, and the graphical representation</text>
      <text start="71" dur="4">of drawing 2 variables, A and B, connected with an arc</text>
      <text start="75" dur="7">that goes from A to B is the graphical representation of a distribution</text>
      <text start="82" dur="4">of 2 variables that are specified in the structure over here,</text>
      <text start="86" dur="5">which has a prior probability and has a conditional probability as shown over here.</text>
      <text start="91" dur="3">Now, I do have a quick quiz for you.</text>
      <text start="94" dur="3">How many parameters does it take to specify</text>
      <text start="97" dur="6">the entire joint probability within A and B, or differently, the entire Bayes network?</text>
      <text start="103" dur="5">I&amp;#39;m not looking for structural parameters that relate to the graph over here.</text>
      <text start="108" dur="4">I&amp;#39;m just looking for the numerical parameters of the underlying probabilities.</text>
    </transcript>
  </video>
  <video title="Unit 3 7b Answer" id="Q5luTxpgFaU">
    <transcript>
      <text start="0" dur="2">And the answer is 3.</text>
      <text start="2" dur="7">It takes 1 parameter to specify P of A from which we can derive P of not A.</text>
      <text start="9" dur="6">It takes 2 parameters to specify P of B given A and P given not A,</text>
      <text start="15" dur="6">from which we can derive P not B given A and P of not B given not A.</text>
      <text start="21" dur="3">So, it&amp;#39;s a total of 3 parameters for this Bayes network.</text>
    </transcript>
  </video>
  <video title="Unit 3 8 More Complex Bayes Networks" id="h59XtnoILcQ">
    <transcript>
      <text start="0" dur="3">So, we just encountered our very first Bayes network</text>
      <text start="3" dur="3">and did a number of interesting calculations.</text>
      <text start="6" dur="4">Let&amp;#39;s now talk about Bayes Rule and look into more complex Bayes networks.</text>
      <text start="10" dur="3">I will look at Bayes Rule again and make an observation</text>
      <text start="13" dur="2">that is really non-trivial.</text>
      <text start="15" dur="5">Here is Bayes Rule, and in practice, what we find is</text>
      <text start="20" dur="3">this term here is relatively easy to compute.</text>
      <text start="23" dur="5">It&amp;#39;s just a product, whereas this term is really hard to compute.</text>
      <text start="28" dur="5">However, this term over here does not depend on what we assume for variable A.</text>
      <text start="33" dur="2">It&amp;#39;s just the function of B.</text>
      <text start="35" dur="5">So, suppose for a moment we also care about the complementary event of not A</text>
      <text start="40" dur="3">given B, for which Bayes Rule unfolds as follows.</text>
      <text start="43" dur="4">Then we find that the normalizer, P(B), is identical,</text>
      <text start="47" dur="4">whether we assume A on the left side or not A on the left side.</text>
      <text start="51" dur="6">We also know from prior work that P(A) given B plus</text>
      <text start="57" dur="6">P of not A given B must be one because these are 2 complementary events.</text>
      <text start="63" dur="3">That allows us to compute Bayes Rule very differently</text>
      <text start="66" dur="5">by basically ignoring the normalizer, so here&amp;#39;s how it goes.</text>
      <text start="71" dur="5">We compute P(A) given B--and I want to call this prime,</text>
      <text start="76" dur="7">because it&amp;#39;s not a real probability--to be just P(B) given A times P(A),</text>
      <text start="83" dur="5">which is the normalizer, so the denominator of the expression over here.</text>
      <text start="88" dur="3">We do the same thing with not A.</text>
      <text start="91" dur="5">So, in both cases, we compute the posterior probability non-normalized</text>
      <text start="96" dur="2">by omitting the normalizer B.</text>
      <text start="98" dur="5">And then we can recover the original probabilities by normalizing</text>
      <text start="103" dur="5">based on those values over here, so the probability of A given B,</text>
      <text start="108" dur="4">the actual probability, is a normalizer, eta,</text>
      <text start="112" dur="3">times this non-normalized form over here.</text>
      <text start="115" dur="4">The same is true for the negation of A over here.</text>
      <text start="119" dur="7">And eta is just the normalizer that results by adding these 2 values over here together</text>
      <text start="126" dur="4">as shown over here, and dividing them for one.</text>
      <text start="130" dur="3">So, take a look at this for a moment.</text>
      <text start="133" dur="5">What we&amp;#39;ve done is we deferred the calculation of the normalizer over here</text>
      <text start="138" dur="4">by computing pseudo probabilities that are non-normalized.</text>
      <text start="142" dur="4">This made the calculation much easier, and when we were done with everything,</text>
      <text start="146" dur="3">we just folded it back into the normalizer based on the resulting</text>
      <text start="149" dur="3">pseudo probabilities and got the correct answer.</text>
    </transcript>
  </video>
  <video title="Unit 3 8a Two Test Cancer Example" id="_AJQSBYRAR4">
    <transcript>
      <text start="0" dur="3">The reason why I gave you all this is because I want you to apply it now</text>
      <text start="3" dur="5">to a slightly more complicated problem, which is the 2-test cancer example.</text>
      <text start="8" dur="6">In this example, we again might have our unobservable cancer C,</text>
      <text start="14" dur="4">but now we&amp;#39;re running 2 tests, test 1 and test 2.</text>
      <text start="18" dur="6">As before, the prior probability of cancer is 0.01.</text>
      <text start="24" dur="6">The probability of receiving a positive test result for either test is 0.9.</text>
      <text start="30" dur="6">The probability of getting a negative result given they&amp;#39;re cancer free is 0.8.</text>
      <text start="36" dur="4">And from those, we were able to compute all the other probabilities,</text>
      <text start="40" dur="3">and we&amp;#39;re just going to write them down over here.</text>
      <text start="43" dur="3">So, take a moment to just verify those.</text>
      <text start="46" dur="4">Now, let&amp;#39;s assume both of my tests come back positive,</text>
      <text start="50" dur="6">so T1 = + and T2 = +.</text>
      <text start="56" dur="4">What&amp;#39;s the probability of cancer now written in short form probability of</text>
      <text start="60" dur="3">C given ++?</text>
      <text start="63" dur="5">I want you to tell me what that is, and this is a non-trivial question.</text>
    </transcript>
  </video>
  <video title="Unit 3 8b Answer" id="sjdPqdZQQCI">
    <transcript>
      <text start="0" dur="10">So, the correct answer is 0.1698 approximately,</text>
      <text start="10" dur="5">and to compute this, I used the trick I&amp;#39;ve shown you before.</text>
      <text start="15" dur="9">Let me write down the running count for cancer and for not cancer</text>
      <text start="24" dur="4">as I integrate the various multiplications in Bayes Rule.</text>
      <text start="28" dur="9">My prior for cancer was 0.01 and for non-cancer was 0.99.</text>
      <text start="37" dur="6">Then I get my first +, and the probability of a + given they have cancer is 0.9,</text>
      <text start="43" dur="5">and the same for non-cancer is 0.2.</text>
      <text start="48" dur="4">So, according to the non-normalized Bayes Rule,</text>
      <text start="52" dur="6">I now multiply these 2 things together to get my non-normalized probability</text>
      <text start="58" dur="2">of having cancer given the plus.</text>
      <text start="60" dur="3">Since multiplication is commutative,</text>
      <text start="63" dur="6">I can do the same thing again with my 2nd test result, 0.9 and 0.2,</text>
      <text start="69" dur="5">and I multiply all of these 3 things together to get my non-normalized probability</text>
      <text start="74" dur="7">P prime to be the following: 0.0081, if you multiply those things together,</text>
      <text start="81" dur="7">and 0.0396 if you multiply these facts together.</text>
      <text start="88" dur="2">And these are not a probability.</text>
      <text start="90" dur="4">If we add those for the 2 complementary of cancer/non-cancer,</text>
      <text start="94" dur="4">I get 0.0477.</text>
      <text start="98" dur="4">However, if I now divide, that is, I normalize</text>
      <text start="102" dur="5">those non-normalized probabilities over here by this factor over here,</text>
      <text start="107" dur="5">I actually get the correct posterior probability P of cancer given ++.</text>
      <text start="112" dur="2">And they look as follows:</text>
      <text start="114" dur="6">approximately 0.1698 and approximately 0.8301.</text>
    </transcript>
  </video>
  <video title="Unit 3 8c Question" id="Ah8mhlLsimM">
    <transcript>
      <text start="0" dur="3">Calculate for me the probability of cancer</text>
      <text start="3" dur="5">given that I received one positive and one negative test result.</text>
      <text start="8" dur="2">Please write your number into this box.</text>
    </transcript>
  </video>
  <video title="Unit 3 8d Answer" id="gM1DfM6CGqw">
    <transcript>
      <text start="0" dur="3">We apply the same trick as before</text>
      <text start="3" dur="4">where we use the exact same prior of 0.01.</text>
      <text start="7" dur="6">Our first + gives us the following factors: 0.9 and 0.2.</text>
      <text start="13" dur="7">And our minus gives us the probability 0.1 for a negative first test result given that we have cancer,</text>
      <text start="20" dur="6">and a 0.8 for the inverse of a negative result of not having cancer.</text>
      <text start="26" dur="2">We multiply those together.</text>
      <text start="28" dur="2">We get our non-normalized probability.</text>
      <text start="30" dur="5">And if we now normalize by the sum of those two things</text>
      <text start="35" dur="6">to turn this back into a probability, we get 0.009</text>
      <text start="41" dur="9">over the sum of those two things over here, and this is 0.0056</text>
      <text start="50" dur="9">for the chance of having cancer and 0.9943 for the chance of being cancer free.</text>
      <text start="59" dur="4">And this adds up approximately to 1, and therefore, is a probability distribution.</text>
    </transcript>
  </video>
  <video title="Unit 3 9 Conditional Independence" id="KY3ecsJDnO4">
    <transcript>
      <text start="0" dur="3">I want to use a few words of terminology.</text>
      <text start="3" dur="5">This, again, is a Bayes network, of which the hidden variable C</text>
      <text start="8" dur="8">causes the still stochastic test outcomes T1 and T2.</text>
      <text start="16" dur="3">And what is really important is that we assume not just</text>
      <text start="19" dur="3">that T1 and T2 are identically distributed.</text>
      <text start="22" dur="5">We use the same 0.9 for test 1 as we use for test 2,</text>
      <text start="27" dur="4">but we also assume that they are conditionally independent.</text>
      <text start="31" dur="6">We assumed that if God told us whether we actually had cancer or not,</text>
      <text start="37" dur="4">if we knew with absolute certainty the value of the variable C,</text>
      <text start="41" dur="7">that knowing anything about T1 would not help us make a statement about T2.</text>
      <text start="48" dur="7">Put differently, we assumed that the probability of T2 given C and T1</text>
      <text start="55" dur="5">is the same as the probability of T2 given C.</text>
      <text start="60" dur="8">This is called conditional independence, which is given the value of the cancer variable C.</text>
      <text start="68" dur="9">If you knew this for a fact, then T2 would be independent of T1.</text>
      <text start="77" dur="4">It&amp;#39;s conditionally independent because the independence only holds true</text>
      <text start="81" dur="5">if we actually know C, and it comes out of this diagram over here.</text>
      <text start="86" dur="6">If we look at this diagram, if you knew the variable C over here,</text>
      <text start="92" dur="7">then C separately causes T1 and T2.</text>
      <text start="99" dur="4">So, as a result, if you know C, whatever counted over here</text>
      <text start="106" dur="2">is kind of cut off causally from what happens over here.</text>
      <text start="108" dur="4">That causes these 2 variables to be conditionally independent.</text>
      <text start="112" dur="6">So, conditional independence is a really big thing in Bayes networks.</text>
      <text start="118" dur="4">Here&amp;#39;s a Bayes network where A causes B and C,</text>
      <text start="122" dur="6">and for a Bayes network of this structure, we know that given A,</text>
      <text start="128" dur="3">B and C are independent.</text>
      <text start="131" dur="5">It&amp;#39;s written as B conditionally independent of C given A.</text>
      <text start="136" dur="2">So, here&amp;#39;s a question.</text>
      <text start="138" dur="3">Suppose we have conditional independence between B and C given A.</text>
      <text start="141" dur="7">Would that imply--and there&amp;#39;s my question--that B and C are independent?</text>
      <text start="148" dur="2">So, suppose we don&amp;#39;t know A.</text>
      <text start="150" dur="3">We don&amp;#39;t know whether we have cancer, for example.</text>
      <text start="153" dur="5">What that means is that the test results individually are still independent of each other</text>
      <text start="158" dur="4">even if we don&amp;#39;t know about the cancer situation.</text>
      <text start="162" dur="3">Please answer yes or no.</text>
    </transcript>
  </video>
  <video title="Unit 3 9a Answer" id="lb6A1Ov-mlQ">
    <transcript>
      <text start="0" dur="3">And the correct answer is No</text>
      <text start="3" dur="5">Intuitively, getting a positive test result about cancer</text>
      <text start="8" dur="5">gives us information about whether you have cancer or not.</text>
      <text start="13" dur="2">So if you get a positive test result</text>
      <text start="15" dur="3">you&amp;#39;re going to raise the probability of having cancer</text>
      <text start="18" dur="2">relative to the prior probability.</text>
      <text start="20" dur="4">With that increased probability we will predict</text>
      <text start="24" dur="3">that another test will with a higher likelihood</text>
      <text start="27" dur="6">give us a positive response than if we hadn&amp;#39;t taken the previous test.</text>
      <text start="33" dur="3">That&amp;#39;s really important to understand</text>
      <text start="36" dur="5">So that we understand it let me make you calculate those probabilities</text>
    </transcript>
  </video>
  <video title="Unit 3 9b Question" id="EmLvORqH-Dg">
    <transcript>
      <text start="0" dur="5">Let me draw the cancer example again with two tests.</text>
      <text start="5" dur="2">Here&amp;#39;s my cancer variable</text>
      <text start="7" dur="6">and then there&amp;#39;s two conditionally independent tests T1 and T2.</text>
      <text start="13" dur="6">And as before let me assume that the prior probability of cancer is 0.01</text>
      <text start="19" dur="7">What I want you to compute for me is the probability of the second test</text>
      <text start="26" dur="7">to be positive if we know that the first test was positive.</text>
      <text start="33" dur="2">So write this into the following box.</text>
    </transcript>
  </video>
  <video title="Unit 3 9c Answer" id="6d2lH9JP6kw">
    <transcript>
      <text start="0" dur="4">So, for this one, we want to apply total probability.</text>
      <text start="4" dur="6">This thing over here is the same as probability of test 2 to be positive,</text>
      <text start="10" dur="4">which I&amp;#39;m going to abbreviate with a +2 over here,</text>
      <text start="14" dur="5">conditioned on test 1 being positive and me having cancer</text>
      <text start="19" dur="6">times the probability of me having cancer given test 1 was positive plus</text>
      <text start="25" dur="6">the probability of test 2 being positive conditioned on test 1 being positive</text>
      <text start="31" dur="5">and me not having cancer times the probability of me not having cancer</text>
      <text start="36" dur="2">given that test 1 is positive.</text>
      <text start="38" dur="4">That&amp;#39;s the same as the theorem of total probability,</text>
      <text start="42" dur="4">but now everything is conditioned on +1.</text>
      <text start="46" dur="2">Take a moment to verify this.</text>
      <text start="48" dur="2">Now, here I can plug in the numbers.</text>
      <text start="50" dur="7">You already calculated this one before, which is approximately 0.043,</text>
      <text start="57" dur="8">and this one over here is 1 minus that, which is 0.957 approximately.</text>
      <text start="65" dur="4">And this term over here now exploits conditional independence,</text>
      <text start="69" dur="5">which is given that I know C, knowledge of the first test</text>
      <text start="74" dur="3">gives me no more information about the second test.</text>
      <text start="77" dur="4">It only gives me information if C was unknown, as was the case over here.</text>
      <text start="81" dur="3">So, I can rewrite this thing over here as follows:</text>
      <text start="84" dur="3">P of +2 given that I have cancer.</text>
      <text start="87" dur="4">I can drop the +1, and the same is true over here.</text>
      <text start="91" dur="3">This is exploiting my conditional independence.</text>
      <text start="94" dur="7">I knew that P of +1 or +2 conditioned on C</text>
      <text start="101" dur="6">is the same as P of +2 conditioned on C and +1.</text>
      <text start="107" dur="3">I can now read those off my table over here,</text>
      <text start="110" dur="8">which is 0.9 times 0.043 plus 0.2,</text>
      <text start="118" dur="5">which is 1 minus 0.8 over here times 0.957,</text>
      <text start="123" dur="6">which gives me approximately 0.2301.</text>
      <text start="129" dur="5">So, that says if my first test comes in positive,</text>
      <text start="134" dur="7">I expect my second test to be positive with probably 0.2301.</text>
      <text start="141" dur="3">That&amp;#39;s an increased probability to the default probability,</text>
      <text start="144" dur="5">which we calculated before, which is the probability of any test,</text>
      <text start="149" dur="9">test 2 come in as positive before was (inaudible) of Bayes rule which was 0.207.</text>
      <text start="158" dur="5">So, my first has a 20% chance of coming in positive.</text>
      <text start="163" dur="4">My second test, after seeing a positive test,</text>
      <text start="167" dur="5">has now an increased probability of about 23% of coming in positive.</text>
    </transcript>
  </video>
  <video title="Unit 3 9d Absolute vs Conditional Independence" id="fYp0lf1P09k">
    <transcript>
      <text start="0" dur="2">So, now we&amp;#39;ve learned about independence,</text>
      <text start="2" dur="2">and the corresponding Bayes network has 2 nodes.</text>
      <text start="4" dur="3">They&amp;#39;re just not connected at all.</text>
      <text start="7" dur="2">And we learned about conditional independence,</text>
      <text start="9" dur="3">in which case we have a Bayes network that looks like this.</text>
      <text start="12" dur="4">Now I would like to know whether absolute independence</text>
      <text start="16" dur="2">implies conditional independence.</text>
      <text start="18" dur="2">True or false?</text>
      <text start="20" dur="5">And I&amp;#39;d also like to know whether conditional independence implies absolute independence.</text>
      <text start="25" dur="2">Again, true or false?</text>
    </transcript>
  </video>
  <video title="Unit 3 9e Answer" id="Em-ahIrk550">
    <transcript>
      <text start="0" dur="3">And the answer is both of them are false.</text>
      <text start="3" dur="4">We already saw that conditional independence, as shown over here,</text>
      <text start="7" dur="2">doesn&amp;#39;t give us absolute independence.</text>
      <text start="9" dur="4">So, for example, this is test #1 and test #2.</text>
      <text start="13" dur="2">You might or might not have cancer.</text>
      <text start="15" dur="3">Our first test gives us information about whether you have cancer or not.</text>
      <text start="18" dur="3">As a result, we&amp;#39;ve changed our prior probability</text>
      <text start="21" dur="3">for the second test to come in positive.</text>
      <text start="24" dur="6">That means that conditional independence does not imply absolute independence,</text>
      <text start="30" dur="2">which means this assumption here falls,</text>
      <text start="32" dur="5">and it also turns out that if you have absolute independence,</text>
      <text start="37" dur="6">things might not be conditionally independent for reasons that I can&amp;#39;t quite explain so far,</text>
      <text start="43" dur="2">but that we will learn about next.</text>
    </transcript>
  </video>
  <video title="Unit 3 10 Different Type of Bayes Network" id="MaAInzCTS1E">
    <transcript>
      <text start="0" dur="4">[Thrun] For my next example, I will study a different type of a Bayes network.</text>
      <text start="4" dur="4">Before, we&amp;#39;ve seen networks of the following type,</text>
      <text start="8" dur="5">where a single hidden cause caused 2 different measurements.</text>
      <text start="13" dur="4">I now want to study a network that looks just like the opposite.</text>
      <text start="17" dur="3">We have 2 independent hidden causes,</text>
      <text start="20" dur="6">but they get confounded within a single observational variable.</text>
      <text start="26" dur="3">I would like to use the example of happiness.</text>
      <text start="29" dur="4">Suppose I can be happy or unhappy.</text>
      <text start="33" dur="8">What makes me happy is when the weather is sunny or if I get a raise in my job,</text>
      <text start="41" dur="2">which means I make more money.</text>
      <text start="43" dur="4">So let&amp;#39;s call this sunny, let&amp;#39;s call this a raise, and call this happiness.</text>
      <text start="47" dur="6">Perhaps the probability of it being sunny is 0.7,</text>
      <text start="53" dur="5">probability of a raise is 0.01.</text>
      <text start="58" dur="7">And I will tell you that the probability of being happy is governed as follows.</text>
      <text start="65" dur="4">The probability of being happy given that both of these things occur--</text>
      <text start="69" dur="4">I got a raise and it is sunny--is 1.</text>
      <text start="73" dur="7">The probability of being happy given that it is not sunny and I still got a raise is 0.9.</text>
      <text start="80" dur="7">The probability of being happy given that it&amp;#39;s sunny but I didn&amp;#39;t get a raise is 0.7.</text>
      <text start="87" dur="8">And the probability of being happy given that it is neither sunny nor did I get a raise is 0.1.</text>
      <text start="95" dur="4">This is a perfectly fine specification of a probability distribution</text>
      <text start="99" dur="7">where 2 causes affect the variable down here, the happiness.</text>
      <text start="106" dur="4">So I&amp;#39;d like you to calculate for me the following questions.</text>
      <text start="110" dur="7">Probability of a raise given that it is sunny, according to this model.</text>
      <text start="117" dur="2">Please enter your answer over here.</text>
    </transcript>
  </video>
  <video title="Unit 3 10a Answer" id="VsesDjAIMmU">
    <transcript>
      <text start="0" dur="3">[Thrun] The answer is surprisingly simple.</text>
      <text start="3" dur="2">It is 0.01.</text>
      <text start="5" dur="3">How do I know this so fast?</text>
      <text start="8" dur="4">Well, if you look at this Bayes network,</text>
      <text start="12" dur="9">both the sunniness and the question whether I got a raise impact my happiness.</text>
      <text start="21" dur="3">But since I don&amp;#39;t know anything about the happiness,</text>
      <text start="24" dur="8">there is no way that just the weather might implicate or impact whether I get a raise or not.</text>
      <text start="32" dur="7">In fact, it might be independently sunny, and I might independently get a raise at work.</text>
      <text start="39" dur="7">There is no mechanism of which these 2 things would co-occur.</text>
      <text start="46" dur="3">Therefore, the probability of a raise given that it&amp;#39;s sunny</text>
      <text start="49" dur="6">is just the same as the probability of a raise given any weather, which is 0.01.</text>
    </transcript>
  </video>
  <video title="Unit 3 11 Explaining Away" id="pyxyYWNo8Qw">
    <transcript>
      <text start="0" dur="7">[Thrun] Let me talk about a really interesting special instance of Bayes net reasoning</text>
      <text start="7" dur="3">which is called explaining away.</text>
      <text start="10" dur="4">And I&amp;#39;ll first give you the intuitive answer,</text>
      <text start="14" dur="5">then I&amp;#39;ll wish you to compute probabilities for me that manifest the explain away effect</text>
      <text start="19" dur="3">in a Bayes network of this type.</text>
      <text start="22" dur="5">Explaining away means that if we know that we are happy,</text>
      <text start="27" dur="7">then sunny weather can explain away the cause of happiness.</text>
      <text start="34" dur="7">If I then also know that it&amp;#39;s sunny, it becomes less likely that I received a raise.</text>
      <text start="41" dur="2">Let me put this differently.</text>
      <text start="43" dur="2">Suppose I&amp;#39;m a happy guy on a specific day</text>
      <text start="45" dur="4">and my wife asks me, &amp;quot;Sebastian, why are you so happy?&amp;quot;</text>
      <text start="49" dur="3">&amp;quot;Is it sunny, or did you get a raise?&amp;quot;</text>
      <text start="52" dur="3">If she then looks outside and sees it is sunny,</text>
      <text start="55" dur="2">then she might explain to herself,</text>
      <text start="57" dur="3">&amp;quot;Well, Sebastian is happy because it is sunny.&amp;quot;</text>
      <text start="60" dur="5">&amp;quot;That makes it effectively less likely that he got a raise</text>
      <text start="65" dur="5">&amp;quot;because I could already explain his happiness by it being sunny.&amp;quot;</text>
      <text start="70" dur="3">If she looks outside and it is rainy,</text>
      <text start="73" dur="3">that makes it more likely I got a raise,</text>
      <text start="76" dur="4">because the weather can&amp;#39;t really explain my happiness.</text>
      <text start="80" dur="7">In other words, if we see a certain effect that could be caused by multiple causes,</text>
      <text start="87" dur="6">seeing one of those causes can explain away any other potential cause</text>
      <text start="93" dur="3">of this effect over here.</text>
      <text start="96" dur="7">So let me put this in numbers and ask you the challenging question of</text>
      <text start="103" dur="8">what&amp;#39;s the probability of a raise given that I&amp;#39;m happy and it&amp;#39;s sunny?</text>
    </transcript>
  </video>
  <video title="Unit 3 11a Answer" id="EZpzEZPy0Wk">
    <transcript>
      <text start="0" dur="7">[Thrun] The answer is approximately 0.0142,</text>
      <text start="7" dur="4">and it is an exercise in expanding this term using Bayes&amp;#39; rule,</text>
      <text start="11" dur="5">using total probability, which I&amp;#39;ll just do for you.</text>
      <text start="16" dur="8">Using Bayes&amp;#39; rule, you can transform this into P of H given R comma S</text>
      <text start="24" dur="10">times P of R given S over P of H given S.</text>
      <text start="34" dur="3">We observe the conditional independence of R and S</text>
      <text start="37" dur="3">to simplify this to just P of R,</text>
      <text start="40" dur="6">and the denominator is expanded by folding in R and not R,</text>
      <text start="46" dur="3">P of H given R comma S</text>
      <text start="49" dur="5">times P of R plus P of H given not R and S</text>
      <text start="54" dur="4">times P of not R, which is total probability.</text>
      <text start="58" dur="3">We can now read off the numbers from the tables over here,</text>
      <text start="61" dur="9">which gives us 1 times 0.01 divided by this expression</text>
      <text start="70" dur="7">that is the same as the expression over here, so 0.01 plus this thing over here,</text>
      <text start="77" dur="6">which you can find over here to be 0.7, times this guy over here,</text>
      <text start="83" dur="4">which is 1 minus the value over here, 0.99,</text>
      <text start="87" dur="5">which gives us approximately 0.0142.</text>
    </transcript>
  </video>
  <video title="Unit 3 11b Question" id="1shSAdfZiJw">
    <transcript>
      <text start="0" dur="4">[Thrun] Now, to understand the explain away effect,</text>
      <text start="4" dur="7">you have to compare this to the probability of a raise given that we&amp;#39;re just happy</text>
      <text start="11" dur="3">and we don&amp;#39;t know anything about the weather.</text>
      <text start="14" dur="2">So let&amp;#39;s do that exercise next.</text>
      <text start="16" dur="8">So my next quiz is, what&amp;#39;s the probability of a raise given that all I know is that I&amp;#39;m happy</text>
      <text start="24" dur="2">and I don&amp;#39;t know about the weather?</text>
      <text start="26" dur="5">This happens to be once again a pretty complicated question, so take your time.</text>
    </transcript>
  </video>
  <video title="Unit 3 11c Answer" id="YE-2ycPWWpQ">
    <transcript>
      <text start="0" dur="2">[Thrun] So this is a difficult question.</text>
      <text start="2" dur="10">Let me compute an auxiliary variable, which is P of happiness.</text>
      <text start="12" dur="7">That one is expanded by looking at the different conditions that can make us happy.</text>
      <text start="19" dur="5">P of happiness given S and R</text>
      <text start="24" dur="5">times P of S and R, which is of course the product of those 2</text>
      <text start="29" dur="2">because they are independent,</text>
      <text start="31" dur="8">plus P of happiness given not S R, probability of not as R</text>
      <text start="39" dur="4">plus P of H given S and not R</text>
      <text start="43" dur="5">times the probability of P of S and not R plus the last case,</text>
      <text start="48" dur="4">P of H given not S and not R.</text>
      <text start="52" dur="4">So this just looks at the happiness under all 4 combinations of the variables</text>
      <text start="56" dur="2">that can lead to happiness.</text>
      <text start="58" dur="2">And you can plug those straight in.</text>
      <text start="60" dur="5">This one over here is 1, and this one over here is the product of S and R,</text>
      <text start="65" dur="5">which is 0.7 times 0.01.</text>
      <text start="70" dur="4">And as you plug all of those in,</text>
      <text start="74" dur="7">you get as a result 0.5245.</text>
      <text start="81" dur="3">That&amp;#39;s P of H.</text>
      <text start="84" dur="4">Just take some time and do the math by going through these different cases</text>
      <text start="88" dur="4">using total probability, and you get this result.</text>
      <text start="92" dur="6">Armed with this number, the rest now becomes easy,</text>
      <text start="98" dur="5">which is we can use Bayes&amp;#39; rule to turn this around.</text>
      <text start="103" dur="6">P of H given R times P of R over P of H.</text>
      <text start="109" dur="5">P of R we know from over here, the probability of a raise is 0.01.</text>
      <text start="114" dur="3">So the only thing we need to compute now is P of H given R.</text>
      <text start="117" dur="2">And again, we apply total probability.</text>
      <text start="119" dur="3">Let me just do this over here.</text>
      <text start="122" dur="7">We can factor P of H given R as P of H given R and S, sunny,</text>
      <text start="129" dur="5">times probability of sunny plus P of H given R and not sunny</text>
      <text start="134" dur="2">times the probability of not sunny.</text>
      <text start="136" dur="5">And if you plug in the numbers with this, you get 1 times 0.7</text>
      <text start="141" dur="4">plus 0.9 times 0.3.</text>
      <text start="145" dur="5">That happens to be 0.97.</text>
      <text start="150" dur="3">So if we now plug this all back into this equation over here,</text>
      <text start="153" dur="12">we get 0.97 times 0.01 over 0.5245.</text>
      <text start="165" dur="8">This gives us approximately as the correct answer 0.0185.</text>
    </transcript>
  </video>
  <video title="Unit 3 11d Question" id="klqEUPy8jZU">
    <transcript>
      <text start="0" dur="4">[Thrun] And if you got this right, I will be deeply impressed</text>
      <text start="4" dur="3">about the fact you got this right.</text>
      <text start="7" dur="6">But the interesting thing now to observe is if we happen to know it&amp;#39;s sunny</text>
      <text start="13" dur="8">and I&amp;#39;m happy, then the probability of a raise is 14%, 0.014.</text>
      <text start="21" dur="5">If I don&amp;#39;t know about the weather and I&amp;#39;m happy,</text>
      <text start="26" dur="4">then the probability of a raise goes up to about 18.5%.</text>
      <text start="30" dur="2">Why is that?</text>
      <text start="32" dur="3">Well, it&amp;#39;s the explaining away effect.</text>
      <text start="35" dur="5">My happiness is well explained by the fact that it&amp;#39;s sunny.</text>
      <text start="40" dur="3">So if someone observes me to be happy and asks the question,</text>
      <text start="43" dur="3">&amp;quot;Is this because Sebastian got a raise at work?&amp;quot;</text>
      <text start="46" dur="7">well, if you know it&amp;#39;s sunny and this is a fairly good explanation for me being happy,</text>
      <text start="53" dur="2">you don&amp;#39;t have to assume I got a raise.</text>
      <text start="55" dur="6">If you don&amp;#39;t know about the weather, then obviously the chances are higher</text>
      <text start="61" dur="2">that the raise caused my happiness,</text>
      <text start="63" dur="7">and therefore this number goes up from 0.014 to 0.018.</text>
      <text start="70" dur="4">Let me ask you one final question in this next quiz,</text>
      <text start="74" dur="9">which is the probability of the raise given that I look happy and it&amp;#39;s not sunny.</text>
      <text start="83" dur="4">This is the most extreme case for making a raise likely</text>
      <text start="87" dur="6">because I am a happy guy, and it&amp;#39;s definitely not caused by the weather.</text>
      <text start="93" dur="4">So it could be just random, or it could be caused by the raise.</text>
      <text start="97" dur="5">So please calculate this number for me and enter it into this box.</text>
    </transcript>
  </video>
  <video title="Unit 3 11e Answer" id="4YzL05_see8">
    <transcript>
      <text start="0" dur="4">[Thrun] Well, the answer follows the exact same scheme as before,</text>
      <text start="4" dur="4">with S being replaced by not S.</text>
      <text start="8" dur="3">So this should be an easier question for you to answer.</text>
      <text start="11" dur="9">P of R given H and not S can be inverted by Bayes&amp;#39; rule to be as follows.</text>
      <text start="20" dur="4">Once we apply Bayes&amp;#39; rule, as indicated over here where we swapped H to the left side</text>
      <text start="24" dur="5">and R to the right side, you can observe that this value over here</text>
      <text start="29" dur="3">can be readily found in the table.</text>
      <text start="32" dur="3">It&amp;#39;s actually the 0.9 over there.</text>
      <text start="35" dur="6">This value over here, the raise is independent of the weather</text>
      <text start="41" dur="4">by virtue of our Bayes network, so it&amp;#39;s just 0.01.</text>
      <text start="45" dur="7">And as before, we apply total probability to the expression over here,</text>
      <text start="52" dur="6">and we obtain off this quotient over here that these 2 expressions are the same.</text>
      <text start="58" dur="5">P of H given not S, not R is the value over here,</text>
      <text start="63" dur="5">and the 0.99 is the complement of probability of R taken from over here,</text>
      <text start="68" dur="8">and that ends up to be 0.0833.</text>
      <text start="76" dur="2">This would have been the right answer.</text>
    </transcript>
  </video>
  <video title="Unit 3 11f Conclusion" id="8SY5T6TFg6c">
    <transcript>
      <text start="0" dur="4">[Thrun] It&amp;#39;s really interesting to compare this to the situation over here.</text>
      <text start="4" dur="4">In both cases I&amp;#39;m happy, as shown over here,</text>
      <text start="8" dur="7">and I ask the same question, which is whether I got a raise at work, as R over here.</text>
      <text start="15" dur="6">But in one case I observe that the weather is sunny; in the other one it isn&amp;#39;t.</text>
      <text start="21" dur="4">And look what it does to my probability of having received a raise.</text>
      <text start="25" dur="5">The sunniness perfectly well explains my happiness,</text>
      <text start="30" dur="11">and my probability of having received a raise ends up to be a mere 1.4%, or 0.014.</text>
      <text start="41" dur="6">However, if my wife observes it to be non-sunny, then it is much more likely</text>
      <text start="47" dur="4">that the cause of my happiness is related to a raise at work,</text>
      <text start="51" dur="7">and now the probability is 8.3%, which is significantly higher than the 1.4% before.</text>
      <text start="58" dur="6">This is a Bayes network of which S and R are independent</text>
      <text start="64" dur="6">but H adds a dependence between S and R.</text>
      <text start="70" dur="5">Let me talk about this in a little bit more detail on the next paper.</text>
      <text start="76" dur="2">So here is our Bayes network again.</text>
      <text start="78" dur="4">In our previous exercises, we computed for this network</text>
      <text start="82" dur="7">that the probability of a raise of R given any of these variables shown here was as follows.</text>
      <text start="89" dur="5">The really interesting thing is that in the absence of information about H,</text>
      <text start="94" dur="3">which is the middle case over here,</text>
      <text start="97" dur="4">the probability of R is unaffected by knowledge of S--</text>
      <text start="101" dur="5">that is, R and S are independent.</text>
      <text start="106" dur="3">This is the same as probability of R,</text>
      <text start="109" dur="7">and R and S are independent.</text>
      <text start="116" dur="6">However, if I know something about the variable H,</text>
      <text start="122" dur="4">then S and R become dependent--</text>
      <text start="126" dur="9">that is, knowing about my happiness over here renders S and R dependent.</text>
      <text start="135" dur="8">This is not the same as probability of just R given H.</text>
      <text start="143" dur="5">Obviously, it isn&amp;#39;t because if I now vary S from S to not S,</text>
      <text start="148" dur="5">it affects my probability for the variable R.</text>
      <text start="153" dur="3">That is a really unusual situation</text>
      <text start="156" dur="4">where we have R and S are independent</text>
      <text start="160" dur="10">but given the variable H, R and S are not independent anymore.</text>
      <text start="170" dur="8">So knowledge of H makes 2 variables that previously were independent non-independent.</text>
      <text start="178" dur="8">Offered differently, 2 variables that are independent may not be in certain cases</text>
      <text start="186" dur="2">conditionally independent.</text>
      <text start="188" dur="5">Independence does not imply conditional independence.</text>
    </transcript>
  </video>
  <video title="Unit 3 12 General Bayes Networks" id="kmSMS3CBLd8">
    <transcript>
      <text start="0" dur="5">[Thrun] So we&amp;#39;re now ready to define Bayes networks in a more general way.</text>
      <text start="5" dur="5">Bayes networks define probability distributions over graphs or random variables.</text>
      <text start="10" dur="4">Here is an example graph of 5 variables,</text>
      <text start="14" dur="5">and this Bayes network defines the distribution over those 5 random variables.</text>
      <text start="19" dur="5">Instead of enumerating all possibilities of combinations of these 5 random variables,</text>
      <text start="24" dur="4">the Bayes network is defined by probability distributions</text>
      <text start="28" dur="4">that are inherent to each individual node.</text>
      <text start="32" dur="6">For node A and B, we just have a distribution P of A and P of B</text>
      <text start="38" dur="4">because A and B have no incoming arcs.</text>
      <text start="42" dur="5">C is a conditional distribution conditioned on A and B.</text>
      <text start="47" dur="5">D and E are conditioned on C.</text>
      <text start="52" dur="4">The joint probability represented by a Bayes network</text>
      <text start="56" dur="4">is the product of various Bayes network probabilities</text>
      <text start="60" dur="3">that are defined over individual nodes</text>
      <text start="63" dur="5">where each node&amp;#39;s probability is only conditioned on the incoming arcs.</text>
      <text start="68" dur="4">So A has no incoming arc; therefore, we just want it P of A.</text>
      <text start="72" dur="6">C has 2 incoming arcs, so we define the probability of C conditioned on A and B.</text>
      <text start="78" dur="4">And D and E have 1 incoming arc that&amp;#39;s shown over here.</text>
      <text start="82" dur="5">The definition of this joint distribution by using the following factors</text>
      <text start="87" dur="3">has one really big advantage.</text>
      <text start="90" dur="10">Whereas the joint distribution over any 5 variables requires 2 to the 5 minus 1,</text>
      <text start="100" dur="3">which is 31 probability values,</text>
      <text start="103" dur="5">the Bayes network over here only requires 10 such values.</text>
      <text start="108" dur="5">P of A is one value, for which we can derive P of not A.</text>
      <text start="113" dur="2">Same for P of B.</text>
      <text start="115" dur="7">P of C given A B is derived by a distribution over C</text>
      <text start="122" dur="5">conditioned on any combination of A and B, of which there are 4 of A and B as binary.</text>
      <text start="127" dur="8">P of D given C is 2 parameters for P of D given C and P of D given not C.</text>
      <text start="135" dur="3">And the same is true for P of E given C.</text>
      <text start="138" dur="3">So if you add those up, you get 10 parameters in total.</text>
      <text start="141" dur="4">So the compactness of the Bayes network</text>
      <text start="145" dur="6">leads to a representation that scales significantly better to large networks</text>
      <text start="151" dur="5">than the common natorial approach which goes through all combinations of variable values.</text>
      <text start="156" dur="3">That is a key advantage of Bayes networks,</text>
      <text start="159" dur="4">and that is the reason why Bayes networks are being used so extensively</text>
      <text start="163" dur="2">for all kinds of problems.</text>
      <text start="165" dur="2">So here is a quiz.</text>
      <text start="167" dur="4">How many probability values are required to specify this Bayes network?</text>
      <text start="171" dur="2">Please put your answer in the following box.</text>
    </transcript>
  </video>
  <video title="Unit 3 12a Answer" id="cvRNI5fULP8">
    <transcript>
      <text start="0" dur="3">[Thrun] And the answer is 13.</text>
      <text start="3" dur="3">One over here, 2 over here, and 4 over here.</text>
      <text start="6" dur="9">Simplifiably speaking, any variable that has K inputs requires 2 to the K such variables.</text>
      <text start="15" dur="4">So in total we have 1, 9, 13.</text>
    </transcript>
  </video>
  <video title="Unit 3 12b Question" id="Fy5wP_9obQU">
    <transcript>
      <text start="0" dur="2">[Thrun] Here&amp;#39;s another quiz.</text>
      <text start="2" dur="4">How many parameters do we need to specify the joint distribution</text>
      <text start="6" dur="3">for this Bayes network over here</text>
      <text start="9" dur="4">where A, B, and C point into D, D points into E, F, and G</text>
      <text start="13" dur="2">and C also points into G?</text>
      <text start="15" dur="2">Please write your answer into this box.</text>
    </transcript>
  </video>
  <video title="Unit 3 12c Answer" id="j0p9VHy-Tu0">
    <transcript>
      <text start="0" dur="2">[Thrun] And the answer is 19.</text>
      <text start="2" dur="7">So 1 here, 1 here, 1 here, 2 here, 2 here, 2 arcs point into G, which makes for 4,</text>
      <text start="9" dur="4">and 3 arcs point into D. Two to the 3 is 8.</text>
      <text start="13" dur="3">So we get 1, 2, 3, 8, 2, 2, 4. If you add those up, it&amp;#39;s 19.</text>
    </transcript>
  </video>
  <video title="Unit 3 12d Question" id="wJsCAF5cAK8">
    <transcript>
      <text start="0" dur="6">[Thrun] And here is our car network which we discussed at the very beginning of this unit.</text>
      <text start="6" dur="5">How many parameters do we need to specify this network?</text>
      <text start="11" dur="4">Remember, there are 16 total variables,</text>
      <text start="15" dur="10">and the naive joint over the 16 will be 2 to the 16th minus 1, which is 65,535.</text>
      <text start="25" dur="3">Please write your answer into this box over here.</text>
    </transcript>
  </video>
  <video title="Unit 3 12e Answer" id="A2ugTxgEJRA">
    <transcript>
      <text start="0" dur="4">[Thrun] To answer this question, let us add up these numbers.</text>
      <text start="4" dur="4">Battery age is 1, 1, 1.</text>
      <text start="8" dur="2">This has 1 incoming arc, so it&amp;#39;s 2.</text>
      <text start="10" dur="3">Two incoming arcs makes 4.</text>
      <text start="13" dur="4">One incoming arc is 2, 2 equals 4.</text>
      <text start="17" dur="4">Four incoming arcs makes 16.</text>
      <text start="21" dur="3">If we add all the right numbers, we get 47.</text>
    </transcript>
  </video>
  <video title="Unit 3 12f Value of the Network" id="9PXrxfOb3p0">
    <transcript>
      <text start="0" dur="5">[Thrun] So it takes 47 numerical probabilities to specify the joint</text>
      <text start="5" dur="6">compared to 65,000 if you didn&amp;#39;t have the graph-like structure.</text>
      <text start="11" dur="3">I think this example really illustrates the advantage</text>
      <text start="14" dur="6">of complex Bayes network representations over unstructured joint representations.</text>
    </transcript>
  </video>
  <video title="Unit 3 13 D-Separation" id="iuad4fQ6UPc">
    <transcript>
      <text start="0" dur="4">[Thrun] The next concept I&amp;#39;d like to teach you is called D-separation.</text>
      <text start="4" dur="5">And let me start the discussion of this concept by a quiz.</text>
      <text start="9" dur="2">We have here a Bayes network,</text>
      <text start="11" dur="5">and I&amp;#39;m going to ask you a conditional independence question.</text>
      <text start="16" dur="4">Is C independent of A?</text>
      <text start="20" dur="2">Please tell me yes or no.</text>
      <text start="22" dur="5">Is C independent of A given B?</text>
      <text start="27" dur="3">Is C independent of D?</text>
      <text start="30" dur="2">Is C independent of D given A?</text>
      <text start="32" dur="3">And is E independent of C given D?</text>
    </transcript>
  </video>
  <video title="Unit 3 13a Answer" id="dL6p3YQDgGM">
    <transcript>
      <text start="0" dur="4">[Thrun] So C is not independent of A.</text>
      <text start="4" dur="5">In fact, A influences C by virtue of B.</text>
      <text start="9" dur="4">But if you know B, then A becomes independent of C,</text>
      <text start="13" dur="4">which means the only determinate into C is B.</text>
      <text start="17" dur="5">If you know B for sure, then knowledge of A won&amp;#39;t really tell you anything about C.</text>
      <text start="22" dur="5">C is also not independent of D, just the same way C is not independent of A.</text>
      <text start="27" dur="4">If I learn something about D, I can infer more about C.</text>
      <text start="31" dur="7">But if I do know A, then it&amp;#39;s hard to imagine how knowledge of D would help me with C</text>
      <text start="38" dur="4">because I can&amp;#39;t learn anything more about A than knowing A already.</text>
      <text start="42" dur="3">Therefore, given A, C and D are independent.</text>
      <text start="45" dur="3">The same is true for E and C.</text>
      <text start="48" dur="4">If we know D, then E and C become independent.</text>
    </transcript>
  </video>
  <video title="Unit 3 13b D-Separation Example" id="DmbahBp7buc">
    <transcript>
      <text start="0" dur="4">[Thrun] In this specific example, the rule that we could apply is very, very simple.</text>
      <text start="4" dur="6">Any 2 variables are independent if they&amp;#39;re not linked by just unknown variables.</text>
      <text start="10" dur="4">So for example, if we know B, then everything downstream of B</text>
      <text start="14" dur="4">becomes independent of anything upstream of B.</text>
      <text start="18" dur="4">E is now independent of C, conditioned on B.</text>
      <text start="22" dur="4">However, knowledge of B does not render A and E independent.</text>
      <text start="26" dur="7">In this graph over here, A and B connect to C and C connects to D and to E.</text>
      <text start="33" dur="4">So let me ask you, is A independent of E,</text>
      <text start="37" dur="2">A independent of E given B,</text>
      <text start="39" dur="2">A independent of E given C,</text>
      <text start="41" dur="2">A independent of B,</text>
      <text start="43" dur="2">and A independent of B given C?</text>
    </transcript>
  </video>
  <video title="Unit 3 13c Answer" id="zQ_xDaok-G0">
    <transcript>
      <text start="0" dur="3">[Thrun] And the answer for this one is really interesting.</text>
      <text start="3" dur="5">A is clearly not independent of E because through C we can see an influence of A to E.</text>
      <text start="8" dur="3">Given B, that doesn&amp;#39;t change.</text>
      <text start="11" dur="4">A still influences C, despite the fact we know B.</text>
      <text start="15" dur="3">However, if we know C, the influence is cut off.</text>
      <text start="18" dur="4">There is no way A can influence E if we know C.</text>
      <text start="22" dur="3">A is clearly independent of B.</text>
      <text start="25" dur="4">They are different entry variables. They have no incoming arcs.</text>
      <text start="29" dur="3">But here is the caveat.</text>
      <text start="32" dur="3">Given C, A and B become dependent.</text>
      <text start="35" dur="3">So whereas initially A and B were independent,</text>
      <text start="38" dur="3">if you give C, they become dependent.</text>
      <text start="41" dur="3">And the reason why they become dependent we&amp;#39;ve studied before.</text>
      <text start="44" dur="4">This is the explain away effect.</text>
      <text start="48" dur="3">If you know, for example, C to be true,</text>
      <text start="51" dur="6">then knowledge of A will substantially affect what we believe about B.</text>
      <text start="57" dur="5">If there&amp;#39;s 2 joint causes for C and we happen to know A is true,</text>
      <text start="62" dur="2">we will discredit cause B.</text>
      <text start="64" dur="5">If we happen to know A is false, we will increase our belief for the cause B.</text>
      <text start="69" dur="6">That was an effect we studied extensively in the happiness example I gave you before.</text>
      <text start="75" dur="4">The interesting thing here is we are facing a situation</text>
      <text start="79" dur="7">where knowledge of variable C renders previously independent variables dependent.</text>
    </transcript>
  </video>
  <video title="Unit 3 13d D-Separation General Definition" id="BBQTF6zbWME">
    <transcript>
      <text start="0" dur="6">[Thrun] This leads me to the general study of conditional independence in Bayes networks,</text>
      <text start="6" dur="4">often called D-separation or reachability.</text>
      <text start="10" dur="7">D-separation is best studied by so-called active triplets and inactive triplets</text>
      <text start="17" dur="3">where active triplets render variables dependent</text>
      <text start="20" dur="3">and inactive triplets render them independent.</text>
      <text start="23" dur="7">Any chain of 3 variables like this makes the initial and final variable dependent</text>
      <text start="30" dur="2">if all variables are unknown.</text>
      <text start="32" dur="3">However, if the center variable is known--</text>
      <text start="35" dur="3">that is, it&amp;#39;s behind the conditioning bar--</text>
      <text start="38" dur="4">then this variable and this variable become independent.</text>
      <text start="42" dur="5">So if we have a structure like this and it&amp;#39;s quote-unquote cut off</text>
      <text start="47" dur="6">by a known variable in the middle, that separates or deseparates</text>
      <text start="53" dur="4">the left variable from the right variable, and they become independent.</text>
      <text start="57" dur="7">Similarly, any structure like this renders the left variable and the right variable dependent</text>
      <text start="64" dur="4">unless the center variable is known,</text>
      <text start="68" dur="4">in which case the left and right variable become independent.</text>
      <text start="72" dur="4">Another active triplet now requires knowledge of a variable.</text>
      <text start="76" dur="3">This is the explain away case.</text>
      <text start="79" dur="6">If this variable is known for a Bayes network that converges into a single variable,</text>
      <text start="85" dur="4">then this variable and this variable over here become dependent.</text>
      <text start="89" dur="4">Contrast this with a case where all variables are unknown.</text>
      <text start="93" dur="7">A situation like this means that this variable on the left or on the right are actually independent.</text>
      <text start="100" dur="8">In a single final example, we also get dependence if we have the following situation:</text>
      <text start="108" dur="4">a direct successor of a conversion variable is known.</text>
      <text start="112" dur="5">So it is sufficient if a successor of this variable is known.</text>
      <text start="117" dur="2">The variable itself does not have to be known,</text>
      <text start="119" dur="3">and the reason is if you know this guy over here,</text>
      <text start="122" dur="3">we get knowledge about this guy over here.</text>
      <text start="125" dur="4">And by virtue of that, the case over here essentially applies.</text>
      <text start="129" dur="2">If you look at those rules,</text>
      <text start="131" dur="4">those rules allow you to determine for any Bayes network</text>
      <text start="135" dur="5">whether variables are dependent or not dependent given the evidence you have.</text>
      <text start="140" dur="5">If you color the nodes dark for which you do have evidence,</text>
      <text start="145" dur="4">then you can use these rules to understand whether any 2 variables</text>
      <text start="149" dur="2">are conditionally independent or not.</text>
      <text start="151" dur="6">So let me ask you for this relatively complicated Bayes network the following questions.</text>
      <text start="157" dur="4">Is F independent of A?</text>
      <text start="161" dur="4">Is F independent of A given D?</text>
      <text start="165" dur="4">Is F independent of A given G?</text>
      <text start="169" dur="2">And is F independent of A given H?</text>
      <text start="171" dur="3">Please mark your answers as you see fit.</text>
    </transcript>
  </video>
  <video title="Unit 3 13e Answer" id="LKDtJM8SQmw">
    <transcript>
      <text start="0" dur="4">[Thrun] And the answer is yes, F is independent of A.</text>
      <text start="4" dur="4">What we find for our rules of D-separation is that F is dependent on D</text>
      <text start="8" dur="3">and A is dependent on D.</text>
      <text start="11" dur="5">But if you don&amp;#39;t know D, you can&amp;#39;t govern any dependence between A and F at all.</text>
      <text start="16" dur="4">If you do know D, then F and A become dependent.</text>
      <text start="20" dur="5">And the reason is B and E are dependent given D,</text>
      <text start="25" dur="4">and we can transform this back into dependence of A and F</text>
      <text start="29" dur="4">because B and A are dependent and E and F are dependent.</text>
      <text start="33" dur="5">There is an active path between A and F which goes across here and here</text>
      <text start="38" dur="2">because D is known.</text>
      <text start="40" dur="4">If we know G, the same thing is true because G gives us knowledge about D,</text>
      <text start="44" dur="3">and D can be applied back to this path over here.</text>
      <text start="47" dur="2">However, if you know H, that&amp;#39;s not the case.</text>
      <text start="49" dur="2">So H might tell us something about G,</text>
      <text start="51" dur="2">but it doesn&amp;#39;t tell us anything about D,</text>
      <text start="53" dur="6">and therefore, we have no reason to close the path between A and F.</text>
      <text start="59" dur="4">The path between A and F is still passive, even though we have knowledge of H.</text>
    </transcript>
  </video>
  <video title="Unit 3 14 Congratulations" id="4OPv8ACeuaU">
    <transcript>
      <text start="0" dur="3">[Thrun] So congratulations. You learned a lot about Bayes networks.</text>
      <text start="3" dur="3">You learned about the graph structure of Bayes networks,</text>
      <text start="6" dur="4">you understood how this is a compact representation,</text>
      <text start="10" dur="2">you learned about conditional independence,</text>
      <text start="12" dur="3">and we talked a little bit about application of Bayes network</text>
      <text start="15" dur="3">to interesting reasoning problems.</text>
      <text start="18" dur="5">But by all means this was a mostly theoretical unit of this class,</text>
      <text start="23" dur="4">and in future classes we will talk more about applications.</text>
      <text start="27" dur="4">The instrument of Bayes networks is really essential to a number of problems.</text>
      <text start="31" dur="5">It really characterizes the sparse dependence that exists in many readable problems</text>
      <text start="36" dur="5">like in robotics and computer vision and filtering and diagnostics and so on.</text>
      <text start="41" dur="2">I really hope you enjoyed this class,</text>
      <text start="43" dur="7">and I really hope you understood in depth how Bayes networks work.</text>
    </transcript>
  </video>
  <video title="Unit 4, 1 Probabilistic Inference" id="1fVWQ-iZqsw">
    <transcript>
      <text start="0" dur="2">[Probabilistic Interference]</text>
      <text start="2" dur="3">[Male] Welcome back. In the previous unit, we went over the basics</text>
      <text start="5" dur="7">of probability theory and saw how</text>
      <text start="12" dur="5">a Bayes network could concisely represent a joint probability distribution,</text>
      <text start="17" dur="7">including the representation of independence between the variables.</text>
      <text start="24" dur="7">In this unit, we will see how to do probabilistic inference.</text>
      <text start="31" dur="5">That is, how to answer probability questions using Bayes nets.</text>
      <text start="36" dur="4">Let&amp;#39;s put up a simple Bayes net.</text>
      <text start="40" dur="5">We&amp;#39;ll use the familiar example of the earthquake</text>
      <text start="45" dur="5">where we can have a burglary or an earthquake</text>
      <text start="50" dur="3">setting off an alarm, and if the alarm goes off,</text>
      <text start="53" dur="5">either John or Mary might call.</text>
      <text start="58" dur="4">Now, what kinds of questions can we ask to do inference about?</text>
      <text start="62" dur="3">The simplest type of question is the same question we ask</text>
      <text start="65" dur="3">with an ordinary subroutine or function in a programming language.</text>
      <text start="68" dur="4">Namely, given some inputs, what are the outputs?</text>
      <text start="72" dur="6">So, in this case, we could say given the inputs of B and E,</text>
      <text start="78" dur="4">what are the outputs, J and M?</text>
      <text start="82" dur="4">Rather than call them input and output variables,</text>
      <text start="86" dur="10">in probabilistic inference, we&amp;#39;ll call them evidence and query variables.</text>
      <text start="96" dur="3">That is, the variables that we know the values of are the evidence,</text>
      <text start="99" dur="5">and the ones that we want to find out the values of are the query variables.</text>
      <text start="104" dur="8">Anything that is neither evidence nor query is known as a hidden variable.</text>
      <text start="112" dur="3">That is, we won&amp;#39;t tell you what its value is.</text>
      <text start="115" dur="3">We won&amp;#39;t figure out what its value is and report it,</text>
      <text start="118" dur="3">but we&amp;#39;ll have to compute with it internally.</text>
      <text start="121" dur="4">And now furthermore, in probabilistic inference,</text>
      <text start="125" dur="5">the output is not a single number for each of the query variables,</text>
      <text start="130" dur="3">but rather, it&amp;#39;s a probability distribution.</text>
      <text start="133" dur="4">So, the answer is going to be a complete, joint probability distribution</text>
      <text start="137" dur="2">over the query variables.</text>
      <text start="139" dur="4">We call this the posterior distribution, given the evidence,</text>
      <text start="143" dur="3">and we can write it like this.</text>
      <text start="146" dur="8">It&amp;#39;s the probability distribution of one or more query variables</text>
      <text start="154" dur="5">given the values of the evidence variables.</text>
      <text start="159" dur="3">And there can be zero or more evidence variables,</text>
      <text start="162" dur="5">and each of them are given an exact value.</text>
      <text start="167" dur="6">And that&amp;#39;s the computation we want to come up with.</text>
      <text start="173" dur="3">There&amp;#39;s another question we can ask.</text>
      <text start="176" dur="2">Which is the most likely explanation?</text>
      <text start="178" dur="5">That is, out of all the possible values for all the query variables,</text>
      <text start="183" dur="5">which combination of values has the highest probability?</text>
      <text start="188" dur="4">We write the formula like this, asking which Q values</text>
      <text start="192" dur="4">are maxable given the evidence values.</text>
      <text start="196" dur="6">Now, in an ordinary programming language, each function goes only one way.</text>
      <text start="202" dur="4">It has input variables, does some computation,</text>
      <text start="206" dur="5">and comes up with a result variable or result variables.</text>
      <text start="211" dur="3">One great thing about Bayes nets is that we&amp;#39;re not restricted</text>
      <text start="214" dur="2">to going only in one direction.</text>
      <text start="216" dur="5">We could go in the causal direction, giving as evidence</text>
      <text start="221" dur="6">the route nodes of the tree and asking as query values the nodes at the bottom.</text>
      <text start="227" dur="3">Or, we could reverse that causal flow.</text>
      <text start="230" dur="5">For example, we could have J and M be the evidence variables</text>
      <text start="235" dur="3">and B and E be the query variables,</text>
      <text start="238" dur="3">or we could have any other combination.</text>
      <text start="241" dur="4">For example, we could have M be the evidence variable</text>
      <text start="245" dur="6">and J and B be the query variables.</text>
      <text start="251" dur="2">Here&amp;#39;s a question for you.</text>
      <text start="253" dur="5">Imagine the situation where Mary has called to report that the alarm is going off,</text>
      <text start="258" dur="4">and we want to know whether or not there has been a burglary.</text>
      <text start="262" dur="5">For each of the nodes, click on the circle to tell us</text>
      <text start="267" dur="5">if the node is an evidence node, a hidden node,</text>
      <text start="272" dur="6">or a query node.</text>
    </transcript>
  </video>
  <video title="Unit 4, 1a Answer" id="VYsys0If8bw">
    <transcript>
      <text start="0" dur="4">The answer is that Mary calling is the evidence node.</text>
      <text start="4" dur="3">The burglary is the query node,</text>
      <text start="7" dur="4">and all the others are hidden variables in this case.</text>
    </transcript>
  </video>
  <video title="Unit 4, 2 Enumeration" id="q5DHnmHtVmc">
    <transcript>
      <text start="0" dur="4">Now we&amp;#39;re going to talk about how to do inference on Bayes net.</text>
      <text start="4" dur="4">We&amp;#39;ll start with our familiar network, and we&amp;#39;ll talk about a method</text>
      <text start="8" dur="4">called enumeration,</text>
      <text start="12" dur="3">which goes through all the possibilities, adds them up,</text>
      <text start="15" dur="2">and comes up with an answer.</text>
      <text start="17" dur="7">So, what we do is start by stating the problem.</text>
      <text start="24" dur="3">We&amp;#39;re going to ask the question of what is the probability</text>
      <text start="27" dur="7">that the burglar alarm occurred given that John called and Mary called?</text>
      <text start="34" dur="5">We&amp;#39;ll use the definition of conditional probability to answer this.</text>
      <text start="39" dur="8">So, this query is equal to the joint probability distribution</text>
      <text start="47" dur="8">of all 3 variables divided by the conditionalized variables.</text>
      <text start="55" dur="6">Now, note I&amp;#39;m using a notation here where instead of writing out the probability</text>
      <text start="61" dur="4">of some variable equals true, I&amp;#39;m just using the notation plus</text>
      <text start="65" dur="3">and then the variable name in lower case,</text>
      <text start="68" dur="5">and if I wanted the negation, I would use negation sign.</text>
      <text start="73" dur="4">Notice there&amp;#39;s a different notation where instead of writing out</text>
      <text start="77" dur="5">the plus and negation signs, we just use the variable name itself, P(e),</text>
      <text start="82" dur="3">to indicate E is true.</text>
      <text start="85" dur="4">That notation works well, but it can get confusing between</text>
      <text start="89" dur="5">does P(e) mean E is true, or does it mean E is a variable?</text>
      <text start="94" dur="3">And so we&amp;#39;re going to stick to the notation where we explicitly have</text>
      <text start="97" dur="4">the pluses and negation signs.</text>
      <text start="101" dur="4">To do inference by enumeration, we first take a conditional probability</text>
      <text start="105" dur="4">and rewrite it as unconditional probabilities.</text>
      <text start="109" dur="7">Now we enumerate all the atomic probabilities and calculate the sum of products.</text>
      <text start="116" dur="4">Let&amp;#39;s look at just the complex term on the numerator first.</text>
      <text start="120" dur="5">The procedure for figuring out the denominator would be similar, and we&amp;#39;ll skip that.</text>
      <text start="125" dur="7">So, the probability of these 3 terms together</text>
      <text start="132" dur="5">can be determined by enumerating all possible values of the hidden variables.</text>
      <text start="137" dur="5">In this case, there are 2, E and A,</text>
      <text start="142" dur="7">so we&amp;#39;ll sum over those variables for all values of E and for all values of A.</text>
      <text start="149" dur="5">In this case, they&amp;#39;re boolean, so there&amp;#39;s only 2 values of each.</text>
      <text start="154" dur="7">We ask what&amp;#39;s the probability of this unconditional term?</text>
      <text start="161" dur="3">And that we get by summing out over all possibilities,</text>
      <text start="164" dur="5">E and A being true or false.</text>
      <text start="169" dur="3">Now, to get the values of these atomic events,</text>
      <text start="172" dur="3">we&amp;#39;ll have to rewrite this equation in a form that corresponds</text>
      <text start="175" dur="5">to the conditional probability tables that we have associated with the Bayes net.</text>
      <text start="180" dur="4">So, we&amp;#39;ll take this whole expression and rewrite it.</text>
      <text start="184" dur="4">It&amp;#39;s still a sum over the hidden variables E and A,</text>
      <text start="188" dur="4">but now I&amp;#39;ll rewrite this expression in terms of the parents</text>
      <text start="192" dur="3">of each of the nodes in the network.</text>
      <text start="195" dur="6">So, that gives us the product of these 5 terms,</text>
      <text start="201" dur="3">which we then have to sum over all values of E and A.</text>
      <text start="204" dur="7">If we call this product f(e,a),</text>
      <text start="211" dur="12">then the whole answer is the sum of F for all values of E and A,</text>
      <text start="223" dur="8">so as the sum of 4 terms where each of the terms is a product of 5 numbers.</text>
      <text start="231" dur="3">Where do we get the numbers to fill in this equation?</text>
      <text start="234" dur="4">From the conditional probability tables from our model,</text>
      <text start="238" dur="5">so let&amp;#39;s put the equation back up, and we&amp;#39;ll ask you for the case</text>
      <text start="243" dur="6">where both E and A are positive</text>
      <text start="249" dur="5">to look up in the conditional probability tables and fill in the numbers</text>
      <text start="254" dur="10">for each of these 5 terms, and then multiply them together and fill in the product.</text>
    </transcript>
  </video>
  <video title="Unit 4, 2a Answer" id="fxYL4PIBXiY">
    <transcript>
      <text start="0" dur="4">We get the answer by reading numbers off the conditional probability tables,</text>
      <text start="4" dur="7">so probability of B being positive is 0.001.</text>
      <text start="11" dur="5">Of E being positive, because we&amp;#39;re dealing with the positive case now</text>
      <text start="16" dur="6">for the variable E, is 0.002.</text>
      <text start="22" dur="4">The probability of A being positive, because we&amp;#39;re dealing with that case,</text>
      <text start="26" dur="4">given that B is positive and the case for an E is positive,</text>
      <text start="30" dur="7">that we can read off here as 0.95.</text>
      <text start="37" dur="7">The probability that J is positive given that A is positive is 0.9.</text>
      <text start="44" dur="6">And finally, the probability that M is positive given that A is positive</text>
      <text start="50" dur="4">we read off here as 0.7.</text>
      <text start="54" dur="3">We multiple all those together, it&amp;#39;s going to be a small number</text>
      <text start="57" dur="3">because we&amp;#39;ve got the .001 and the .002 here.</text>
      <text start="60" dur="12">Can&amp;#39;t quite fit it in the box, but it works out to .000001197.</text>
      <text start="72" dur="2">That seems like a really small number, but remember,</text>
      <text start="74" dur="5">we have to normalize by the P(+j,+m) term,</text>
      <text start="79" dur="3">and this is only 1 of the 4 possibilities.</text>
      <text start="82" dur="4">We have to enumerate over all 4 possibilities for E and A,</text>
      <text start="86" dur="6">and in the end, it works out that the probability of the burglar alarm being true</text>
      <text start="92" dur="6">given that John and Mary calls, is 0.284.</text>
      <text start="98" dur="4">And we get that number because intuitively,</text>
      <text start="102" dur="2">it seems that the alarm is fairly reliable.</text>
      <text start="104" dur="3">John and Mary calling are very reliable,</text>
      <text start="107" dur="2">but the prior probability of burglary is low.</text>
      <text start="109" dur="5">And those 2 terms combine together to give us the 0.284 value</text>
      <text start="114" dur="5">when we sum up each of the 4 terms of these products.</text>
    </transcript>
  </video>
  <video title="Unit 4, 3 Speeding up Enumeration" id="DWO-XKo2iS8">
    <transcript>
      <text start="0" dur="4">[Norvig] We&amp;#39;ve seen how to do enumeration to solve the inference problem</text>
      <text start="4" dur="2">on belief networks.</text>
      <text start="6" dur="4">For a simple network like the alarm network, that&amp;#39;s all we need to know.</text>
      <text start="10" dur="4">There&amp;#39;s only 5 variables, so even if all 5 of them were hidden,</text>
      <text start="14" dur="6">there would only be 32 rows in the table to sum up.</text>
      <text start="20" dur="2">From a theoretical point of view, we&amp;#39;re done.</text>
      <text start="22" dur="4">But from a practical point of view, other networks could give us trouble.</text>
      <text start="26" dur="9">Consider this network, which is one for determining insurance for car owners.</text>
      <text start="35" dur="3">There are 27 different variables.</text>
      <text start="38" dur="6">If each of the variables were boolean, that would give us over 100 million rows to sum out.</text>
      <text start="44" dur="2">But in fact, some of the variables are non-boolean,</text>
      <text start="46" dur="6">they have multiple values, and it turns out that representing this entire network</text>
      <text start="52" dur="5">and doing enumeration we&amp;#39;d have to sum over a quadrillion rows.</text>
      <text start="57" dur="4">That&amp;#39;s just not practical, so we&amp;#39;re going to have to come up with methods</text>
      <text start="61" dur="3">that are faster than enumerating everything.</text>
      <text start="64" dur="5">The first technique we can use to get a speed-up in doing inference on Bayes nets</text>
      <text start="69" dur="4">is to pull out terms from the enumeration.</text>
      <text start="73" dur="7">For example, here the probability of b is going to be the same for all values of E and a.</text>
      <text start="80" dur="6">So we can take that term and move it out of the summation,</text>
      <text start="86" dur="2">and now we have a little bit less work to do.</text>
      <text start="88" dur="5">We can multiply by that term once rather than having it in each row of the table.</text>
      <text start="93" dur="7">We can also move this term, the P of e, to the left of the summation over a,</text>
      <text start="100" dur="3">because it doesn&amp;#39;t depend on a.</text>
      <text start="103" dur="2">By doing this, we&amp;#39;re doing less work.</text>
      <text start="105" dur="5">The inner loop of the summation now has only 3 terms rather than 5 terms.</text>
      <text start="110" dur="3">So we&amp;#39;ve reduced the cost of doing each row of the table.</text>
      <text start="113" dur="4">But we still have the same number of rows in the table,</text>
      <text start="117" dur="3">so we&amp;#39;re going to have to do better than that.</text>
      <text start="120" dur="8">The next technique for efficient inference is to maximize independence of variables.</text>
      <text start="128" dur="4">The structure of a Bayes net determines how efficient it is to do inference on it.</text>
      <text start="132" dur="5">For example, a network that&amp;#39;s a linear string of variables,</text>
      <text start="137" dur="10">X1 through Xn, can have inference done in time proportional to the number n,</text>
      <text start="147" dur="4">whereas a network that&amp;#39;s a complete network</text>
      <text start="151" dur="9">where every node points to every other node and so on could take time 2 to the n</text>
      <text start="160" dur="5">if all n variables are boolean variables.</text>
      <text start="165" dur="5">In the alarm network we saw previously, we took care</text>
      <text start="170" dur="4">to make sure that we had all the independence relations represented</text>
      <text start="174" dur="3">in the structure of the network.</text>
      <text start="177" dur="3">But if we put the nodes together in a different order,</text>
      <text start="180" dur="3">we would end up with a different structure.</text>
      <text start="183" dur="6">Let&amp;#39;s start by ordering the node John calls first</text>
      <text start="189" dur="4">and then adding in the node Mary calls.</text>
      <text start="193" dur="6">The question is, given just these 2 nodes and looking at the node for Mary calls,</text>
      <text start="199" dur="8">is that node dependent or independent of the node for John calls?</text>
    </transcript>
  </video>
  <video title="Unit 4, 3a Answer" id="r3mOvkvHbts">
    <transcript>
      <text start="1" dur="4">[Norvig] The answer is that the node for Mary calls in this network</text>
      <text start="5" dur="3">is dependent on John calls.</text>
      <text start="8" dur="5">In the previous network, they were independent given that we knew that the alarm had occurred.</text>
      <text start="13" dur="3">But here we don&amp;#39;t know that the alarm had occurred,</text>
      <text start="16" dur="2">and so the nodes are dependent</text>
      <text start="18" dur="6">because having information about one will affect the information about the other.</text>
    </transcript>
  </video>
  <video title="Unit 4, 3b Second Question" id="uZfGhIFH92g">
    <transcript>
      <text start="0" dur="5">[Norvig] Now we&amp;#39;ll continue and we&amp;#39;ll add the node A for alarm to the network.</text>
      <text start="5" dur="4">And what I want you to do is click on all the other variables</text>
      <text start="9" dur="4">that A is dependent on in this network.</text>
    </transcript>
  </video>
  <video title="Unit 4, 3c Second Answer" id="X1WygrN9ens">
    <transcript>
      <text start="1" dur="4">[Norvig] The answer is that alarm is dependent on both John and Mary.</text>
      <text start="5" dur="4">And so we can draw both nodes in, both arrows in.</text>
      <text start="9" dur="5">Intuitively that makes sense because if John calls,</text>
      <text start="14" dur="2">then it&amp;#39;s more likely that the alarm has occurred,</text>
      <text start="16" dur="4">likely as if Mary calls, and if both called, it&amp;#39;s really likely.</text>
      <text start="20" dur="3">So you can figure out the answer by intuitive reasoning,</text>
      <text start="23" dur="4">or you can figure it out by going to the conditional probability tables</text>
      <text start="27" dur="4">and seeing according to the definition of conditional probability</text>
      <text start="31" dur="2">whether the numbers work out.</text>
    </transcript>
  </video>
  <video title="Unit 4, 3d Third Question" id="rTeQXHTu2_A">
    <transcript>
      <text start="1" dur="4">[Norvig] Now we&amp;#39;ll continue and we&amp;#39;ll add the node B for burglary</text>
      <text start="5" dur="6">and ask again, click on all the variables that B is dependent on.</text>
    </transcript>
  </video>
  <video title="Unit 4, 3e Third Answer" id="_l7rPalYjmU">
    <transcript>
      <text start="0" dur="4">[Norvig] The answer is that B is dependent only on A.</text>
      <text start="4" dur="6">In other words, B is independent of J and M given A.</text>
    </transcript>
  </video>
  <video title="Unit 4, 3f Fourth Question" id="DX1YTIQsjtU">
    <transcript>
      <text start="0" dur="4">[Norvig] And finally, we&amp;#39;ll add the last node, E,</text>
      <text start="4" dur="3">and ask you to click on all the nodes that E is dependent on.</text>
    </transcript>
  </video>
  <video title="Unit 4, 3g Fourth Answer" id="T609y-a8bZc">
    <transcript>
      <text start="0" dur="4">[Norvig] And the answer is that E is dependent on A.</text>
      <text start="4" dur="2">That much is fairly obvious.</text>
      <text start="6" dur="2">But it&amp;#39;s also dependent on B.</text>
      <text start="8" dur="2">Now, why is that?</text>
      <text start="10" dur="3">E is dependent on A because if the earthquake did occur,</text>
      <text start="13" dur="3">then it&amp;#39;s more likely that the alarm would go off.</text>
      <text start="16" dur="3">On the other hand, E is also dependent on B</text>
      <text start="19" dur="4">because if a burglary occurred, then that would explain why the alarm is going off,</text>
      <text start="23" dur="3">and it would mean that the earthquake is less likely.</text>
    </transcript>
  </video>
  <video title="Unit 4, 3h Causal Direction" id="YPmGGwlRqY0">
    <transcript>
      <text start="0" dur="4">[Norvig] The moral is that Bayes nets tend to be the most compact</text>
      <text start="4" dur="8">and thus the easier to do inference on when they&amp;#39;re written in the causal direction--</text>
      <text start="12" dur="6">that is, when the networks flow from causes to effects.</text>
    </transcript>
  </video>
  <video title="Unit 4, 4 Variable Elimination" id="qyXspkUOhGc">
    <transcript>
      <text start="0" dur="6">Let&amp;#39;s return to this equation, which we use to show how to do inference by enumeration.</text>
      <text start="6" dur="4">In this equation, we join up the whole joint distribution</text>
      <text start="10" dur="5">before we sum out over the hidden variables.</text>
      <text start="15" dur="3">That&amp;#39;s slow, because we end up repeating a lot of work.</text>
      <text start="18" dur="7">Now we&amp;#39;re going to show a new technique called variable elimination,</text>
      <text start="25" dur="2">which in many networks operates much faster.</text>
      <text start="27" dur="3">It&amp;#39;s still a difficult computation, an NP-hard computation,</text>
      <text start="30" dur="4">to do inference over Bayes nets in general.</text>
      <text start="34" dur="4">Variable elimination works faster than inference by enumeration</text>
      <text start="38" dur="3">in most practical cases.</text>
      <text start="41" dur="4">It requires an algebra for manipulating factors,</text>
      <text start="45" dur="3">which are just names for multidimensional arrays</text>
      <text start="48" dur="5">that come out of these probabilistic terms.</text>
      <text start="53" dur="4">We&amp;#39;ll use another example to show how variable elimination works.</text>
      <text start="57" dur="3">We&amp;#39;ll start off with a network that has 3 boolean variables.</text>
      <text start="60" dur="4">R indicates whether or not it&amp;#39;s raining.</text>
      <text start="64" dur="8">T indicates whether or not there&amp;#39;s traffic,</text>
      <text start="72" dur="3">and T is dependent on whether it&amp;#39;s raining.</text>
      <text start="75" dur="4">And finally, L indicates whether or not I&amp;#39;ll be late for my next appointment,</text>
      <text start="79" dur="3">and that depends on whether or not there&amp;#39;s traffic.</text>
      <text start="82" dur="7">Now we&amp;#39;ll put up the conditional probability tables for each of these 3 variables.</text>
      <text start="89" dur="6">And then we can use inference to figure out the answer to questions like</text>
      <text start="95" dur="3">am I going to be late?</text>
      <text start="98" dur="4">And we know by definition that we could do that through enumeration</text>
      <text start="102" dur="5">by going through all the possible values for R and T</text>
      <text start="107" dur="7">and summing up the product of these 3 nodes.</text>
      <text start="114" dur="5">Now, in a simple network like this, straight enumeration would work fine,</text>
      <text start="119" dur="4">but in a more complex network, what variable elimination does is give us a way</text>
      <text start="123" dur="6">to combine together parts of the network into smaller parts</text>
      <text start="129" dur="4">and then enumerate over those smaller parts and then continue combining.</text>
      <text start="133" dur="2">So, we start with a big network.</text>
      <text start="135" dur="2">We eliminate some of the variables.</text>
      <text start="137" dur="7">We compute by marginalizing out, and then we have a smaller network to deal with,</text>
      <text start="144" dur="4">and we&amp;#39;ll show you how those 2 steps work.</text>
      <text start="148" dur="7">The first operation in variable elimination is called joining factors.</text>
      <text start="155" dur="4">A factor, again, is one of these tables.</text>
      <text start="159" dur="4">It&amp;#39;s a multidimensional matrix, and what we do is choose 2 of the factors,</text>
      <text start="163" dur="2">2 or more of the factors.</text>
      <text start="165" dur="4">In this case, we&amp;#39;ll choose these 2, and we&amp;#39;ll combine them together</text>
      <text start="169" dur="3">to form a new factor which represents</text>
      <text start="172" dur="4">the joint probability of all the variables in that factor.</text>
      <text start="176" dur="4">In this case, R and T.</text>
      <text start="180" dur="3">Now we&amp;#39;ll draw out that table.</text>
      <text start="183" dur="3">In each case, we just look up in the corresponding table,</text>
      <text start="186" dur="2">figure out the numbers, and multiply them together.</text>
      <text start="188" dur="5">For example, in this row we have a +r and a +t,</text>
      <text start="193" dur="6">so the +r is 0.1, and the entry for +r and +t  is 0.8,</text>
      <text start="199" dur="3">so multiply them together and you get 0.08.</text>
      <text start="202" dur="6">Go all the way down. For example, in the last row we have a -r and a -t.</text>
      <text start="208" dur="6">-r is 0.9. The entry for -r and -t is also 0.9.</text>
      <text start="214" dur="6">Multiply those together and you get 0.81.</text>
      <text start="220" dur="2">So, what have we done?</text>
      <text start="222" dur="3">We used the operation of joining factors on these 2 factors,</text>
      <text start="225" dur="5">getting us a new factor which is part of the existing network.</text>
      <text start="230" dur="6">Now we want to apply a second operation called elimination,</text>
      <text start="236" dur="6">also called summing out or marginalization, to take this table and reduce it.</text>
      <text start="242" dur="4">Right now, the tables we have look like this.</text>
      <text start="246" dur="4">We could sum out or marginalize over the variable R</text>
      <text start="250" dur="4">to give us a table that just operates on T.</text>
      <text start="254" dur="6">So, the question is to fill in this table for P(T)--</text>
      <text start="260" dur="3">there will be 2 entries in this table, the +t entry, formed by summing out</text>
      <text start="263" dur="5">all the entries here for all values of r for which t is positive,</text>
      <text start="268" dur="4">and the -t entry, formed the same way, by looking in this table</text>
      <text start="272" dur="5">and summing up all the rows over all values of r where t is negative.</text>
      <text start="277" dur="3">Put your answers in these boxes.</text>
    </transcript>
  </video>
  <video title="Unit 4, 4a Answer" id="4lm-TI7APX0">
    <transcript>
      <text start="0" dur="5">The answer is that for +t we look up the 2 possible values for r,</text>
      <text start="5" dur="4">and we get 0.08 or 0.09.</text>
      <text start="9" dur="4">Sum those up, get 0.17,</text>
      <text start="13" dur="5">and then we look at the 2 possible values of R for -t,</text>
      <text start="18" dur="4">and we get 0.02 and 0.81.</text>
      <text start="22" dur="5">Add those up, and we get 0.83.</text>
    </transcript>
  </video>
  <video title="Unit 4, 4b More Variable Elimination" id="Bk2S3ffdtsc">
    <transcript>
      <text start="0" dur="4">So, we took our network with RT and L. We summed out over R.</text>
      <text start="4" dur="5">That gives us a new network with T and L</text>
      <text start="9" dur="4">with these conditional probability tables.</text>
      <text start="13" dur="4">And now we want to do a join over T and L</text>
      <text start="17" dur="8">and give us a new table with the joint probability of P(T, L).</text>
      <text start="25" dur="3">And that table is going to look like this.</text>
    </transcript>
  </video>
  <video title="Unit 4, 4c Answer" id="LU9gMODL04Y">
    <transcript>
      <text start="0" dur="5">The answer, again, for joining variables is determined by pointwise multiplication,</text>
      <text start="5" dur="7">so we have 0.17 times 0.3 is 0.051,</text>
      <text start="12" dur="9">+t and +l, 0.17 times 0.7 is 0.119.</text>
      <text start="21" dur="2">Then we go to the minuses.</text>
      <text start="23" dur="8">Minus 0.83 times 0.1 is 0.083.</text>
      <text start="31" dur="7">And finally, 0.83 times 0.9 is 0.747.</text>
    </transcript>
  </video>
  <video title="Unit 4, 4d Even More Variable Elimination" id="5lImmoAK49A">
    <transcript>
      <text start="0" dur="6">Now we&amp;#39;re down to a network with a single node, T, L,</text>
      <text start="6" dur="6">with this joint probability table, and the only operation we have left to do</text>
      <text start="12" dur="5">is to sum out to give us a node with just L in it.</text>
      <text start="17" dur="9">So, the question is to compute P(L) for both values of L,</text>
      <text start="26" dur="4">+l and -l.</text>
    </transcript>
  </video>
  <video title="Unit 4, 4e Answer" id="3lqdPCE-sg8">
    <transcript>
      <text start="0" dur="3">The answer is that the +l values,</text>
      <text start="3" dur="8">0.051 plus 0.083 equals 0.134.</text>
      <text start="11" dur="4">And the negative values, 0.119 plus 0.747</text>
      <text start="15" dur="5">equals 0.886.</text>
    </transcript>
  </video>
  <video title="Unit 4, 4f Summary" id="-sFOKd_ZEJ8">
    <transcript>
      <text start="0" dur="3">So, that&amp;#39;s how variable elimination works.</text>
      <text start="3" dur="3">It&amp;#39;s a continued process of joining together factors</text>
      <text start="6" dur="5">to form a larger factor and then eliminating variables by summing out.</text>
      <text start="11" dur="4">If we make a good choice of the order in which we apply these operations,</text>
      <text start="15" dur="3">then variable elimination can be much more efficient</text>
      <text start="18" dur="3">than just doing the whole enumeration.</text>
    </transcript>
  </video>
  <video title="Unit 4, 4f Summary" id="hDdAZG4w5kA">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 4, 5 Approximate Inference Sampling" id="W5g-4a2PIcI">
    <transcript>
      <text start="0" dur="7">Now I want to talk about approximate inference</text>
      <text start="7" dur="5">by means of sampling.</text>
      <text start="12" dur="2">What do I mean by that?</text>
      <text start="14" dur="3">Say we want to deal with a joint probability distribution,</text>
      <text start="17" dur="7">say the distribution of heads and tails over these 2 coins.</text>
      <text start="24" dur="6">We can build a table and then start counting by sampling.</text>
      <text start="30" dur="2">Here we have our first sample.</text>
      <text start="32" dur="3">We flip the coins and the one-cent piece came up heads,</text>
      <text start="35" dur="4">and the five-cent piece came up tails,</text>
      <text start="39" dur="3">so we would mark down one count.</text>
      <text start="42" dur="3">Then we&amp;#39;d toss them again.</text>
      <text start="45" dur="5">This time the five cents is heads, and the one cent is tails,</text>
      <text start="50" dur="10">so we put down a count there, and we&amp;#39;d repeat that process</text>
      <text start="60" dur="6">and keep repeating it until we got enough counts that we could estimate</text>
      <text start="66" dur="5">the joint probability distribution by looking at the counts.</text>
      <text start="71" dur="4">Now, if we do a small number of samples, the counts might not be very accurate.</text>
      <text start="75" dur="4">There may be some random variation that causes them not to converge</text>
      <text start="79" dur="4">to their true values, but as we add more counts,</text>
      <text start="83" dur="2">the counts--as we add more samples,</text>
      <text start="85" dur="4">the counts we get will come closer to the true distribution.</text>
      <text start="89" dur="6">Thus, sampling has an advantage over inference in that we know a procedure</text>
      <text start="95" dur="7">for coming up with at least an approximate value for the joint probability distribution,</text>
      <text start="102" dur="8">as opposed to exact inference, where the computation may be very complex.</text>
      <text start="110" dur="3">There&amp;#39;s another advantage to sampling, which is if we don&amp;#39;t know</text>
      <text start="113" dur="6">what the conditional probability tables are, as we did in our other models,</text>
      <text start="119" dur="5">if we don&amp;#39;t know these numeric values, but we can simulate the process,</text>
      <text start="124" dur="4">we can still proceed with sampling, whereas we couldn&amp;#39;t with exact inference.</text>
    </transcript>
  </video>
  <video title="Unit 4, 6 Sampling Example" id="mXgfRvRmDFI">
    <transcript>
      <text start="0" dur="5">Here&amp;#39;s a new network that we&amp;#39;ll use to investigate</text>
      <text start="5" dur="5">how sampling can be used to do inference.</text>
      <text start="10" dur="4">In this network, we have 4 variables. They&amp;#39;re all boolean.</text>
      <text start="14" dur="3">Cloudy tells us if it&amp;#39;s cloudy or not outside,</text>
      <text start="17" dur="4">and that can have an effect on whether the sprinklers are turned on,</text>
      <text start="21" dur="2">and whether it&amp;#39;s raining.</text>
      <text start="23" dur="5">And those 2 variables in turn have an effect on whether the grass gets wet.</text>
      <text start="28" dur="6">Now, to do inference over this network using sampling,</text>
      <text start="34" dur="4">we start off with a variable where all the parents are defined.</text>
      <text start="38" dur="4">In this case, there&amp;#39;s only one such variable, Cloudy.</text>
      <text start="42" dur="6">And it&amp;#39;s conditional probability table tells us that the probability is 50% for Cloudy,</text>
      <text start="48" dur="4">50% for not Cloudy, and so we sample from that.</text>
      <text start="52" dur="7">We generate a random number, and let&amp;#39;s say it comes up with positive for Cloudy.</text>
      <text start="59" dur="3">Now that variable is defined, we can choose another variable.</text>
      <text start="62" dur="6">In this case, let&amp;#39;s choose Sprinkler, and we look at the rows in the table</text>
      <text start="68" dur="5">for which Cloudy, the parent, is positive, and we see we should sample</text>
      <text start="73" dur="6">with probability 10% to +s and 90% a -s.</text>
      <text start="79" dur="4">And so let&amp;#39;s say we do that sampling with a random number generator,</text>
      <text start="83" dur="3">and it comes up negative for Sprinkler.</text>
      <text start="86" dur="3">Now let&amp;#39;s jump over here. Look at the Rain variable.</text>
      <text start="89" dur="5">Again, the parent, Cloudy, is positive,</text>
      <text start="94" dur="4">so we&amp;#39;re looking at this part of the table.</text>
      <text start="98" dur="3">We get a 0.8 probability for Rain being positive,</text>
      <text start="101" dur="3">and a 0.2 probability for Rain being negative.</text>
      <text start="104" dur="7">Let&amp;#39;s say we sample that randomly, and it comes up Rain is positive.</text>
      <text start="111" dur="3">And now we&amp;#39;re ready to sample the final variable,</text>
      <text start="114" dur="7">and what I want  you to do is tell me which of the rows</text>
      <text start="121" dur="6">of this table should we be considering and tell me what&amp;#39;s more likely.</text>
      <text start="127" dur="8">Is it more likely that we have a +w or a -w?</text>
    </transcript>
  </video>
  <video title="Unit 4, 6a Sampling Example" id="K1ZyqpTJPK0">
    <transcript>
      <text start="0" dur="3">The answer to the question is that we look at the parents.</text>
      <text start="3" dur="3">We find that the Sprinkler variable is negative,</text>
      <text start="6" dur="3">so we&amp;#39;re looking at this part of the table.</text>
      <text start="9" dur="5">And the Rain variable is positive, so we&amp;#39;re looking at this part.</text>
      <text start="14" dur="4">So, it would be these 2 rows that we would consider,</text>
      <text start="18" dur="7">and thus, we&amp;#39;d find there&amp;#39;s a 0.9 probability for w, the grass being wet,</text>
      <text start="25" dur="3">and only 0.1 for it being negative,</text>
      <text start="28" dur="3">so the positive is more likely.</text>
      <text start="31" dur="3">And once we&amp;#39;ve done that, then we generated a complete sample,</text>
      <text start="34" dur="3">and we can write down the sample here.</text>
      <text start="37" dur="6">We had +c, -s, +r.</text>
      <text start="43" dur="8">And assuming we got a probability of 0.9 came out in favor of the +w,</text>
      <text start="51" dur="3">that would be the end of the sample.</text>
      <text start="54" dur="5">Then we could throw all this information out and start over again</text>
      <text start="59" dur="6">by having another 50/50 choice for cloudy and then working our way through the network.</text>
    </transcript>
  </video>
  <video title="Unit 4, 6b More Sampling" id="fChe7bVEdHQ">
    <transcript>
      <text start="0" dur="4">Now, the probability of sampling a particular variable,</text>
      <text start="4" dur="6">choosing a +w or a -w, depends on the values of the parents.</text>
      <text start="10" dur="4">But those are chosen according to the conditional probability tables,</text>
      <text start="14" dur="4">so in the limit, the count of each sampled variable</text>
      <text start="18" dur="2">will approach the true probability.</text>
      <text start="20" dur="4">That is, with an infinite number of samples, this procedure computes the true</text>
      <text start="24" dur="3">joint probability distribution.</text>
      <text start="27" dur="6">We say that the sampling method is consistent.</text>
      <text start="33" dur="5">We can use this kind of sampling to compute the complete joint probability distribution,</text>
      <text start="38" dur="5">or we can use it to compute a value for an individual variable.</text>
      <text start="43" dur="4">But what if we wanted to compute a conditional probability?</text>
      <text start="47" dur="6">Say we wanted to compute the probability of wet grass</text>
      <text start="53" dur="5">given that it&amp;#39;s not cloudy.</text>
      <text start="58" dur="5">To do that, the sample that we generated here wouldn&amp;#39;t be helpful at all</text>
      <text start="63" dur="5">because it has to do with being cloudy, not with being not cloudy.</text>
      <text start="68" dur="3">So, we would cross this sample off the list.</text>
      <text start="71" dur="6">We would say that we reject the sample, and this technique is called rejection sampling.</text>
      <text start="77" dur="4">We go through ignoring any samples that don&amp;#39;t match</text>
      <text start="81" dur="3">the conditional probabilities that we&amp;#39;re interested in</text>
      <text start="84" dur="10">and keeping samples that do, say the sample -c, +s, +r, -w.</text>
      <text start="94" dur="3">We would just continue going through generating samples,</text>
      <text start="97" dur="4">crossing off the ones that don&amp;#39;t match, keeping the ones that do.</text>
      <text start="101" dur="5">And this procedure would also be consistent.</text>
      <text start="106" dur="5">We call this procedure rejection sampling.</text>
    </transcript>
  </video>
  <video title="Unit 4, 7 Rejection Sampling" id="9IdjpH4xkGM">
    <transcript>
      <text start="0" dur="3">But there&amp;#39;s a problem with rejection sampling.</text>
      <text start="3" dur="5">If the evidence is unlikely, you end up rejecting a lot of the samples.</text>
      <text start="8" dur="8">Let&amp;#39;s go back to the alarm network where we had variables for burglary and for an alarm</text>
      <text start="16" dur="6">and say when arrested, in computing the probability of a burglary,</text>
      <text start="22" dur="3">given that the alarm goes off.</text>
      <text start="25" dur="3">The problem is that burglaries are very infrequent,</text>
      <text start="28" dur="4">so most of the samples we would get would end up being--</text>
      <text start="32" dur="7">we start with generating a B, and we get a -b and then a -a.</text>
      <text start="39" dur="4">We go back and say does this match?</text>
      <text start="43" dur="2">No, we have to reject this sample,</text>
      <text start="45" dur="5">so we generate another sample, and we get another -b, -a.</text>
      <text start="50" dur="4">We reject that. We get another -b, -a.</text>
      <text start="54" dur="6">And we keep rejecting, and eventually we get a +b,</text>
      <text start="60" dur="4">but we&amp;#39;d end up spending a lot of time rejecting samples.</text>
      <text start="64" dur="9">So, we&amp;#39;re going to introduce a new method called likelihood weighting</text>
      <text start="73" dur="4">that generates samples so that we can keep every one.</text>
      <text start="77" dur="3">With likelihood weighting, we fix the evidence variables.</text>
      <text start="80" dur="5">That is, we say that A will always be positive,</text>
      <text start="85" dur="3">and then we sample the rest of the variables,</text>
      <text start="88" dur="3">so then we get samples that we want.</text>
      <text start="91" dur="6">We would get a list like -b, +a,</text>
      <text start="97" dur="3">-b, +a,</text>
      <text start="100" dur="2">+b, +a.</text>
      <text start="102" dur="4">We get to keep every sample, but we have a problem.</text>
      <text start="106" dur="6">The resulting set of samples is inconsistent.</text>
      <text start="112" dur="4">We can fix that, however, by assigning a probability</text>
      <text start="116" dur="3">to each sample and weighing them correctly.</text>
    </transcript>
  </video>
  <video title="Unit 4, 8 Likelihood Weighting" id="GYcIruSqT_k">
    <transcript>
      <text start="0" dur="5">In likelihood weighting, we&amp;#39;re going to be collecting samples just like before,</text>
      <text start="5" dur="6">but we&amp;#39;re going to add a probabilistic weight to each sample.</text>
      <text start="11" dur="6">Now, let&amp;#39;s say we want to compute the probability of rain</text>
      <text start="17" dur="5">given that the sprinklers are on, and the grass is wet.</text>
      <text start="22" dur="2">We start as before.</text>
      <text start="24" dur="6">We make a choice for Cloudy, and let&amp;#39;s say that, again,</text>
      <text start="30" dur="3">we choose Cloudy being positive.</text>
      <text start="33" dur="4">Now we want to make a choice for Sprinkler,</text>
      <text start="37" dur="4">but we&amp;#39;re constrained to always choose Sprinkler being positive,</text>
      <text start="41" dur="3">so we&amp;#39;ll make that choice.</text>
      <text start="44" dur="6">And we know we were dealing with Cloudy being positive,</text>
      <text start="50" dur="6">so we&amp;#39;re in this row, and we&amp;#39;re forced to make the choice of Sprinkler being positive,</text>
      <text start="56" dur="9">and that has a probability of only 0.1, so we&amp;#39;ll put that 0.1 into the weight.</text>
      <text start="65" dur="4">Next, we&amp;#39;ll look at the Rain variable,</text>
      <text start="69" dur="4">and here we&amp;#39;re not constrained in any way, so we make a choice</text>
      <text start="73" dur="6">according to the probability tables with Cloudy being positive.</text>
      <text start="79" dur="8">And let&amp;#39;s say that we choose the more popular choice, and Rain gets the positive value.</text>
      <text start="87" dur="3">Now, we look at Wet Grass.</text>
      <text start="90" dur="5">We&amp;#39;re constrained to choose positive, and we know that the parents</text>
      <text start="95" dur="6">are also positive, so we&amp;#39;re dealing with this row here.</text>
      <text start="101" dur="6">Since it&amp;#39;s a constrained choice, we&amp;#39;re going to add in or multiply in an additional weight,</text>
      <text start="107" dur="8">and I want you to tell me what that weight should be.</text>
    </transcript>
  </video>
  <video title="Unit 4, 8a Answer" id="hvIL_fFvUGM">
    <transcript>
      <text start="0" dur="4">The answer is we&amp;#39;re looking for the probability</text>
      <text start="4" dur="5">of having a +w given a +s and a +r,</text>
      <text start="9" dur="7">so that&amp;#39;s in this row, so it&amp;#39;s 0.99.</text>
      <text start="16" dur="6">So, we take our old weight and multiply it by 0.99,</text>
      <text start="22" dur="6">gives us a final weight of 0.099</text>
      <text start="28" dur="9">for a sample of +c, +s, +r and +w.</text>
    </transcript>
  </video>
  <video title="Unit 4, 8b Likelihood Weighting is Consistent" id="jKcp0uQ_rUo">
    <transcript>
      <text start="0" dur="3">When we include the weights,</text>
      <text start="3" dur="5">counting this sample that was forced to have a +s and a +w</text>
      <text start="8" dur="6">with a weight of 0.099, instead of counting it as a full one sample,</text>
      <text start="14" dur="6">we find that likelihood weighting is also consistent.</text>
    </transcript>
  </video>
  <video title="Unit 4, 8c Likelihood Weighting Problems" id="ngGCGaIEvBU">
    <transcript>
      <text start="0" dur="3">Likelihood weighting is a great technique,</text>
      <text start="3" dur="2">but it doesn&amp;#39;t solve all our problems.</text>
      <text start="5" dur="9">Suppose we wanted to compute the probability of C given +s and +r.</text>
      <text start="14" dur="7">In other words, we&amp;#39;re constraining Sprinkler and Rain to always be positive.</text>
      <text start="21" dur="6">Since we use the evidence when we generate a node that has that evidence as parents,</text>
      <text start="27" dur="4">the Wet Grass node will always get good values based on that evidence.</text>
      <text start="31" dur="8">But the Cloudy node won&amp;#39;t, and so it will be generating values at random</text>
      <text start="39" dur="5">without looking at these values, and most of the time, or some of the time,</text>
      <text start="44" dur="4">it will be generating values that don&amp;#39;t go well with the evidence.</text>
      <text start="48" dur="3">Now, we won&amp;#39;t have to reject them like we do in rejection sampling,</text>
      <text start="51" dur="5">but they&amp;#39;ll have a low probability associated with them.</text>
    </transcript>
  </video>
  <video title="Unit 4, 9 Gibbs Sampling" id="QaojSzk7Hpw">
    <transcript>
      <text start="0" dur="7">A technique called Gibbs sampling,</text>
      <text start="7" dur="3">named after the physicist Josiah Gibbs,</text>
      <text start="10" dur="4">takes all the evidence into account and not just the upstream evidence.</text>
      <text start="14" dur="12">It uses a method called Markov Chain Monte Carlo, or MCMC.</text>
      <text start="26" dur="5">The idea is that we resample just one variable at a time</text>
      <text start="31" dur="2">conditioned on all the others.</text>
      <text start="33" dur="4">That is, we have a set of variables,</text>
      <text start="37" dur="7">and we initialize them to random variables, keeping the evidence values fixed.</text>
      <text start="44" dur="4">Maybe we have values like this,</text>
      <text start="48" dur="6">and that constitutes one sample, and now, at each iteration through the loop,</text>
      <text start="54" dur="7">we select just one non-evidence variable and resample it</text>
      <text start="61" dur="3">based on all the other variables.</text>
      <text start="64" dur="7">And that will give us another sample, and repeat that again.</text>
      <text start="71" dur="4">Choose another variable.</text>
      <text start="75" dur="6">Resample that variable and repeat.</text>
      <text start="81" dur="6">We end up walking around in this space of assignments of variables randomly.</text>
      <text start="87" dur="3">Now, in rejection and likelihood sampling,</text>
      <text start="90" dur="4">each sample was independent of the other samples.</text>
      <text start="94" dur="3">In MCMC, that&amp;#39;s not true.</text>
      <text start="97" dur="3">The samples are dependent on each other, and in fact,</text>
      <text start="100" dur="2">adjacent samples are very similar.</text>
      <text start="102" dur="4">They only vary or differ in one place.</text>
      <text start="106" dur="4">However, the technique is still consistent. We won&amp;#39;t show the proof for that.</text>
    </transcript>
  </video>
  <video title="Unit 4, 10 Monty Hall Problem" id="6uF6Fh0qpV0">
    <transcript>
      <text start="0" dur="2">Now, just one more thing.</text>
      <text start="2" dur="5">I can&amp;#39;t help but describe what is probably the most famous probability problem of all.</text>
      <text start="7" dur="4">It&amp;#39;s called the Monty Hall Problem after the game show host.</text>
      <text start="11" dur="4">And the idea is that  you&amp;#39;re on a game show, and there&amp;#39;s 3 doors:</text>
      <text start="15" dur="5">door #1, door #2, and door #3.</text>
      <text start="20" dur="6">And behind each door is a prize, and you know that one of the doors</text>
      <text start="26" dur="3">contains an expensive sports car, which  you would find desirable,</text>
      <text start="29" dur="6">and the other 2 doors contain a goat, which you would find less desirable.</text>
      <text start="35" dur="7">Now, say you&amp;#39;re given a choice, and let&amp;#39;s say you choose door #1.</text>
      <text start="42" dur="5">But according to the conventions of the game, the host, Monty Hall,</text>
      <text start="47" dur="5">will now open one of the doors, knowing that the door that he opens</text>
      <text start="52" dur="5">contains a goat, and he shows you door #3.</text>
      <text start="57" dur="5">And he now gives you the opportunity to stick with your choice</text>
      <text start="62" dur="3">or to switch to the other door.</text>
      <text start="65" dur="5">What I want you to tell me is, what is your probability of winning</text>
      <text start="70" dur="5">if you stick to door #1, and what is the probability of winning</text>
      <text start="75" dur="4">if you switched to door #2?</text>
    </transcript>
  </video>
  <video title="Unit 4, 10a Answer" id="x7x6nHvQEQ4">
    <transcript>
      <text start="0" dur="8">The answer is that you have a 1/3 chance of winning if you stick with door #1</text>
      <text start="8" dur="4">and a 2/3 chance if  you switch to door #2.</text>
      <text start="12" dur="4">How do we explain that, and why isn&amp;#39;t it 50/50?</text>
      <text start="16" dur="2">Well, it&amp;#39;s true that there&amp;#39;s 2 possibilities,</text>
      <text start="18" dur="4">but we&amp;#39;ve learned from probability that just because there are 2 options</text>
      <text start="22" dur="4">doesn&amp;#39;t mean that both options are equally likely.</text>
      <text start="26" dur="4">It&amp;#39;s easier to explain why the first door has a 1/3 probability</text>
      <text start="30" dur="4">because when you started, the car could be in any one of 3 places.</text>
      <text start="34" dur="3">You chose one of them. That probability was 1/3.</text>
      <text start="37" dur="6">And that probability hasn&amp;#39;t been changed by the revealing of one of the other doors.</text>
      <text start="43" dur="2">Why is door #2 two-thirds?</text>
      <text start="45" dur="4">Well, one way to explain it is that the probability has to sum to 1,</text>
      <text start="49" dur="4">and if 1/3 is here, the 2/3 has to be here.</text>
      <text start="53" dur="5">But why doesn&amp;#39;t the same argument that you use for 1 hold for 2?</text>
      <text start="58" dur="5">Why can&amp;#39;t we say the probability of 2 holding the car</text>
      <text start="63" dur="4">was 1/3 before this door was revealed?</text>
      <text start="67" dur="4">Why has that changed 2 and has not changed 1?</text>
      <text start="71" dur="3">And the reason is because we&amp;#39;ve learned something about door #2.</text>
      <text start="74" dur="4">We&amp;#39;ve learned that it wasn&amp;#39;t the door that was flipped over by the host,</text>
      <text start="78" dur="4">and so that additional information has updated the probability,</text>
      <text start="82" dur="4">whereas we haven&amp;#39;t learned anything additional about door #1</text>
      <text start="86" dur="4">because it was never an option that the host might switch door #1.</text>
      <text start="90" dur="7">And in fact, in this case, if we reveal the door,</text>
      <text start="97" dur="3">we find that&amp;#39;s where the car actually is.</text>
      <text start="100" dur="5">So you see, learning probability may end up winning you something.</text>
    </transcript>
  </video>
  <video title="Unit 4, 10b Monty Hall Letter" id="CIrfGiP65UI">
    <transcript>
      <text start="0" dur="7">Now, as a final epilogue, I have here a copy of a letter written by Monty Hall himself</text>
      <text start="7" dur="3">in 1990 to Professor Lawrence Denenberg of Harvard</text>
      <text start="10" dur="4">who, with Harry Lewis, wrote a statistics book</text>
      <text start="14" dur="4">in which they used the Monty Hall Problem as an example,</text>
      <text start="18" dur="5">and they wrote to Monty asking him for permission to use his name.</text>
      <text start="23" dur="3">Monty kindly granted the permission, but in his letter,</text>
      <text start="26" dur="5">he writes, &amp;quot;As I see it, it wouldn&amp;#39;t make any difference after the player</text>
      <text start="31" dur="3">has selected Door A, and having been shown Door C--</text>
      <text start="34" dur="4">why should he then attempt to switch to Door B?</text>
      <text start="38" dur="6">So, we see Monty Hall himself did not understand the Monty Hall Problem.</text>
    </transcript>
  </video>
  <video title="Homework 2 Bayes Rule" id="_fJTJNK9ejY">
    <transcript>
      <text start="0" dur="6">[Thrun] Given the following Bayes network with P of A equal to 0.5,</text>
      <text start="6" dur="2">P of B given the A equals 0.2,</text>
      <text start="8" dur="4">and P of B given not A 0.8,</text>
      <text start="12" dur="4">calculate the following probability.</text>
    </transcript>
  </video>
  <video title="Homework 2 Simple Bayes Net" id="f6mq9rTj-Po">
    <transcript>
      <text start="0" dur="3">[Thrun] Consider a network of the following type:</text>
      <text start="3" dur="7">a variable, A, that is binary connects to three variables, X1, X2, and X3,</text>
      <text start="10" dur="2">that are also binary.</text>
      <text start="12" dur="12">The probability of A is 0.5, and for all variable XI we have the probability of XI given A is 0.2,</text>
      <text start="24" dur="5">and the probability of XI given not A equals 0.6.</text>
      <text start="29" dur="2">I would like to know from you the probability of A</text>
      <text start="31" dur="6">given that we observed X1, X2, and not X3.</text>
      <text start="37" dur="5">Notice that these variables over here are conditionally independent given A.</text>
    </transcript>
  </video>
  <video title="Homework 2 Simple Bayes Net 2 " id="P6WEObhmL_o">
    <transcript>
      <text start="0" dur="3">[Thrun] Let us consider the same network again.</text>
      <text start="3" dur="7">I would like to know the probability of X3 given that I observed X1.</text>
    </transcript>
  </video>
  <video title="Homework 2 Conditional Independence " id="pP7U6KIO9yE">
    <transcript>
      <text start="0" dur="4">[Thrun] In this next homework assignment I will be drawing you a Bayes network</text>
      <text start="4" dur="5">and will ask you some conditional independence questions.</text>
      <text start="9" dur="5">Is B conditionally independent of C? And say yes or no.</text>
      <text start="14" dur="5">Is B conditionally independent of C given D? And say yes or no.</text>
      <text start="19" dur="5">Is B conditionally independent of C given A? And say yes or no.</text>
      <text start="24" dur="5">And is B conditionally independent given A and D? And say yes or no.</text>
    </transcript>
  </video>
  <video title="Homework 2 Conditional Indepedence 2 " id="LMKW60DmJtc">
    <transcript>
      <text start="0" dur="2">[Thrun] Consider the following network.</text>
      <text start="2" dur="6">I would like to know whether the following statements are true or false.</text>
      <text start="8" dur="4">C is conditionally independent of E given A.</text>
      <text start="12" dur="6">B is conditionally independent of D given C and E.</text>
      <text start="18" dur="3">A is conditionally independent of C given E.</text>
      <text start="21" dur="4">And A is conditionally independent of C given B.</text>
      <text start="25" dur="3">Please check yes or no for each of these questions.</text>
    </transcript>
  </video>
  <video title="Homework 2 Parameter Count " id="8npZMwT0Sac">
    <transcript>
      <text start="0" dur="4">[Thrun] In my final question I&amp;#39;ll look at the exact same network as before,</text>
      <text start="4" dur="4">but I would like to know the minimum number of numerical parameters</text>
      <text start="8" dur="5">such as the values to define probabilities and conditional probabilities</text>
      <text start="13" dur="4">that are necessary to specify the joint distribution of all 5 variables.</text>
    </transcript>
  </video>
  <video title="Unit 5 1 Introduction" id="8o1fAcyhap4">
    <transcript>
      <text start="0" dur="3">Welcome to the machine learning unit.</text>
      <text start="3" dur="3">Machine learning is a fascinating area.</text>
      <text start="6" dur="3">The world has become immeasurably data-rich.</text>
      <text start="9" dur="3">The world wide web has come up over the last decade.</text>
      <text start="12" dur="3">The human genome is being sequenced.</text>
      <text start="15" dur="4">Vast chemical databases, pharmaceutical databases,</text>
      <text start="19" dur="3">and financial databases are now available</text>
      <text start="22" dur="4">on a scale unthinkable even 5 years ago.</text>
      <text start="26" dur="2">To make sense out of the data,</text>
      <text start="28" dur="2">to extract information from the data,</text>
      <text start="30" dur="3">machine learning is the discipline to go.</text>
      <text start="33" dur="4">Machine learning is an important subfeed of artificial intelligence,</text>
      <text start="37" dur="3">it&amp;#39;s my personal favorite next to robotics</text>
      <text start="40" dur="3">because I believe it has a huge impact on society</text>
      <text start="43" dur="4">and is absolutely necessary as we move forward.</text>
      <text start="47" dur="3">So in this class, I teach you some of the very basics of</text>
      <text start="50" dur="2">machine learning, and in our next unit</text>
      <text start="52" dur="4">Peter will tell you some more about machine learning.</text>
      <text start="56" dur="4">We&amp;#39;ll talk about supervised learning, which is one side of machine learning,</text>
      <text start="60" dur="2">and Peter will tell you about unsupervised learning,</text>
      <text start="62" dur="3">which is a different style.</text>
      <text start="65" dur="2">Later in this class we will also encounter reinforcement learning,</text>
      <text start="67" dur="3">which is yet another set of machine learning.</text>
      <text start="70" dur="1">Anyhow, let&amp;#39;s just dive in.</text>
    </transcript>
  </video>
  <video title="Unit 5 2 What is Machine Learning" id="tEzGdI9nQt4">
    <transcript>
      <text start="0" dur="3.999">Welcome to the first class on machine learning.</text>
      <text start="3.999" dur="3.575">So far we talked a lot about Bayes Networks.</text>
      <text start="7.574" dur="2.836">And the way we talked about them</text>
      <text start="10.41" dur="3.69">is all about reasoning within Bayes Networks</text>
      <text start="14.1" dur="0.982">that are known.</text>
      <text start="15.082" dur="2.035">Machine learning addresses the problem</text>
      <text start="17.117" dur="2.169">of how to find those networks</text>
      <text start="19.286" dur="0.867">or other models</text>
      <text start="20.153" dur="2.369">based on data.</text>
      <text start="22.522" dur="3.275">Learning models from data</text>
      <text start="25.797" dur="3.265">is a major, major area of artificial intelligence</text>
      <text start="29.062" dur="2.006">and it&amp;#39;s perhaps the one</text>
      <text start="31.068" dur="2.632">that had the most commercial success.</text>
      <text start="33.7" dur="3.304">In many commercial applications</text>
      <text start="37.004" dur="2.068">the models themselves are fitted</text>
      <text start="39.072" dur="1.402">based on data.</text>
      <text start="40.474" dur="1.702">For example, Google</text>
      <text start="42.176" dur="2.135">uses data to understand</text>
      <text start="44.311" dur="2.593">how to respond to each search query.</text>
      <text start="46.904" dur="2.379">Amazon uses data</text>
      <text start="49.283" dur="2.769">to understand how to place products on their website.</text>
      <text start="52.052" dur="1.635">And these machine learning techniques</text>
      <text start="53.687" dur="2.503">are the enabling techniques that make that possible.</text>
      <text start="56.19" dur="1.334">So this class</text>
      <text start="57.524" dur="1.635">which is about supervised learning</text>
      <text start="59.159" dur="3.37">will go through some very basic methods</text>
      <text start="62.529" dur="1.902">for learning models from data</text>
      <text start="64.431" dur="2.369">in particular, specific types of Bayes Networks.</text>
      <text start="66.8" dur="1.635">We will complement this</text>
      <text start="68.435" dur="2.435">with a class on unsupervised learning</text>
      <text start="70.87" dur="3.204">that will be taught next</text>
      <text start="74.074" dur="1.502">after this class.</text>
      <text start="75.576" dur="3.224">Let me start off with a quiz.</text>
      <text start="78.8" dur="1.814">The quiz is: What companies are famous</text>
      <text start="80.614" dur="3.503">for machine learning using data?</text>
      <text start="84.117" dur="5.533">Google for mining the web.</text>
      <text start="89.65" dur="1.953">Netflix for mining what people</text>
      <text start="91.603" dur="4.426">would like to rent on DVDs.</text>
      <text start="96.029" dur="4.605">Which is DVD recommendations.</text>
      <text start="100.634" dur="5.205">Amazon.com for product placement.</text>
      <text start="105.839" dur="2.102">Check any or all</text>
      <text start="107.941" dur="1.135">and if none of those apply</text>
      <text start="109.076" dur="4">check down here.</text>
    </transcript>
  </video>
  <video title="Unit 5 3 Answer" id="SnbvK3_ayWI">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 4 Stanley DARPA Grand Challenge" id="Q1xFdQfq5Fk">
    <transcript>
      <text start="0" dur="5">In my own research, I&amp;#39;ve extensively used machine learning for robotics.</text>
      <text start="5" dur="3">What you see here is a robot my students and I built at Stanford</text>
      <text start="8" dur="4">called Stanley, and it won the DARPA Grand Challenge.</text>
      <text start="12" dur="4">It&amp;#39;s a self-driving car that drives without any human assistance whatsoever,</text>
      <text start="16" dur="5">and this vehicle extensively uses machine learning.</text>
      <text start="22" dur="3">The robot is equipped with a laser system</text>
      <text start="25" dur="3">I will talk more about lasers in my robotics class,</text>
      <text start="28" dur="3">but here you can see how the robot is able to build</text>
      <text start="31" dur="3">3-D models of the terrain ahead.</text>
      <text start="34" dur="3">These are almost like video game models that allow it to make</text>
      <text start="37" dur="2">assessments where to drive and where not to drive.</text>
      <text start="39" dur="4">Essentially, it&amp;#39;s trying to drive on flat ground.</text>
      <text start="43" dur="3">The problem with these lasers is that they don&amp;#39;t see very far.</text>
      <text start="46" dur="4">They see about 25 meters out, so to drive really fast</text>
      <text start="50" dur="3">the robot has to see further.</text>
      <text start="53" dur="3">This is where machine learning comes into play.</text>
      <text start="56" dur="2">What you see here is camera images delivered by the robot</text>
      <text start="58" dur="3">superimposed with laser data that doesn&amp;#39;t see very far,</text>
      <text start="61" dur="3">but the laser is good enough to extract samples</text>
      <text start="64" dur="4">of driveable road surface that can then be machine learned</text>
      <text start="68" dur="2">and extrapolated into the entire camera image.</text>
      <text start="70" dur="3">That enables the robot to use the camera</text>
      <text start="73" dur="3">to see driveable terrain all the way to the horizon</text>
      <text start="76" dur="6">up to like 200 meters out, enough to drive really, really fast.</text>
      <text start="82" dur="5">This ability to adapt its vision by driving its own training examples using lasers</text>
      <text start="87" dur="3">but seeing out 200 meters or more</text>
      <text start="90" dur="3">was a key factor in winning the race.</text>
    </transcript>
  </video>
  <video title="Unit 5 5 Taxonomy" id="m-hcAePIkWY">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 6 Supervised Learning" id="nxX9Ihi4HZQ">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 7 Occam's Razor" id="FHJx9RVVKFg">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 8 SPAM Detection" id="wMMGexgmES4">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 9 Answer" id="fPkxtmxRt5k">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 10 Question" id="Diqx3Z20YWc">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 11 Answer" id="WFE-dmEJZF8">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 12 Maximum Likelihood_1" id="QBlERVSlFx4">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 13 Answer" id="4q4Tk-4Long">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 14 Relationship to Bayes Networks" id="MvwZNmJQIJw">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 15 Answer" id="-Pms2FiJQIA">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 16 Question" id="2BFCqec6n04">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 17 Answer" id="lQe4iNP6HDA">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 18 Question" id="qVdxj8XOB00">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 19 Answer" id="eSbURIQ6pSQ">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 20 Question" id="dfVAnFFxFP4">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 21 Answer and Laplace Smoothing" id="0BpC-cLDCIE">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 22 Answer" id="2sKSZHkQPrc">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 23 Question" id="2Ar6jFKZhUM">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 24 Answer" id="DjvGl1qRVdE">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 25 Question" id="RJAFdBfGOrY">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 26 Answer" id="oh4uc-8O6Pc">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 27 Summary Naive Bayes" id="c2yFCp6BrEA">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 28 Advanced SPAM Filtering" id="GSHJspQH15c">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 29 Digit Recognition" id="kD2wD_MDVk4">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 29 Digit Recognition" id="ZCzrCk8FvcE">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 30 Overfitting Prevention" id="-jswWk8YLro">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 31 Classification vs Regression" id="5RLRKkzYWuQ">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 32 Answer" id="4kXyi3KWcSw">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 33 Linear Regression" id="4bGWN67R9G0">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 34 Answer" id="pLwMXAPKdas">
    <transcript>
      <text start="0" dur="3">This is a suprisingly challenging question.</text>
      <text start="3" dur="4">If you look at these numbers from 3 to 6.</text>
      <text start="7" dur="7">When we increase X by 3, Y decreases by 3,</text>
      <text start="14" dur="4">which suggests W1 is -1.</text>
      <text start="18" dur="2">Now let&amp;#39;s see if this holds.</text>
      <text start="20" dur="4">If we increase X by 3, it decreases Y by 3.</text>
      <text start="24" dur="4">If we increase X by 1, we decrease Y by 1.</text>
      <text start="28" dur="4">If we increase X by 2, we decrease Y by 2.</text>
      <text start="32" dur="4">So this number seems to be an exact fit.</text>
      <text start="36" dur="5">Next we have to get the constant W0 right.</text>
      <text start="41" dur="7">For X = 3, we get -3 as an expression over here,</text>
      <text start="48" dur="2">because we know W1 = -1.</text>
      <text start="50" dur="7">So if this has to equal zero in the end, then W0 has to be 3.</text>
      <text start="57" dur="2">Let&amp;#39;s do a quick check.</text>
      <text start="59" dur="3">-3 plus 3 is 0.</text>
      <text start="62" dur="3">-6 plus 3 is -3.</text>
      <text start="65" dur="4">And if we plug in any of the numbers, you find those are correct.</text>
      <text start="69" dur="3">Now this is the case of an exact data set.</text>
      <text start="72" dur="5">It gets much more challenging if the data set cannot be fit with a linear function.</text>
    </transcript>
  </video>
  <video title="Unit 5 35 More Linear Regression" id="v4XIkABA1N0">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 36 Quadratic Loss" id="wUFYzzrd6TQ">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 37 Answer" id="ocviSEb04bk">
    <transcript>
      <text start="0" dur="9">And the answer is W0 = 0.5, and W1 = 0.9.</text>
      <text start="9" dur="5">If I were to draw a line, it would go about like this.</text>
      <text start="14" dur="5">It doesn&amp;#39;t really hit the two points at the end.</text>
      <text start="19" dur="5">If you were thinking of something like this, you were wrong.</text>
      <text start="24" dur="4">If you draw a curve like this, your quadratic error becomes 2.</text>
      <text start="28" dur="2">One over here, and one over here.</text>
      <text start="30" dur="5">The quadratic error is smaller for the line that goes in between those points.</text>
      <text start="35" dur="6">This is easily seen by computing as shown in the previous slide.</text>
      <text start="41" dur="14">W1 equals (4 x 118 - 20 x 20) / (4 x 120 - 400) which is 0.9.</text>
      <text start="55" dur="5">This is merely plugging in those numbers into the formulas I gave you.</text>
      <text start="60" dur="5">W0 then becomes  x 20.</text>
      <text start="65" dur="7">Now we plug in W1-- 0.9 / 4  x  20 equals 0.5.</text>
      <text start="72" dur="4">This is an example of linear regression,</text>
      <text start="76" dur="2">in which case there is a residual error,</text>
      <text start="78" dur="4">and the best-fitting curve is the one that minimizes</text>
      <text start="82" dur="5">the total of the residual vertical error in this graph over here.</text>
    </transcript>
  </video>
  <video title="Unit 5 38 Problems with Linear Regression" id="w7Ip8r0EIJQ">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 39 Answer" id="PYZ-7YS5T0k">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 40 Linear Regression and Complexity Control" id="4G5mH4FW-WY">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 41 Minimizing Complicated Loss Functions" id="0RmqLOxexh4">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 42 Answer" id="rAcwpZJqAZA">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 43 Question" id="dKKigX6nhyU">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 44 Answer" id="5Vm8ibmxroE">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 45 Question" id="2oy1QoXsvGQ">
    <transcript>
      <text start="0" dur="4">[Thrun] Here is a final gradient descent quiz.</text>
      <text start="4" dur="4">Suppose we have a loss function like this</text>
      <text start="8" dur="4">and our gradient descent starts over here.</text>
      <text start="12" dur="3">Will it likely reach the global minimum?</text>
      <text start="15" dur="2">Yes or no.</text>
      <text start="17" dur="4">Please check one of those boxes.</text>
    </transcript>
  </video>
  <video title="Unit 5 46 Answer" id="R1o9wbhnv94">
    <transcript>
      <text start="0" dur="2">[Thrun] And the answer is yes,</text>
      <text start="2" dur="4">although, technically speaking, to reach the absolute global minimum</text>
      <text start="6" dur="5">we need the learning rates to become smaller and smaller over time.</text>
      <text start="11" dur="4">If they stay constant, there is a chance this thing might bounce around</text>
      <text start="15" dur="3">between 2 points in the end and never reach the global minimum.</text>
      <text start="18" dur="4">But assuming that we implement gradient descent correctly,</text>
      <text start="22" dur="2">we will finally reach the global minimum.</text>
      <text start="24" dur="5">That&amp;#39;s not the case if you start over here, where we can get stuck over here</text>
      <text start="29" dur="3">and settle for the minimum over here, which is a local minimum</text>
      <text start="32" dur="3">and not the best solution to our optimization problem.</text>
      <text start="35" dur="3">So one of the important points to take away from this is</text>
      <text start="38" dur="5">gradient descent is universally applicable to more complicated problems--</text>
      <text start="43" dur="3">problems that don&amp;#39;t have a plausible solution.</text>
      <text start="46" dur="3">But you have to check whether there is many local minima,</text>
      <text start="49" dur="2">and if so, you have to worry about this.</text>
      <text start="51" dur="4">Any optimization book can tell you tricks how to overcome this.</text>
      <text start="55" dur="5">I won&amp;#39;t go into any more depth here in this class.</text>
    </transcript>
  </video>
  <video title="Unit 5 47 Gradient Descent Implementation" id="Iy9gzbQ7_3g">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 48 Perceptron" id="yOSGC67bOIk">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 49 Answer and SVMs" id="xRf9wAeU1kI">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 50 k Nearest Neighbors" id="ZLEilYyt28c">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 51 kNN Definition" id="r1PWSm6xMUk">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 52 Answer" id="PoRpuj4bijU">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 53 k as Smoothing Parameter" id="mhrG7atAn4Q">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 54 Problems with kNN" id="tOSoqfK9UNE">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 5 55 Congratulations" id="Ta7tyUB-EqM">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 1 Unsupervised Learning" id="s4Ou3NRJc-s">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 1a Answer" id="kFwsW2VtWWA">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 1b Question" id="GxeyaI9_P4o">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 1c Answer" id="4uj36iX1Pkk">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 2 Terminology" id="EZEOXNFgu8M">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 3 Google Street View and Clustering" id="W2dkDmHFMWg">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 4 k-Means Clustering Example" id="zaKjh2N8jN4">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 4a k-Means Algorithm" id="myqnyxkdQpc">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 4b Answer" id="0RMhiWfe73M">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 4c Question" id="oQYC32jKCvg">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 4d Answer" id="uxdSfp9n2CY">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 4e Question" id="3zlXl82LUVI">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 4f Answer" id="LgxZJ7GAB3o">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5 Expectation Maximization" id="_DhelJs0BFc">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5a Gaussian Learning" id="S4-694lgERs">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5b Maximum Likelihood" id="rMcw3uu4efY">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5c Answer" id="n1Ikbbe1g5M">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5d Question" id="R4izy_dyQzA">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5e Answer" id="Fr33yWlbvLk">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5f Question" id="pRGEQy7BgiY">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5g Answer" id="FWOa3qoYOd8">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5h Gaussian Summary" id="mlz-1yfyeoU">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5i EM as Generalization of k-Means" id="1CWDWmF0i2s">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5j EM Algorithm" id="tTr7547zVCc">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5k Answer" id="JW74VRSnZAk">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5l Question" id="TFViJ3P6NwM">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5m Answer" id="ZcTAhLG4OSs">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5n Question" id="0HENenZeAsE">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5o Answer" id="DODedtJZ3FA">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5p Choosing k" id="_-Ol1cXIWvQ">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 5q Clustering Summary" id="DH7FWwCgx5M">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 6 Dimensionality Reduction" id="lDyEk72TezE">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 6a Answer" id="AaSibhWmkQM">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 6b Question" id="0I4p7lyKo4k">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 6c Answer" id="wVkPH0eC4z0">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 6d Linear Dimensionality Reduction" id="5m6TeKw_e1M">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 6e Face Example" id="KuSZmepQA_s">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 6f Scan Example" id="XNCHCncvDto">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 6g Piece-Wise Linear Projection" id="bIZrRYKN_RY">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 7 Spectral Clustering" id="VxAMBkDUfeg">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 7a Answer" id="fuMoXRHxjTg">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 7b Spectral Clustering Algorithm" id="P-LEH-AFovE">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 7c Answer" id="VG8F24TAwzg">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 7d Question" id="1FZjz9O65ZU">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 7e Answer" id="924fCzIWetY">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Unit 6 8 Supervised vs Unsupervised Learning" id="qkcFRr7LqAw">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Homework 3 K Nearest Neighbors 2" id="qXR_IIL-VZY">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Homework 3 Perceptron " id="zpLDF6HrW_w">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Homework 3 Naive Bayes" id="rGWjGzcWm_Y">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Homework 3 Naive Bayes 2" id="YUhCs9cdoNQ">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Homework 3 Maximum Likelihood" id="OtnU31P68bQ">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Homework 3 Linear Regression" id="KcpbUw86hXg">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Homework 3 Linear Regression 2" id="FcIEuDUzo1M">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
  <video title="Homework 3 K Nearest Neighbors" id="RM3FfIYoOy8">
    <transcript>
      <text start="0" dur="3">No subtitles...</text>
    </transcript>
  </video>
</videos>