<videos date="Wed Nov 2 2011">
  <group title="Unit 0w" count="1">
    <video title="1 Introduction" id="BnIJ7Ba5Sr4" length="75">
      <transcript>
        <text start="0" dur="4">Welcome to the online introduction to artificial intelligence.</text>
        <text start="4" dur="3">My name is Sebastian Thrun. &amp;gt;&amp;gt;I&amp;#39;m Peter Norvig.</text>
        <text start="7" dur="2">We are teaching this class at Stanford,</text>
        <text start="9" dur="2">and now we are teaching it online for the entire world.</text>
        <text start="11" dur="2">We are really excited about this.</text>
        <text start="13" dur="1">It&amp;#39;s great to have you all here.</text>
        <text start="14" dur="4">It&amp;#39;s exciting to have such a record-breaking number of people.</text>
        <text start="18" dur="4">We think we can deliver a good introduction to artificial intelligence.</text>
        <text start="22" dur="2">We hope you&amp;#39;ll stick with it.</text>
        <text start="24" dur="1">It&amp;#39;s going to be a lot of work,</text>
        <text start="25" dur="2">but we think it&amp;#39;s going to be very rewarding.</text>
        <text start="27" dur="2">The way that it is going to be organized is that</text>
        <text start="29" dur="3">every week there is going to be new videos and with these videos, quizes.</text>
        <text start="32" dur="3">With these quizzes, you can test your knowledge about AI.</text>
        <text start="35" dur="3">We also post for the advanced version of this class, homework assignments and exams</text>
        <text start="38" dur="2">on which you&amp;#39;ll be quizzed.</text>
        <text start="40" dur="4">We&amp;#39;re going to grade those to give you a final score to see</text>
        <text start="44" dur="3">if you can actually master artificial intelligence the same way</text>
        <text start="47" dur="2">any good student at Stanford would do it.</text>
        <text start="49" dur="5">If you do that, then at the end of the class, we&amp;#39;ll sign a letter of accomplishment,</text>
        <text start="54" dur="4">and let you know that you&amp;#39;ve achieved this and what your rank in the class was.</text>
        <text start="58" dur="4">So I hope you have fun.  Watch us on videotape.</text>
        <text start="62" dur="2">We will teach you AI.</text>
        <text start="64" dur="2">Participate in the discussion forum.</text>
        <text start="66" dur="3">Ask your questions, and help others answer questions.</text>
        <text start="69" dur="3">I hope we have a fantastic time ahead of us in the next 10 weeks.</text>
        <text start="72" dur="3">Welcome to the class. We&amp;#39;ll see you online.</text>
      </transcript>
    </video>
  </group>
  <group title="Unit 1w" count="15">
    <video title="1 Introduction" id="Q7_GQq7cDyM" length="120">
      <transcript>
        <text start="0" dur="5">Welcome to the first unit of Online Introduction to Artificial Intelligence.</text>
        <text start="5" dur="4">I will be teaching you the very, very basics today.</text>
        <text start="9" dur="5">This is Unit 1 of Artificial Intelligence.</text>
        <text start="14" dur="2">Welcome.</text>
        <text start="16" dur="4">The purpose of this class is twofold:</text>
        <text start="20" dur="5">Number 1, to teach you the very basics of artificial intelligence</text>
        <text start="25" dur="4">so you&amp;#39;ll be able to talk to people in the field</text>
        <text start="29" dur="3">and understand the basic tools of the trade;</text>
        <text start="32" dur="5">and also, very importantly, to excite you about the field.</text>
        <text start="37" dur="5">I have been in the field of artificial intelligence for about 20 years,</text>
        <text start="42" dur="2">and it&amp;#39;s been truly rewarding.</text>
        <text start="44" dur="4">So I want you to participate in the beauty and the excitement of AI</text>
        <text start="48" dur="4">so you can become a professional who gets the same reward</text>
        <text start="52" dur="3">and excitement out of this field as I do.</text>
        <text start="55" dur="5">The basic structure of this class involves videos</text>
        <text start="60" dur="3">in which Peter or I will teach you something new,</text>
        <text start="63" dur="8">then also quizzes, which we will ask you about your ability to answer AI questions,</text>
        <text start="71" dur="6">and finally, answer videos in which we tell you what the right answer would have been</text>
        <text start="77" dur="5">for the quiz that you might have falsely or incorrectly answered before.</text>
        <text start="82" dur="6">This will all be reiterated, and every so often you get a homework assignment,</text>
        <text start="88" dur="6">also in the form of quizzes but without the answers.</text>
        <text start="94" dur="3">And then we also have video exams.</text>
        <text start="97" dur="2">If you check our website, there&amp;#39;s requirements</text>
        <text start="99" dur="4">on how you have to do assignments and exams.</text>
        <text start="103" dur="5">Please go to ai-class.org in this class.</text>
        <text start="108" dur="10">An AI program is called wetware, a formula, or an intelligent agent.</text>
        <text start="118" dur="2">Pick the one that fits best.</text>
      </transcript>
    </video>
    <video title="2 Intelligent Agents" id="cx3lV07w-XE" length="94">
      <transcript>
        <text start="0" dur="4">[Thrun] The correct answer is intelligent agent.</text>
        <text start="4" dur="3">Let&amp;#39;s talk about intelligent agents.</text>
        <text start="7" dur="4">Here is my intelligent agent,</text>
        <text start="11" dur="6">and it gets to interact with an environment.</text>
        <text start="17" dur="5">The agent can perceive the state of the environment</text>
        <text start="22" dur="3">through its sensors,</text>
        <text start="25" dur="4">and it can affect its state through its actuators.</text>
        <text start="29" dur="8">The big question of artificial intelligence is the function that maps sensors to actuators.</text>
        <text start="37" dur="4">That is called the control policy for the agent.</text>
        <text start="41" dur="7">So all of this class will deal with how does an agent make decisions</text>
        <text start="48" dur="6">that it can carry out with its actuators based on past sensor data.</text>
        <text start="54" dur="4">Those decisions take place many, many times,</text>
        <text start="58" dur="5">and the loop of environment feedback to sensors, agent decision,</text>
        <text start="63" dur="9">actuator interaction with the environment and so on is called perception action cycle.</text>
        <text start="72" dur="3">So here is my very first quiz for you.</text>
        <text start="75" dur="6">Artificial intelligence, AI, has successfully been used in finance,</text>
        <text start="81" dur="5">robotics, games, medicine, and the Web.</text>
        <text start="86" dur="2">Check any or all of those that apply.</text>
        <text start="88" dur="6">And if none of them applies, check the box down here that says none of them.</text>
      </transcript>
    </video>
    <video title="3 Applications of AI" id="N6JW8TQzbX8" length="388">
      <transcript>
        <text start="0" dur="3">So the correct answer is all of those--</text>
        <text start="3" dur="5">finance, robotics, games, medicine, the Web, and many more applications.</text>
        <text start="8" dur="2">So let me talk about them in some detail.</text>
        <text start="10" dur="5">There is a huge number of applications of artificial intelligence in finance,</text>
        <text start="15" dur="3">very often in the shape of making trading decisions--</text>
        <text start="18" dur="3">in which case, the agent is called a trading agent.</text>
        <text start="21" dur="6">And the environment might be things like the stock market or the bond market</text>
        <text start="27" dur="2">or the commodities market.</text>
        <text start="29" dur="4">And our trading agent can sense the course of certain things,</text>
        <text start="33" dur="2">like the stock or bonds or commodities.</text>
        <text start="35" dur="5">It can also read the news online and follow certain events.</text>
        <text start="40" dur="8">And its decisions are usually things like buy or sell decisions--trades.</text>
        <text start="48" dur="7">There&amp;#39;s a huge history of artificial intelligence finding methods to look at data over time</text>
        <text start="55" dur="3">and make predictions as to how courses develop over time--</text>
        <text start="58" dur="3">and then put in trades behind those.</text>
        <text start="61" dur="5">And very frequently, people using artificial intelligence trading agents</text>
        <text start="66" dur="4">have made a good amount of money with superior trading decisions.</text>
        <text start="70" dur="4">There&amp;#39;s also a long history of AI in Robotics.</text>
        <text start="74" dur="3">Here is my depiction of a robot.</text>
        <text start="77" dur="3">Of course, there are many different types of robots</text>
        <text start="80" dur="4">and they all interact with their environments through their sensors,</text>
        <text start="84" dur="9">which include things like cameras, microphones, tactile sensor or touch.</text>
        <text start="93" dur="5">And the way they impact their environments is to move motors around,</text>
        <text start="98" dur="5">in particular, their wheels, their legs, their arms, their grippers.</text>
        <text start="103" dur="3">They can also say things to people using voice.</text>
        <text start="106" dur="4">Now there&amp;#39;s a huge history of using artificial intelligence in robotics.</text>
        <text start="110" dur="4">Pretty much, every robot that does something interesting today uses AI.</text>
        <text start="114" dur="4">In fact, often AI has been studied together with robotics, as one discipline.</text>
        <text start="118" dur="5">But because robots are somewhat special in that they use physical actuators</text>
        <text start="123" dur="3">and deal with physical environments, they are a little bit different from</text>
        <text start="126" dur="2">just artificial intelligence, as a whole.</text>
        <text start="128" dur="7">When the Web came out, the early Web crawlers were called robots</text>
        <text start="135" dur="5">and to block a robot from accessing your website, to the present day,</text>
        <text start="140" dur="4">there&amp;#39;s a file called robot.txt, that allows you to deny any Web crawler</text>
        <text start="144" dur="4">to access and retrieve that information from your website.</text>
        <text start="148" dur="4">So historically, robotics played a huge role in artificial intelligence</text>
        <text start="152" dur="4">and a good chunk of this class will be focusing on robotics.</text>
        <text start="156" dur="3">AI has a huge history in games--</text>
        <text start="159" dur="4">to make games smarter or feel more natural.</text>
        <text start="163" dur="4">There are 2 ways in which AI has been used in games, as a game agent.</text>
        <text start="167" dur="3">One is to play against you, as a human user.</text>
        <text start="170" dur="4">So for example, if you play the game of Chess,</text>
        <text start="174" dur="3">then you are the environment to the game agent.</text>
        <text start="177" dur="6">The game agent gets to observe your moves, and it generates its own moves</text>
        <text start="183" dur="4">with the purpose of defeating you in Chess.</text>
        <text start="187" dur="3">So most adversarial games, where you play against an opponent</text>
        <text start="190" dur="3">and the opponent is a computer program,</text>
        <text start="193" dur="7">the game agent is built to play against you--against your own interests--and make you lose.</text>
        <text start="200" dur="2">And of course, your objective is to win.</text>
        <text start="202" dur="3">That&amp;#39;s an AI games-type situation.</text>
        <text start="205" dur="4">The second thing is that games agents in AI</text>
        <text start="209" dur="3">also are used to make games feel more natural.</text>
        <text start="212" dur="4">So very often games have characters inside, and these characters act in some way.</text>
        <text start="216" dur="6">And it&amp;#39;s important for you, as the player, to feel that these characters are believable.</text>
        <text start="222" dur="3">There&amp;#39;s an entire sub-field of artificial intelligence to use AI</text>
        <text start="225" dur="6">to make characters in a game more believable--look smarter, so to speak--</text>
        <text start="231" dur="4">so that you, as a player, think you&amp;#39;re playing a better game.</text>
        <text start="235" dur="5">Artificial intelligence has a long history in medicine as well.</text>
        <text start="240" dur="4">The classic example is that of a diagnostic agent.</text>
        <text start="244" dur="5">So here you are--and you might be sick, and you go to your doctor.</text>
        <text start="249" dur="2">And your doctor wishes to understand</text>
        <text start="251" dur="6">what the reason for your symptoms and your sickness is.</text>
        <text start="257" dur="4">The diagnostic agent will observe you through various measurements--</text>
        <text start="261" dur="4">for example, blood pressure and heart signals, and so on--</text>
        <text start="265" dur="4">and it&amp;#39;ll come up with the hypothesis as to what you might be suffering from.</text>
        <text start="269" dur="5">But rather than intervene directly, in most cases the diagnostic of your disease</text>
        <text start="274" dur="4">is communicated to the doctor, who then takes on the intervention.</text>
        <text start="278" dur="2">This is called a diagnostic agent.</text>
        <text start="280" dur="3">There are many other versions of AI in medicine.</text>
        <text start="283" dur="5">AI is used in intensive care to understand whether there are situations</text>
        <text start="288" dur="2">that need immediate attention.</text>
        <text start="290" dur="4">It&amp;#39;s been used for life-long medicine to monitor signs over long periods of time.</text>
        <text start="294" dur="4">And as medicine becomes more personal, the role of artificial intelligence</text>
        <text start="298" dur="3">will definitely increase.</text>
        <text start="301" dur="4">We already mentioned AI on the Web.</text>
        <text start="305" dur="4">The most generic version of AI is to crawl the Web and understand the Web,</text>
        <text start="309" dur="3">and assist you in answering questions.</text>
        <text start="312" dur="3">So when you have this search box over here</text>
        <text start="315" dur="3">and it says &amp;quot;Search&amp;quot; on the left,</text>
        <text start="318" dur="2">and &amp;quot;I&amp;#39;m Feeling Lucky&amp;quot; on the right,</text>
        <text start="320" dur="1">and you type in the words,</text>
        <text start="321" dur="7">what AI does for you is it understands what words you typed in</text>
        <text start="328" dur="2">and finds the most relevant pages.</text>
        <text start="330" dur="2">That is really co-artificial intelligence.</text>
        <text start="332" dur="4">It&amp;#39;s used by a number of companies, such as Microsoft and Google</text>
        <text start="336" dur="3">and Amazon, Yahoo, and many others.</text>
        <text start="339" dur="4">And the way this works is that there&amp;#39;s a crawling agent that can go</text>
        <text start="343" dur="8">to the World Wide Web and retrieve pages, through just a computer program.</text>
        <text start="351" dur="5">It then sorts these pages into a big database inside the crawler</text>
        <text start="356" dur="5">and also analyzes developments of each page to any possible query.</text>
        <text start="361" dur="3">When you then come and issue a query,</text>
        <text start="364" dur="4">the AI system is able to give you a response--</text>
        <text start="368" dur="4">for example, a collection of 10 best Web links.</text>
        <text start="372" dur="3">In short, every time you try to write a piece of software,</text>
        <text start="375" dur="3">that makes your computer software smart</text>
        <text start="378" dur="2">likely you will need artificial intelligence.</text>
        <text start="380" dur="3">And in this class, Peter and I will teach you</text>
        <text start="383" dur="2">many of the basic tricks of the trade</text>
        <text start="385" dur="3">to make your software really smart.</text>
      </transcript>
    </video>
    <video title="4 Terminology" id="5lcLmhsmBnQ" length="317">
      <transcript>
        <text start="0" dur="4">It will be good to introduce some basic terminology</text>
        <text start="4" dur="5">that is commonly used in artificial intelligence to distinguish different types of problems.</text>
        <text start="9" dur="7">The very first word I will teach you is  fully versus partially observable.</text>
        <text start="16" dur="3">An environment is called fully observable if what your agent can sense</text>
        <text start="19" dur="7">at any point in time is completely sufficient to make the optimal decision.</text>
        <text start="26" dur="3">So, for example, in many card games,</text>
        <text start="29" dur="7">when all the cards are on the table, the momentary site of all those cards</text>
        <text start="36" dur="4">is really sufficient to make the optimal choice.</text>
        <text start="40" dur="6">That is in contrast to some other environments where you need memory</text>
        <text start="46" dur="4">on the side of the agent to make the best possible decision.</text>
        <text start="50" dur="5">For example, in the game of poker, the cards aren&amp;#39;t openly on the table,</text>
        <text start="55" dur="5">and memorizing past moves will help you make a better decision.</text>
        <text start="60" dur="4">To fully understand the difference, consider the interaction of an agent</text>
        <text start="64" dur="4">with the environment to its sensors and its actuators,</text>
        <text start="68" dur="3">and this interaction takes place over many cycles,</text>
        <text start="71" dur="5">often called the perception-action cycle.</text>
        <text start="76" dur="3">For many environments, it&amp;#39;s convenient to assume</text>
        <text start="79" dur="3">that the environment has some sort of internal state.</text>
        <text start="82" dur="6">For example, in a card game where the cards are not openly on the table,</text>
        <text start="88" dur="5">the state might pertain to the cards in your hand.</text>
        <text start="93" dur="4">An environment is fully observable if the sensors can always see</text>
        <text start="97" dur="4">the entire state of the environment.</text>
        <text start="101" dur="5">It&amp;#39;s partially observable if the sensors can only see a fraction of the state,</text>
        <text start="106" dur="6">yet memorizing past measurements gives us additional information of the state</text>
        <text start="112" dur="3">that is not readily observable right now.</text>
        <text start="115" dur="6">So any game, for example, where past moves have information about</text>
        <text start="121" dur="5">what might be in a person&amp;#39;s hand, those games are partially observable,</text>
        <text start="126" dur="2">and they require different treatment.</text>
        <text start="128" dur="4">Very often agents that deal with partially observable environments</text>
        <text start="132" dur="3">need to acquire internal memory to understand what</text>
        <text start="135" dur="3">the state of the environment is, and we&amp;#39;ll talk extensively</text>
        <text start="138" dur="3">when we talk about hidden Markov models about how this structure</text>
        <text start="141" dur="2">has such internal memory.</text>
        <text start="143" dur="3">A second terminology for environments pertains to whether the environment</text>
        <text start="146" dur="3">is deterministic or stochastic.</text>
        <text start="149" dur="6">Deterministic environment is one where your agent&amp;#39;s actions</text>
        <text start="155" dur="2">uniquely determine the outcome.</text>
        <text start="157" dur="5">So, for example, in chess, there&amp;#39;s really no randomness when you move a piece.</text>
        <text start="162" dur="4">The effect of moving a piece is completely predetermined,</text>
        <text start="166" dur="4">and no matter where I&amp;#39;m going to move the same piece, the outcome is the same.</text>
        <text start="170" dur="2">That we call deterministic.</text>
        <text start="172" dur="4">Games with dice, for example, like backgammon, are stochastic.</text>
        <text start="176" dur="4">While you can still deterministically move your pieces,</text>
        <text start="180" dur="3">the outcome of an action also involves throwing of the dice,</text>
        <text start="183" dur="2">and  you can&amp;#39;t predict those.</text>
        <text start="185" dur="3">There&amp;#39;s a certain amount of randomness involved for the outcome of dice,</text>
        <text start="188" dur="2">and therefore, we call this stochastic.</text>
        <text start="190" dur="4">Let me talk about discrete versus continuous.</text>
        <text start="194" dur="4">A discrete environment is one where you have finitely many action choices,</text>
        <text start="198" dur="3">and finitely many things you can sense.</text>
        <text start="201" dur="4">So, for example, in chess, again, there&amp;#39;s finitely many board positions,</text>
        <text start="205" dur="3">and finitely many things you can do.</text>
        <text start="208" dur="2">That is different from a continuous environment</text>
        <text start="210" dur="5">where the space of possible actions or things you could sense may be infinite.</text>
        <text start="215" dur="6">So, for example, if you throw darts, there&amp;#39;s infinitely many ways to angle the darts</text>
        <text start="221" dur="2">and to accelerate them.</text>
        <text start="223" dur="6">Finally, we distinguish benign versus adversarial environments.</text>
        <text start="229" dur="4">In benign environments, the environment might be random.</text>
        <text start="233" dur="4">It might be stochastic, but it has no objective on its own</text>
        <text start="237" dur="2">that would contradict the own objective.</text>
        <text start="239" dur="3">So, for example, weather is benign.</text>
        <text start="242" dur="4">It might be random. It might affect the outcome of your actions.</text>
        <text start="246" dur="2">But it isn&amp;#39;t really out there to get you.</text>
        <text start="248" dur="6">Contrast this with adversarial environments, such as many games, like chess,</text>
        <text start="254" dur="2">where your opponent is really out there to get you.</text>
        <text start="256" dur="5">It turns out it&amp;#39;s much harder to find good actions in adversarial environments</text>
        <text start="261" dur="5">where the opponent actively observes you and counteracts what you&amp;#39;re trying to achieve</text>
        <text start="266" dur="4">relative to benign environment, where the environment might merely be stochastic</text>
        <text start="270" dur="5">but isn&amp;#39;t really interested in making your life worse.</text>
        <text start="275" dur="3">So, let&amp;#39;s see to what extent these expressions make sense to you</text>
        <text start="278" dur="2">by going to our next quiz.</text>
        <text start="280" dur="5">So here are the 4 concepts again: partially observable versus fully,</text>
        <text start="285" dur="5">stochastic versus deterministic, continuous versus discrete,</text>
        <text start="290" dur="2">adversarial versus benign.</text>
        <text start="292" dur="4">And let me ask you about the game of checkers.</text>
        <text start="296" dur="4">Check one or all of those attributes that apply.</text>
        <text start="300" dur="3">So, if you think checkers is partially observable, check this one.</text>
        <text start="303" dur="2">Otherwise, just don&amp;#39;t check it.</text>
        <text start="305" dur="2">If you think it&amp;#39;s stochastic, check this one,</text>
        <text start="307" dur="4">continuous, check this one, adversarial, check this one.</text>
        <text start="311" dur="4">If you don&amp;#39;t know about checkers, you can check the Web and Google it</text>
        <text start="315" dur="2">to find a little more information about checkers.</text>
      </transcript>
    </video>
    <video title="5 Checkers Answer" id="qVppDRbx2kM" length="52">
      <transcript>
        <text start="0" dur="4">So, checkers is an interesting game.</text>
        <text start="4" dur="4">Here&amp;#39;s the typical board of the game of checkers.</text>
        <text start="8" dur="3">Your pieces might look like this,</text>
        <text start="11" dur="5">and your opponent&amp;#39;s pieces might look like this.</text>
        <text start="16" dur="3">And apart from some very cryptic rules in checkers,</text>
        <text start="19" dur="4">which I won&amp;#39;t really discuss here, the board basically tells you</text>
        <text start="23" dur="5">everything there is to know about checkers, so it&amp;#39;s clearly fully observable.</text>
        <text start="28" dur="5">It is deterministic because your move and your opponent&amp;#39;s move</text>
        <text start="33" dur="3">very clearly affect the state of the board in ways that have</text>
        <text start="36" dur="3">absolutely no stochasticity.</text>
        <text start="39" dur="6">It is also discrete because there&amp;#39;s finitely many action choices</text>
        <text start="45" dur="2">and finitely many board positions,</text>
        <text start="47" dur="5">and obviously, it is adversarial, since your opponent is out to get you.</text>
      </transcript>
    </video>
    <video title="6 Poker" id="M_AdFAazf4k" length="12">
      <transcript>
        <text start="0" dur="6">[Male narrator] The game of poker--is this partially observable, stochastic,</text>
        <text start="6" dur="3">continuous, or adversarial?</text>
        <text start="9" dur="3">Please check any or all of those that apply.</text>
      </transcript>
    </video>
    <video title="7 Poker Answer" id="DjILhASM3A8" length="30">
      <transcript>
        <text start="0" dur="3">[Male narrator] I would argue poker is partially observable</text>
        <text start="3" dur="5">because it can&amp;#39;t be seen what is in your opponent&amp;#39;s hands.</text>
        <text start="8" dur="5">It is stochastic because you&amp;#39;re being dealt cards that are kind of coming at random.</text>
        <text start="13" dur="3">It is not continuous; it&amp;#39;s just finding many cards</text>
        <text start="16" dur="4">and finding many actions you can do, even though you might argue</text>
        <text start="20" dur="4">that there&amp;#39;s a huge number of different monies you can bet.</text>
        <text start="24" dur="3">It&amp;#39;s still finite, and it is clearly adversarial.</text>
        <text start="27" dur="3">If you&amp;#39;ve ever played poker before, you know how brutal it can be.</text>
      </transcript>
    </video>
    <video title="8 Robotic Car" id="vz-ERydsKLU" length="22">
      <transcript>
        <text start="0" dur="4">[Male narrator] --a favorite, a robotic car.</text>
        <text start="4" dur="2">I wish to know whether it is partially observable,</text>
        <text start="6" dur="5">stochastic, continuous, or adversarial.</text>
        <text start="11" dur="5">That is, is the problem of driving robotically--</text>
        <text start="16" dur="4">say, in a city--subject to any of those 4 categories?</text>
        <text start="20" dur="2">Please check any or all that might apply.</text>
      </transcript>
    </video>
    <video title="9 Robotic Car Answer" id="nOWCfVG0xNQ" length="33">
      <transcript>
        <text start="0" dur="4">Well, the robotic car clearly deals with a partially observable environment</text>
        <text start="4" dur="6">if you just look at momentary sensing input, you can&amp;#39;t even tell how fast other cars are going.</text>
        <text start="10" dur="2">So, you need to memorize something.</text>
        <text start="12" dur="3">It is stochastic because it&amp;#39;s inherently unpredictable</text>
        <text start="15" dur="2">what&amp;#39;s going to happen next with other cars.</text>
        <text start="17" dur="3">It is continuous.</text>
        <text start="20" dur="3">There&amp;#39;s the infinitely many ways to set your steering</text>
        <text start="23" dur="3">or push your gas pedal or your brake,</text>
        <text start="26" dur="3">and, well, you can argue with adversarial or not.</text>
        <text start="29" dur="2">Depending on where you live, it might be highly adversarial.</text>
        <text start="31" dur="2">Where I live, it isn&amp;#39;t.</text>
      </transcript>
    </video>
    <video title="10 AI and Uncertainty" id="ytw6_8a5Wls" length="88">
      <transcript>
        <text start="0" dur="3">I&amp;#39;m going to briefly talk of AI as something else,</text>
        <text start="3" dur="7">which is AI is the technique of uncertainty management in computer software.</text>
        <text start="10" dur="7">Put differently, AI is the discipline that you apply when you want to know what to do</text>
        <text start="17" dur="5">when you don&amp;#39;t know what to do.</text>
        <text start="22" dur="5">Now, there&amp;#39;s many reasons why there might be uncertainty in a computer program.</text>
        <text start="27" dur="2">There could be a sensor limit.</text>
        <text start="29" dur="4">That is, your sensors are unable to tell me</text>
        <text start="33" dur="4">what exactly is the case outside the AI system.</text>
        <text start="37" dur="4">There could be adversaries who act in a way that makes it hard for  you</text>
        <text start="41" dur="3">to understand what is the case.</text>
        <text start="44" dur="4">There could be stochastic environments.</text>
        <text start="48" dur="3">Every time you roll the dice in a dice game,</text>
        <text start="51" dur="4">the stochasticity of the dice will make it impossible for you</text>
        <text start="55" dur="2">to be absolutely certain of what&amp;#39;s the situation.</text>
        <text start="57" dur="3">There could be laziness.</text>
        <text start="60" dur="4">So perhaps you can actually compute what the situation is,</text>
        <text start="64" dur="3">but your computer program is just too lazy to do it.</text>
        <text start="67" dur="4">And here&amp;#39;s my favorite: ignorance, plain ignorance.</text>
        <text start="71" dur="3">Many people are just ignorant of what&amp;#39;s going on.</text>
        <text start="74" dur="3">They could know it, but they just don&amp;#39;t care.</text>
        <text start="77" dur="4">All of these things are cause for uncertainty.</text>
        <text start="81" dur="7">AI is the discipline that deals with uncertainty and manages it in decision making.</text>
      </transcript>
    </video>
    <video title="11 Examples of AI in Practice" id="sPSN0aI0PgE" length="240">
      <transcript>
        <text start="0" dur="3">Now we&amp;#39;ve had an introduction to AI.</text>
        <text start="3" dur="3">We&amp;#39;ve heard about some of the properties of environments,</text>
        <text start="6" dur="4">and we&amp;#39;ve seen some possible architecture for agents.</text>
        <text start="10" dur="3">I&amp;#39;d like next to show you some examples of AI in practice.</text>
        <text start="13" dur="5">And Sebastian and I have some experience personally in things we have done</text>
        <text start="18" dur="3">at Google, at NASA, and at Stanford.</text>
        <text start="21" dur="4">And I want to tell you a little bit about some of those.</text>
        <text start="25" dur="3">One of the best successes of AI technology at Google</text>
        <text start="28" dur="3">has been the machine translation system.</text>
        <text start="31" dur="6">Here we see an example of an article in Italian automatically translated into English.</text>
        <text start="37" dur="4">Now, these systems are built for 50 different languages,</text>
        <text start="41" dur="5">and we can translate from any of the languages into any of the other languages.</text>
        <text start="46" dur="5">So, that&amp;#39;s over 2,500 different systems, and we&amp;#39;ve done this all</text>
        <text start="51" dur="4">using machine learning techniques, using AI techniques,</text>
        <text start="55" dur="3">rather than trying to build them by hand.</text>
        <text start="58" dur="5">And the way it works is that we go out and collect examples of text</text>
        <text start="63" dur="3">that&amp;#39;s a line between the 2 languages.</text>
        <text start="66" dur="5">So we find, say, a newspaper that publishes 2 editions,</text>
        <text start="71" dur="5">an Italian edition and an English edition, and now we have examples of translations.</text>
        <text start="76" dur="6">And if anybody ever asked us for exactly the translation of this one particular article,</text>
        <text start="82" dur="3">then we could just look it up and say &amp;quot;We already know that.&amp;quot;</text>
        <text start="85" dur="2">But of course, we aren&amp;#39;t often going to be asked that.</text>
        <text start="87" dur="3">Rather, we&amp;#39;re going to be asked parts of this.</text>
        <text start="90" dur="4">Here are some words that we&amp;#39;ve seen before, and we have to figure out</text>
        <text start="94" dur="6">which words in this article correspond to which words in the translation article.</text>
        <text start="100" dur="5">And when we do that by examining many, many millions of words of text</text>
        <text start="105" dur="4">in the 2 languages and making the correspondence,</text>
        <text start="109" dur="2">and then we can put that all together.</text>
        <text start="111" dur="3">And then when we see a new example of text that we haven&amp;#39;t seen before,</text>
        <text start="114" dur="4">we can just look up what we&amp;#39;ve seen in the past for that correspondence.</text>
        <text start="118" dur="3">So, the task is really two parts.</text>
        <text start="121" dur="4">Off-line, before we see an example of text we want to translate,</text>
        <text start="125" dur="2">we first build our translation model.</text>
        <text start="127" dur="3">We do that by examining all of the different examples</text>
        <text start="130" dur="4">and figuring out which part aligns to which.</text>
        <text start="134" dur="4">Now, when we&amp;#39;re given a text to translate, we use that model,</text>
        <text start="138" dur="4">and we go through and find the most probable translation.</text>
        <text start="142" dur="2">So, what does it look like?</text>
        <text start="144" dur="2">Well, let&amp;#39;s look at it in some example text.</text>
        <text start="146" dur="3">And rather than look at news articles, I&amp;#39;m going to look at something simpler.</text>
        <text start="149" dur="6">I&amp;#39;m going to switch from Italian to Chinese.</text>
        <text start="155" dur="2">Here&amp;#39;s a bilingual text.</text>
        <text start="157" dur="4">Now, for a large-scale machine translation, examples are found on the Web.</text>
        <text start="161" dur="5">This example was found in a Chinese restaurant by Adam Lopez.</text>
        <text start="166" dur="3">Now, it&amp;#39;s given, for a text of this form,</text>
        <text start="169" dur="6">that a line in Chinese corresponds to a line in English,</text>
        <text start="175" dur="4">and that&amp;#39;s true for each of the individual lines.</text>
        <text start="179" dur="3">But to learn from this text, what we really want to discover</text>
        <text start="182" dur="5">is what individual words in Chinese correspond to individual words</text>
        <text start="187" dur="2">or small phrases in English.</text>
        <text start="189" dur="7">I&amp;#39;ve started that process by highlighting  the word &amp;quot;wonton&amp;quot; in English.</text>
        <text start="196" dur="2">It appears 3 times throughout the text.</text>
        <text start="198" dur="5">Now, in each of those lines, there&amp;#39;s a character that appears,</text>
        <text start="203" dur="4">and that&amp;#39;s the only place in the Chinese text where that character appears.</text>
        <text start="207" dur="6">So, that seems like it&amp;#39;s a high probability that this character in Chinese</text>
        <text start="213" dur="3">corresponds to the word &amp;quot;wonton&amp;quot; in English.</text>
        <text start="216" dur="2">Let&amp;#39;s see if we can go farther.</text>
        <text start="218" dur="6">My question for you is what word or what character or characters in Chinese</text>
        <text start="224" dur="3">correspond to the word &amp;quot;chicken&amp;quot; in English?</text>
        <text start="227" dur="7">And here we see &amp;quot;chicken&amp;quot; appears in these locations.</text>
        <text start="234" dur="6">Click on the character or characters in Chinese that corresponds to &amp;quot;chicken.&amp;quot;</text>
      </transcript>
    </video>
    <video title="12 Chinese Translation Answer" id="RWhwKudtixY" length="44">
      <transcript>
        <text start="1" dur="3">The answer is that chicken appears here,</text>
        <text start="4" dur="6">here, here, and here.</text>
        <text start="10" dur="4">Now, I don&amp;#39;t know for sure, 100%, that that is the character for chicken in Chinese,</text>
        <text start="14" dur="3">but I do know that there is a good correspondence.</text>
        <text start="17" dur="3">Every place the word chicken appears in English,</text>
        <text start="20" dur="4">this character appears in Chinese and no other place.</text>
        <text start="24" dur="3">Let&amp;#39;s go 1 step farther.</text>
        <text start="27" dur="3">Let&amp;#39;s see if we can work out a phrase in Chinese</text>
        <text start="30" dur="3">and see if it corresponds to a phrase in English.</text>
        <text start="33" dur="4">Here&amp;#39;s the phrase corn cream.</text>
        <text start="38" dur="6">Click on the characters in Chinese that correspond to corn cream.</text>
      </transcript>
    </video>
    <video title="13 Chinese Translation Answer 2" id="vvyaXxjsxBU" length="29">
      <transcript>
        <text start="0" dur="4">The answer is: these 2 characters here</text>
        <text start="4" dur="3">appear only in these 2 locations</text>
        <text start="7" dur="3">corresponding to the words corn cream</text>
        <text start="10" dur="3">which appear only in these locations in the English text.</text>
        <text start="13" dur="4">Again, we&amp;#39;re not 100% sure that&amp;#39;s the right answer,</text>
        <text start="17" dur="3">but it looks like a strong correlation.</text>
        <text start="20" dur="2">Now, 1 more question.</text>
        <text start="22" dur="4">Tell me what character or characters in Chinese</text>
        <text start="26" dur="3">correspond to the English word soup.</text>
      </transcript>
    </video>
    <video title="14 Chinese Translation Answer 3" id="lFJey0tOvBg" length="48">
      <transcript>
        <text start="0" dur="5">The answer is that soup occurs in most of these phrases</text>
        <text start="9" dur="2">but not 100% of them.</text>
        <text start="11" dur="2">It&amp;#39;s missing in this phrase.</text>
        <text start="14" dur="3">Equivalently, on the Chinese side</text>
        <text start="17" dur="3">we see this character occurs</text>
        <text start="20" dur="3">in most of the phrases,</text>
        <text start="23" dur="4">but it&amp;#39;s missing here.</text>
        <text start="27" dur="4">So we see that the correspondence doesn&amp;#39;t have to be 100%</text>
        <text start="31" dur="3">to tell us that there is still a good chance of a correlation.</text>
        <text start="34" dur="3">When we&amp;#39;re learning to do machine translation</text>
        <text start="37" dur="4">we use these kinds of alignments to learn probability tables</text>
        <text start="41" dur="4">of what is the probability of one phrase in one language</text>
        <text start="45" dur="3">corresponding to the phrase in another language.</text>
      </transcript>
    </video>
    <video title="15 Congratulations" id="mXM38kjzK-M" length="56">
      <transcript>
        <text start="0" dur="3">So congratulations, you just finished unit 1.</text>
        <text start="3" dur="4">You just finished unit 1 of this class,</text>
        <text start="7" dur="3">where I told you about key applications</text>
        <text start="10" dur="3">of artificial intelligence,</text>
        <text start="13" dur="5">I told you about the definition of an intelligent agent,</text>
        <text start="18" dur="5">I gave you 4 key attributes of intelligent agents</text>
        <text start="24" dur="6">(partial observability, stochasticity, continuous spaces, and adversarial natures),</text>
        <text start="31" dur="3">I discussed sources and management of uncertainty,</text>
        <text start="34" dur="6">and I briefly mentioned the mathematical concept of rationality.</text>
        <text start="40" dur="5">Obviously, I only touched any of these issues superficially,</text>
        <text start="45" dur="4">but as this class goes on you&amp;#39;re going to dive into any of those</text>
        <text start="49" dur="2">and learn much more about</text>
        <text start="51" dur="4">what it takes to make a truly intelligent AI system.</text>
        <text start="55" dur="1">Thank you.</text>
      </transcript>
    </video>
  </group>
  <group title="Unit 2" count="42">
    <video title="Topic 1, Introduction" id="ZQmJuHtpGfs" length="94">
      <transcript>
        <text start="0" dur="1">[PROBLEM SOLVING]</text>
        <text start="1" dur="3">In this unit we&amp;#39;re going to talk about problem solving.</text>
        <text start="4" dur="2">The theory and technology of building agents</text>
        <text start="6" dur="4">that can plan ahead to solve problems.</text>
        <text start="10" dur="3">In particular, we&amp;#39;re talking about problem solving</text>
        <text start="13" dur="4">where the complexity of the problem comes from the idea that there are many states.</text>
        <text start="17" dur="2">As in this problem here.</text>
        <text start="19" dur="5">A navigation problem where there are many choices to start with.</text>
        <text start="24" dur="5">And the complexity comes from picking the right choice now and picking the right choice at the</text>
        <text start="29" dur="3">next intersection and the intersection after that.</text>
        <text start="32" dur="3">Streaming together a sequence of actions.</text>
        <text start="35" dur="4">This is in contrast to the type of complexity shown in this picture,</text>
        <text start="39" dur="4">where the complexity comes from the partial observability</text>
        <text start="43" dur="3">that we can&amp;#39;t see through the fog where the possible paths are.</text>
        <text start="46" dur="2">We can&amp;#39;t see the results of our actions</text>
        <text start="48" dur="3">and even the actions themselves are not known.</text>
        <text start="51" dur="5">This type of complexity will be covered in a later unit.</text>
        <text start="56" dur="2">Here&amp;#39;s an example of a problem.</text>
        <text start="58" dur="5">This is a route-finding problem where we&amp;#39;re given a start city,</text>
        <text start="63" dur="6">in this case, Arad, and a destination, Bucharest, the capital of Romania,</text>
        <text start="69" dur="2">from which this is a corner of the map.</text>
        <text start="71" dur="5">And the problem then is to find a route from Arad to Bucharest.</text>
        <text start="76" dur="4">The actions that the agent can execute when driving</text>
        <text start="80" dur="3">from one city to the next along one of the roads shown on the map.</text>
        <text start="83" dur="5">The question is, is there a solution that the agent can come up with</text>
        <text start="88" dur="6">given the knowledge shown here to the problem of driving from Arad to Bucharest?</text>
      </transcript>
    </video>
    <video title="Topic 2, Route Finding Question" id="SIHc9LgMeaU" length="269">
      <transcript>
        <text start="0" dur="3">And the answer is no.</text>
        <text start="3" dur="3">There is no solution that the agent can come up with</text>
        <text start="6" dur="2">because Bucharest doesn&amp;#39;t appear on the map,</text>
        <text start="8" dur="4">and so the agent doesn&amp;#39;t know any actions that can arrive there.</text>
        <text start="12" dur="7">So let&amp;#39;s give the agent a better chance.</text>
        <text start="19" dur="4">Now we&amp;#39;ve given the agent the full map of Romania.</text>
        <text start="23" dur="7">To start, he&amp;#39;s in Arad, and the destination--or goal--is in Bucharest.</text>
        <text start="30" dur="5">And the agent is given the problem of coming up with a sequence of actions</text>
        <text start="35" dur="2">that will arrive at the destination.</text>
        <text start="37" dur="6">Now, is it possible for the agent to solve this problem?</text>
        <text start="43" dur="2">And the answer is yes.</text>
        <text start="45" dur="5">There are many routes or steps or sequences of actions that will arrive at the destination.</text>
        <text start="50" dur="3">Here is one of them:</text>
        <text start="53" dur="7">Starting out in Arad, taking this step first, then this one, then this one,</text>
        <text start="60" dur="5">then this one, and then this one to arrive at the destination.</text>
        <text start="65" dur="3">So that would count as a solution to the problem.</text>
        <text start="68" dur="4">So sequence of actions, chained together, that are guaranteed to get us to the goal.</text>
        <text start="72" dur="2">[DEFINITION OF A PROBLEM]</text>
        <text start="74" dur="3">Now let&amp;#39;s formally define what a problem looks like.</text>
        <text start="77" dur="4">A problem can be broken down into a number of components.</text>
        <text start="81" dur="4">First, the initial state that the agent starts out with.</text>
        <text start="85" dur="7">In our route finding problem, the initial state was the agent being in the city of Arad.</text>
        <text start="92" dur="9">Next, a function--Actions--that takes a state as input and returns</text>
        <text start="101" dur="6">a set of possible actions that the agent can execute when the agent is in this state.</text>
        <text start="107" dur="3">[ACTIONS (s)     {a,a2,a3...}]</text>
        <text start="110" dur="4">In some problems, the agent will have the same actions available in all states</text>
        <text start="114" dur="4">and in other problems, he&amp;#39;ll have different actions dependent on the state.</text>
        <text start="118" dur="4">In the route finding problem, the actions are dependent on the state.</text>
        <text start="122" dur="4">When we&amp;#39;re in one city, we can take the routes to the neighboring cities--</text>
        <text start="126" dur="3">but we can&amp;#39;t go to any other cities.</text>
        <text start="129" dur="11">Next we have a function called Result, which takes, as input, a state and an action</text>
        <text start="140" dur="4">and delivers, as its output, a new state.</text>
        <text start="144" dur="9">So, for example, if the agent is in the city of Arad, and takes--that would be the state--</text>
        <text start="153" dur="7">and takes the action of driving along Route E-671 towards Timisoara,</text>
        <text start="160" dur="5">then the result of applying that action in that state would be the new state--</text>
        <text start="165" dur="6">where the agent is in the city of Timisoara.</text>
        <text start="171" dur="7">Next, we need a function called Goal Test,</text>
        <text start="178" dur="6">which takes a state and returns a Boolean value--</text>
        <text start="184" dur="5">true or false--telling us if this state is a goal or not.</text>
        <text start="189" dur="5">In a route-finding problem, the only goal would be being in the destination city--</text>
        <text start="194" dur="5">the city of Bucharest--and all the other states would return false for the Goal Test.</text>
        <text start="199" dur="9">And finally, we need one more thing which is a Path Cost function--</text>
        <text start="208" dur="12">which takes a path, a sequence of state/action transitions,</text>
        <text start="220" dur="4">and returns a number, which is the cost of that path.</text>
        <text start="224" dur="6">Now, for most of the problems we&amp;#39;ll deal with, we&amp;#39;ll make the Path Cost function be additive</text>
        <text start="230" dur="6">so that the cost of the path is just the sum of the costs of the individual steps.</text>
        <text start="236" dur="8">And so we&amp;#39;ll implement this Path Cost function, in terms of a Step Cost function.</text>
        <text start="244" dur="10">The Step Cost function takes a state, an action, and the resulting state from that action</text>
        <text start="254" dur="4">and returns a number--n--which is the cost of that action.</text>
        <text start="258" dur="6">In the route finding example, the cost might be the number of miles traveled</text>
        <text start="264" dur="5">or maybe the number of minutes it takes to get to that destination.</text>
      </transcript>
    </video>
    <video title="Topic 3, Route Finding" id="bEi73QXP7PA" length="175">
      <transcript>
        <text start="0" dur="6">Now lets see how the definition of a problem</text>
        <text start="6" dur="4">maps onto the route finding, the domain.</text>
        <text start="10" dur="2">First, the initial state was given.</text>
        <text start="12" dur="3">Lets say we start off in Arad,</text>
        <text start="15" dur="2">and the goal test,</text>
        <text start="17" dur="5">lets say that the state of being in Bucharest</text>
        <text start="22" dur="2">is the only state that counts as a goal,</text>
        <text start="24" dur="2">and all the other states are not goals.</text>
        <text start="26" dur="3">Now the set of all of the states here</text>
        <text start="29" dur="2">is known as the state space,</text>
        <text start="31" dur="4">and we navigate the state space by applying actions.</text>
        <text start="35" dur="4">The actions are specific to each city,</text>
        <text start="39" dur="3">so when we are in Arad, there are three possible actions,</text>
        <text start="42" dur="4">to follow this road, this one, or this one.</text>
        <text start="46" dur="3">And as we follow them, we build paths</text>
        <text start="49" dur="2">or sequences of actions.</text>
        <text start="51" dur="4">So just being in Arad is the path of length zero,</text>
        <text start="55" dur="3">and now we could start exploring the space</text>
        <text start="58" dur="3">and add in this path of length one,</text>
        <text start="61" dur="2">this path of length one,</text>
        <text start="63" dur="3">and this path of length one.</text>
        <text start="66" dur="5">We could add in another path here of length two</text>
        <text start="71" dur="3">and another path here of length two.</text>
        <text start="74" dur="3">Here is another path of length two.</text>
        <text start="77" dur="4">Here is a path of length three.</text>
        <text start="81" dur="5">Another path of length two, and so on.</text>
        <text start="86" dur="2">Now at ever point,</text>
        <text start="88" dur="6">we want to separate the state out into three parts.</text>
        <text start="94" dur="3">First, the ends of the paths</text>
        <text start="97" dur="3">The farthest paths that have been explored,</text>
        <text start="100" dur="2">we call the frontier.</text>
        <text start="102" dur="4">And so the frontier in this case</text>
        <text start="106" dur="5">consists of these states</text>
        <text start="111" dur="4">that are the farthest out we have explored.</text>
        <text start="115" dur="4">And then to the left of that in this diagram,</text>
        <text start="119" dur="3">we have the explored part of the state.</text>
        <text start="122" dur="2">And then off to the rigtht,</text>
        <text start="124" dur="2">we have the unexplored.</text>
        <text start="126" dur="3">So lets write down those three components.</text>
        <text start="129" dur="6">We have the frontier.</text>
        <text start="135" dur="5">We have the unexplored region,</text>
        <text start="140" dur="5">and we have the explored region.</text>
        <text start="145" dur="2">One more thing,</text>
        <text start="147" dur="3">in this diagram we have labeled the step cost</text>
        <text start="150" dur="3">of each action along the route.</text>
        <text start="153" dur="4">So the step cost of going between Neamt to Iasi</text>
        <text start="157" dur="5">would be 87 corresponding to a distance of 87 kilometers,</text>
        <text start="162" dur="4">and the path cost is just the sum of the step costs.</text>
        <text start="166" dur="2">So the cost of the path</text>
        <text start="168" dur="2">of going from Arad to Oradea</text>
        <text start="170" dur="5">would be 71 plus 75.</text>
      </transcript>
    </video>
    <video title="Topic 4, Tree Search" id="c0PfWsqtfdo" length="199">
      <transcript>
        <text start="0" dur="4">[Narrator] Now let&amp;#39;s define a function for solving problems.</text>
        <text start="4" dur="3">It&amp;#39;s called Tree Search because it superimposes</text>
        <text start="7" dur="3">a search tree over the state space.</text>
        <text start="10" dur="2">Here&amp;#39;s how it works: It starts off by</text>
        <text start="12" dur="2">initializing the frontier to be the path</text>
        <text start="14" dur="2">consisting of only the initial states,</text>
        <text start="16" dur="2">and then it goes into a loop</text>
        <text start="18" dur="3">in which it first checks to see</text>
        <text start="21" dur="2">do we still have anything left in the frontier?</text>
        <text start="23" dur="2">If not we fail, there can be no solution.</text>
        <text start="25" dur="3">If we do have something, then we make a choice.</text>
        <text start="28" dur="3">Tree Search is really a family of functions</text>
        <text start="31" dur="2">not a single algorithm which</text>
        <text start="33" dur="2">depends on how we make that choice,</text>
        <text start="35" dur="3">and we&amp;#39;ll see some of the options later.</text>
        <text start="38" dur="3">If we go ahead and make a choice of one of</text>
        <text start="41" dur="2">the paths on the frontier and remove that</text>
        <text start="43" dur="2">path from the frontier, we find the state</text>
        <text start="45" dur="2">which is at the end of the path, and if that</text>
        <text start="47" dur="2">state&amp;#39;s a go then we&amp;#39;re done.</text>
        <text start="49" dur="2">We found a path to the goal; otherwise,</text>
        <text start="51" dur="3">we do what&amp;#39;s called expanding that path.</text>
        <text start="54" dur="3">We look at all the actions from that state,</text>
        <text start="57" dur="3">and we add to the path the actions</text>
        <text start="60" dur="3">and the result of that state; so we get</text>
        <text start="63" dur="3">a new path that has the old path, the action</text>
        <text start="66" dur="3">and the result of that action, and we</text>
        <text start="69" dur="4">stick all of those paths back onto the frontier.</text>
        <text start="77" dur="2">Now Tree Search represents a whole family</text>
        <text start="79" dur="3">of algorithms, and where you get the family</text>
        <text start="82" dur="2">resemblance is that they&amp;#39;re all looking</text>
        <text start="84" dur="2">at the frontier, copying items off and</text>
        <text start="86" dur="3">and looking to see if their goal tests,</text>
        <text start="89" dur="2">but where you get the difference is right here,</text>
        <text start="91" dur="3">in the choice of how you&amp;#39;re going to expand</text>
        <text start="94" dur="2">the next item on the frontier, which</text>
        <text start="96" dur="3">path do we look at first, and we&amp;#39;ll go through</text>
        <text start="99" dur="3">different sets of algorithms that make</text>
        <text start="102" dur="3">different choices for which path to look at first.</text>
        <text start="107" dur="2">The first algorithm I want to consider</text>
        <text start="109" dur="2">is called Breadth-First Search.</text>
        <text start="111" dur="3">Now it could be called shortest-first search</text>
        <text start="114" dur="2">because what it does is always choose</text>
        <text start="116" dur="3">of the frontier one of the paths that hadn&amp;#39;t been</text>
        <text start="119" dur="3">considered yet that&amp;#39;s the shortest possible.</text>
        <text start="122" dur="2">So how does it work?</text>
        <text start="124" dur="2">Well we start off with the path of</text>
        <text start="126" dur="4">length 0, starting in the start state, and</text>
        <text start="130" dur="3">that&amp;#39;s the only path in the frontier so</text>
        <text start="133" dur="2">it&amp;#39;s the shortest one so we pick it,</text>
        <text start="135" dur="2">and then we expand it, and we add in</text>
        <text start="137" dur="3">all the paths that result from</text>
        <text start="140" dur="2">applying all the possible actions.</text>
        <text start="142" dur="3">So now we&amp;#39;ve removed</text>
        <text start="145" dur="3">this path from the frontier,</text>
        <text start="148" dur="3">but we&amp;#39;ve added in 3 new paths.</text>
        <text start="151" dur="2">This one,</text>
        <text start="153" dur="4">this one, and this one.</text>
        <text start="157" dur="2">Now we&amp;#39;re in a position where</text>
        <text start="159" dur="3">we have 3 paths on the frontier, and</text>
        <text start="162" dur="3">we have to pick the shortest one.</text>
        <text start="165" dur="2">Now in this case all 3 paths</text>
        <text start="167" dur="3">have the same length, length 1, so we</text>
        <text start="170" dur="2">break the tie at random or using some</text>
        <text start="172" dur="4">other technique, and let&amp;#39;s suppose that</text>
        <text start="176" dur="2">in this case we choose this path</text>
        <text start="178" dur="2">from Arad to Sibiu.</text>
        <text start="180" dur="3">Now the question I want you to answer</text>
        <text start="183" dur="6">is once we remove that from the frontier,</text>
        <text start="189" dur="2">what paths are we going to add next?</text>
        <text start="191" dur="3">So show me by checking off the cities</text>
        <text start="194" dur="2">that ends the paths, which paths</text>
        <text start="196" dur="3">are going to be added to the frontier?</text>
      </transcript>
    </video>
    <video title="Topic 5, Tree Search Answer" id="GKKQyJLee84" length="174">
      <transcript>
        <text start="0" dur="6">[Male narrator] The answer is that in Sibiu, the action function gives us 4 actions</text>
        <text start="6" dur="3">corresponding to traveling along these 4 roads,</text>
        <text start="9" dur="6">so we have to add in paths for each of those actions.</text>
        <text start="15" dur="2">One of those paths goes here,</text>
        <text start="17" dur="4">the other path continues from Arad and goes out here.</text>
        <text start="21" dur="4">The third path continues out here</text>
        <text start="25" dur="6">and then the fourth path goes from here--from Arad to Sibiu</text>
        <text start="31" dur="5">and then backtracks back to Arad.</text>
        <text start="36" dur="5">Now, it may seem silly and redundant to have a path that starts in Arad,</text>
        <text start="41" dur="3">goes to Sibiu and returns to Arad.</text>
        <text start="44" dur="5">How can that help us get to our destination in Bucharest?</text>
        <text start="49" dur="3">But we can see if we&amp;#39;re dealing with a tree search,</text>
        <text start="52" dur="4">why it&amp;#39;s natural to have this type of formulation</text>
        <text start="56" dur="4">and why the tree search doesn&amp;#39;t even notice that it&amp;#39;s backtracked.</text>
        <text start="60" dur="5">What the tree search does is superimpose on top of the state space</text>
        <text start="65" dur="4">a tree of searches, and the tree looks like this.</text>
        <text start="69" dur="6">We start off in state A, and in state A, there were 3 actions,</text>
        <text start="75" dur="6">so we gave those paths going to Z, S, and T.</text>
        <text start="81" dur="13">And from S, there were 4 actions, so that gave us paths going from O, F, R, and A,</text>
        <text start="94" dur="3">and then the tree would continue on from here.</text>
        <text start="97" dur="3">We&amp;#39;d take one of the next items</text>
        <text start="100" dur="8">and we&amp;#39;d move it and continue on, but notice that we returned to the A state</text>
        <text start="108" dur="3">in the state space, but in the tree,</text>
        <text start="111" dur="4">it&amp;#39;s just another item in the tree.</text>
        <text start="115" dur="2">Now, here&amp;#39;s another representation of the search space</text>
        <text start="117" dur="4">and what&amp;#39;s happening is as we start to explore the state,</text>
        <text start="121" dur="8">we keep track of the frontier, which is the set of states that are at the end of the paths</text>
        <text start="129" dur="4">that we haven&amp;#39;t explored yet, and behind that frontier</text>
        <text start="133" dur="6">is the set of explored states, and ahead of the frontier is the unexplored states.</text>
        <text start="139" dur="3">Now the reason we keep track of the explored states</text>
        <text start="142" dur="5">is that when we want to expand and we find a duplicate--</text>
        <text start="147" dur="6">so say when we expand from here, if we pointed back to state T,</text>
        <text start="153" dur="9">if we hadn&amp;#39;t kept track of that, we would have to add in a new state for T down here.</text>
        <text start="162" dur="5">But because we&amp;#39;ve already seen it and we know that this is actually a regressive step</text>
        <text start="167" dur="4">into the already explored state, now, because we kept track of that,</text>
        <text start="171" dur="3">we don&amp;#39;t need it anymore.</text>
      </transcript>
    </video>
    <video title="Topic 6, Graph Search" id="mtbfvJuOV_U" length="65">
      <transcript>
        <text start="0" dur="4">Now we see how to modify the Tree Search Function</text>
        <text start="4" dur="2">to make it be a Graph Search Function</text>
        <text start="6" dur="3">to avoid those repeated paths.</text>
        <text start="9" dur="4">What we do, is we start off and initialize a set</text>
        <text start="13" dur="3">called the explored set of states that we have already explored.</text>
        <text start="16" dur="3">Then, when we consider a new path,</text>
        <text start="19" dur="4">we add the new state to the set of already explored states,</text>
        <text start="23" dur="3">and then when we are expanding the path</text>
        <text start="26" dur="3">and adding in new states to the end of it,</text>
        <text start="29" dur="4">we dont  add that in if we have already seen that new state</text>
        <text start="33" dur="4">in either the frontier or the explored.</text>
        <text start="37" dur="2">Now back to Breadth First Search.</text>
        <text start="39" dur="2">Lets assume we are using the Graph Search</text>
        <text start="41" dur="3">so that we have eliminated the duplicate paths.</text>
        <text start="44" dur="3">Arad is crossed off the list.</text>
        <text start="47" dur="2">The path that goes from Arad to Sibiu</text>
        <text start="49" dur="2">and back to Arad is removed,</text>
        <text start="51" dur="2">and we are left with these one, two, three,</text>
        <text start="53" dur="4">four, five possible paths.</text>
        <text start="57" dur="2">Given these 5 paths,</text>
        <text start="59" dur="3">show me which ones are candidates to be expanded next</text>
        <text start="62" dur="3">by the Breadth First Search Algorithm.</text>
      </transcript>
    </video>
    <video title="Topic 7, Graph Search Answer" id="HfYXaw56-0w" length="42">
      <transcript>
        <text start="0" dur="3">[Male narrator] And the answer is that Breadth - First Search always considers</text>
        <text start="3" dur="5">the shortest paths first, and in this case, there&amp;#39;s 2 paths of length 1,</text>
        <text start="8" dur="4">and 1, the paths from Arad to Zerind and Arad to Timisoara,</text>
        <text start="12" dur="3">so those would be the 2 paths that would be considered.</text>
        <text start="15" dur="3">Now, let&amp;#39;s suppose that the tie is broken in some way</text>
        <text start="18" dur="4">and we chose this path from Arad to Zerind.</text>
        <text start="22" dur="3">Now, we want to expand that node.</text>
        <text start="25" dur="6">We remove it from the frontier and put it in the explored list</text>
        <text start="31" dur="4">and now we say, &amp;quot;What paths are we going to add?&amp;quot;</text>
        <text start="35" dur="7">So check off the ends of the paths the cities that we&amp;#39;re going to add.</text>
      </transcript>
    </video>
    <video title="Topic 8, Graph Search Answer" id="CUfmOLQi3RM" length="13">
      <transcript>
        <text start="0" dur="3">[Male narrator] In this case, there&amp;#39;s nothing to add</text>
        <text start="3" dur="6">because of the 2 neighbors, 1 is in the explored list and 1 is in the frontier,</text>
        <text start="9" dur="4">and if we&amp;#39;re using graph search, then we won&amp;#39;t add either of those.</text>
      </transcript>
    </video>
    <video title="Topic 9, More Graph Search" id="I3lrnzdgwmI" length="38">
      <transcript>
        <text start="0" dur="4">[Male narrator] So we move on, we look for another shortest path.</text>
        <text start="4" dur="7">There&amp;#39;s one path left of length 1, so we look at that path, we expand it,</text>
        <text start="11" dur="5">add in this path, put that one on the explored list,</text>
        <text start="16" dur="4">and now we&amp;#39;ve got 3 paths of length 2.</text>
        <text start="20" dur="3">We choose 1 of them, and let&amp;#39;s say we choose this one.</text>
        <text start="23" dur="7">Now, my question is show me which states we add to the path</text>
        <text start="30" dur="5">and tell me whether we&amp;#39;re going to terminate the algorithm at this point</text>
        <text start="35" dur="3">because we&amp;#39;ve reached the goal or whether we&amp;#39;re going to continue.</text>
      </transcript>
    </video>
    <video title="Topic 10, Graph Search Answer" id="cr1Ck1Fr60M" length="29">
      <transcript>
        <text start="0" dur="8">[Male narrator] The answer is that we add 1 more path, the path to Bucharest.</text>
        <text start="8" dur="3">We don&amp;#39;t add the path going back because it&amp;#39;s in the explored list,</text>
        <text start="11" dur="2">but we don&amp;#39;t terminate it yet.</text>
        <text start="13" dur="3">True, we have added a path that ends in Bucharest,</text>
        <text start="16" dur="6">but the goal test isn&amp;#39;t applied when we add a path to the frontier.</text>
        <text start="22" dur="4">Rather, it&amp;#39;s applied when we remove that path from the frontier,</text>
        <text start="26" dur="3">and we haven&amp;#39;t done that yet.</text>
      </transcript>
    </video>
    <video title="Topic 11, Graph Search Termination" id="mueRduwpg-U" length="90">
      <transcript>
        <text start="0" dur="6">[Male narrator] Now, why doesn&amp;#39;t the general tree search or graph search algorithm stop</text>
        <text start="6" dur="3">when it adds a goal node to the frontier?</text>
        <text start="9" dur="4">The reason is because it might not be the best path to the goal.</text>
        <text start="13" dur="3">Now, here we found a path of length 2</text>
        <text start="16" dur="5">and we added a path of length 3 that reached the goal.</text>
        <text start="21" dur="3">The general graph search or tree search doesn&amp;#39;t know</text>
        <text start="24" dur="3">that there might be some other path that we could expand</text>
        <text start="27" dur="3">that would have a distance of say, 2-1/2,</text>
        <text start="30" dur="3">but there&amp;#39;s an optimization that could be made.</text>
        <text start="33" dur="2">If we know we&amp;#39;re doing Breadth - First Search</text>
        <text start="35" dur="5">and we know there&amp;#39;s no possibility of a path of length 2-1/2.</text>
        <text start="40" dur="4">Then we can change algorithm so that it checks states</text>
        <text start="44" dur="2">as soon as they&amp;#39;re added to the frontier</text>
        <text start="46" dur="3">rather than waiting until they&amp;#39;re expanded</text>
        <text start="49" dur="4">and in that case, we can write a specific Breadth - First Search routine</text>
        <text start="53" dur="8">that terminates early and gives us a result as soon as we add a goal state to the frontier.</text>
        <text start="61" dur="3">Breadth - First Search will find this path</text>
        <text start="64" dur="4">that ends up in Bucharest, and if we&amp;#39;re looking for the shortest path</text>
        <text start="68" dur="2">in terms of number of steps,</text>
        <text start="70" dur="2">Breadth - First Search is guaranteed to find it,</text>
        <text start="72" dur="5">But if we&amp;#39;re looking for the shortest path in terms of total cost</text>
        <text start="77" dur="4">by adding up the step costs, then it turns out</text>
        <text start="81" dur="5">that this path is shorter than the path found by Breadth - First Search.</text>
        <text start="86" dur="4">So let&amp;#39;s look at how we could find that path.</text>
      </transcript>
    </video>
    <video title="Topic 12, Uniform Cost Search" id="Qrig0mznzG4" length="51">
      <transcript>
        <text start="0" dur="5">An algorithm that has traditionally been called uniform-cost search</text>
        <text start="5" dur="3">but could be called cheapest-first search,</text>
        <text start="8" dur="3">is guaranteed to find the path with the cheapest total cost.</text>
        <text start="11" dur="3">Let&amp;#39;s see how it works.</text>
        <text start="14" dur="5">We start out as before in the start state.</text>
        <text start="19" dur="5">And we pop that empty path off.</text>
        <text start="24" dur="4">Move it from the frontier to explored,</text>
        <text start="28" dur="5">and then add in the paths out of that state.</text>
        <text start="33" dur="6">As before, there will be 3 of those paths.</text>
        <text start="39" dur="4">And now, which path are we going to pick next</text>
        <text start="43" dur="8">in order to expand according to the rules of cheapest first?</text>
      </transcript>
    </video>
    <video title="Topic 13, Uniform Cost Search" id="7MbW6kZ_vb8" length="44">
      <transcript>
        <text start="0" dur="3">Cheapest first says that we pick the path with</text>
        <text start="4" dur="2">the lowest total cost.</text>
        <text start="6" dur="1">And that would be this path.</text>
        <text start="7" dur="6">It has a cost of 75 compared to the cost of 118 and 140</text>
        <text start="13" dur="1">for the other paths.</text>
        <text start="14" dur="5">So we get here. We take that path off the frontier,</text>
        <text start="19" dur="4">put it on the explored list, add in its neighbors.</text>
        <text start="23" dur="3">Not going back to Arad,</text>
        <text start="26" dur="4">but adding in this new path.</text>
        <text start="30" dur="3">Summing up the total cost of that path,</text>
        <text start="33" dur="7">71 + 75 is 146 for this path.</text>
        <text start="40" dur="1">And now the question is,</text>
        <text start="41" dur="3">which path gets expanded next?</text>
      </transcript>
    </video>
    <video title="Topic 14, Uniform Cost Search" id="9vNvrRP0ymw" length="56">
      <transcript>
        <text start="0" dur="5">Of the 3 paths on the frontier, we have ones</text>
        <text start="5" dur="5">with a cost of 146, 140, and 118.</text>
        <text start="10" dur="3">And that&amp;#39;s the cheapest, so this one gets expanded.</text>
        <text start="13" dur="3">We take it off the frontier, move it to explored,</text>
        <text start="16" dur="5">add in its successors. In this case it&amp;#39;s only 1.</text>
        <text start="21" dur="8">And that has a path total of 229.</text>
        <text start="29" dur="1">Which path do we expand next?</text>
        <text start="30" dur="3">Well, we&amp;#39;ve got 146, 140, and 229</text>
        <text start="33" dur="5">So 140 is the lowest.</text>
        <text start="38" dur="3">Take it off the frontier. Put it on explored.</text>
        <text start="41" dur="3">Add in this path</text>
        <text start="44" dur="4">for a total cost of 220.</text>
        <text start="48" dur="5">And this path for a total cost of 239.</text>
        <text start="53" dur="3">And now the question is, which path do we expand next?</text>
      </transcript>
    </video>
    <video title="Topic 15, Uniform Cost Search" id="LVCMMPXaQlE" length="15">
      <transcript>
        <text start="0" dur="4">The answer is this one, 146.</text>
        <text start="4" dur="3">Put it on explored.</text>
        <text start="7" dur="5">But there&amp;#39;s nothing to add because</text>
        <text start="12" dur="1">both of its neighbors have already been explored.</text>
        <text start="13" dur="2">Which path do we look at next?</text>
      </transcript>
    </video>
    <video title="Topic 16, Uniform Cost Termination" id="G-H1AnA8uBI" length="73">
      <transcript>
        <text start="0" dur="5">The answer is this one. Two-twenty is less than 229 or 239.</text>
        <text start="5" dur="4">Take it off the frontier. Put it on explored.</text>
        <text start="9" dur="6">Add in 2 more paths and sum them up.</text>
        <text start="15" dur="6">So, 220 plus 146 is 366.</text>
        <text start="21" dur="8">And 220 plus 97 is 317.</text>
        <text start="29" dur="3">Okay, and now, notice that we&amp;#39;re closing in on Bucharest.</text>
        <text start="32" dur="6">We&amp;#39;ve got 2 neighbors almost there, but neither of them is their turn yet.</text>
        <text start="38" dur="5">Instead, the cheapest path is this one over here,</text>
        <text start="43" dur="2">so move it to the explored list.</text>
        <text start="45" dur="5">Add 70 to the path cost so far,</text>
        <text start="50" dur="7">and we get 299.</text>
        <text start="57" dur="4">Now the cheapest node is 239 here,</text>
        <text start="61" dur="8">so we expand, finally, into Bucharest at a cost of 460.</text>
        <text start="69" dur="4">And now the question is are we done? Can we terminate the algorithm?</text>
      </transcript>
    </video>
    <video title="Topic 17, Uniform Cost Termination Answer" id="NxCUVltVoZ8" length="106">
      <transcript>
        <text start="0" dur="3">[Male] And the answer is no, we&amp;#39;re not done yet.</text>
        <text start="3" dur="4">We&amp;#39;ve put Bucharest, the gold state, onto the frontier,</text>
        <text start="7" dur="2">but we haven&amp;#39;t popped it off the frontier yet.</text>
        <text start="9" dur="4">And the reason is because we&amp;#39;ve got to look around and see if there&amp;#39;s a better path</text>
        <text start="13" dur="2">that can reach it, Bucharest.</text>
        <text start="15" dur="3">And so, let&amp;#39;s continue.</text>
        <text start="18" dur="2">Look at everything on the frontier.</text>
        <text start="20" dur="3">Here&amp;#39;s the cheapest one over here.</text>
        <text start="23" dur="3">Expand that.</text>
        <text start="26" dur="4">Now, what&amp;#39;s the cheapest next one?</text>
        <text start="30" dur="3">Well, over here.</text>
        <text start="33" dur="3">Oops, forgot to take this one off the list.</text>
        <text start="36" dur="8">So now, we&amp;#39;re at 317 plus 101 gives us another path into Bucharest,</text>
        <text start="44" dur="2">and this is a better path.</text>
        <text start="46" dur="8">This is 418, gives us another route in.</text>
        <text start="54" dur="5">But we have to keep going.</text>
        <text start="59" dur="7">The best path on the frontier is 366,</text>
        <text start="66" dur="8">so pop that off, and that would give us 2 more routes into here,</text>
        <text start="74" dur="4">and eventually we pop off all of these.</text>
        <text start="78" dur="6">And then we get to the point where 418 was the best path on the frontier.</text>
        <text start="84" dur="5">We pop that off, and then we recognize that we&amp;#39;d reach the goal,</text>
        <text start="89" dur="6">and the reason that uniform cost finds the optimal path, the cheapest cost,</text>
        <text start="95" dur="5">is because it&amp;#39;s guaranteed that it will first pop off this cheapest path,</text>
        <text start="100" dur="6">the 418, before it gets to the more expensive path, like the 460.</text>
      </transcript>
    </video>
    <video title="Topic 18, Depth First Search" id="Ve-mmCM8TI0" length="110">
      <transcript>
        <text start="0" dur="3">So, we&amp;#39;ve looked at 2 search algorithms.</text>
        <text start="3" dur="5">One, breadth-first search, in which we always expand first</text>
        <text start="8" dur="4">the shallowest paths, the shortest paths.</text>
        <text start="12" dur="5">Second, cheapest-first search, in which we always expand first the path</text>
        <text start="17" dur="3">with the lowest total cost.</text>
        <text start="20" dur="5">And I&amp;#39;m going to take this opportunity to introduce a third algorithm, depth-first search,</text>
        <text start="25" dur="3">which is in a way the opposite of breadth-first search.</text>
        <text start="28" dur="5">In depth-first search, we always expand first the longest path,</text>
        <text start="33" dur="3">the path with the most lengths in it.</text>
        <text start="36" dur="6">Now, what I want to ask you to do is for each of these nodes in each of the trees,</text>
        <text start="42" dur="2">tell us in what order they&amp;#39;re expanded,</text>
        <text start="44" dur="5">first, second, third, fourth, fifth and so on by putting a number into the box.</text>
        <text start="49" dur="9">And if there are ties, put that number in and resolve the ties in left to right order.</text>
        <text start="58" dur="5">Then I want you to ask one more question or answer one more question</text>
        <text start="63" dur="3">which is are these searches optimal?</text>
        <text start="66" dur="5">That is, are they guaranteed to find the best solution?</text>
        <text start="71" dur="5">And for breadth-first search, optimal would mean finding the shortest path.</text>
        <text start="76" dur="5">If you think it&amp;#39;s guaranteed to find the shortest path, check here.</text>
        <text start="81" dur="5">For cheapest first, it would mean finding the path with the lowest total path cost.</text>
        <text start="86" dur="4">Check here if you think it&amp;#39;s guaranteed to do that.</text>
        <text start="90" dur="4">And we&amp;#39;ll allow the assumption that all costs have to be positive.</text>
        <text start="94" dur="7">And in depth first, cheapest or optimal would mean, again,</text>
        <text start="101" dur="5">as in breadth first, finding the shortest possible path in terms of number of lengths.</text>
        <text start="106" dur="4">Check here if  you think depth first will always find that.</text>
      </transcript>
    </video>
    <video title="Topic 19, Search Optimality Answer" id="slLRsFFiiRc" length="109">
      <transcript>
        <text start="0" dur="4">Here are the answers.</text>
        <text start="4" dur="6">Breadth-first search, as the name implies, expands nodes in this order.</text>
        <text start="10" dur="7">One, 2, 3, 4, 5, 6, 7.</text>
        <text start="17" dur="6">So, it&amp;#39;s going across a stripe at a time, breadth first.</text>
        <text start="23" dur="2">Is it optimal?</text>
        <text start="25" dur="3">Well, it&amp;#39;s always expanding in the shortest paths first,</text>
        <text start="28" dur="6">and so wherever the goal is hiding, it&amp;#39;s going to find it by examining</text>
        <text start="34" dur="4">no longer paths, so in fact, it is optimal.</text>
        <text start="38" dur="7">Cheapest first, first we expand the path of length zero,</text>
        <text start="45" dur="2">then the path of length 2.</text>
        <text start="47" dur="6">Now there&amp;#39;s a path of length 4, path of length 5,</text>
        <text start="53" dur="9">path of length 6, a path of length 7, and finally, a path of length 8.</text>
        <text start="62" dur="6">And as we&amp;#39;ve seen, it&amp;#39;s guaranteed to find the cheapest path of all,</text>
        <text start="68" dur="6">assuming that all the individual step costs are not negative.</text>
        <text start="74" dur="3">Depth-first search tries to go as deep as it can first,</text>
        <text start="77" dur="7">so it goes 1, 2, 3, then backs up, 4,</text>
        <text start="84" dur="5">then backs up, 5, 6, 7.</text>
        <text start="89" dur="5">And you can see that it doesn&amp;#39;t necessarily find the shortest path of all.</text>
        <text start="94" dur="5">Let&amp;#39;s say that there were goals in position 5 and in position 3.</text>
        <text start="99" dur="4">It would find the longer path to position 3 and find the goal there</text>
        <text start="103" dur="3">and would not find the goal in position 5.</text>
        <text start="106" dur="3">So, it is not optimal.</text>
      </transcript>
    </video>
    <video title="Topic 20, Storage Requirements, Completeness" id="RntnUP9QRiU" length="122">
      <transcript>
        <text start="0" dur="4">Given the non-optimality of depth-first search,</text>
        <text start="4" dur="3">why would anybody choose to use it?</text>
        <text start="7" dur="3">Well, the answer has to do with the storage requirements.</text>
        <text start="10" dur="3">Here I&amp;#39;ve illustrated a state space</text>
        <text start="13" dur="5">consisting of a very large or even infinite binary tree.</text>
        <text start="18" dur="4">As we go to levels 1, 2, 3, down to level n,</text>
        <text start="22" dur="2">the tree gets larger and larger.</text>
        <text start="24" dur="5">Now, let&amp;#39;s consider the frontier for each of these search algorithms.</text>
        <text start="29" dur="6">For breadth-first search, we know a frontier looks like that,</text>
        <text start="35" dur="5">and so when we get down to level n, we&amp;#39;ll require a storage space of</text>
        <text start="40" dur="5">2 to the n of pass in a breadth-first search.</text>
        <text start="45" dur="4">For cheapest first, the frontier is going to be more complicated.</text>
        <text start="49" dur="4">It&amp;#39;s going to sort of work out this contour of cost,</text>
        <text start="53" dur="4">but it&amp;#39;s going to have a similar total number of nodes.</text>
        <text start="57" dur="6">But for depth-first search, as we go down the tree, we start going down this branch,</text>
        <text start="63" dur="5">and then we back up, but at any point, our frontier is only going to have n nodes</text>
        <text start="68" dur="6">rather than 2 to the n nodes, so that&amp;#39;s a substantial savings for depth-first search.</text>
        <text start="74" dur="5">Now, of course, if we&amp;#39;re also keeping track of the explored set,</text>
        <text start="79" dur="2">then we don&amp;#39;t get that much savings.</text>
        <text start="81" dur="4">But without the explored set, depth-first search has a huge advantage</text>
        <text start="85" dur="2">in terms of space saved.</text>
        <text start="87" dur="3">One more property of the algorithms to consider</text>
        <text start="90" dur="5">is the property of completeness, meaning if there is a goal somewhere,</text>
        <text start="95" dur="2">will the algorithm find it?</text>
        <text start="97" dur="4">So, let&amp;#39;s move from very large trees to infinite trees,</text>
        <text start="101" dur="6">and let&amp;#39;s say that there&amp;#39;s some goal hidden somewhere deep down in that tree.</text>
        <text start="107" dur="4">And the question is, are each of these algorithms complete?</text>
        <text start="111" dur="4">That is, are they guaranteed to find a path to the goal?</text>
        <text start="115" dur="7">Mark off the check boxes for the algorithms that you believe are complete in this sense.</text>
      </transcript>
    </video>
    <video title="Topic 21, Completeness Answer" id="aEZOJ-KazvU" length="49">
      <transcript>
        <text start="0" dur="4">The answer is that breadth-first search is complete,</text>
        <text start="4" dur="6">so even if the tree is infinite, if the goal is placed at any finite level,</text>
        <text start="10" dur="6">eventually, we&amp;#39;re going to march down and find that goal.</text>
        <text start="16" dur="2">Same with cheapest first.</text>
        <text start="18" dur="3">No matter where the goal is, if it has a finite cost,</text>
        <text start="21" dur="4">eventually, we&amp;#39;re going to go down and find it.</text>
        <text start="25" dur="3">But not so for depth-first search.</text>
        <text start="28" dur="5">If there&amp;#39;s an infinite path, depth-first search will keep following that,</text>
        <text start="33" dur="4">so it will keep going down and down and down along this path</text>
        <text start="37" dur="5">and never get to the path that the goal consists of</text>
        <text start="42" dur="4">and never get to the path on which the goal sits.</text>
        <text start="46" dur="3">So, depth-first search is not complete.</text>
      </transcript>
    </video>
    <video title="Topic 22, More on Uniform Cost Search" id="IBAuWgq0ews" length="268">
      <transcript>
        <text start="0" dur="5">Let&amp;#39;s try to understand a little better how uniform cost search works.</text>
        <text start="5" dur="3">We start at a start state,</text>
        <text start="8" dur="5">and then we start expanding out from there looking at different paths,</text>
        <text start="13" dur="8">and what we end of doing is expanding in terms of contours like on a topological map,</text>
        <text start="21" dur="7">where first we span out to a certain distance, then to a farther distance,</text>
        <text start="28" dur="3">and then to a farther distance.</text>
        <text start="31" dur="4">Now at some point we meet up with a goal.  Let&amp;#39;s say the goal is here.</text>
        <text start="35" dur="7">Now we found a path from the start to the goal.</text>
        <text start="42" dur="4">But notice that the search really wasn&amp;#39;t directed at any way towards the goal.</text>
        <text start="46" dur="6">It was expanding out everywhere in the space and depending on where the goal is,</text>
        <text start="52" dur="5">we should expect to have to explore half the space, on average, before we find the goal.</text>
        <text start="57" dur="3">If the space is small, that can be fine,</text>
        <text start="60" dur="5">but when spaces are large, that won&amp;#39;t get us to the goal fast enough.</text>
        <text start="65" dur="5">Unfortunately, there is really nothing we can do, with what we know, to do better than that,</text>
        <text start="70" dur="5">and so if we want to improve, if we want to be able to find the goal faster,</text>
        <text start="75" dur="6">we&amp;#39;re going to have to add more knowledge.</text>
        <text start="81" dur="6">The type of knowledge that is proven most useful in search is an estimate of the distance</text>
        <text start="87" dur="5">from the start state to the goal.</text>
        <text start="92" dur="4">So let&amp;#39;s say we&amp;#39;re dealing with a route-finding problem,</text>
        <text start="96" dur="7">and we can move in any direction--up or down, right or left--</text>
        <text start="103" dur="7">and we&amp;#39;ll take as our estimate, the straight line distance between a state and a goal,</text>
        <text start="110" dur="5">and we&amp;#39;ll try to use that estimate to find our way to the goal fastest.</text>
        <text start="115" dur="9">Now an algorithm called greedy best-first search does exactly that.</text>
        <text start="124" dur="5">It expands first the path that&amp;#39;s closest to the goal according to the estimate.</text>
        <text start="129" dur="4">So what do the contours look like in this approach?</text>
        <text start="133" dur="4">Well, we start here, and then we look at all the neighboring states,</text>
        <text start="137" dur="4">and the ones that appear to be closest to the goal we would expand first.</text>
        <text start="141" dur="9">So we&amp;#39;d start expanding like this and like this and like this and like this</text>
        <text start="150" dur="3">and that would lead us directly to the goal.</text>
        <text start="153" dur="5">So now instead of exploring whole circles that go out everywhere with a certain space,</text>
        <text start="158" dur="3">our search is directed towards the goal.</text>
        <text start="161" dur="5">In this case it gets us immediately towards the goal, but that won&amp;#39;t always be the case</text>
        <text start="166" dur="4">if there are obstacles along the way.</text>
        <text start="170" dur="4">Consider this search space.  We have a start state and a goal,</text>
        <text start="174" dur="3">and there&amp;#39;s an impassable barrier.</text>
        <text start="177" dur="5">Now greedy best-first search will start expanding out as before,</text>
        <text start="182" dur="6">trying to get towards the goal,</text>
        <text start="188" dur="3">and when it reaches the barrier, what will it do next?</text>
        <text start="191" dur="4">Well, it will try to increase along a path that&amp;#39;s getting closer and closer to the goal.</text>
        <text start="195" dur="5">So it won&amp;#39;t consider going back this way which is farther from the goal.</text>
        <text start="200" dur="4">Rather it will continue expanding out along these lines</text>
        <text start="204" dur="4">which always get closer and closer to the goal,</text>
        <text start="208" dur="3">and eventually it will find its way towards the goal.</text>
        <text start="211" dur="5">So it does find a path, and it does it by expanding a small number of nodes,</text>
        <text start="216" dur="6">but it&amp;#39;s willing to accept a path which is longer than other paths.</text>
        <text start="222" dur="5">Now if we explored in the other direction, we could have found a much simpler path,</text>
        <text start="227" dur="7">a much shorter path, by just popping over the barrier, and then going directly to the goal.</text>
        <text start="234" dur="2">but greedy best-first search wouldn&amp;#39;t have done that because</text>
        <text start="236" dur="5">that would have involved getting to this point, which is this distance to the goal,</text>
        <text start="241" dur="7">and then considering states which were farther from the goal.</text>
        <text start="248" dur="3">What we would really like is an algorithm that combines the best parts</text>
        <text start="251" dur="6">of greedy search which explores a small number of nodes in many cases</text>
        <text start="257" dur="5">and uniform cost search which is guaranteed to find a shortest path.</text>
        <text start="262" dur="6">We&amp;#39;ll show how to do that next using an algorithm called the A-star algorithm.</text>
      </transcript>
    </video>
    <video title="Topic 23, A-Star Search" id="_CBhTubi-CU" length="194">
      <transcript>
        <text start="0" dur="3">[Male narrator] A* Search works by always expanding the path</text>
        <text start="3" dur="4">that has a minimum value of the function f</text>
        <text start="7" dur="5">which is defined as a sum of the g + h components.</text>
        <text start="12" dur="4">Now, the function g of a path</text>
        <text start="16" dur="3">is just the path cost,</text>
        <text start="19" dur="4">and the function h of a path</text>
        <text start="23" dur="4">is equal to the h value of the state,</text>
        <text start="27" dur="3">which is the final state of the path,</text>
        <text start="30" dur="6">which is equal to the estimated distance to the goal.</text>
        <text start="36" dur="3">Here&amp;#39;s an example of how A* works.</text>
        <text start="39" dur="5">Suppose we found this path through the state&amp;#39;s base to a state x</text>
        <text start="44" dur="4">and we&amp;#39;re trying to give a measure to the value of this path.</text>
        <text start="48" dur="7">The measure f is a sum of g, the path cost so far,</text>
        <text start="55" dur="7">and h, which is the estimated distance that the path will take</text>
        <text start="62" dur="2">to complete its path to the goal.</text>
        <text start="64" dur="4">Now, minimizing g helps us keep the path short</text>
        <text start="68" dur="5">and minimizing h helps us keep focused on finding the goal</text>
        <text start="73" dur="4">and the result is a search strategy that is the best possible</text>
        <text start="77" dur="3">in the sense that it finds the shortest length path</text>
        <text start="80" dur="4">while expanding the minimum number of paths possible.</text>
        <text start="84" dur="4">It could be called &amp;quot;best estimated total path cost first,&amp;quot;</text>
        <text start="88" dur="4">but the name A* is traditional.</text>
        <text start="92" dur="4">Now let&amp;#39;s go back to Romania and apply the A* algorithm</text>
        <text start="96" dur="4">and we&amp;#39;re going to use a heuristic, which is a straight line distance</text>
        <text start="100" dur="2">between a state and the goal.</text>
        <text start="102" dur="2">The goal, again, is Bucharest,</text>
        <text start="104" dur="3">and so the distance from Bucharest to Bucharest is, of course, 0.</text>
        <text start="107" dur="4">And for all the other states, I&amp;#39;ve written in red</text>
        <text start="111" dur="2">the straight line distance.</text>
        <text start="113" dur="2">For example, straight across like that.</text>
        <text start="115" dur="4">Now, I should say that all the roads here I&amp;#39;ve drawn as straight lines,</text>
        <text start="119" dur="4">but actually, roads are going to be curved to some degree,</text>
        <text start="123" dur="3">so the actual distance along the roads is going to be longer</text>
        <text start="126" dur="3">than the straight line distance.</text>
        <text start="129" dur="4">Now, we start out as usual--we&amp;#39;ll start in Arad as a start state--</text>
        <text start="133" dur="8">and we&amp;#39;ll expand out Arad and so we&amp;#39;ll add 3 paths</text>
        <text start="141" dur="5">and the evaluation function, f, will be the sum of the path length,</text>
        <text start="146" dur="3">which is given in black, and the estimated distance,</text>
        <text start="149" dur="3">which is given in red.</text>
        <text start="152" dur="5">And so the path length from this path</text>
        <text start="157" dur="8">will be 140+253 or 393;</text>
        <text start="165" dur="10">for this path, 75+374, or 449;</text>
        <text start="175" dur="10">and for this path, 118+329, or 447.</text>
        <text start="185" dur="4">And now, the question is out of all the paths that are on the frontier,</text>
        <text start="189" dur="5">which path would we expand next under the A* algorithm?</text>
      </transcript>
    </video>
    <video title="Topic 23, A-Star Search ANSWER" id="yO5Cx5zw8h4" length="14">
      <transcript>
        <text start="0" dur="5">The answer is that we select this path first--the one from Arad to Sibiu--</text>
        <text start="5" dur="9">because it has the smallest value--393--of the sum f=g+h.</text>
      </transcript>
    </video>
    <video title="Topic 24, A-Star Second Question" id="KP8JiOrl5As" length="39">
      <transcript>
        <text start="0" dur="3">Let&amp;#39;s go ahead and expand this node now.</text>
        <text start="3" dur="3">So we&amp;#39;re going to add 3 paths.</text>
        <text start="6" dur="4">This one has a path cost of 291</text>
        <text start="10" dur="4">and an estimated distance to the goal of 380,</text>
        <text start="14" dur="4">for a total of 671.</text>
        <text start="18" dur="3">This one has a path cost of 239</text>
        <text start="21" dur="6">and an estimated distance of 176, for a total of 415.</text>
        <text start="27" dur="6">And the final one is 220+193=413.</text>
        <text start="33" dur="6">And now the question is which state to we expand next?</text>
      </transcript>
    </video>
    <video title="Topic 24, A-Star Second Question ANSWER" id="YOjVW4NKgDQ" length="12">
      <transcript>
        <text start="0" dur="3">The answer is we expand this path next</text>
        <text start="3" dur="3">because its total, 413,</text>
        <text start="6" dur="3">is less than all the other ones on the front tier--</text>
        <text start="9" dur="3">although only slightly less than the 415 for this path.</text>
      </transcript>
    </video>
    <video title="Topic 25, A-Star Third Question" id="u6_Xjgz7MCg" length="20">
      <transcript>
        <text start="0" dur="3">So we expand this node,</text>
        <text start="3" dur="3">giving us 2 more paths--</text>
        <text start="6" dur="4">this one with an f-value of 417,</text>
        <text start="10" dur="6">and this one with an f-value of 526.</text>
        <text start="16" dur="4">The question again--which path are we going to expand next?</text>
      </transcript>
    </video>
    <video title="Topic 25, A-Star Third Question ANSWER" id="BG5V3_MQP54" length="11">
      <transcript>
        <text start="0" dur="5">And the answer is that we expand this path, Fagaras, next,</text>
        <text start="5" dur="3">because its f-total, 415,</text>
        <text start="8" dur="3">is less than all the other paths in the front tier.</text>
      </transcript>
    </video>
    <video title="Topic 26, A-Star Fourth Question" id="i0ExF1xivqc" length="26">
      <transcript>
        <text start="1" dur="3">Now we expand Fagaras</text>
        <text start="4" dur="3">and we get a path that reaches the goal</text>
        <text start="7" dur="4">and it has a path length of 450 and an estimated distance of 0</text>
        <text start="11" dur="3">for a total f value of 450,</text>
        <text start="14" dur="3">and now the question is: What do we do next?</text>
        <text start="17" dur="5">Click here if you think we&amp;#39;re at the end of the algorithm</text>
        <text start="22" dur="2">and we don&amp;#39;t need to expand next</text>
        <text start="24" dur="2">or click on the node that you think we will expand next.</text>
      </transcript>
    </video>
    <video title="Topic 26, A-Star Fourth Question ANSWER" id="qLfsDlLP2SY" length="23">
      <transcript>
        <text start="0" dur="3">The answer is that we&amp;#39;re not done yet,</text>
        <text start="3" dur="3">because the algorithm works by doing the goal test,</text>
        <text start="6" dur="2">when we take a path off the front tier,</text>
        <text start="8" dur="3">not when we put a path on the front tier.</text>
        <text start="11" dur="4">Instead, we just continue in the normal way and choose the node</text>
        <text start="15" dur="3">on the front tier which has the lowest value.</text>
        <text start="18" dur="5">That would be this one--the path through Pitesti, with a total of 417.</text>
      </transcript>
    </video>
    <video title="Topic 27, A-Star Fifth Question" id="pFPqrufkL48" length="84">
      <transcript>
        <text start="1" dur="3">So let&amp;#39;s expand the node at Pitesti.</text>
        <text start="4" dur="4">We have to go down this direction, up,</text>
        <text start="8" dur="3">then we reach a path we&amp;#39;ve seen before,</text>
        <text start="11" dur="2">and we go in this direction.</text>
        <text start="13" dur="3">Now we reach Bucharest, which is the goal,</text>
        <text start="16" dur="3">and the h value is going to be 0</text>
        <text start="19" dur="5">because we&amp;#39;re at the goal, and the g value works out to 418.</text>
        <text start="24" dur="7">Again, we don&amp;#39;t stop here just because we put a path onto the front tier,</text>
        <text start="31" dur="4">we put it there, we don&amp;#39;t apply the goal test next,</text>
        <text start="35" dur="3">but, now we go back to the front tier,</text>
        <text start="38" dur="5">and it turns out that this 418 is the lowest-cost path on the front tier.</text>
        <text start="43" dur="2">So now we pull it off, do the goal test,</text>
        <text start="45" dur="4">and now we found our path to the goal,</text>
        <text start="49" dur="3">and it is, in fact, the shortest possible path.</text>
        <text start="55" dur="4">In this case, A-star was able to find the lowest-cost path.</text>
        <text start="59" dur="3">Now the question that you&amp;#39;ll have to think about,</text>
        <text start="62" dur="2">because we haven&amp;#39;t explained it yet,</text>
        <text start="64" dur="2">is whether A-star will always do this.</text>
        <text start="66" dur="6">Answer yes if you think A-star will always find the shortest cost path,</text>
        <text start="72" dur="5">or answer no if you think it depends on the particular problem given,</text>
        <text start="77" dur="7">or answer no if you think it depends on the particular heuristic estimate function, h.</text>
      </transcript>
    </video>
    <video title="Topic 27, A-Star Fifth Question ANSWER Mandatory" id="z86_jYE6CDA" length="49">
      <transcript>
        <text start="2" dur="4">The answer is that it depends on the h function.</text>
        <text start="6" dur="3">A-star will find the lowest-cost path</text>
        <text start="9" dur="7">if the h function for a state is less than the true cost</text>
        <text start="16" dur="4">of the path to the goal through that state.</text>
        <text start="20" dur="6">In other words, we want the h to never overestimate the distance to the goal.</text>
        <text start="26" dur="5">We also say that h is optimistic.</text>
        <text start="31" dur="3">Another way of stating that</text>
        <text start="34" dur="3">is that h is admissible,</text>
        <text start="37" dur="4">meaning is it admissible to use it to find the lowest-cost path.</text>
        <text start="41" dur="4">Think of all of these of being the same way</text>
        <text start="45" dur="4">of stating the conditions under which A-star finds the lowest-cost path.</text>
      </transcript>
    </video>
    <video title="Topic 28, Optimistic Heuristics" id="3Vmn9Rn-lDM" length="82">
      <transcript>
        <text start="1" dur="2">Here we give you an intuition as to why</text>
        <text start="3" dur="4">an optimistic heuristic function, h, finds the lowest-cost path.</text>
        <text start="8" dur="7">When A-star ends, it returns a path, p, with estimated cost, c.</text>
        <text start="15" dur="5">It turns out that c is also the actual cost,</text>
        <text start="20" dur="3">because at the goal the h component is 0,</text>
        <text start="23" dur="4">and so the path cost is the total cost as estimated by the function.</text>
        <text start="28" dur="3">Now, all the paths on the front tier</text>
        <text start="31" dur="4">have an estimated cost that&amp;#39;s greater than c,</text>
        <text start="35" dur="5">and we know that because the front tier is explored in cheapest-first order.</text>
        <text start="40" dur="4">If h is optimistic, then the estimated cost</text>
        <text start="44" dur="3">is less than the true cost,</text>
        <text start="47" dur="4">so the path p must have a cost that&amp;#39;s less than the true cost</text>
        <text start="51" dur="3">of any of the paths on the front tier.</text>
        <text start="54" dur="3">Any paths that go beyond the front tier</text>
        <text start="57" dur="2">must have a cost that&amp;#39;s greater than that</text>
        <text start="59" dur="5">because we agree that the step cost is always 0 or more.</text>
        <text start="64" dur="5">So that means that this path, p, must be the minimal cost path.</text>
        <text start="69" dur="4">Now, this argument, I should say, only goes through</text>
        <text start="73" dur="3">as is for tree search.</text>
        <text start="76" dur="3">For graph search the argument is slightly more complicated,</text>
        <text start="79" dur="3">but the general intuitions hold the same.</text>
      </transcript>
    </video>
    <video title="Topic 29, State Spaces" id="8dXgwOvQYVE" length="59">
      <transcript>
        <text start="1" dur="4">So far we&amp;#39;ve looked at the state space of cities in Romania--</text>
        <text start="5" dur="2">a 2-dimensional, physical space.</text>
        <text start="7" dur="3">But the technology for problem solving through search</text>
        <text start="10" dur="2">can deal with many types of state spaces,</text>
        <text start="12" dur="5">dealing with abstract properties, not just x-y position in a plane.</text>
        <text start="17" dur="4">Here I introduce another state space--the vacuum world.</text>
        <text start="21" dur="4">It&amp;#39;s a very simple world in which there are only 2 positions</text>
        <text start="25" dur="5">as opposed to the many positions in the Romania state space.</text>
        <text start="30" dur="3">But there are additional properties to deal with as well.</text>
        <text start="33" dur="3">The robot vacuum cleaner can be in either of the 2 conditions,</text>
        <text start="36" dur="4">but as well as that each of the positions</text>
        <text start="40" dur="3">can either have dirt in it or not have dirt in it.</text>
        <text start="43" dur="4">Now the question is to represent this as a state space</text>
        <text start="47" dur="4">how many states do we need?</text>
        <text start="51" dur="8">The number of states can fill in this box here.</text>
      </transcript>
    </video>
    <video title="Topic 29, State Spaces ANSWER" id="6KTjn8LpbZM" length="35">
      <transcript>
        <text start="1" dur="3">And the answer is there are 8 states.</text>
        <text start="4" dur="6">There are 2 physical states that the robot vacuum cleaner can be in--</text>
        <text start="10" dur="2">either in state A or in state B.</text>
        <text start="12" dur="5">But in addition to that, there are states about how the world is</text>
        <text start="17" dur="2">as well as where the robot is in the world.</text>
        <text start="19" dur="5">So state A can be dirty or not.</text>
        <text start="24" dur="2">That&amp;#39;s 2 possibilities.</text>
        <text start="26" dur="2">And B can be dirty or not.</text>
        <text start="28" dur="3">That&amp;#39;s 2 more possibilities.</text>
        <text start="31" dur="4">We multiply those together.                                 We get 8 possible states.</text>
      </transcript>
    </video>
    <video title="Topic 30, State Space Diagram and More Complexity" id="NCfWMf9lL5I" length="104">
      <transcript>
        <text start="1" dur="4">Here is a diagram of the state space for the vacuum world.</text>
        <text start="5" dur="4">Note that there are 8 states, and we have the actions connecting the states</text>
        <text start="9" dur="3">just as we did in the Romania problem.</text>
        <text start="12" dur="3">Now let&amp;#39;s look at a path through this state.</text>
        <text start="15" dur="4">Let&amp;#39;s say we start out in this position,</text>
        <text start="19" dur="4">and then we apply the action of moving right.</text>
        <text start="23" dur="4">Then we end up in a position where the state of the world looks the same,</text>
        <text start="27" dur="5">except the robot has moved from position &amp;#39;A&amp;#39; to position &amp;#39;B&amp;#39;.</text>
        <text start="32" dur="5">Now if we turn on the sucking action,</text>
        <text start="37" dur="5">then we end up in a state where the robot is in the same position</text>
        <text start="42" dur="4">but that position is no longer dirty.</text>
        <text start="47" dur="3">Let&amp;#39;s take this very simple vacuum world</text>
        <text start="50" dur="3">and make a slightly more complicated one.</text>
        <text start="53" dur="3">First, we&amp;#39;ll say that the robot has a power switch,</text>
        <text start="56" dur="8">which can be in one of three conditions:                     on, off, or sleep.</text>
        <text start="64" dur="5">Next, we&amp;#39;ll say that the robot has a dirt-sensing camera,</text>
        <text start="69" dur="4">and that camera can either be on or off.</text>
        <text start="73" dur="3">Third, this is the deluxe model of robot</text>
        <text start="76" dur="3">in which the brushes that clean up the dust</text>
        <text start="79" dur="3">can be set at 1 of 5 different heights</text>
        <text start="82" dur="5">to be appropriate for whatever level of carpeting you have.</text>
        <text start="87" dur="3">Finally, rather that just having the 2 positions,</text>
        <text start="90" dur="7">we&amp;#39;ll extend that out and have 10 positions.</text>
        <text start="97" dur="7">Now the question is how many states are in this state space?</text>
      </transcript>
    </video>
    <video title="Topic 30, State Space Diagram and More Complexity ANSWER" id="ATEXTIBgH4o" length="57">
      <transcript>
        <text start="1" dur="4">The answer is that the number of states is the cross product</text>
        <text start="5" dur="3">of the numbers of all the variables, since they&amp;#39;re each independent,</text>
        <text start="8" dur="2">and any combination can occur.</text>
        <text start="10" dur="4">For the power we have 3 possible positions.</text>
        <text start="14" dur="4">The camera has 2.</text>
        <text start="18" dur="5">The brush height has 5.</text>
        <text start="23" dur="5">The dirt has 2 for each of the 10 positions.</text>
        <text start="28" dur="5">That&amp;#39;s 2^10 or 1024.</text>
        <text start="33" dur="6">Then the robot&amp;#39;s position can be any of those 10 positions as well.</text>
        <text start="39" dur="5">That works out to 307,200 states in the state space.</text>
        <text start="44" dur="2">Notice how a fairly trivial problem--</text>
        <text start="46" dur="4">we&amp;#39;re only modeling a few variables and only 10 positions--</text>
        <text start="50" dur="2">works out to a large number of state spaces.</text>
        <text start="52" dur="5">That&amp;#39;s why we need efficient algorithms for searching through states spaces.</text>
      </transcript>
    </video>
    <video title="Topic 31, Sliding Blocks Puzzle" id="-HvDwJAM2y4" length="109">
      <transcript>
        <text start="1" dur="4">I want to introduce one more problem that can be solved with search techniques.</text>
        <text start="5" dur="3">This is a sliding blocks puzzle, called a 15 puzzle.</text>
        <text start="8" dur="2">You may have seen something like this.</text>
        <text start="10" dur="4">So there are a bunch of little squares or blocks or tiles</text>
        <text start="14" dur="2">and you can slide them around.</text>
        <text start="19" dur="2">and the goal is to get into a certain configuration.</text>
        <text start="21" dur="6">So we&amp;#39;ll say that this is the goal state, where the numbers 1-15 are in order</text>
        <text start="27" dur="2">left to right, top to bottom.</text>
        <text start="29" dur="5">The starting state would be some state where all the positions are messed up.</text>
        <text start="34" dur="4">Now the question is: Can we come up with a good heuristic for this?</text>
        <text start="38" dur="4">Let&amp;#39;s examine that as a way of thinking about where heuristics come from.</text>
        <text start="42" dur="4">The first heuristic we&amp;#39;re going to consider</text>
        <text start="46" dur="8">we&amp;#39;ll call h1, and that is equal to the number of misplaced blocks.</text>
        <text start="54" dur="5">So here 10 and 11 are misplaced because they should be there and there, respectively,</text>
        <text start="59" dur="3">12 is in the right place, 13 is in the right place,</text>
        <text start="62" dur="2">and 14 and 15 are misplaced.</text>
        <text start="64" dur="3">That&amp;#39;s a total of 4 misplaced blocks.</text>
        <text start="67" dur="6">The 2nd heuristic, h2, is equal to</text>
        <text start="73" dur="6">the sum of the distances that each block would have to move to get to the right position.</text>
        <text start="79" dur="7">For this position, 10 would have to move 1 space to get to the right position,</text>
        <text start="86" dur="4">11 would have to move 1, so that&amp;#39;s a total of 2 so far,</text>
        <text start="90" dur="1">13 is in the right place,</text>
        <text start="91" dur="2">14 is 1 displaced,</text>
        <text start="93" dur="2">and 15 is 1 displaced,</text>
        <text start="95" dur="3">so that would also be a total of 4.</text>
        <text start="98" dur="6">Now, the question is: Which, if any, of these heuristics are admissible?</text>
        <text start="104" dur="3">Check the boxes next to the heuristics that you think</text>
        <text start="107" dur="2">are admissible.</text>
      </transcript>
    </video>
    <video title="Topic 31, Sliding Blocks Puzzle ANSWER" id="lviKMjofhZ0" length="42">
      <transcript>
        <text start="2" dur="5">H1 is admissible, because every tile that&amp;#39;s in the wrong position</text>
        <text start="7" dur="3">must be moved at least once to get into the right position.</text>
        <text start="10" dur="3">So h1 never overestimates.</text>
        <text start="13" dur="2">How about h2?</text>
        <text start="15" dur="5">H2 is also admissible, because every tile in the wrong position</text>
        <text start="20" dur="6">can be moved closer to the correct position no faster than 1 space per move.</text>
        <text start="26" dur="2">Therefore, both are admissible.</text>
        <text start="28" dur="5">But notice that h2 is always greater than or equal to h1.</text>
        <text start="33" dur="2">That means that, with the exception of breaking ties,</text>
        <text start="35" dur="4">an A* search using h2 will always expand</text>
        <text start="39" dur="3">fewer paths than one using h1</text>
      </transcript>
    </video>
    <video title="Topic 32, Where is the Intelligence" id="lL-8KGXehNY" length="196">
      <transcript>
        <text start="1" dur="3">Now, we&amp;#39;re trying to build an artificial intelligence</text>
        <text start="4" dur="3">that can solve problems like this all on its own.</text>
        <text start="8" dur="4">You can see that the search algorithms do a great job</text>
        <text start="12" dur="3">of finding solutions to problems like this.</text>
        <text start="15" dur="4">But, you might complain that in order for the search algorithms to work,</text>
        <text start="19" dur="3">we had to provide it with a heurstic function.</text>
        <text start="22" dur="3">A heurstic function came from the outside.</text>
        <text start="25" dur="5">You might think that coming up with a good heurstic function is really where all the intelligence is.</text>
        <text start="30" dur="4">So, a problem solver that uses an heurstic function given to it</text>
        <text start="34" dur="2">really isn&amp;#39;t intelligent at all.</text>
        <text start="36" dur="3">So let&amp;#39;s think about where the intelligence could come from</text>
        <text start="39" dur="4">and can we automatically come up with good heurstic functions.</text>
        <text start="45" dur="2">I&amp;#39;m going to sketch a description of</text>
        <text start="47" dur="3">a program that can automatically come up with good heurstics</text>
        <text start="50" dur="2">given a description of a problem.</text>
        <text start="52" dur="5">Suppose this program is given a description of the sliding blocks puzzle</text>
        <text start="57" dur="5">where we say that a block can move from square A to square B</text>
        <text start="62" dur="4">if A is adjacent to B and B is blank.</text>
        <text start="66" dur="4">Now, imagine that we try to loosen this restriction.</text>
        <text start="70" dur="4">We cross out &amp;quot;B is blank,&amp;quot;</text>
        <text start="74" dur="2">and then we get the rule</text>
        <text start="76" dur="4">&amp;quot;a block can move from A to B if A is adjacent to B,&amp;quot;</text>
        <text start="80" dur="3">and that&amp;#39;s equal to our heurstic h2</text>
        <text start="83" dur="4">because a block can move anywhere to an adjacent state.</text>
        <text start="87" dur="4">Now, we could also cross out the other part of the rule,</text>
        <text start="91" dur="5">and we now get &amp;quot;a block can move from any square A</text>
        <text start="96" dur="4">to any square B regardless of any condition.</text>
        <text start="100" dur="3">That gives us heurstic h1.</text>
        <text start="103" dur="5">So we see that both of our heurstics can be derived</text>
        <text start="108" dur="2">from a simple mechanical manipulation</text>
        <text start="110" dur="3">of the formal description of the problem.</text>
        <text start="113" dur="5">Once we&amp;#39;ve generated automatically these candidate heuristics,</text>
        <text start="118" dur="4">another way to come up with a good heurstic is to say</text>
        <text start="122" dur="2">that a new heurstic, h,</text>
        <text start="124" dur="6">is equal to the maximum of h1 and h2,</text>
        <text start="130" dur="3">and that&amp;#39;s guaranteed to be admissible as long as</text>
        <text start="133" dur="3">h1 and h2 are admissible</text>
        <text start="136" dur="2">because it still never overestimates,</text>
        <text start="138" dur="4">and it&amp;#39;s guaranteed to be better because its getting closer to the true value.</text>
        <text start="142" dur="5">The only problem with combining multiple heuristics like this</text>
        <text start="147" dur="2">is that there is some cause to compute the heuristic</text>
        <text start="149" dur="2">and it could take longer to compute</text>
        <text start="151" dur="4">even if we end up expanding pure paths.</text>
        <text start="155" dur="3">Crossing out parts of the rules like this</text>
        <text start="158" dur="3">is called &amp;quot;generating a relaxed problem.&amp;quot;</text>
        <text start="161" dur="3">What we&amp;#39;ve done is we&amp;#39;ve taken the original problem,</text>
        <text start="164" dur="2">where it&amp;#39;s hard to move squares around,</text>
        <text start="166" dur="3">and made it easier by relaxing one of the constraints.</text>
        <text start="169" dur="5">You can see that as adding new links in the state space,</text>
        <text start="174" dur="5">so if we have a state space in which there are only particular links,</text>
        <text start="179" dur="6">by relaxing the problem it&amp;#39;s as if we are adding new operators</text>
        <text start="185" dur="2">that traverse the state in new ways.</text>
        <text start="187" dur="4">So adding new operators only makes the problem easier,</text>
        <text start="191" dur="5">and thus never overestimates, and thus is admissible.</text>
      </transcript>
    </video>
    <video title="Topic 33, What Can't Search Do" id="UbqrrN4wbqQ" length="112">
      <transcript>
        <text start="0" dur="3">We&amp;#39;ve seen what search can do for problem solving.</text>
        <text start="3" dur="3">It can find the lowest-cost path to a goal,</text>
        <text start="6" dur="6">and it can do that in a way in which we never generate more paths than we have to.</text>
        <text start="12" dur="3">We can find the optimal number of paths to generate,</text>
        <text start="15" dur="4">and we can do that with a heuristic function that we generate on our own</text>
        <text start="19" dur="3">by relaxing the existing problem definition.</text>
        <text start="22" dur="3">But let&amp;#39;s be clear on what search can&amp;#39;t do.</text>
        <text start="25" dur="6">All the solutions that we have found consist of a fixed sequence of actions.</text>
        <text start="31" dur="7">In other words, the agent Hirin Arad, thinks, comes up with a plan that it wants to execute</text>
        <text start="38" dur="4">and then essentially closes his eyes and starts driving,</text>
        <text start="42" dur="4">never considering along the way if something has gone wrong.</text>
        <text start="46" dur="3">That works fine for this type of problem,</text>
        <text start="49" dur="4">but it only works when we satisfy the following conditions.</text>
        <text start="53" dur="2">[Problem solving works when:]</text>
        <text start="55" dur="4">Problem-solving technology works when the following set of conditions is true:</text>
        <text start="59" dur="4">First, the domain must be fully observable.</text>
        <text start="63" dur="5">In other words, we must be able to see what initial state we start out with.</text>
        <text start="68" dur="4">Second, the domain must be known.</text>
        <text start="72" dur="4">That is, we have to know the set of available actions to us.</text>
        <text start="76" dur="4">Third, the domain must be discrete.</text>
        <text start="80" dur="4">There must be a finite number of actions to chose from.</text>
        <text start="84" dur="4">Fourth, the domain must be deterministic.</text>
        <text start="88" dur="4">We have to know the result of taking an action.</text>
        <text start="92" dur="4">Finally, the domain must be static.</text>
        <text start="96" dur="5">There must be nothing else in the world that can change the world except our own actions.</text>
        <text start="101" dur="3">If all these conditions are true, then we can search for a plan</text>
        <text start="104" dur="3">which solves the problem and is guaranteed to work.</text>
        <text start="107" dur="5">In later units, we will see what to do if any of these conditions fail to hold.</text>
      </transcript>
    </video>
    <video title="Topic 34, Note on Implementation" id="3muiVUU0sys" length="155">
      <transcript>
        <text start="1" dur="7">Our description of the algorithm has talked about paths in the state space.</text>
        <text start="8" dur="7">I want to say a little bit now about how to implement that in terms of a computer algorithm.</text>
        <text start="15" dur="4">We talk about paths, but we want to implement that in some ways.</text>
        <text start="19" dur="3">In the implementation we talk about nodes.</text>
        <text start="22" dur="5">A node is a data structure, and it has four fields.</text>
        <text start="27" dur="8">The state field indicates the state at the end of the path.</text>
        <text start="35" dur="5">The action was the action it took to get there.</text>
        <text start="40" dur="5">The cost is the total cost,</text>
        <text start="45" dur="5">and the parent is a pointer to another node.</text>
        <text start="50" dur="6">In this case, the node that has state &amp;quot;S&amp;quot;,</text>
        <text start="56" dur="10">and it will have a parent which points to the node that has state &amp;quot;A&amp;quot;,</text>
        <text start="66" dur="4">and that will have a parent pointer that&amp;#39;s null.</text>
        <text start="70" dur="5">So we have a linked list of nodes representing the path.</text>
        <text start="75" dur="3">We&amp;#39;ll use the word &amp;quot;path&amp;quot; for the abstract idea,</text>
        <text start="78" dur="4">and the word &amp;quot;node&amp;quot; for the representation in the computer memory.</text>
        <text start="82" dur="4">But otherwise, you can think of those two terms as being synonyms,</text>
        <text start="86" dur="5">because they&amp;#39;re in a one-to-one correspondence.</text>
        <text start="91" dur="4">Now there are two main data structures that deal with nodes.</text>
        <text start="95" dur="6">We have the &amp;quot;frontier&amp;quot; and we have the &amp;quot;explored&amp;quot; list.</text>
        <text start="101" dur="3">Let&amp;#39;s talk about how to implement them.</text>
        <text start="104" dur="4">In the frontier the operations we have to deal with</text>
        <text start="108" dur="4">are removing the best item from the frontier and adding in new ones.</text>
        <text start="112" dur="3">And that suggests we should implement it as a priority queue,</text>
        <text start="115" dur="4">which knows how to keep track of the best items in proper order.</text>
        <text start="119" dur="4">But we also need to have an additional operation</text>
        <text start="123" dur="4">of a membership test as a new item in the frontier.</text>
        <text start="127" dur="3">And that suggests representing it as a set,</text>
        <text start="130" dur="4">which can be built from a hash table or a tree.</text>
        <text start="134" dur="6">So the most efficient implementations of search actually have both representations.</text>
        <text start="140" dur="3">The explored set, on the other hand, is easier.</text>
        <text start="143" dur="5">All we have to do there is be able to add new members and check for membership.</text>
        <text start="148" dur="3">So we represent that as a single set,</text>
        <text start="151" dur="4">which again can be done with either a hash table or tree.</text>
      </transcript>
    </video>
  </group>
  <group title="Homework 1" count="16">
    <video title="Congratulations!" id="IXVOQEFTvb4" length="5">
      <transcript>
        <text start="0" dur="2">Congratulations.</text>
        <text start="2" dur="3">You just made assignment 1.</text>
      </transcript>
    </video>
    <video title="Introduction" id="dnnGEYjD9wo" length="5">
      <transcript>
        <text start="0" dur="5">This is homework assignment #1.</text>
      </transcript>
    </video>
    <video title="Question 1, Peg Solitaire" id="CxjV8H50xfU" length="60">
      <transcript>
        <text start="1" dur="3">This is a question about peg solitaire.</text>
        <text start="4" dur="4">In peg solitaire, a single player faces</text>
        <text start="8" dur="2">the following kind of board.</text>
        <text start="13" dur="6">Initially, all pieces are occupied except for the center piece.</text>
        <text start="22" dur="4">You can find more information on peg solitare at the following URL.</text>
        <text start="26" dur="9">[http://en.wikipedia.org/wiki/peg_solitaire]</text>
        <text start="36" dur="4">I wish to know whether this game is partially observable,</text>
        <text start="40" dur="3">Please say yes or no.</text>
        <text start="43" dur="3">I wish to know whether it is stochastic.</text>
        <text start="46" dur="4">Please say yes if it is and no if it&amp;#39;s deterministic.</text>
        <text start="50" dur="5">Let me know if it&amp;#39;s continuous, yes or no,</text>
        <text start="55" dur="5">and let me know if it&amp;#39;s adversarial, yes or no.</text>
      </transcript>
    </video>
    <video title="Question 1, Peg Solitaire ANSWER" id="YOfAe4Xo_P4" length="22">
      <transcript>
        <text start="0" dur="6">&amp;gt;&amp;gt;Peg Solitaire is not partially observable because you can see the board at all times.</text>
        <text start="6" dur="3">It is not stochastic because you just make all the moves,</text>
        <text start="9" dur="2">and they have very different mystic effects.</text>
        <text start="11" dur="4">It is not continuous.  It&amp;#39;s just finding many choices of actions</text>
        <text start="15" dur="3">and finding many board positions, so therefore, it is not continuous.</text>
        <text start="18" dur="4">and it&amp;#39;s not adversarial because there is no adversaries--just you playing.</text>
      </transcript>
    </video>
    <video title="Question 2, Loaded Coin" id="ZmVLMZ5Fwcg" length="54">
      <transcript>
        <text start="1" dur="4">I am going to ask you about the problem to learn about a loaded coin.</text>
        <text start="5" dur="2">A loaded coin is a coin,</text>
        <text start="7" dur="2">that if you flip it,</text>
        <text start="9" dur="4">might have a non 0.5 chance</text>
        <text start="13" dur="2">of coming up heads or tails.</text>
        <text start="16" dur="4">Fair coins always come up 50% heads or tails.</text>
        <text start="20" dur="3">Loaded coins might come up, for example,</text>
        <text start="23" dur="4">0.9 chance heads and 0.1 chance tails.</text>
        <text start="27" dur="3">Your task will be to understand,</text>
        <text start="30" dur="1">from coin flips,</text>
        <text start="31" dur="2">whether a coin is loaded,</text>
        <text start="33" dur="2">and if so, at what probability.</text>
        <text start="35" dur="2">I don&amp;#39;t want you to solve the problem,</text>
        <text start="37" dur="3">but I want you to answer the following questions:</text>
        <text start="40" dur="2">Is it partially observable?</text>
        <text start="42" dur="2">Yes or no.</text>
        <text start="44" dur="2">Is it stochastic?</text>
        <text start="46" dur="2">Yes or no.</text>
        <text start="48" dur="3">Is it continuous?  [Yes or no.]</text>
        <text start="51" dur="2">And finally, is it adversarial?</text>
        <text start="53" dur="1">Yes or no.</text>
      </transcript>
    </video>
    <video title="Question 2, Loaded Coin ANSWER" id="GsKZT-aAZFI" length="38">
      <transcript>
        <text start="0" dur="6">[Thrun] So the loaded coin example is clearly partially observable,</text>
        <text start="6" dur="3">and the reason is it is actually used for the memory</text>
        <text start="9" dur="5">if you flip it more than 1 time so you can learn more about what the actual probability is.</text>
        <text start="14" dur="6">Therefore, looking at the most recent coin flip is insufficient to make your choice.</text>
        <text start="20" dur="5">It is stochastic because you flip a coin.</text>
        <text start="25" dur="6">It is not continuous because there&amp;#39;s only 1 action--a flip--and 2 outcomes.</text>
        <text start="31" dur="5">And it isn&amp;#39;t really adversarial because while you do your learning task</text>
        <text start="36" dur="2">no adversary interferes.</text>
      </transcript>
    </video>
    <video title="Question 3, Path Through Maze" id="dj6jEEU-jZc" length="32">
      <transcript>
        <text start="0" dur="5">Let&amp;#39;s talk about the problem of finding a path through a maze.</text>
        <text start="5" dur="5">Let me draw you a maze.</text>
        <text start="10" dur="5">Suppose you wish to find the path from the start to your goal.</text>
        <text start="15" dur="4">I don&amp;#39;t want to you to solve this problem.</text>
        <text start="19" dur="4">Rather I want you to tell me whether it&amp;#39;s partially observable.</text>
        <text start="23" dur="2">Yes or no.</text>
        <text start="25" dur="2">It is stochastic?</text>
        <text start="27" dur="2">Yes or no.</text>
        <text start="29" dur="2">Is it continuous?</text>
        <text start="31" dur="1">Yes or no.</text>
      </transcript>
    </video>
    <video title="Question 3, Path Through Maze ANSWER" id="TskS2qHzi90" length="18">
      <transcript>
        <text start="0" dur="3">[Thrun] The path through the maze is clearly not partially observable</text>
        <text start="3" dur="3">because you can see the maze entirely at all times.</text>
        <text start="6" dur="4">It is not stochastic. There is no randomness involved.</text>
        <text start="10" dur="2">It isn&amp;#39;t really continuous.</text>
        <text start="12" dur="3">There&amp;#39;s typically just finitely many choices--go left or right.</text>
        <text start="15" dur="3">And it isn&amp;#39;t adversarial because there&amp;#39;s no real adversary involved.</text>
      </transcript>
    </video>
    <video title="Question 4, Search Tree" id="qsxMRW2SOqI" length="43">
      <transcript>
        <text start="0" dur="2">This is a search question.</text>
        <text start="2" dur="3">Suppose we are given the following search tree.</text>
        <text start="5" dur="3">We are searching from the top, the start node,</text>
        <text start="8" dur="4">to the goal, which is over here.</text>
        <text start="12" dur="5">Assume we expand from left to right.</text>
        <text start="17" dur="3">Tell me how many nodes are expanded</text>
        <text start="20" dur="3">if we expand from left to right,</text>
        <text start="23" dur="4">counting the start node and the goal node in your answer.</text>
        <text start="27" dur="5">And give me the same answer for Depth First Search.</text>
        <text start="32" dur="3">Now, let&amp;#39;s assume you&amp;#39;re going to search from right to left.</text>
        <text start="35" dur="4">How many nodes would we now expand in Breadth First Search,</text>
        <text start="39" dur="4">and how many do we expand in Depth First Search?</text>
      </transcript>
    </video>
    <video title="Question 4, Search Tree ANSWER" id="FDTlQfGb9SY" length="38">
      <transcript>
        <text start="0" dur="3">[Thrun] Breadth first from left to right is 6--</text>
        <text start="3" dur="4">1, 2, 3, 4, 5, 6.</text>
        <text start="7" dur="8">Depth first from left to right is 4--1, 2, 3, 4.</text>
        <text start="15" dur="4">Breadth first searched from right to left is 9--</text>
        <text start="19" dur="6">1, 2, 3, 4, 5, 6, 7, 8, 9.</text>
        <text start="25" dur="3">And depth first from right to left is 9--</text>
        <text start="28" dur="10">1, 2, 3, 4, 5, 6, 7, 8, 9.</text>
      </transcript>
    </video>
    <video title="Question 5, Another Search Tree" id="vWNEaVcK2gU" length="31">
      <transcript>
        <text start="0" dur="3">Another search problem--</text>
        <text start="3" dur="5">Consider the following search tree,</text>
        <text start="8" dur="4">where this is the start node.</text>
        <text start="12" dur="3">Now, assume we search from left to right.</text>
        <text start="15" dur="4">I would like you to tell me the number of nodes expanded from Breadth-First Search</text>
        <text start="19" dur="3">and Depth-First Search.</text>
        <text start="22" dur="3">Please do count the start and the goal node,</text>
        <text start="25" dur="3">and please give me the same numbers for Right-to-Left Search,</text>
        <text start="28" dur="3">for Breadth-First, and Depth-First.</text>
      </transcript>
    </video>
    <video title="Question 5, Another Search Tree ANSWER" id="V_eXNj-LA9E" length="48">
      <transcript>
        <text start="0" dur="5">[Thrun] The correct answer for breadth first left to right is 13--</text>
        <text start="5" dur="8">1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13.</text>
        <text start="13" dur="4">And for depth first it is 10--</text>
        <text start="17" dur="11">1, 2, 3, 4, 5, 6, 7, 8, 9, and 10.</text>
        <text start="28" dur="4">For right to left search, the right answer for breadth first is 11--</text>
        <text start="32" dur="6">1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11.</text>
        <text start="38" dur="4">And for depth first the right answer is 7--</text>
        <text start="42" dur="6">1, 2, 3, 4, 5, 6, 7.</text>
      </transcript>
    </video>
    <video title="Question 6, Search Network" id="IQhUlwJaBqc" length="60">
      <transcript>
        <text start="0" dur="4">This is another search problem.</text>
        <text start="4" dur="3">Let&amp;#39;s assume we have a search graph.</text>
        <text start="7" dur="6">It isn&amp;#39;t quite a tree but looks like this.</text>
        <text start="13" dur="5">Obviously in the structure we can reach nodes through multiple paths.</text>
        <text start="18" dur="4">So let&amp;#39;s assume that our search never expands the same node twice.</text>
        <text start="22" dur="5">Let&amp;#39;s also assume this start node is on top. We search down.</text>
        <text start="27" dur="3">And this over here is our goal node.</text>
        <text start="30" dur="5">So left-to-right search, tell me how many nodes</text>
        <text start="35" dur="8">breadth first would expand--do count the start and goal node in the final answer.</text>
        <text start="43" dur="5">Give me the same result for a depth-first search.</text>
        <text start="48" dur="3">Again counting the start and the goal node in your answer.</text>
        <text start="51" dur="3">And again give me your answer for breadth-first</text>
        <text start="54" dur="6">and for depth-first in the right-to-left search paradigm.</text>
      </transcript>
    </video>
    <video title="Question 6, Search Network ANSWER" id="mXT-9-K5OtU" length="49">
      <transcript>
        <text start="0" dur="5">[Thrun] The right answer over here is 10 for breadth first from left to right--</text>
        <text start="5" dur="6">1, 2, 3, 4, 5, 6, 7, 8, 9, 10.</text>
        <text start="11" dur="4">Depth first is 16, or all nodes--</text>
        <text start="15" dur="15">1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16.</text>
        <text start="30" dur="4">And notice how I never expanded a node twice.</text>
        <text start="34" dur="4">Correct answer for breadth first right to left is 7--</text>
        <text start="38" dur="5">1, 2, 3, 4, 5, 6, 7.</text>
        <text start="43" dur="6">And the correct answer for depth first from right to left is 4--1, 2, 3, and 4.</text>
      </transcript>
    </video>
    <video title="Question 7, A* Search" id="V4h2H0jpGsg" length="76">
      <transcript>
        <text start="0" dur="3">Let&amp;#39;s talk about a star search.</text>
        <text start="3" dur="5">Let&amp;#39;s assume we have the following grid.</text>
        <text start="8" dur="5">The start state is right here.</text>
        <text start="13" dur="3">And the goal state is right here.</text>
        <text start="16" dur="6">And just for convenience, I will give each here a little number.</text>
        <text start="22" dur="4">A. B. C. D.</text>
        <text start="26" dur="4">Let me draw a heuristic function.</text>
        <text start="30" dur="2">Please take a look for a moment</text>
        <text start="32" dur="6">and tell me whether this heuristic function is admissable.</text>
        <text start="38" dur="3">Check here if yes and here if no.</text>
        <text start="41" dur="5">Which one is the first node a star would expand?</text>
        <text start="46" dur="5">B1 or A2?</text>
        <text start="51" dur="5">What&amp;#39;s the second node to expand?</text>
        <text start="56" dur="10">B1, C1, A2, A3, or B2?</text>
        <text start="66" dur="4">And finally, what is the third node to expand?</text>
        <text start="70" dur="6">D1, C2, B3, or A4?</text>
      </transcript>
    </video>
    <video title="Question 7, A* Search ANSWER" id="forv6djwNWM" length="104">
      <transcript>
        <text start="0" dur="5">[Thrun] Clearly this is an admissable heuristic because the distance to the goal</text>
        <text start="5" dur="2">is strictly underestimated.</text>
        <text start="7" dur="2">From here it would take 1 step,</text>
        <text start="9" dur="6">from here it will take 1, 2 steps, so the answer is yes.</text>
        <text start="15" dur="7">Now, to understand A*, let me also draw the g function</text>
        <text start="22" dur="2">for development part of this table.</text>
        <text start="24" dur="3">Clearly g is 0 over here.</text>
        <text start="27" dur="4">To understand which node to expand, this one or this one,</text>
        <text start="31" dur="3">let&amp;#39;s project the g function, which is 1,</text>
        <text start="34" dur="6">and we will see that 3 plus 1 is smaller than 4 plus 1;</text>
        <text start="40" dur="7">therefore, this is the second node to expand, which is b1.</text>
        <text start="47" dur="8">Now let me for the next step explain the g function from this guy here, 2 and 2.</text>
        <text start="55" dur="13">So 2 plus 2 is 4 versus 3 plus 2 is 5, so we expand this node next, which is c1.</text>
        <text start="68" dur="6">And finally, the g function from here would go 3 and 3.</text>
        <text start="74" dur="10">3 plus 1 is better than 3 plus 2, so we would expand d1 next.</text>
        <text start="84" dur="5">And notice how in the sum of g and h,</text>
        <text start="89" dur="6">this node over here, which has a total of 4, is better than any other node that is unexpanded.</text>
        <text start="95" dur="5">So in particular, 4 plus 1 is 5, and 3 plus 2 is 5 as well,</text>
        <text start="100" dur="4">and 2 plus 3 is 5 as well, so this is the next one to expand.</text>
      </transcript>
    </video>
  </group>
  <group title="Unit 3" count="64">
    <video title="1 Introduction" id="-8DyY8_IuA0" length="386">
      <transcript>
        <text start="0" dur="3">So the next units will be concerned with probabilities</text>
        <text start="3" dur="5">and particularly with structured probabilities using Bayes networks.</text>
        <text start="8" dur="4">This is some of the most involved material in this class.</text>
        <text start="12" dur="2">And since this is a Stanford level class,</text>
        <text start="14" dur="4">you will find out that some of the quizzes are actually really hard.</text>
        <text start="18" dur="5">So as you go through the material, I hope the hardness of the quizzes won&amp;#39;t discourage you;</text>
        <text start="23" dur="7">it&amp;#39;ll really entice you to take a piece of paper and a pen and work them out.</text>
        <text start="30" dur="5">Let me give you a flavor of a Bayes network using an example.</text>
        <text start="35" dur="4">Suppose you find in the morning that your car won&amp;#39;t start.</text>
        <text start="39" dur="4">Well, there&amp;#39;s many causes why your car might not start.</text>
        <text start="43" dur="3">One is that your battery is flat.</text>
        <text start="46" dur="4">Even for a flat battery there is multiple causes.</text>
        <text start="50" dur="2">One, it&amp;#39;s just plain dead,</text>
        <text start="52" dur="3">and one is that the battery is okay but it&amp;#39;s not charging.</text>
        <text start="55" dur="6">The reason why a battery might not charge is that the alternator might be broken</text>
        <text start="61" dur="2">or the fan belt might be broken.</text>
        <text start="63" dur="4">If you look at this influence diagram, also called a Bayes network,</text>
        <text start="67" dur="5">you&amp;#39;ll find there&amp;#39;s many different ways to explain that the car won&amp;#39;t start.</text>
        <text start="72" dur="5">And a natural question you might have is, &amp;quot;Can we diagnose the problem?&amp;quot;</text>
        <text start="77" dur="3">One diagnostic tool is a battery meter,</text>
        <text start="80" dur="6">which may increase or decrease your belief that the battery may cause your car failure.</text>
        <text start="86" dur="3">You might also know your battery age.</text>
        <text start="89" dur="2">Older batteries tend to go dead more often.</text>
        <text start="91" dur="6">And there&amp;#39;s many other ways to look at reasons why the car might not start.</text>
        <text start="97" dur="6">You might inspect the lights, the oil light, the gas gauge.</text>
        <text start="103" dur="5">You might even dip into the engine to see what the oil level is with a dipstick.</text>
        <text start="108" dur="4">All of those relate to alternative reasons why the car might not be starting,</text>
        <text start="112" dur="7">like no oil, no gas, the fuel line might be blocked, or the starter may be broken.</text>
        <text start="119" dur="5">And all of these can influence your measurements,</text>
        <text start="124" dur="3">like the oil light or the gas gauge, in different ways.</text>
        <text start="127" dur="5">For example, the battery flat would have an effect on the lights.</text>
        <text start="132" dur="4">It might have an effect on the oil light and on the gas gauge,</text>
        <text start="136" dur="4">but it won&amp;#39;t really affect the oil you measure with the dipstick.</text>
        <text start="140" dur="6">That is affected by the actual oil level, which also affects the oil light.</text>
        <text start="146" dur="6">Gas will affect the gas gauge, and of course without gas the car doesn&amp;#39;t start.</text>
        <text start="152" dur="7">So this is a complicated structure that really describes one way to understand</text>
        <text start="159" dur="2">how a car doesn&amp;#39;t start.</text>
        <text start="161" dur="2">A car is a complex system.</text>
        <text start="163" dur="3">It has lots of variables you can&amp;#39;t really measure immediately,</text>
        <text start="166" dur="6">and it has sensors which allow you to understand a little bit about the state of the car.</text>
        <text start="172" dur="2">What the Bayes network does,</text>
        <text start="174" dur="7">it really assists you in reasoning from observable variables, like the car won&amp;#39;t start</text>
        <text start="181" dur="5">and the value of the dipstick, to hidden causes, like is the fan belt broken</text>
        <text start="186" dur="3">or is the battery dead.</text>
        <text start="189" dur="4">What you have here is a Bayes network.</text>
        <text start="193" dur="2">A Bayes network is composed of nodes.</text>
        <text start="195" dur="6">These nodes correspond to events that you might or might not know</text>
        <text start="201" dur="3">that are typically called random variables.</text>
        <text start="204" dur="7">These nodes are linked by arcs, and the arcs suggest that a child of an arc</text>
        <text start="211" dur="4">is influenced by its parent but not in a deterministic way.</text>
        <text start="215" dur="6">It might be influenced in a probabilistic way, which means an older battery, for example,</text>
        <text start="221" dur="4">has a higher chance of causing the battery to be dead,</text>
        <text start="225" dur="3">but it&amp;#39;s not clear that every old battery is dead.</text>
        <text start="228" dur="5">There is a total of 16 variables in this Bayes network.</text>
        <text start="233" dur="6">What the graph structure and associated probabilities specify</text>
        <text start="239" dur="7">is a huge probability distribution in the space of all of these 16 variables.</text>
        <text start="246" dur="4">If they are all binary, which we&amp;#39;ll assume throughout this unit,</text>
        <text start="250" dur="5">they can take 2 to the 16th different values, which is a lot.</text>
        <text start="255" dur="3">The Bayes network, as we find out, is a complex representation</text>
        <text start="258" dur="8">of a distribution over this very, very large joint probability distribution of all of these variables.</text>
        <text start="266" dur="3">Further, once we specify the Bayes network,</text>
        <text start="269" dur="4">we can observe, for example, the car won&amp;#39;t start.</text>
        <text start="273" dur="4">We can observe things like the oil light and the lights and the battery meter</text>
        <text start="277" dur="4">and then compute probabilities of the hypothesis, like the alternator is broken</text>
        <text start="281" dur="4">or the fan belt is broken or the battery is dead.</text>
        <text start="285" dur="5">So in this class we&amp;#39;re going to talk about how to construct this Bayes network,</text>
        <text start="290" dur="6">what the semantics are, and how to reason in this Bayes network</text>
        <text start="296" dur="6">to find out about variables we can&amp;#39;t observe, like whether the fan belt is broken or not.</text>
        <text start="302" dur="2">That&amp;#39;s an overview.</text>
        <text start="304" dur="4">Throughout this unit I am going to assume that every event is discrete--</text>
        <text start="308" dur="2">in fact, it&amp;#39;s binary.</text>
        <text start="310" dur="4">We&amp;#39;ll start with some consideration of basic probability,</text>
        <text start="314" dur="5">we&amp;#39;ll work our way into some simple Bayes networks,</text>
        <text start="319" dur="4">we&amp;#39;ll talk about concepts like conditional independence</text>
        <text start="323" dur="3">and then define Bayes networks more generally,</text>
        <text start="326" dur="6">move into concepts like D-separation and start doing parameter counts.</text>
        <text start="332" dur="4">Later on, Peter will tell you about inference in Bayes networks.</text>
        <text start="336" dur="2">So we won&amp;#39;t do this in this class.</text>
        <text start="338" dur="5">I can&amp;#39;t overemphasize how important this class is.</text>
        <text start="343" dur="6">Bayes networks are used extensively in almost all fields of smart computer system,</text>
        <text start="349" dur="8">in diagnostics, for prediction, for machine learning, and fields like finance,</text>
        <text start="357" dur="3">inside Google, in robotics.</text>
        <text start="360" dur="5">Bayes networks are also the building blocks of more advanced AI techniques</text>
        <text start="365" dur="7">such as particle filters, hidden Markov models, MDPs and POMDPs,</text>
        <text start="372" dur="2">Kalman filters, and many others.</text>
        <text start="374" dur="4">These are words that don&amp;#39;t sound familiar quite yet,</text>
        <text start="378" dur="4">but as you go through the class, I can promise you you will get to know what they mean.</text>
        <text start="382" dur="4">So let&amp;#39;s start now at the very, very basics.</text>
      </transcript>
    </video>
    <video title="2 Probabilities" id="EdONkI3RNKg" length="40">
      <transcript>
        <text start="0" dur="2">[Thrun] So let&amp;#39;s talk about probabilities.</text>
        <text start="2" dur="3">Probabilities are the cornerstone of artificial intelligence.</text>
        <text start="5" dur="3">They are used to express uncertainty,</text>
        <text start="8" dur="4">and the management of uncertainty is really key to many, many things in AI</text>
        <text start="12" dur="4">such as machine learning and Bayes network inference</text>
        <text start="16" dur="5">and filtering and robotics and computer vision and so on.</text>
        <text start="21" dur="3">So I&amp;#39;m going to start with some very basic questions,</text>
        <text start="24" dur="2">and we&amp;#39;re going to work our way up from there.</text>
        <text start="26" dur="2">Here is a coin.</text>
        <text start="28" dur="4">The coin can come up heads or tails, and my question is the following:</text>
        <text start="32" dur="6">Suppose the probability for heads is 0.5.</text>
        <text start="38" dur="2">What&amp;#39;s the probability for it coming up tails?</text>
      </transcript>
    </video>
    <video title="2a Answer" id="orhhEZGH_Es" length="19">
      <transcript>
        <text start="0" dur="3">[Thrun] So the right answer is a half, or 0.5,</text>
        <text start="3" dur="4">and the reason is the coin can only come up heads or tails.</text>
        <text start="7" dur="3">We know that it has to be either one.</text>
        <text start="10" dur="4">Therefore, the total probability of both coming up is 1.</text>
        <text start="14" dur="5">So if half of the probability is assigned to heads, then the other half is assigned to tail.</text>
      </transcript>
    </video>
    <video title="2b Question" id="Ee9g6dhDL9A" length="8">
      <transcript>
        <text start="0" dur="2">[Thrun] Let me ask my next quiz.</text>
        <text start="2" dur="4">Suppose the probability of heads is a quarter, 0.25.</text>
        <text start="6" dur="2">What&amp;#39;s the probability of tail?</text>
      </transcript>
    </video>
    <video title="2c Answer" id="84KcxfggKRg" length="17">
      <transcript>
        <text start="0" dur="2">[Thrun] And the answer is 3/4.</text>
        <text start="2" dur="3">It&amp;#39;s a loaded coin, and the reason is, well,</text>
        <text start="5" dur="3">each of them come up with a certain probability.</text>
        <text start="8" dur="4">The total of those is 1. The quarter is claimed by heads.</text>
        <text start="12" dur="5">Therefore, 3/4 remain for tail, which is the answer over here.</text>
      </transcript>
    </video>
    <video title="2d Question" id="koOpSPz-voY" length="14">
      <transcript>
        <text start="0" dur="2">[Thrun] Here&amp;#39;s another quiz.</text>
        <text start="2" dur="6">What&amp;#39;s the probability that the coin comes up heads, heads, heads, three times in a row,</text>
        <text start="8" dur="4">assuming that each one of those has a probability of a half</text>
        <text start="12" dur="2">and that these coin flips are independent?</text>
      </transcript>
    </video>
    <video title="2e Answer" id="7pZQS5inJXs" length="14">
      <transcript>
        <text start="0" dur="4">[Thrun] And the answer is 0.125.</text>
        <text start="4" dur="2">Each head has a probability of a half.</text>
        <text start="6" dur="4">We can multiply those probabilities because they are independent events,</text>
        <text start="10" dur="4">and that gives us 1 over 8 or 0.125.</text>
      </transcript>
    </video>
    <video title="2f Question" id="KatS5xl7vn8" length="32">
      <transcript>
        <text start="0" dur="11">[Thrun] Now let&amp;#39;s flip the coin 4 times, and let&amp;#39;s call Xi the result of the i-th coin flip.</text>
        <text start="11" dur="5">So each Xi is going to be drawn from heads or tail.</text>
        <text start="16" dur="6">What&amp;#39;s the probability that all 4 of those flips give us the same result,</text>
        <text start="22" dur="4">no matter what it is, assuming that each one of those has identically</text>
        <text start="26" dur="6">an equally distributed probability of coming up heads of the half?</text>
      </transcript>
    </video>
    <video title="2g Answer" id="g_M3o3QXBjo" length="23">
      <transcript>
        <text start="0" dur="4">[Thrun] And the answer is, well, there&amp;#39;s 2 ways that we can achieve this.</text>
        <text start="4" dur="2">One is the all heads and one is all tails.</text>
        <text start="6" dur="4">You already know that 4 times heads is 1/16,</text>
        <text start="10" dur="3">and we know that 4 times tail is also 1/16.</text>
        <text start="13" dur="2">These are completely independent events.</text>
        <text start="15" dur="8">The probability of either one occurring is 1/16 plus 1/16, which is 1/8, which is 0.125.</text>
      </transcript>
    </video>
    <video title="2h Question" id="hdQER9u46yU" length="10">
      <transcript>
        <text start="0" dur="2">[Thrun] So here&amp;#39;s another one.</text>
        <text start="2" dur="5">What&amp;#39;s the probability that within the set of X1, X2, X3, and X4</text>
        <text start="7" dur="3">there are at least three heads?</text>
      </transcript>
    </video>
    <video title="2i Answer" id="FEqiaraw3GE" length="28">
      <transcript>
        <text start="0" dur="3">[Thrun] And the solution is let&amp;#39;s look at different sequences</text>
        <text start="3" dur="3">in which head occurs at least 3 times.</text>
        <text start="6" dur="4">It could be head, head, head, head, in which it comes 4 times.</text>
        <text start="10" dur="6">It could be head, head, head, tail and so on, all the way to tail, head, head, head.</text>
        <text start="16" dur="3">There&amp;#39;s 1, 2, 3, 4, 5 of those outcomes.</text>
        <text start="19" dur="9">Each of them has a 16th for probability, so it&amp;#39;s 5 times a 16th, which is 0.3125.</text>
      </transcript>
    </video>
    <video title="2j Summary" id="Xblzy61pBDQ" length="45">
      <transcript>
        <text start="0" dur="2">[Thrun] So we just learned a number of things.</text>
        <text start="2" dur="3">One is about complementary probability.</text>
        <text start="5" dur="3">If an event has a certain probability, p,</text>
        <text start="8" dur="5">the complementary event has the probability 1-p.</text>
        <text start="13" dur="2">We also learned about independence.</text>
        <text start="15" dur="4">If 2 random variables, X and Y, are independent,</text>
        <text start="19" dur="2">which you&amp;#39;re going to write like this,</text>
        <text start="21" dur="5">that means the probability of the joint that any 2 variables can assume</text>
        <text start="26" dur="4">is the product of the marginals.</text>
        <text start="30" dur="4">So rather than asking the question, &amp;quot;What is the probability</text>
        <text start="34" dur="6">&amp;quot;for any combination that these 2 coins or maybe 5 coins could have taken?&amp;quot;</text>
        <text start="40" dur="2">we can now look at the probability of each coin individually,</text>
        <text start="42" dur="3">look at its probability and just multiply them up.</text>
      </transcript>
    </video>
    <video title="3 Dependence" id="uy0sL0DGV7o" length="64">
      <transcript>
        <text start="0" dur="3">[Thrun] So let me ask you about dependence.</text>
        <text start="3" dur="2">Suppose we flip 2 coins.</text>
        <text start="5" dur="7">Our first coin is a fair coin, and we&amp;#39;re going to denote the outcome by X1.</text>
        <text start="12" dur="3">So the chance of X1 coming up heads is half.</text>
        <text start="15" dur="5">But now we branch into picking a coin based on the first outcome.</text>
        <text start="20" dur="3">So if the first outcome was heads,</text>
        <text start="23" dur="5">you pick a coin whose probability of coming up heads is going to be 0.9.</text>
        <text start="28" dur="4">The way I word this is by conditional probability,</text>
        <text start="32" dur="3">probability of the second coin flip coming up heads</text>
        <text start="35" dur="6">provided that or given that X1, the first coin flip, was heads, is 0.9.</text>
        <text start="41" dur="3">The first coin flip might also come up tails,</text>
        <text start="44" dur="3">in which case I pick a very different coin.</text>
        <text start="47" dur="7">In this case I pick a coin which with 0.8 probability will once again give me tails,</text>
        <text start="54" dur="3">conditioned on the first coin flip coming up tails.</text>
        <text start="57" dur="2">So my question for you is,</text>
        <text start="59" dur="5">what&amp;#39;s the probability of the second coin flip coming up heads?</text>
      </transcript>
    </video>
    <video title="3a Answer" id="kpdV5I5WHW8" length="66">
      <transcript>
        <text start="0" dur="4">[Thrun] The answer is 0.55.</text>
        <text start="4" dur="4">The way to compute this is by the theorem of total probability.</text>
        <text start="8" dur="4">Probability of X2 equals heads.</text>
        <text start="12" dur="3">There&amp;#39;s 2 ways I can get to this outcome.</text>
        <text start="15" dur="3">One is via this path over here, and one is via this path over here.</text>
        <text start="18" dur="2">Let me just write both of them down.</text>
        <text start="20" dur="6">So first of all, it could be the probability of X2 equals heads</text>
        <text start="26" dur="4">given that and I will assume X1 was head already.</text>
        <text start="30" dur="2">Now I have to add the complementary event.</text>
        <text start="32" dur="3">Suppose X1 came up tails.</text>
        <text start="35" dur="5">Then I can ask the question, what is the probability that X2 comes up heads regardless,</text>
        <text start="40" dur="2">even though X1 was tails?</text>
        <text start="42" dur="2">Plugging in the numbers gives us the following.</text>
        <text start="44" dur="5">This one over here is 0.9 times a half.</text>
        <text start="49" dur="2">The probability of tails is 0.8,</text>
        <text start="51" dur="7">thereby my head probability becomes 1 minus 0.8, which is 0.2.</text>
        <text start="58" dur="5">Adding all of this together gives me 0.45 plus 0.1,</text>
        <text start="63" dur="3">which is exactly 0.55.</text>
      </transcript>
    </video>
    <video title="4 What We Learned" id="9fxuibvkZ9g" length="67">
      <transcript>
        <text start="0" dur="2">So, we actually just learned some interesting lessons.</text>
        <text start="2" dur="6">The probability of any random variable Y can be written as</text>
        <text start="8" dur="5">probability of Y given that some other random variable X assumes value i</text>
        <text start="13" dur="4">times probability of X equals i,</text>
        <text start="17" dur="5">sums over all possible outcomes i for the (inaudible) variable X.</text>
        <text start="22" dur="2">This is called total probability.</text>
        <text start="24" dur="3">The second thing we learned has to do with negation of probabilities.</text>
        <text start="27" dur="10">We found that probability of not X given Y is 1 minus probability of X given Y.</text>
        <text start="37" dur="6">Now, you might be tempted to say &amp;quot;What about the probability of X given not Y?&amp;quot;</text>
        <text start="43" dur="8">&amp;quot;Is this the same as 1 minus probability of X given Y?&amp;quot;</text>
        <text start="51" dur="3">And the answer is absolutely no.</text>
        <text start="54" dur="2">That&amp;#39;s not the case.</text>
        <text start="56" dur="4">If you condition on something that has a certain probability value,</text>
        <text start="60" dur="3">you can take the event you&amp;#39;re looking at and negate this,</text>
        <text start="63" dur="2">but you can never negate your conditional variable</text>
        <text start="65" dur="2">and assume these values add up to 1.</text>
      </transcript>
    </video>
    <video title="5 Weather Quiz" id="RRYo6jVL6ao" length="25">
      <transcript>
        <text start="0" dur="6">We assume there is sometimes sunny days and sometimes rainy days,</text>
        <text start="6" dur="3">and on day 1, which we&amp;#39;re going to call D1,</text>
        <text start="9" dur="4">the probability of sunny is 0.9.</text>
        <text start="13" dur="7">And then let&amp;#39;s assume that a sunny day follows a sunny day with 0.8 chance,</text>
        <text start="20" dur="5">and a rainy day follows a sunny day with--well--</text>
      </transcript>
    </video>
    <video title="5a Answer" id="GqCNDJhZQnc" length="5">
      <transcript>
        <text start="0" dur="5">Well, the correct answer is 0.2, which is a negation of this event over here.</text>
      </transcript>
    </video>
    <video title="5b Question" id="ASgU5Ekoz-A" length="13">
      <transcript>
        <text start="0" dur="6">A sunny day follows a rainy day with 0.6 chance,</text>
        <text start="6" dur="5">and a rainy day follows a rainy day--</text>
        <text start="11" dur="2">please give me your number.</text>
      </transcript>
    </video>
    <video title="5c Answer" id="KgEX10LtY8Y" length="3">
      <transcript>
        <text start="0" dur="3">0.4</text>
      </transcript>
    </video>
    <video title="5d Question" id="aEVUaEK84UQ" length="18">
      <transcript>
        <text start="0" dur="3">So, what are the chances that D2 is sunny?</text>
        <text start="3" dur="3">Suppose the same dynamics apply from D2 to D3,</text>
        <text start="6" dur="4">so just replace D3 over here with D2s over there.</text>
        <text start="10" dur="4">That means the transition probabilities from one day to the next remain the same.</text>
        <text start="14" dur="4">Tell me, what&amp;#39;s the probability that D3 is sunny?</text>
      </transcript>
    </video>
    <video title="5e Answer" id="tn9chzKS9sM" length="85">
      <transcript>
        <text start="0" dur="4">So, the correct answer over here is 0.78,</text>
        <text start="4" dur="6">and over here it&amp;#39;s 0.756.</text>
        <text start="10" dur="3">To get there, let&amp;#39;s complete this one first.</text>
        <text start="13" dur="3">The probability of D2 = sunny.</text>
        <text start="16" dur="5">Well, we know there&amp;#39;s a 0.9 chance it&amp;#39;s sunny on D1,</text>
        <text start="21" dur="4">and then if it is sunny, we know it stays sunny with a 0.8 chance.</text>
        <text start="25" dur="4">So, we multiply these 2 things together, and we get 0.72.</text>
        <text start="29" dur="4">We know there&amp;#39;s a 0.1 chance of it being rainy on day 1, which is the complement,</text>
        <text start="33" dur="4">but if it&amp;#39;s rainy, we know it switches to sunny with 0.6 chance,</text>
        <text start="37" dur="4">so you multiply these 2 things, and you get 0.06.</text>
        <text start="41" dur="5">Adding those two up equals 0.78.</text>
        <text start="46" dur="5">Now, for the next day, we know our prior for sunny is 0.78.</text>
        <text start="51" dur="4">If it is sunny, it stays sunny with 0.8 probability.</text>
        <text start="55" dur="6">Multiplying these 2 things gives us 0.624.</text>
        <text start="61" dur="6">We know it&amp;#39;s rainy with 0.2 chance, which is the complement of 0.78,</text>
        <text start="67" dur="3">but a 0.6 chance if it was (inaudible) sunny.</text>
        <text start="70" dur="4">But if you multiply those, 0.132.</text>
        <text start="74" dur="5">Adding those 2 things up gives us 0.756.</text>
        <text start="79" dur="4">So, to some extents, it&amp;#39;s tedious to compute these values,</text>
        <text start="83" dur="2">but they can be perfectly computed, as shown here.</text>
      </transcript>
    </video>
    <video title="6 Cancer Quiz" id="nhIDr-yogzg" length="19">
      <transcript>
        <text start="0" dur="5">Next example is a cancer example.</text>
        <text start="5" dur="6">Suppose there&amp;#39;s a specific type of cancer which exists for 1% of the population.</text>
        <text start="11" dur="2">I&amp;#39;m going to write this as follows.</text>
        <text start="13" dur="6">You can probably tell me now what the probability of not having this cancer is.</text>
      </transcript>
    </video>
    <video title="6a Answer and Cancer Test" id="_NRpTjkvWv0" length="28">
      <transcript>
        <text start="0" dur="4">And yes, the answer is 0.99.</text>
        <text start="4" dur="3">Let&amp;#39;s assume there&amp;#39;s a test for this cancer,</text>
        <text start="7" dur="5">which gives us probabilistically an answer whether we have this cancer or not.</text>
        <text start="12" dur="6">So, let&amp;#39;s say the probability of a test being positive, as indicated by this + sign,</text>
        <text start="18" dur="4">given that we have cancer, is 0.9.</text>
        <text start="22" dur="6">The probability of the test coming out negative if we have the cancer is--you name it.</text>
      </transcript>
    </video>
    <video title="6b Answer" id="sAnyHLFbiXg" length="61">
      <transcript>
        <text start="0" dur="6">0.1, which is the difference between 1 and 0.9.</text>
        <text start="6" dur="5">Let&amp;#39;s assume the probability of the test coming out positive</text>
        <text start="11" dur="4">given that we don&amp;#39;t have this cancer is 0.2.</text>
        <text start="15" dur="4">In other words, the probability of the test correctly saying</text>
        <text start="19" dur="5">we don&amp;#39;t have the cancer if we&amp;#39;re cancer free is 0.8.</text>
        <text start="24" dur="4">Now, ultimately, I&amp;#39;d like to know what&amp;#39;s the probability</text>
        <text start="28" dur="7">they have this cancer given they just received a single, positive test?</text>
        <text start="35" dur="4">Before I do this, please help me filling out some other probabilities</text>
        <text start="39" dur="2">that are actually important.</text>
        <text start="41" dur="4">Specifically, the joint probabilities.</text>
        <text start="45" dur="6">The probability of a positive test and having cancer.</text>
        <text start="51" dur="2">The probability of a negative test and having cancer,</text>
        <text start="53" dur="2">and this is not conditional anymore.</text>
        <text start="55" dur="2">It&amp;#39;s now a joint probability.</text>
        <text start="57" dur="4">So, please give me those 4 values over here.</text>
      </transcript>
    </video>
    <video title="6c Answer" id="PCKlid_iMNo" length="40">
      <transcript>
        <text start="0" dur="5">And here the correct answer is 0.009,</text>
        <text start="5" dur="7">which is the product of your prior, 0.01, times the conditional, 0.9.</text>
        <text start="12" dur="9">Over here we get 0.001, the probability of our prior cancer times 0.1.</text>
        <text start="21" dur="5">Over here we get 0.198,</text>
        <text start="26" dur="3">the probability of not having cancer is 0.99</text>
        <text start="29" dur="3">times still getting a positive reading, which is 0.2.</text>
        <text start="32" dur="5">And finally, we get 0.792,</text>
        <text start="37" dur="3">which is the probability of this guy over here, and this guy over here.</text>
      </transcript>
    </video>
    <video title="6d Question" id="BX_uy8rCS5k" length="7">
      <transcript>
        <text start="0" dur="4">Now, our next quiz, I want you to fill in the probability of</text>
        <text start="4" dur="3">the cancer given that we just received a positive test.</text>
      </transcript>
    </video>
    <video title="6e Answer" id="JgYH7UEcA6c" length="112">
      <transcript>
        <text start="0" dur="6">And the correct answer is 0.043.</text>
        <text start="6" dur="3">So, even though I received a positive test,</text>
        <text start="9" dur="5">my probability of having cancer is just 4.3%,</text>
        <text start="14" dur="4">which is not very much given that the test itself is quite sensitive.</text>
        <text start="18" dur="8">It really gives me a 0.8 chance of getting a negative result if I don&amp;#39;t have cancer.</text>
        <text start="26" dur="6">It gives me a 0.9 chance of detecting cancer given that I have cancer.</text>
        <text start="32" dur="3">Now, what comes (inaudible) small?</text>
        <text start="35" dur="3">Well, let&amp;#39;s just put all the cases together.</text>
        <text start="38" dur="3">You already know that we received a positive test.</text>
        <text start="41" dur="6">Therefore, this entry over here, and this entry over here are relevant.</text>
        <text start="47" dur="9">Now, the chance of having a positive test and having cancer is 0.009.</text>
        <text start="56" dur="5">Well, I might--when I receive a positive test--have cancer or not cancer,</text>
        <text start="61" dur="5">so we will just normalize by these 2 possible causes for the positive test,</text>
        <text start="66" dur="5">which is 0.009 + 0.198.</text>
        <text start="71" dur="9">We know both these 2 things together gets 0.009 over 0.207,</text>
        <text start="80" dur="3">which is approximately 0.043.</text>
        <text start="83" dur="5">Now, the interesting thing in this equation is that the chances</text>
        <text start="88" dur="4">of having seen a positive test result in the absence of cancers</text>
        <text start="92" dur="3">are still much, much higher than the chance of seeing a positive result</text>
        <text start="95" dur="4">in the presence of cancer, and that&amp;#39;s because our prior for cancer</text>
        <text start="99" dur="5">is so small in the population that it&amp;#39;s just very unlikely to have cancer.</text>
        <text start="104" dur="3">So, the additional information of a positive test</text>
        <text start="107" dur="5">only erased my posterior probability to 0.043.</text>
      </transcript>
    </video>
    <video title="7 Bayes Rule" id="OWCRop639TA" length="214">
      <transcript>
        <text start="0" dur="3">So, we&amp;#39;ve just learned about what&amp;#39;s probably the most important</text>
        <text start="3" dur="6">piece of math for this class in statistics called Bayes Rule.</text>
        <text start="9" dur="6">It was invented by Reverend Thomas Bayes, who was a British mathematician</text>
        <text start="15" dur="3">and a Presbyterian minister in the 18th century.</text>
        <text start="18" dur="9">Bayes Rule is usually stated as follows: P of A given B where B is the evidence</text>
        <text start="27" dur="9">and A is the variable we care about is P of B given A times P of A over P of B.</text>
        <text start="36" dur="4">This expression is called the likelihood.</text>
        <text start="40" dur="6">This is called the prior, and this is called marginal likelihood.</text>
        <text start="46" dur="4">The expression over here is called the posterior.</text>
        <text start="50" dur="5">The interesting thing here is the way the probabilities are reworded.</text>
        <text start="55" dur="2">Say we have evidence B.</text>
        <text start="57" dur="4">We know about B, but we really care about the variable A.</text>
        <text start="61" dur="2">So, for example, B is a test result.</text>
        <text start="63" dur="3">We don&amp;#39;t care about the test result as much as we care about the fact</text>
        <text start="66" dur="2">whether we have cancer or not.</text>
        <text start="68" dur="8">This diagnostic reasoning--which is from evidence to its causes--</text>
        <text start="76" dur="6">is turned upside down by Bayes Rule into a causal reasoning,</text>
        <text start="82" dur="5">which is given--hypothetically, if we knew the cause,</text>
        <text start="87" dur="4">what would be the probability of the evidence we just observed.</text>
        <text start="91" dur="5">But to correct for this inversion, we have to multiply</text>
        <text start="96" dur="4">by the prior of the cause to be the case in the first place,</text>
        <text start="100" dur="2">in this case, having cancer or not,</text>
        <text start="102" dur="5">and divide it by the probability of the evidence, P(B),</text>
        <text start="107" dur="5">which often is expanded using the theorem of total probability as follows.</text>
        <text start="112" dur="6">The probability of B is a sum over all probabilities of B</text>
        <text start="118" dur="6">conditional on A, lower caps a, times the probability of A equals lower caps a.</text>
        <text start="124" dur="4">This is total probability as we already encountered it.</text>
        <text start="128" dur="2">So, let&amp;#39;s apply this to the cancer case</text>
        <text start="130" dur="3">and say we really care about whether you have cancer,</text>
        <text start="133" dur="4">which is our cause, conditioned on the evidence</text>
        <text start="137" dur="6">that is the result of this hidden cause, in this case, a positive test result.</text>
        <text start="143" dur="2">Let&amp;#39;s just plug in the numbers.</text>
        <text start="145" dur="5">Our likelihood is the probability of seeing a positive test result</text>
        <text start="150" dur="3">given that you have cancer multiplied by the prior probability</text>
        <text start="153" dur="5">of having cancer over the probability of the positive test result,</text>
        <text start="158" dur="5">and that is--according to the tables we looked at before--</text>
        <text start="163" dur="7">0.9 times a prior of 0.01 over--</text>
        <text start="170" dur="5">now we&amp;#39;re going to expand this right over here according to total probability</text>
        <text start="175" dur="6">which gives us 0.9 times 0.01.</text>
        <text start="181" dur="5">That&amp;#39;s the probability of + given that we do have cancer.</text>
        <text start="186" dur="5">So, the probability of + given that we don&amp;#39;t have cancer is 0.2,</text>
        <text start="191" dur="4">but the prior here is 0.99.</text>
        <text start="195" dur="5">So, if we plug in the numbers we know about, we get 0.009</text>
        <text start="200" dur="7">over 0.009 + 0.198.</text>
        <text start="207" dur="7">That is approximately 0.0434, which is the number we saw before.</text>
      </transcript>
    </video>
    <video title="7a Bayes Rule Graphically" id="1DhY4Cs_qEs" length="112">
      <transcript>
        <text start="0" dur="3">So, if you want to draw Bayes rule graphically,</text>
        <text start="3" dur="5">we have a situation where we have an internal variable A,</text>
        <text start="8" dur="5">like whether I&amp;#39;m going to die of cancer, but we can&amp;#39;t sense A.</text>
        <text start="13" dur="3">Instead, we have a second variable, called B,</text>
        <text start="16" dur="5">which is our test, and B is observable, but A isn&amp;#39;t.</text>
        <text start="21" dur="5">This is a classical example of a Bayes network.</text>
        <text start="26" dur="4">The Bayes network is composed of 2 variables, A and B.</text>
        <text start="30" dur="3">We know the prior probability for A,</text>
        <text start="33" dur="2">and we know the conditional.</text>
        <text start="35" dur="3">A causes B--whether or not we have cancer,</text>
        <text start="38" dur="3">causes the test result to be positive or not,</text>
        <text start="41" dur="3">although there was some randomness involved.</text>
        <text start="44" dur="5">So, we know what the probability of B given the different values for A,</text>
        <text start="49" dur="5">and what we care about in this specific instance is called diagnostic reasoning,</text>
        <text start="54" dur="4">which is the inverse of the causal reasoning,</text>
        <text start="58" dur="8">the probability of A given B or similarly, probability of A given not B.</text>
        <text start="66" dur="5">This is our very first Bayes network, and the graphical representation</text>
        <text start="71" dur="4">of drawing 2 variables, A and B, connected with an arc</text>
        <text start="75" dur="7">that goes from A to B is the graphical representation of a distribution</text>
        <text start="82" dur="4">of 2 variables that are specified in the structure over here,</text>
        <text start="86" dur="5">which has a prior probability and has a conditional probability as shown over here.</text>
        <text start="91" dur="3">Now, I do have a quick quiz for you.</text>
        <text start="94" dur="3">How many parameters does it take to specify</text>
        <text start="97" dur="6">the entire joint probability within A and B, or differently, the entire Bayes network?</text>
        <text start="103" dur="5">I&amp;#39;m not looking for structural parameters that relate to the graph over here.</text>
        <text start="108" dur="4">I&amp;#39;m just looking for the numerical parameters of the underlying probabilities.</text>
      </transcript>
    </video>
    <video title="7b Answer" id="Q5luTxpgFaU" length="24">
      <transcript>
        <text start="0" dur="2">And the answer is 3.</text>
        <text start="2" dur="7">It takes 1 parameter to specify P of A from which we can derive P of not A.</text>
        <text start="9" dur="6">It takes 2 parameters to specify P of B given A and P given not A,</text>
        <text start="15" dur="6">from which we can derive P not B given A and P of not B given not A.</text>
        <text start="21" dur="3">So, it&amp;#39;s a total of 3 parameters for this Bayes network.</text>
      </transcript>
    </video>
    <video title="8 More Complex Bayes Networks" id="h59XtnoILcQ" length="152">
      <transcript>
        <text start="0" dur="3">So, we just encountered our very first Bayes network</text>
        <text start="3" dur="3">and did a number of interesting calculations.</text>
        <text start="6" dur="4">Let&amp;#39;s now talk about Bayes Rule and look into more complex Bayes networks.</text>
        <text start="10" dur="3">I will look at Bayes Rule again and make an observation</text>
        <text start="13" dur="2">that is really non-trivial.</text>
        <text start="15" dur="5">Here is Bayes Rule, and in practice, what we find is</text>
        <text start="20" dur="3">this term here is relatively easy to compute.</text>
        <text start="23" dur="5">It&amp;#39;s just a product, whereas this term is really hard to compute.</text>
        <text start="28" dur="5">However, this term over here does not depend on what we assume for variable A.</text>
        <text start="33" dur="2">It&amp;#39;s just the function of B.</text>
        <text start="35" dur="5">So, suppose for a moment we also care about the complementary event of not A</text>
        <text start="40" dur="3">given B, for which Bayes Rule unfolds as follows.</text>
        <text start="43" dur="4">Then we find that the normalizer, P(B), is identical,</text>
        <text start="47" dur="4">whether we assume A on the left side or not A on the left side.</text>
        <text start="51" dur="6">We also know from prior work that P(A) given B plus</text>
        <text start="57" dur="6">P of not A given B must be one because these are 2 complementary events.</text>
        <text start="63" dur="3">That allows us to compute Bayes Rule very differently</text>
        <text start="66" dur="5">by basically ignoring the normalizer, so here&amp;#39;s how it goes.</text>
        <text start="71" dur="5">We compute P(A) given B--and I want to call this prime,</text>
        <text start="76" dur="7">because it&amp;#39;s not a real probability--to be just P(B) given A times P(A),</text>
        <text start="83" dur="5">which is the normalizer, so the denominator of the expression over here.</text>
        <text start="88" dur="3">We do the same thing with not A.</text>
        <text start="91" dur="5">So, in both cases, we compute the posterior probability non-normalized</text>
        <text start="96" dur="2">by omitting the normalizer B.</text>
        <text start="98" dur="5">And then we can recover the original probabilities by normalizing</text>
        <text start="103" dur="5">based on those values over here, so the probability of A given B,</text>
        <text start="108" dur="4">the actual probability, is a normalizer, eta,</text>
        <text start="112" dur="3">times this non-normalized form over here.</text>
        <text start="115" dur="4">The same is true for the negation of A over here.</text>
        <text start="119" dur="7">And eta is just the normalizer that results by adding these 2 values over here together</text>
        <text start="126" dur="4">as shown over here, and dividing them for one.</text>
        <text start="130" dur="3">So, take a look at this for a moment.</text>
        <text start="133" dur="5">What we&amp;#39;ve done is we deferred the calculation of the normalizer over here</text>
        <text start="138" dur="4">by computing pseudo probabilities that are non-normalized.</text>
        <text start="142" dur="4">This made the calculation much easier, and when we were done with everything,</text>
        <text start="146" dur="3">we just folded it back into the normalizer based on the resulting</text>
        <text start="149" dur="3">pseudo probabilities and got the correct answer.</text>
      </transcript>
    </video>
    <video title="8a Two Test Cancer Example" id="_AJQSBYRAR4" length="68">
      <transcript>
        <text start="0" dur="3">The reason why I gave you all this is because I want you to apply it now</text>
        <text start="3" dur="5">to a slightly more complicated problem, which is the 2-test cancer example.</text>
        <text start="8" dur="6">In this example, we again might have our unobservable cancer C,</text>
        <text start="14" dur="4">but now we&amp;#39;re running 2 tests, test 1 and test 2.</text>
        <text start="18" dur="6">As before, the prior probability of cancer is 0.01.</text>
        <text start="24" dur="6">The probability of receiving a positive test result for either test is 0.9.</text>
        <text start="30" dur="6">The probability of getting a negative result given they&amp;#39;re cancer free is 0.8.</text>
        <text start="36" dur="4">And from those, we were able to compute all the other probabilities,</text>
        <text start="40" dur="3">and we&amp;#39;re just going to write them down over here.</text>
        <text start="43" dur="3">So, take a moment to just verify those.</text>
        <text start="46" dur="4">Now, let&amp;#39;s assume both of my tests come back positive,</text>
        <text start="50" dur="6">so T1 = + and T2 = +.</text>
        <text start="56" dur="4">What&amp;#39;s the probability of cancer now written in short form probability of</text>
        <text start="60" dur="3">C given ++?</text>
        <text start="63" dur="5">I want you to tell me what that is, and this is a non-trivial question.</text>
      </transcript>
    </video>
    <video title="8b Answer" id="sjdPqdZQQCI" length="120">
      <transcript>
        <text start="0" dur="10">So, the correct answer is 0.1698 approximately,</text>
        <text start="10" dur="5">and to compute this, I used the trick I&amp;#39;ve shown you before.</text>
        <text start="15" dur="9">Let me write down the running count for cancer and for not cancer</text>
        <text start="24" dur="4">as I integrate the various multiplications in Bayes Rule.</text>
        <text start="28" dur="9">My prior for cancer was 0.01 and for non-cancer was 0.99.</text>
        <text start="37" dur="6">Then I get my first +, and the probability of a + given they have cancer is 0.9,</text>
        <text start="43" dur="5">and the same for non-cancer is 0.2.</text>
        <text start="48" dur="4">So, according to the non-normalized Bayes Rule,</text>
        <text start="52" dur="6">I now multiply these 2 things together to get my non-normalized probability</text>
        <text start="58" dur="2">of having cancer given the plus.</text>
        <text start="60" dur="3">Since multiplication is commutative,</text>
        <text start="63" dur="6">I can do the same thing again with my 2nd test result, 0.9 and 0.2,</text>
        <text start="69" dur="5">and I multiply all of these 3 things together to get my non-normalized probability</text>
        <text start="74" dur="7">P prime to be the following: 0.0081, if you multiply those things together,</text>
        <text start="81" dur="7">and 0.0396 if you multiply these facts together.</text>
        <text start="88" dur="2">And these are not a probability.</text>
        <text start="90" dur="4">If we add those for the 2 complementary of cancer/non-cancer,</text>
        <text start="94" dur="4">I get 0.0477.</text>
        <text start="98" dur="4">However, if I now divide, that is, I normalize</text>
        <text start="102" dur="5">those non-normalized probabilities over here by this factor over here,</text>
        <text start="107" dur="5">I actually get the correct posterior probability P of cancer given ++.</text>
        <text start="112" dur="2">And they look as follows:</text>
        <text start="114" dur="6">approximately 0.1698 and approximately 0.8301.</text>
      </transcript>
    </video>
    <video title="8c Question" id="Ah8mhlLsimM" length="10">
      <transcript>
        <text start="0" dur="3">Calculate for me the probability of cancer</text>
        <text start="3" dur="5">given that I received one positive and one negative test result.</text>
        <text start="8" dur="2">Please write your number into this box.</text>
      </transcript>
    </video>
    <video title="8d Answer" id="gM1DfM6CGqw" length="63">
      <transcript>
        <text start="0" dur="3">We apply the same trick as before</text>
        <text start="3" dur="4">where we use the exact same prior of 0.01.</text>
        <text start="7" dur="6">Our first + gives us the following factors: 0.9 and 0.2.</text>
        <text start="13" dur="7">And our minus gives us the probability 0.1 for a negative first test result given that we have cancer,</text>
        <text start="20" dur="6">and a 0.8 for the inverse of a negative result of not having cancer.</text>
        <text start="26" dur="2">We multiply those together.</text>
        <text start="28" dur="2">We get our non-normalized probability.</text>
        <text start="30" dur="5">And if we now normalize by the sum of those two things</text>
        <text start="35" dur="6">to turn this back into a probability, we get 0.009</text>
        <text start="41" dur="9">over the sum of those two things over here, and this is 0.0056</text>
        <text start="50" dur="9">for the chance of having cancer and 0.9943 for the chance of being cancer free.</text>
        <text start="59" dur="4">And this adds up approximately to 1, and therefore, is a probability distribution.</text>
      </transcript>
    </video>
    <video title="9 Conditional Independence" id="KY3ecsJDnO4" length="165">
      <transcript>
        <text start="0" dur="3">I want to use a few words of terminology.</text>
        <text start="3" dur="5">This, again, is a Bayes network, of which the hidden variable C</text>
        <text start="8" dur="8">causes the still stochastic test outcomes T1 and T2.</text>
        <text start="16" dur="3">And what is really important is that we assume not just</text>
        <text start="19" dur="3">that T1 and T2 are identically distributed.</text>
        <text start="22" dur="5">We use the same 0.9 for test 1 as we use for test 2,</text>
        <text start="27" dur="4">but we also assume that they are conditionally independent.</text>
        <text start="31" dur="6">We assumed that if God told us whether we actually had cancer or not,</text>
        <text start="37" dur="4">if we knew with absolute certainty the value of the variable C,</text>
        <text start="41" dur="7">that knowing anything about T1 would not help us make a statement about T2.</text>
        <text start="48" dur="7">Put differently, we assumed that the probability of T2 given C and T1</text>
        <text start="55" dur="5">is the same as the probability of T2 given C.</text>
        <text start="60" dur="8">This is called conditional independence, which is given the value of the cancer variable C.</text>
        <text start="68" dur="9">If you knew this for a fact, then T2 would be independent of T1.</text>
        <text start="77" dur="4">It&amp;#39;s conditionally independent because the independence only holds true</text>
        <text start="81" dur="5">if we actually know C, and it comes out of this diagram over here.</text>
        <text start="86" dur="6">If we look at this diagram, if you knew the variable C over here,</text>
        <text start="92" dur="7">then C separately causes T1 and T2.</text>
        <text start="99" dur="4">So, as a result, if you know C, whatever counted over here</text>
        <text start="106" dur="2">is kind of cut off causally from what happens over here.</text>
        <text start="108" dur="4">That causes these 2 variables to be conditionally independent.</text>
        <text start="112" dur="6">So, conditional independence is a really big thing in Bayes networks.</text>
        <text start="118" dur="4">Here&amp;#39;s a Bayes network where A causes B and C,</text>
        <text start="122" dur="6">and for a Bayes network of this structure, we know that given A,</text>
        <text start="128" dur="3">B and C are independent.</text>
        <text start="131" dur="5">It&amp;#39;s written as B conditionally independent of C given A.</text>
        <text start="136" dur="2">So, here&amp;#39;s a question.</text>
        <text start="138" dur="3">Suppose we have conditional independence between B and C given A.</text>
        <text start="141" dur="7">Would that imply--and there&amp;#39;s my question--that B and C are independent?</text>
        <text start="148" dur="2">So, suppose we don&amp;#39;t know A.</text>
        <text start="150" dur="3">We don&amp;#39;t know whether we have cancer, for example.</text>
        <text start="153" dur="5">What that means is that the test results individually are still independent of each other</text>
        <text start="158" dur="4">even if we don&amp;#39;t know about the cancer situation.</text>
        <text start="162" dur="3">Please answer yes or no.</text>
      </transcript>
    </video>
    <video title="9a Answer" id="lb6A1Ov-mlQ" length="41">
      <transcript>
        <text start="0" dur="3">And the correct answer is No</text>
        <text start="3" dur="5">Intuitively, getting a positive test result about cancer</text>
        <text start="8" dur="5">gives us information about whether you have cancer or not.</text>
        <text start="13" dur="2">So if you get a positive test result</text>
        <text start="15" dur="3">you&amp;#39;re going to raise the probability of having cancer</text>
        <text start="18" dur="2">relative to the prior probability.</text>
        <text start="20" dur="4">With that increased probability we will predict</text>
        <text start="24" dur="3">that another test will with a higher likelihood</text>
        <text start="27" dur="6">give us a positive response than if we hadn&amp;#39;t taken the previous test.</text>
        <text start="33" dur="3">That&amp;#39;s really important to understand</text>
        <text start="36" dur="5">So that we understand it let me make you calculate those probabilities</text>
      </transcript>
    </video>
    <video title="9b Question" id="EmLvORqH-Dg" length="35">
      <transcript>
        <text start="0" dur="5">Let me draw the cancer example again with two tests.</text>
        <text start="5" dur="2">Here&amp;#39;s my cancer variable</text>
        <text start="7" dur="6">and then there&amp;#39;s two conditionally independent tests T1 and T2.</text>
        <text start="13" dur="6">And as before let me assume that the prior probability of cancer is 0.01</text>
        <text start="19" dur="7">What I want you to compute for me is the probability of the second test</text>
        <text start="26" dur="7">to be positive if we know that the first test was positive.</text>
        <text start="33" dur="2">So write this into the following box.</text>
      </transcript>
    </video>
    <video title="9c Answer" id="6d2lH9JP6kw" length="172">
      <transcript>
        <text start="0" dur="4">So, for this one, we want to apply total probability.</text>
        <text start="4" dur="6">This thing over here is the same as probability of test 2 to be positive,</text>
        <text start="10" dur="4">which I&amp;#39;m going to abbreviate with a +2 over here,</text>
        <text start="14" dur="5">conditioned on test 1 being positive and me having cancer</text>
        <text start="19" dur="6">times the probability of me having cancer given test 1 was positive plus</text>
        <text start="25" dur="6">the probability of test 2 being positive conditioned on test 1 being positive</text>
        <text start="31" dur="5">and me not having cancer times the probability of me not having cancer</text>
        <text start="36" dur="2">given that test 1 is positive.</text>
        <text start="38" dur="4">That&amp;#39;s the same as the theorem of total probability,</text>
        <text start="42" dur="4">but now everything is conditioned on +1.</text>
        <text start="46" dur="2">Take a moment to verify this.</text>
        <text start="48" dur="2">Now, here I can plug in the numbers.</text>
        <text start="50" dur="7">You already calculated this one before, which is approximately 0.043,</text>
        <text start="57" dur="8">and this one over here is 1 minus that, which is 0.957 approximately.</text>
        <text start="65" dur="4">And this term over here now exploits conditional independence,</text>
        <text start="69" dur="5">which is given that I know C, knowledge of the first test</text>
        <text start="74" dur="3">gives me no more information about the second test.</text>
        <text start="77" dur="4">It only gives me information if C was unknown, as was the case over here.</text>
        <text start="81" dur="3">So, I can rewrite this thing over here as follows:</text>
        <text start="84" dur="3">P of +2 given that I have cancer.</text>
        <text start="87" dur="4">I can drop the +1, and the same is true over here.</text>
        <text start="91" dur="3">This is exploiting my conditional independence.</text>
        <text start="94" dur="7">I knew that P of +1 or +2 conditioned on C</text>
        <text start="101" dur="6">is the same as P of +2 conditioned on C and +1.</text>
        <text start="107" dur="3">I can now read those off my table over here,</text>
        <text start="110" dur="8">which is 0.9 times 0.043 plus 0.2,</text>
        <text start="118" dur="5">which is 1 minus 0.8 over here times 0.957,</text>
        <text start="123" dur="6">which gives me approximately 0.2301.</text>
        <text start="129" dur="5">So, that says if my first test comes in positive,</text>
        <text start="134" dur="7">I expect my second test to be positive with probably 0.2301.</text>
        <text start="141" dur="3">That&amp;#39;s an increased probability to the default probability,</text>
        <text start="144" dur="5">which we calculated before, which is the probability of any test,</text>
        <text start="149" dur="9">test 2 come in as positive before was (inaudible) of Bayes rule which was 0.207.</text>
        <text start="158" dur="5">So, my first has a 20% chance of coming in positive.</text>
        <text start="163" dur="4">My second test, after seeing a positive test,</text>
        <text start="167" dur="5">has now an increased probability of about 23% of coming in positive.</text>
      </transcript>
    </video>
    <video title="9d Absolute vs Conditional Independence" id="fYp0lf1P09k" length="27">
      <transcript>
        <text start="0" dur="2">So, now we&amp;#39;ve learned about independence,</text>
        <text start="2" dur="2">and the corresponding Bayes network has 2 nodes.</text>
        <text start="4" dur="3">They&amp;#39;re just not connected at all.</text>
        <text start="7" dur="2">And we learned about conditional independence,</text>
        <text start="9" dur="3">in which case we have a Bayes network that looks like this.</text>
        <text start="12" dur="4">Now I would like to know whether absolute independence</text>
        <text start="16" dur="2">implies conditional independence.</text>
        <text start="18" dur="2">True or false?</text>
        <text start="20" dur="5">And I&amp;#39;d also like to know whether conditional independence implies absolute independence.</text>
        <text start="25" dur="2">Again, true or false?</text>
      </transcript>
    </video>
    <video title="9e Answer" id="Em-ahIrk550" length="45">
      <transcript>
        <text start="0" dur="3">And the answer is both of them are false.</text>
        <text start="3" dur="4">We already saw that conditional independence, as shown over here,</text>
        <text start="7" dur="2">doesn&amp;#39;t give us absolute independence.</text>
        <text start="9" dur="4">So, for example, this is test #1 and test #2.</text>
        <text start="13" dur="2">You might or might not have cancer.</text>
        <text start="15" dur="3">Our first test gives us information about whether you have cancer or not.</text>
        <text start="18" dur="3">As a result, we&amp;#39;ve changed our prior probability</text>
        <text start="21" dur="3">for the second test to come in positive.</text>
        <text start="24" dur="6">That means that conditional independence does not imply absolute independence,</text>
        <text start="30" dur="2">which means this assumption here falls,</text>
        <text start="32" dur="5">and it also turns out that if you have absolute independence,</text>
        <text start="37" dur="6">things might not be conditionally independent for reasons that I can&amp;#39;t quite explain so far,</text>
        <text start="43" dur="2">but that we will learn about next.</text>
      </transcript>
    </video>
    <video title="10 Different Type of Bayes Network" id="MaAInzCTS1E" length="119">
      <transcript>
        <text start="0" dur="4">[Thrun] For my next example, I will study a different type of a Bayes network.</text>
        <text start="4" dur="4">Before, we&amp;#39;ve seen networks of the following type,</text>
        <text start="8" dur="5">where a single hidden cause caused 2 different measurements.</text>
        <text start="13" dur="4">I now want to study a network that looks just like the opposite.</text>
        <text start="17" dur="3">We have 2 independent hidden causes,</text>
        <text start="20" dur="6">but they get confounded within a single observational variable.</text>
        <text start="26" dur="3">I would like to use the example of happiness.</text>
        <text start="29" dur="4">Suppose I can be happy or unhappy.</text>
        <text start="33" dur="8">What makes me happy is when the weather is sunny or if I get a raise in my job,</text>
        <text start="41" dur="2">which means I make more money.</text>
        <text start="43" dur="4">So let&amp;#39;s call this sunny, let&amp;#39;s call this a raise, and call this happiness.</text>
        <text start="47" dur="6">Perhaps the probability of it being sunny is 0.7,</text>
        <text start="53" dur="5">probability of a raise is 0.01.</text>
        <text start="58" dur="7">And I will tell you that the probability of being happy is governed as follows.</text>
        <text start="65" dur="4">The probability of being happy given that both of these things occur--</text>
        <text start="69" dur="4">I got a raise and it is sunny--is 1.</text>
        <text start="73" dur="7">The probability of being happy given that it is not sunny and I still got a raise is 0.9.</text>
        <text start="80" dur="7">The probability of being happy given that it&amp;#39;s sunny but I didn&amp;#39;t get a raise is 0.7.</text>
        <text start="87" dur="8">And the probability of being happy given that it is neither sunny nor did I get a raise is 0.1.</text>
        <text start="95" dur="4">This is a perfectly fine specification of a probability distribution</text>
        <text start="99" dur="7">where 2 causes affect the variable down here, the happiness.</text>
        <text start="106" dur="4">So I&amp;#39;d like you to calculate for me the following questions.</text>
        <text start="110" dur="7">Probability of a raise given that it is sunny, according to this model.</text>
        <text start="117" dur="2">Please enter your answer over here.</text>
      </transcript>
    </video>
    <video title="10a Answer" id="VsesDjAIMmU" length="55">
      <transcript>
        <text start="0" dur="3">[Thrun] The answer is surprisingly simple.</text>
        <text start="3" dur="2">It is 0.01.</text>
        <text start="5" dur="3">How do I know this so fast?</text>
        <text start="8" dur="4">Well, if you look at this Bayes network,</text>
        <text start="12" dur="9">both the sunniness and the question whether I got a raise impact my happiness.</text>
        <text start="21" dur="3">But since I don&amp;#39;t know anything about the happiness,</text>
        <text start="24" dur="8">there is no way that just the weather might implicate or impact whether I get a raise or not.</text>
        <text start="32" dur="7">In fact, it might be independently sunny, and I might independently get a raise at work.</text>
        <text start="39" dur="7">There is no mechanism of which these 2 things would co-occur.</text>
        <text start="46" dur="3">Therefore, the probability of a raise given that it&amp;#39;s sunny</text>
        <text start="49" dur="6">is just the same as the probability of a raise given any weather, which is 0.01.</text>
      </transcript>
    </video>
    <video title="11 Explaining Away" id="pyxyYWNo8Qw" length="111">
      <transcript>
        <text start="0" dur="7">[Thrun] Let me talk about a really interesting special instance of Bayes net reasoning</text>
        <text start="7" dur="3">which is called explaining away.</text>
        <text start="10" dur="4">And I&amp;#39;ll first give you the intuitive answer,</text>
        <text start="14" dur="5">then I&amp;#39;ll wish you to compute probabilities for me that manifest the explain away effect</text>
        <text start="19" dur="3">in a Bayes network of this type.</text>
        <text start="22" dur="5">Explaining away means that if we know that we are happy,</text>
        <text start="27" dur="7">then sunny weather can explain away the cause of happiness.</text>
        <text start="34" dur="7">If I then also know that it&amp;#39;s sunny, it becomes less likely that I received a raise.</text>
        <text start="41" dur="2">Let me put this differently.</text>
        <text start="43" dur="2">Suppose I&amp;#39;m a happy guy on a specific day</text>
        <text start="45" dur="4">and my wife asks me, &amp;quot;Sebastian, why are you so happy?&amp;quot;</text>
        <text start="49" dur="3">&amp;quot;Is it sunny, or did you get a raise?&amp;quot;</text>
        <text start="52" dur="3">If she then looks outside and sees it is sunny,</text>
        <text start="55" dur="2">then she might explain to herself,</text>
        <text start="57" dur="3">&amp;quot;Well, Sebastian is happy because it is sunny.&amp;quot;</text>
        <text start="60" dur="5">&amp;quot;That makes it effectively less likely that he got a raise</text>
        <text start="65" dur="5">&amp;quot;because I could already explain his happiness by it being sunny.&amp;quot;</text>
        <text start="70" dur="3">If she looks outside and it is rainy,</text>
        <text start="73" dur="3">that makes it more likely I got a raise,</text>
        <text start="76" dur="4">because the weather can&amp;#39;t really explain my happiness.</text>
        <text start="80" dur="7">In other words, if we see a certain effect that could be caused by multiple causes,</text>
        <text start="87" dur="6">seeing one of those causes can explain away any other potential cause</text>
        <text start="93" dur="3">of this effect over here.</text>
        <text start="96" dur="7">So let me put this in numbers and ask you the challenging question of</text>
        <text start="103" dur="8">what&amp;#39;s the probability of a raise given that I&amp;#39;m happy and it&amp;#39;s sunny?</text>
      </transcript>
    </video>
    <video title="11a Answer" id="EZpzEZPy0Wk" length="92">
      <transcript>
        <text start="0" dur="7">[Thrun] The answer is approximately 0.0142,</text>
        <text start="7" dur="4">and it is an exercise in expanding this term using Bayes&amp;#39; rule,</text>
        <text start="11" dur="5">using total probability, which I&amp;#39;ll just do for you.</text>
        <text start="16" dur="8">Using Bayes&amp;#39; rule, you can transform this into P of H given R comma S</text>
        <text start="24" dur="10">times P of R given S over P of H given S.</text>
        <text start="34" dur="3">We observe the conditional independence of R and S</text>
        <text start="37" dur="3">to simplify this to just P of R,</text>
        <text start="40" dur="6">and the denominator is expanded by folding in R and not R,</text>
        <text start="46" dur="3">P of H given R comma S</text>
        <text start="49" dur="5">times P of R plus P of H given not R and S</text>
        <text start="54" dur="4">times P of not R, which is total probability.</text>
        <text start="58" dur="3">We can now read off the numbers from the tables over here,</text>
        <text start="61" dur="9">which gives us 1 times 0.01 divided by this expression</text>
        <text start="70" dur="7">that is the same as the expression over here, so 0.01 plus this thing over here,</text>
        <text start="77" dur="6">which you can find over here to be 0.7, times this guy over here,</text>
        <text start="83" dur="4">which is 1 minus the value over here, 0.99,</text>
        <text start="87" dur="5">which gives us approximately 0.0142.</text>
      </transcript>
    </video>
    <video title="11b Question" id="1shSAdfZiJw" length="31">
      <transcript>
        <text start="0" dur="4">[Thrun] Now, to understand the explain away effect,</text>
        <text start="4" dur="7">you have to compare this to the probability of a raise given that we&amp;#39;re just happy</text>
        <text start="11" dur="3">and we don&amp;#39;t know anything about the weather.</text>
        <text start="14" dur="2">So let&amp;#39;s do that exercise next.</text>
        <text start="16" dur="8">So my next quiz is, what&amp;#39;s the probability of a raise given that all I know is that I&amp;#39;m happy</text>
        <text start="24" dur="2">and I don&amp;#39;t know about the weather?</text>
        <text start="26" dur="5">This happens to be once again a pretty complicated question, so take your time.</text>
      </transcript>
    </video>
    <video title="11c Answer" id="YE-2ycPWWpQ" length="173">
      <transcript>
        <text start="0" dur="2">[Thrun] So this is a difficult question.</text>
        <text start="2" dur="10">Let me compute an auxiliary variable, which is P of happiness.</text>
        <text start="12" dur="7">That one is expanded by looking at the different conditions that can make us happy.</text>
        <text start="19" dur="5">P of happiness given S and R</text>
        <text start="24" dur="5">times P of S and R, which is of course the product of those 2</text>
        <text start="29" dur="2">because they are independent,</text>
        <text start="31" dur="8">plus P of happiness given not S R, probability of not as R</text>
        <text start="39" dur="4">plus P of H given S and not R</text>
        <text start="43" dur="5">times the probability of P of S and not R plus the last case,</text>
        <text start="48" dur="4">P of H given not S and not R.</text>
        <text start="52" dur="4">So this just looks at the happiness under all 4 combinations of the variables</text>
        <text start="56" dur="2">that can lead to happiness.</text>
        <text start="58" dur="2">And you can plug those straight in.</text>
        <text start="60" dur="5">This one over here is 1, and this one over here is the product of S and R,</text>
        <text start="65" dur="5">which is 0.7 times 0.01.</text>
        <text start="70" dur="4">And as you plug all of those in,</text>
        <text start="74" dur="7">you get as a result 0.5245.</text>
        <text start="81" dur="3">That&amp;#39;s P of H.</text>
        <text start="84" dur="4">Just take some time and do the math by going through these different cases</text>
        <text start="88" dur="4">using total probability, and you get this result.</text>
        <text start="92" dur="6">Armed with this number, the rest now becomes easy,</text>
        <text start="98" dur="5">which is we can use Bayes&amp;#39; rule to turn this around.</text>
        <text start="103" dur="6">P of H given R times P of R over P of H.</text>
        <text start="109" dur="5">P of R we know from over here, the probability of a raise is 0.01.</text>
        <text start="114" dur="3">So the only thing we need to compute now is P of H given R.</text>
        <text start="117" dur="2">And again, we apply total probability.</text>
        <text start="119" dur="3">Let me just do this over here.</text>
        <text start="122" dur="7">We can factor P of H given R as P of H given R and S, sunny,</text>
        <text start="129" dur="5">times probability of sunny plus P of H given R and not sunny</text>
        <text start="134" dur="2">times the probability of not sunny.</text>
        <text start="136" dur="5">And if you plug in the numbers with this, you get 1 times 0.7</text>
        <text start="141" dur="4">plus 0.9 times 0.3.</text>
        <text start="145" dur="5">That happens to be 0.97.</text>
        <text start="150" dur="3">So if we now plug this all back into this equation over here,</text>
        <text start="153" dur="12">we get 0.97 times 0.01 over 0.5245.</text>
        <text start="165" dur="8">This gives us approximately as the correct answer 0.0185.</text>
      </transcript>
    </video>
    <video title="11d Question" id="klqEUPy8jZU" length="102">
      <transcript>
        <text start="0" dur="4">[Thrun] And if you got this right, I will be deeply impressed</text>
        <text start="4" dur="3">about the fact you got this right.</text>
        <text start="7" dur="6">But the interesting thing now to observe is if we happen to know it&amp;#39;s sunny</text>
        <text start="13" dur="8">and I&amp;#39;m happy, then the probability of a raise is 14%, 0.014.</text>
        <text start="21" dur="5">If I don&amp;#39;t know about the weather and I&amp;#39;m happy,</text>
        <text start="26" dur="4">then the probability of a raise goes up to about 18.5%.</text>
        <text start="30" dur="2">Why is that?</text>
        <text start="32" dur="3">Well, it&amp;#39;s the explaining away effect.</text>
        <text start="35" dur="5">My happiness is well explained by the fact that it&amp;#39;s sunny.</text>
        <text start="40" dur="3">So if someone observes me to be happy and asks the question,</text>
        <text start="43" dur="3">&amp;quot;Is this because Sebastian got a raise at work?&amp;quot;</text>
        <text start="46" dur="7">well, if you know it&amp;#39;s sunny and this is a fairly good explanation for me being happy,</text>
        <text start="53" dur="2">you don&amp;#39;t have to assume I got a raise.</text>
        <text start="55" dur="6">If you don&amp;#39;t know about the weather, then obviously the chances are higher</text>
        <text start="61" dur="2">that the raise caused my happiness,</text>
        <text start="63" dur="7">and therefore this number goes up from 0.014 to 0.018.</text>
        <text start="70" dur="4">Let me ask you one final question in this next quiz,</text>
        <text start="74" dur="9">which is the probability of the raise given that I look happy and it&amp;#39;s not sunny.</text>
        <text start="83" dur="4">This is the most extreme case for making a raise likely</text>
        <text start="87" dur="6">because I am a happy guy, and it&amp;#39;s definitely not caused by the weather.</text>
        <text start="93" dur="4">So it could be just random, or it could be caused by the raise.</text>
        <text start="97" dur="5">So please calculate this number for me and enter it into this box.</text>
      </transcript>
    </video>
    <video title="11e Answer" id="4YzL05_see8" length="78">
      <transcript>
        <text start="0" dur="4">[Thrun] Well, the answer follows the exact same scheme as before,</text>
        <text start="4" dur="4">with S being replaced by not S.</text>
        <text start="8" dur="3">So this should be an easier question for you to answer.</text>
        <text start="11" dur="9">P of R given H and not S can be inverted by Bayes&amp;#39; rule to be as follows.</text>
        <text start="20" dur="4">Once we apply Bayes&amp;#39; rule, as indicated over here where we swapped H to the left side</text>
        <text start="24" dur="5">and R to the right side, you can observe that this value over here</text>
        <text start="29" dur="3">can be readily found in the table.</text>
        <text start="32" dur="3">It&amp;#39;s actually the 0.9 over there.</text>
        <text start="35" dur="6">This value over here, the raise is independent of the weather</text>
        <text start="41" dur="4">by virtue of our Bayes network, so it&amp;#39;s just 0.01.</text>
        <text start="45" dur="7">And as before, we apply total probability to the expression over here,</text>
        <text start="52" dur="6">and we obtain off this quotient over here that these 2 expressions are the same.</text>
        <text start="58" dur="5">P of H given not S, not R is the value over here,</text>
        <text start="63" dur="5">and the 0.99 is the complement of probability of R taken from over here,</text>
        <text start="68" dur="8">and that ends up to be 0.0833.</text>
        <text start="76" dur="2">This would have been the right answer.</text>
      </transcript>
    </video>
    <video title="11f Conclusion" id="8SY5T6TFg6c" length="193">
      <transcript>
        <text start="0" dur="4">[Thrun] It&amp;#39;s really interesting to compare this to the situation over here.</text>
        <text start="4" dur="4">In both cases I&amp;#39;m happy, as shown over here,</text>
        <text start="8" dur="7">and I ask the same question, which is whether I got a raise at work, as R over here.</text>
        <text start="15" dur="6">But in one case I observe that the weather is sunny; in the other one it isn&amp;#39;t.</text>
        <text start="21" dur="4">And look what it does to my probability of having received a raise.</text>
        <text start="25" dur="5">The sunniness perfectly well explains my happiness,</text>
        <text start="30" dur="11">and my probability of having received a raise ends up to be a mere 1.4%, or 0.014.</text>
        <text start="41" dur="6">However, if my wife observes it to be non-sunny, then it is much more likely</text>
        <text start="47" dur="4">that the cause of my happiness is related to a raise at work,</text>
        <text start="51" dur="7">and now the probability is 8.3%, which is significantly higher than the 1.4% before.</text>
        <text start="58" dur="6">This is a Bayes network of which S and R are independent</text>
        <text start="64" dur="6">but H adds a dependence between S and R.</text>
        <text start="70" dur="5">Let me talk about this in a little bit more detail on the next paper.</text>
        <text start="76" dur="2">So here is our Bayes network again.</text>
        <text start="78" dur="4">In our previous exercises, we computed for this network</text>
        <text start="82" dur="7">that the probability of a raise of R given any of these variables shown here was as follows.</text>
        <text start="89" dur="5">The really interesting thing is that in the absence of information about H,</text>
        <text start="94" dur="3">which is the middle case over here,</text>
        <text start="97" dur="4">the probability of R is unaffected by knowledge of S--</text>
        <text start="101" dur="5">that is, R and S are independent.</text>
        <text start="106" dur="3">This is the same as probability of R,</text>
        <text start="109" dur="7">and R and S are independent.</text>
        <text start="116" dur="6">However, if I know something about the variable H,</text>
        <text start="122" dur="4">then S and R become dependent--</text>
        <text start="126" dur="9">that is, knowing about my happiness over here renders S and R dependent.</text>
        <text start="135" dur="8">This is not the same as probability of just R given H.</text>
        <text start="143" dur="5">Obviously, it isn&amp;#39;t because if I now vary S from S to not S,</text>
        <text start="148" dur="5">it affects my probability for the variable R.</text>
        <text start="153" dur="3">That is a really unusual situation</text>
        <text start="156" dur="4">where we have R and S are independent</text>
        <text start="160" dur="10">but given the variable H, R and S are not independent anymore.</text>
        <text start="170" dur="8">So knowledge of H makes 2 variables that previously were independent non-independent.</text>
        <text start="178" dur="8">Offered differently, 2 variables that are independent may not be in certain cases</text>
        <text start="186" dur="2">conditionally independent.</text>
        <text start="188" dur="5">Independence does not imply conditional independence.</text>
      </transcript>
    </video>
    <video title="12 General Bayes Networks" id="kmSMS3CBLd8" length="173">
      <transcript>
        <text start="0" dur="5">[Thrun] So we&amp;#39;re now ready to define Bayes networks in a more general way.</text>
        <text start="5" dur="5">Bayes networks define probability distributions over graphs or random variables.</text>
        <text start="10" dur="4">Here is an example graph of 5 variables,</text>
        <text start="14" dur="5">and this Bayes network defines the distribution over those 5 random variables.</text>
        <text start="19" dur="5">Instead of enumerating all possibilities of combinations of these 5 random variables,</text>
        <text start="24" dur="4">the Bayes network is defined by probability distributions</text>
        <text start="28" dur="4">that are inherent to each individual node.</text>
        <text start="32" dur="6">For node A and B, we just have a distribution P of A and P of B</text>
        <text start="38" dur="4">because A and B have no incoming arcs.</text>
        <text start="42" dur="5">C is a conditional distribution conditioned on A and B.</text>
        <text start="47" dur="5">D and E are conditioned on C.</text>
        <text start="52" dur="4">The joint probability represented by a Bayes network</text>
        <text start="56" dur="4">is the product of various Bayes network probabilities</text>
        <text start="60" dur="3">that are defined over individual nodes</text>
        <text start="63" dur="5">where each node&amp;#39;s probability is only conditioned on the incoming arcs.</text>
        <text start="68" dur="4">So A has no incoming arc; therefore, we just want it P of A.</text>
        <text start="72" dur="6">C has 2 incoming arcs, so we define the probability of C conditioned on A and B.</text>
        <text start="78" dur="4">And D and E have 1 incoming arc that&amp;#39;s shown over here.</text>
        <text start="82" dur="5">The definition of this joint distribution by using the following factors</text>
        <text start="87" dur="3">has one really big advantage.</text>
        <text start="90" dur="10">Whereas the joint distribution over any 5 variables requires 2 to the 5 minus 1,</text>
        <text start="100" dur="3">which is 31 probability values,</text>
        <text start="103" dur="5">the Bayes network over here only requires 10 such values.</text>
        <text start="108" dur="5">P of A is one value, for which we can derive P of not A.</text>
        <text start="113" dur="2">Same for P of B.</text>
        <text start="115" dur="7">P of C given A B is derived by a distribution over C</text>
        <text start="122" dur="5">conditioned on any combination of A and B, of which there are 4 of A and B as binary.</text>
        <text start="127" dur="8">P of D given C is 2 parameters for P of D given C and P of D given not C.</text>
        <text start="135" dur="3">And the same is true for P of E given C.</text>
        <text start="138" dur="3">So if you add those up, you get 10 parameters in total.</text>
        <text start="141" dur="4">So the compactness of the Bayes network</text>
        <text start="145" dur="6">leads to a representation that scales significantly better to large networks</text>
        <text start="151" dur="5">than the common natorial approach which goes through all combinations of variable values.</text>
        <text start="156" dur="3">That is a key advantage of Bayes networks,</text>
        <text start="159" dur="4">and that is the reason why Bayes networks are being used so extensively</text>
        <text start="163" dur="2">for all kinds of problems.</text>
        <text start="165" dur="2">So here is a quiz.</text>
        <text start="167" dur="4">How many probability values are required to specify this Bayes network?</text>
        <text start="171" dur="2">Please put your answer in the following box.</text>
      </transcript>
    </video>
    <video title="12a Answer" id="cvRNI5fULP8" length="19">
      <transcript>
        <text start="0" dur="3">[Thrun] And the answer is 13.</text>
        <text start="3" dur="3">One over here, 2 over here, and 4 over here.</text>
        <text start="6" dur="9">Simplifiably speaking, any variable that has K inputs requires 2 to the K such variables.</text>
        <text start="15" dur="4">So in total we have 1, 9, 13.</text>
      </transcript>
    </video>
    <video title="12b Question" id="Fy5wP_9obQU" length="17">
      <transcript>
        <text start="0" dur="2">[Thrun] Here&amp;#39;s another quiz.</text>
        <text start="2" dur="4">How many parameters do we need to specify the joint distribution</text>
        <text start="6" dur="3">for this Bayes network over here</text>
        <text start="9" dur="4">where A, B, and C point into D, D points into E, F, and G</text>
        <text start="13" dur="2">and C also points into G?</text>
        <text start="15" dur="2">Please write your answer into this box.</text>
      </transcript>
    </video>
    <video title="12c Answer" id="j0p9VHy-Tu0" length="16">
      <transcript>
        <text start="0" dur="2">[Thrun] And the answer is 19.</text>
        <text start="2" dur="7">So 1 here, 1 here, 1 here, 2 here, 2 here, 2 arcs point into G, which makes for 4,</text>
        <text start="9" dur="4">and 3 arcs point into D. Two to the 3 is 8.</text>
        <text start="13" dur="3">So we get 1, 2, 3, 8, 2, 2, 4. If you add those up, it&amp;#39;s 19.</text>
      </transcript>
    </video>
    <video title="12d Question" id="wJsCAF5cAK8" length="28">
      <transcript>
        <text start="0" dur="6">[Thrun] And here is our car network which we discussed at the very beginning of this unit.</text>
        <text start="6" dur="5">How many parameters do we need to specify this network?</text>
        <text start="11" dur="4">Remember, there are 16 total variables,</text>
        <text start="15" dur="10">and the naive joint over the 16 will be 2 to the 16th minus 1, which is 65,535.</text>
        <text start="25" dur="3">Please write your answer into this box over here.</text>
      </transcript>
    </video>
    <video title="12e Answer" id="A2ugTxgEJRA" length="24">
      <transcript>
        <text start="0" dur="4">[Thrun] To answer this question, let us add up these numbers.</text>
        <text start="4" dur="4">Battery age is 1, 1, 1.</text>
        <text start="8" dur="2">This has 1 incoming arc, so it&amp;#39;s 2.</text>
        <text start="10" dur="3">Two incoming arcs makes 4.</text>
        <text start="13" dur="4">One incoming arc is 2, 2 equals 4.</text>
        <text start="17" dur="4">Four incoming arcs makes 16.</text>
        <text start="21" dur="3">If we add all the right numbers, we get 47.</text>
      </transcript>
    </video>
    <video title="12f Value of the Network" id="9PXrxfOb3p0" length="20">
      <transcript>
        <text start="0" dur="5">[Thrun] So it takes 47 numerical probabilities to specify the joint</text>
        <text start="5" dur="6">compared to 65,000 if you didn&amp;#39;t have the graph-like structure.</text>
        <text start="11" dur="3">I think this example really illustrates the advantage</text>
        <text start="14" dur="6">of compact Bayes network representations over unstructured joint representations.</text>
      </transcript>
    </video>
    <video title="13 D-Separation" id="iuad4fQ6UPc" length="35">
      <transcript>
        <text start="0" dur="4">[Thrun] The next concept I&amp;#39;d like to teach you is called D-separation.</text>
        <text start="4" dur="5">And let me start the discussion of this concept by a quiz.</text>
        <text start="9" dur="2">We have here a Bayes network,</text>
        <text start="11" dur="5">and I&amp;#39;m going to ask you a conditional independence question.</text>
        <text start="16" dur="4">Is C independent of A?</text>
        <text start="20" dur="2">Please tell me yes or no.</text>
        <text start="22" dur="5">Is C independent of A given B?</text>
        <text start="27" dur="3">Is C independent of D?</text>
        <text start="30" dur="2">Is C independent of D given A?</text>
        <text start="32" dur="3">And is E independent of C given D?</text>
      </transcript>
    </video>
    <video title="13a Answer" id="dL6p3YQDgGM" length="52">
      <transcript>
        <text start="0" dur="4">[Thrun] So C is not independent of A.</text>
        <text start="4" dur="5">In fact, A influences C by virtue of B.</text>
        <text start="9" dur="4">But if you know B, then A becomes independent of C,</text>
        <text start="13" dur="4">which means the only determinate into C is B.</text>
        <text start="17" dur="5">If you know B for sure, then knowledge of A won&amp;#39;t really tell you anything about C.</text>
        <text start="22" dur="5">C is also not independent of D, just the same way C is not independent of A.</text>
        <text start="27" dur="4">If I learn something about D, I can infer more about C.</text>
        <text start="31" dur="7">But if I do know A, then it&amp;#39;s hard to imagine how knowledge of D would help me with C</text>
        <text start="38" dur="4">because I can&amp;#39;t learn anything more about A than knowing A already.</text>
        <text start="42" dur="3">Therefore, given A, C and D are independent.</text>
        <text start="45" dur="3">The same is true for E and C.</text>
        <text start="48" dur="4">If we know D, then E and C become independent.</text>
      </transcript>
    </video>
    <video title="13b D-Separation Example" id="DmbahBp7buc" length="45">
      <transcript>
        <text start="0" dur="4">[Thrun] In this specific example, the rule that we could apply is very, very simple.</text>
        <text start="4" dur="6">Any 2 variables are independent if they&amp;#39;re not linked by just unknown variables.</text>
        <text start="10" dur="4">So for example, if we know B, then everything downstream of B</text>
        <text start="14" dur="4">becomes independent of anything upstream of B.</text>
        <text start="18" dur="4">E is now independent of C, conditioned on B.</text>
        <text start="22" dur="4">However, knowledge of B does not render A and E independent.</text>
        <text start="26" dur="7">In this graph over here, A and B connect to C and C connects to D and to E.</text>
        <text start="33" dur="4">So let me ask you, is A independent of E,</text>
        <text start="37" dur="2">A independent of E given B,</text>
        <text start="39" dur="2">A independent of E given C,</text>
        <text start="41" dur="2">A independent of B,</text>
        <text start="43" dur="2">and A independent of B given C?</text>
      </transcript>
    </video>
    <video title="13c Answer" id="zQ_xDaok-G0" length="86">
      <transcript>
        <text start="0" dur="3">[Thrun] And the answer for this one is really interesting.</text>
        <text start="3" dur="5">A is clearly not independent of E because through C we can see an influence of A to E.</text>
        <text start="8" dur="3">Given B, that doesn&amp;#39;t change.</text>
        <text start="11" dur="4">A still influences C, despite the fact we know B.</text>
        <text start="15" dur="3">However, if we know C, the influence is cut off.</text>
        <text start="18" dur="4">There is no way A can influence E if we know C.</text>
        <text start="22" dur="3">A is clearly independent of B.</text>
        <text start="25" dur="4">They are different entry variables. They have no incoming arcs.</text>
        <text start="29" dur="3">But here is the caveat.</text>
        <text start="32" dur="3">Given C, A and B become dependent.</text>
        <text start="35" dur="3">So whereas initially A and B were independent,</text>
        <text start="38" dur="3">if you give C, they become dependent.</text>
        <text start="41" dur="3">And the reason why they become dependent we&amp;#39;ve studied before.</text>
        <text start="44" dur="4">This is the explain away effect.</text>
        <text start="48" dur="3">If you know, for example, C to be true,</text>
        <text start="51" dur="6">then knowledge of A will substantially affect what we believe about B.</text>
        <text start="57" dur="5">If there&amp;#39;s 2 joint causes for C and we happen to know A is true,</text>
        <text start="62" dur="2">we will discredit cause B.</text>
        <text start="64" dur="5">If we happen to know A is false, we will increase our belief for the cause B.</text>
        <text start="69" dur="6">That was an effect we studied extensively in the happiness example I gave you before.</text>
        <text start="75" dur="4">The interesting thing here is we are facing a situation</text>
        <text start="79" dur="7">where knowledge of variable C renders previously independent variables dependent.</text>
      </transcript>
    </video>
    <video title="13d D-Separation General Definition" id="BBQTF6zbWME" length="174">
      <transcript>
        <text start="0" dur="6">[Thrun] This leads me to the general study of conditional independence in Bayes networks,</text>
        <text start="6" dur="4">often called D-separation or reachability.</text>
        <text start="10" dur="7">D-separation is best studied by so-called active triplets and inactive triplets</text>
        <text start="17" dur="3">where active triplets render variables dependent</text>
        <text start="20" dur="3">and inactive triplets render them independent.</text>
        <text start="23" dur="7">Any chain of 3 variables like this makes the initial and final variable dependent</text>
        <text start="30" dur="2">if all variables are unknown.</text>
        <text start="32" dur="3">However, if the center variable is known--</text>
        <text start="35" dur="3">that is, it&amp;#39;s behind the conditioning bar--</text>
        <text start="38" dur="4">then this variable and this variable become independent.</text>
        <text start="42" dur="5">So if we have a structure like this and it&amp;#39;s quote-unquote cut off</text>
        <text start="47" dur="6">by a known variable in the middle, that separates or deseparates</text>
        <text start="53" dur="4">the left variable from the right variable, and they become independent.</text>
        <text start="57" dur="7">Similarly, any structure like this renders the left variable and the right variable dependent</text>
        <text start="64" dur="4">unless the center variable is known,</text>
        <text start="68" dur="4">in which case the left and right variable become independent.</text>
        <text start="72" dur="4">Another active triplet now requires knowledge of a variable.</text>
        <text start="76" dur="3">This is the explain away case.</text>
        <text start="79" dur="6">If this variable is known for a Bayes network that converges into a single variable,</text>
        <text start="85" dur="4">then this variable and this variable over here become dependent.</text>
        <text start="89" dur="4">Contrast this with a case where all variables are unknown.</text>
        <text start="93" dur="7">A situation like this means that this variable on the left or on the right are actually independent.</text>
        <text start="100" dur="8">In a single final example, we also get dependence if we have the following situation:</text>
        <text start="108" dur="4">a direct successor of a conversion variable is known.</text>
        <text start="112" dur="5">So it is sufficient if a successor of this variable is known.</text>
        <text start="117" dur="2">The variable itself does not have to be known,</text>
        <text start="119" dur="3">and the reason is if you know this guy over here,</text>
        <text start="122" dur="3">we get knowledge about this guy over here.</text>
        <text start="125" dur="4">And by virtue of that, the case over here essentially applies.</text>
        <text start="129" dur="2">If you look at those rules,</text>
        <text start="131" dur="4">those rules allow you to determine for any Bayes network</text>
        <text start="135" dur="5">whether variables are dependent or not dependent given the evidence you have.</text>
        <text start="140" dur="5">If you color the nodes dark for which you do have evidence,</text>
        <text start="145" dur="4">then you can use these rules to understand whether any 2 variables</text>
        <text start="149" dur="2">are conditionally independent or not.</text>
        <text start="151" dur="6">So let me ask you for this relatively complicated Bayes network the following questions.</text>
        <text start="157" dur="4">Is F independent of A?</text>
        <text start="161" dur="4">Is F independent of A given D?</text>
        <text start="165" dur="4">Is F independent of A given G?</text>
        <text start="169" dur="2">And is F independent of A given H?</text>
        <text start="171" dur="3">Please mark your answers as you see fit.</text>
      </transcript>
    </video>
    <video title="13e Answer" id="LKDtJM8SQmw" length="63">
      <transcript>
        <text start="0" dur="4">[Thrun] And the answer is yes, F is independent of A.</text>
        <text start="4" dur="4">What we find for our rules of D-separation is that F is dependent on D</text>
        <text start="8" dur="3">and A is dependent on D.</text>
        <text start="11" dur="5">But if you don&amp;#39;t know D, you can&amp;#39;t govern any dependence between A and F at all.</text>
        <text start="16" dur="4">If you do know D, then F and A become dependent.</text>
        <text start="20" dur="5">And the reason is B and E are dependent given D,</text>
        <text start="25" dur="4">and we can transform this back into dependence of A and F</text>
        <text start="29" dur="4">because B and A are dependent and E and F are dependent.</text>
        <text start="33" dur="5">There is an active path between A and F which goes across here and here</text>
        <text start="38" dur="2">because D is known.</text>
        <text start="40" dur="4">If we know G, the same thing is true because G gives us knowledge about D,</text>
        <text start="44" dur="3">and D can be applied back to this path over here.</text>
        <text start="47" dur="2">However, if you know H, that&amp;#39;s not the case.</text>
        <text start="49" dur="2">So H might tell us something about G,</text>
        <text start="51" dur="2">but it doesn&amp;#39;t tell us anything about D,</text>
        <text start="53" dur="6">and therefore, we have no reason to close the path between A and F.</text>
        <text start="59" dur="4">The path between A and F is still passive, even though we have knowledge of H.</text>
      </transcript>
    </video>
    <video title="14 Congratulations" id="4OPv8ACeuaU" length="50">
      <transcript>
        <text start="0" dur="3">[Thrun] So congratulations. You learned a lot about Bayes networks.</text>
        <text start="3" dur="3">You learned about the graph structure of Bayes networks,</text>
        <text start="6" dur="4">you understood how this is a compact representation,</text>
        <text start="10" dur="2">you learned about conditional independence,</text>
        <text start="12" dur="3">and we talked a little bit about application of Bayes network</text>
        <text start="15" dur="3">to interesting reasoning problems.</text>
        <text start="18" dur="5">But by all means this was a mostly theoretical unit of this class,</text>
        <text start="23" dur="4">and in future classes we will talk more about applications.</text>
        <text start="27" dur="4">The instrument of Bayes networks is really essential to a number of problems.</text>
        <text start="31" dur="5">It really characterizes the sparse dependence that exists in many readable problems</text>
        <text start="36" dur="5">like in robotics and computer vision and filtering and diagnostics and so on.</text>
        <text start="41" dur="2">I really hope you enjoyed this class,</text>
        <text start="43" dur="7">and I really hope you understood in depth how Bayes networks work.</text>
      </transcript>
    </video>
  </group>
  <group title="Unit 4" count="34">
    <video title="1 Probabilistic Inference" id="1fVWQ-iZqsw" length="278">
      <transcript>
        <text start="0" dur="2">[Probabilistic Interference]</text>
        <text start="2" dur="3">[Male] Welcome back. In the previous unit, we went over the basics</text>
        <text start="5" dur="7">of probability theory and saw how</text>
        <text start="12" dur="5">a Bayes network could concisely represent a joint probability distribution,</text>
        <text start="17" dur="7">including the representation of independence between the variables.</text>
        <text start="24" dur="7">In this unit, we will see how to do probabilistic inference.</text>
        <text start="31" dur="5">That is, how to answer probability questions using Bayes nets.</text>
        <text start="36" dur="4">Let&amp;#39;s put up a simple Bayes net.</text>
        <text start="40" dur="5">We&amp;#39;ll use the familiar example of the earthquake</text>
        <text start="45" dur="5">where we can have a burglary or an earthquake</text>
        <text start="50" dur="3">setting off an alarm, and if the alarm goes off,</text>
        <text start="53" dur="5">either John or Mary might call.</text>
        <text start="58" dur="4">Now, what kinds of questions can we ask to do inference about?</text>
        <text start="62" dur="3">The simplest type of question is the same question we ask</text>
        <text start="65" dur="3">with an ordinary subroutine or function in a programming language.</text>
        <text start="68" dur="4">Namely, given some inputs, what are the outputs?</text>
        <text start="72" dur="6">So, in this case, we could say given the inputs of B and E,</text>
        <text start="78" dur="4">what are the outputs, J and M?</text>
        <text start="82" dur="4">Rather than call them input and output variables,</text>
        <text start="86" dur="10">in probabilistic inference, we&amp;#39;ll call them evidence and query variables.</text>
        <text start="96" dur="3">That is, the variables that we know the values of are the evidence,</text>
        <text start="99" dur="5">and the ones that we want to find out the values of are the query variables.</text>
        <text start="104" dur="8">Anything that is neither evidence nor query is known as a hidden variable.</text>
        <text start="112" dur="3">That is, we won&amp;#39;t tell you what its value is.</text>
        <text start="115" dur="3">We won&amp;#39;t figure out what its value is and report it,</text>
        <text start="118" dur="3">but we&amp;#39;ll have to compute with it internally.</text>
        <text start="121" dur="4">And now furthermore, in probabilistic inference,</text>
        <text start="125" dur="5">the output is not a single number for each of the query variables,</text>
        <text start="130" dur="3">but rather, it&amp;#39;s a probability distribution.</text>
        <text start="133" dur="4">So, the answer is going to be a complete, joint probability distribution</text>
        <text start="137" dur="2">over the query variables.</text>
        <text start="139" dur="4">We call this the posterior distribution, given the evidence,</text>
        <text start="143" dur="3">and we can write it like this.</text>
        <text start="146" dur="8">It&amp;#39;s the probability distribution of one or more query variables</text>
        <text start="154" dur="5">given the values of the evidence variables.</text>
        <text start="159" dur="3">And there can be zero or more evidence variables,</text>
        <text start="162" dur="5">and each of them are given an exact value.</text>
        <text start="167" dur="6">And that&amp;#39;s the computation we want to come up with.</text>
        <text start="173" dur="3">There&amp;#39;s another question we can ask.</text>
        <text start="176" dur="2">Which is the most likely explanation?</text>
        <text start="178" dur="5">That is, out of all the possible values for all the query variables,</text>
        <text start="183" dur="5">which combination of values has the highest probability?</text>
        <text start="188" dur="4">We write the formula like this, asking which Q values</text>
        <text start="192" dur="4">are maxable given the evidence values.</text>
        <text start="196" dur="6">Now, in an ordinary programming language, each function goes only one way.</text>
        <text start="202" dur="4">It has input variables, does some computation,</text>
        <text start="206" dur="5">and comes up with a result variable or result variables.</text>
        <text start="211" dur="3">One great thing about Bayes nets is that we&amp;#39;re not restricted</text>
        <text start="214" dur="2">to going only in one direction.</text>
        <text start="216" dur="5">We could go in the causal direction, giving as evidence</text>
        <text start="221" dur="6">the route nodes of the tree and asking as query values the nodes at the bottom.</text>
        <text start="227" dur="3">Or, we could reverse that causal flow.</text>
        <text start="230" dur="5">For example, we could have J and M be the evidence variables</text>
        <text start="235" dur="3">and B and E be the query variables,</text>
        <text start="238" dur="3">or we could have any other combination.</text>
        <text start="241" dur="4">For example, we could have M be the evidence variable</text>
        <text start="245" dur="6">and J and B be the query variables.</text>
        <text start="251" dur="2">Here&amp;#39;s a question for you.</text>
        <text start="253" dur="5">Imagine the situation where Mary has called to report that the alarm is going off,</text>
        <text start="258" dur="4">and we want to know whether or not there has been a burglary.</text>
        <text start="262" dur="5">For each of the nodes, click on the circle to tell us</text>
        <text start="267" dur="5">if the node is an evidence node, a hidden node,</text>
        <text start="272" dur="6">or a query node.</text>
      </transcript>
    </video>
    <video title="1a Answer" id="VYsys0If8bw" length="11">
      <transcript>
        <text start="0" dur="4">The answer is that Mary calling is the evidence node.</text>
        <text start="4" dur="3">The burglary is the query node,</text>
        <text start="7" dur="4">and all the others are hidden variables in this case.</text>
      </transcript>
    </video>
    <video title="2 Enumeration" id="q5DHnmHtVmc" length="264">
      <transcript>
        <text start="0" dur="4">Now we&amp;#39;re going to talk about how to do inference on Bayes net.</text>
        <text start="4" dur="4">We&amp;#39;ll start with our familiar network, and we&amp;#39;ll talk about a method</text>
        <text start="8" dur="4">called enumeration,</text>
        <text start="12" dur="3">which goes through all the possibilities, adds them up,</text>
        <text start="15" dur="2">and comes up with an answer.</text>
        <text start="17" dur="7">So, what we do is start by stating the problem.</text>
        <text start="24" dur="3">We&amp;#39;re going to ask the question of what is the probability</text>
        <text start="27" dur="7">that the burglar alarm occurred given that John called and Mary called?</text>
        <text start="34" dur="5">We&amp;#39;ll use the definition of conditional probability to answer this.</text>
        <text start="39" dur="8">So, this query is equal to the joint probability distribution</text>
        <text start="47" dur="8">of all 3 variables divided by the conditionalized variables.</text>
        <text start="55" dur="6">Now, note I&amp;#39;m using a notation here where instead of writing out the probability</text>
        <text start="61" dur="4">of some variable equals true, I&amp;#39;m just using the notation plus</text>
        <text start="65" dur="3">and then the variable name in lower case,</text>
        <text start="68" dur="5">and if I wanted the negation, I would use negation sign.</text>
        <text start="73" dur="4">Notice there&amp;#39;s a different notation where instead of writing out</text>
        <text start="77" dur="5">the plus and negation signs, we just use the variable name itself, P(e),</text>
        <text start="82" dur="3">to indicate E is true.</text>
        <text start="85" dur="4">That notation works well, but it can get confusing between</text>
        <text start="89" dur="5">does P(e) mean E is true, or does it mean E is a variable?</text>
        <text start="94" dur="3">And so we&amp;#39;re going to stick to the notation where we explicitly have</text>
        <text start="97" dur="4">the pluses and negation signs.</text>
        <text start="101" dur="4">To do inference by enumeration, we first take a conditional probability</text>
        <text start="105" dur="4">and rewrite it as unconditional probabilities.</text>
        <text start="109" dur="7">Now we enumerate all the atomic probabilities and calculate the sum of products.</text>
        <text start="116" dur="4">Let&amp;#39;s look at just the complex term on the numerator first.</text>
        <text start="120" dur="5">The procedure for figuring out the denominator would be similar, and we&amp;#39;ll skip that.</text>
        <text start="125" dur="7">So, the probability of these 3 terms together</text>
        <text start="132" dur="5">can be determined by enumerating all possible values of the hidden variables.</text>
        <text start="137" dur="5">In this case, there are 2, E and A,</text>
        <text start="142" dur="7">so we&amp;#39;ll sum over those variables for all values of E and for all values of A.</text>
        <text start="149" dur="5">In this case, they&amp;#39;re boolean, so there&amp;#39;s only 2 values of each.</text>
        <text start="154" dur="7">We ask what&amp;#39;s the probability of this unconditional term?</text>
        <text start="161" dur="3">And that we get by summing out over all possibilities,</text>
        <text start="164" dur="5">E and A being true or false.</text>
        <text start="169" dur="3">Now, to get the values of these atomic events,</text>
        <text start="172" dur="3">we&amp;#39;ll have to rewrite this equation in a form that corresponds</text>
        <text start="175" dur="5">to the conditional probability tables that we have associated with the Bayes net.</text>
        <text start="180" dur="4">So, we&amp;#39;ll take this whole expression and rewrite it.</text>
        <text start="184" dur="4">It&amp;#39;s still a sum over the hidden variables E and A,</text>
        <text start="188" dur="4">but now I&amp;#39;ll rewrite this expression in terms of the parents</text>
        <text start="192" dur="3">of each of the nodes in the network.</text>
        <text start="195" dur="6">So, that gives us the product of these 5 terms,</text>
        <text start="201" dur="3">which we then have to sum over all values of E and A.</text>
        <text start="204" dur="7">If we call this product f(e,a),</text>
        <text start="211" dur="12">then the whole answer is the sum of F for all values of E and A,</text>
        <text start="223" dur="8">so as the sum of 4 terms where each of the terms is a product of 5 numbers.</text>
        <text start="231" dur="3">Where do we get the numbers to fill in this equation?</text>
        <text start="234" dur="4">From the conditional probability tables from our model,</text>
        <text start="238" dur="5">so let&amp;#39;s put the equation back up, and we&amp;#39;ll ask you for the case</text>
        <text start="243" dur="6">where both E and A are positive</text>
        <text start="249" dur="5">to look up in the conditional probability tables and fill in the numbers</text>
        <text start="254" dur="10">for each of these 5 terms, and then multiply them together and fill in the product.</text>
      </transcript>
    </video>
    <video title="2a Answer" id="fxYL4PIBXiY" length="119">
      <transcript>
        <text start="0" dur="4">We get the answer by reading numbers off the conditional probability tables,</text>
        <text start="4" dur="7">so probability of B being positive is 0.001.</text>
        <text start="11" dur="5">Of E being positive, because we&amp;#39;re dealing with the positive case now</text>
        <text start="16" dur="6">for the variable E, is 0.002.</text>
        <text start="22" dur="4">The probability of A being positive, because we&amp;#39;re dealing with that case,</text>
        <text start="26" dur="4">given that B is positive and the case for an E is positive,</text>
        <text start="30" dur="7">that we can read off here as 0.95.</text>
        <text start="37" dur="7">The probability that J is positive given that A is positive is 0.9.</text>
        <text start="44" dur="6">And finally, the probability that M is positive given that A is positive</text>
        <text start="50" dur="4">we read off here as 0.7.</text>
        <text start="54" dur="3">We multiple all those together, it&amp;#39;s going to be a small number</text>
        <text start="57" dur="3">because we&amp;#39;ve got the .001 and the .002 here.</text>
        <text start="60" dur="12">Can&amp;#39;t quite fit it in the box, but it works out to .000001197.</text>
        <text start="72" dur="2">That seems like a really small number, but remember,</text>
        <text start="74" dur="5">we have to normalize by the P(+j,+m) term,</text>
        <text start="79" dur="3">and this is only 1 of the 4 possibilities.</text>
        <text start="82" dur="4">We have to enumerate over all 4 possibilities for E and A,</text>
        <text start="86" dur="6">and in the end, it works out that the probability of the burglar alarm being true</text>
        <text start="92" dur="6">given that John and Mary calls, is 0.284.</text>
        <text start="98" dur="4">And we get that number because intuitively,</text>
        <text start="102" dur="2">it seems that the alarm is fairly reliable.</text>
        <text start="104" dur="3">John and Mary calling are very reliable,</text>
        <text start="107" dur="2">but the prior probability of burglary is low.</text>
        <text start="109" dur="5">And those 2 terms combine together to give us the 0.284 value</text>
        <text start="114" dur="5">when we sum up each of the 4 terms of these products.</text>
      </transcript>
    </video>
    <video title="3 Speeding up Enumeration" id="DWO-XKo2iS8" length="207">
      <transcript>
        <text start="0" dur="4">[Norvig] We&amp;#39;ve seen how to do enumeration to solve the inference problem</text>
        <text start="4" dur="2">on belief networks.</text>
        <text start="6" dur="4">For a simple network like the alarm network, that&amp;#39;s all we need to know.</text>
        <text start="10" dur="4">There&amp;#39;s only 5 variables, so even if all 5 of them were hidden,</text>
        <text start="14" dur="6">there would only be 32 rows in the table to sum up.</text>
        <text start="20" dur="2">From a theoretical point of view, we&amp;#39;re done.</text>
        <text start="22" dur="4">But from a practical point of view, other networks could give us trouble.</text>
        <text start="26" dur="9">Consider this network, which is one for determining insurance for car owners.</text>
        <text start="35" dur="3">There are 27 different variables.</text>
        <text start="38" dur="6">If each of the variables were boolean, that would give us over 100 million rows to sum out.</text>
        <text start="44" dur="2">But in fact, some of the variables are non-boolean,</text>
        <text start="46" dur="6">they have multiple values, and it turns out that representing this entire network</text>
        <text start="52" dur="5">and doing enumeration we&amp;#39;d have to sum over a quadrillion rows.</text>
        <text start="57" dur="4">That&amp;#39;s just not practical, so we&amp;#39;re going to have to come up with methods</text>
        <text start="61" dur="3">that are faster than enumerating everything.</text>
        <text start="64" dur="5">The first technique we can use to get a speed-up in doing inference on Bayes nets</text>
        <text start="69" dur="4">is to pull out terms from the enumeration.</text>
        <text start="73" dur="7">For example, here the probability of b is going to be the same for all values of E and a.</text>
        <text start="80" dur="6">So we can take that term and move it out of the summation,</text>
        <text start="86" dur="2">and now we have a little bit less work to do.</text>
        <text start="88" dur="5">We can multiply by that term once rather than having it in each row of the table.</text>
        <text start="93" dur="7">We can also move this term, the P of e, to the left of the summation over a,</text>
        <text start="100" dur="3">because it doesn&amp;#39;t depend on a.</text>
        <text start="103" dur="2">By doing this, we&amp;#39;re doing less work.</text>
        <text start="105" dur="5">The inner loop of the summation now has only 3 terms rather than 5 terms.</text>
        <text start="110" dur="3">So we&amp;#39;ve reduced the cost of doing each row of the table.</text>
        <text start="113" dur="4">But we still have the same number of rows in the table,</text>
        <text start="117" dur="3">so we&amp;#39;re going to have to do better than that.</text>
        <text start="120" dur="8">The next technique for efficient inference is to maximize independence of variables.</text>
        <text start="128" dur="4">The structure of a Bayes net determines how efficient it is to do inference on it.</text>
        <text start="132" dur="5">For example, a network that&amp;#39;s a linear string of variables,</text>
        <text start="137" dur="10">X1 through Xn, can have inference done in time proportional to the number n,</text>
        <text start="147" dur="4">whereas a network that&amp;#39;s a complete network</text>
        <text start="151" dur="9">where every node points to every other node and so on could take time 2 to the n</text>
        <text start="160" dur="5">if all n variables are boolean variables.</text>
        <text start="165" dur="5">In the alarm network we saw previously, we took care</text>
        <text start="170" dur="4">to make sure that we had all the independence relations represented</text>
        <text start="174" dur="3">in the structure of the network.</text>
        <text start="177" dur="3">But if we put the nodes together in a different order,</text>
        <text start="180" dur="3">we would end up with a different structure.</text>
        <text start="183" dur="6">Let&amp;#39;s start by ordering the node John calls first</text>
        <text start="189" dur="4">and then adding in the node Mary calls.</text>
        <text start="193" dur="6">The question is, given just these 2 nodes and looking at the node for Mary calls,</text>
        <text start="199" dur="8">is that node dependent or independent of the node for John calls?</text>
      </transcript>
    </video>
    <video title="3a Answer" id="r3mOvkvHbts" length="24">
      <transcript>
        <text start="1" dur="4">[Norvig] The answer is that the node for Mary calls in this network</text>
        <text start="5" dur="3">is dependent on John calls.</text>
        <text start="8" dur="5">In the previous network, they were independent given that we knew that the alarm had occurred.</text>
        <text start="13" dur="3">But here we don&amp;#39;t know that the alarm had occurred,</text>
        <text start="16" dur="2">and so the nodes are dependent</text>
        <text start="18" dur="6">because having information about one will affect the information about the other.</text>
      </transcript>
    </video>
    <video title="3b Second Question" id="uZfGhIFH92g" length="13">
      <transcript>
        <text start="0" dur="5">[Norvig] Now we&amp;#39;ll continue and we&amp;#39;ll add the node A for alarm to the network.</text>
        <text start="5" dur="4">And what I want you to do is click on all the other variables</text>
        <text start="9" dur="4">that A is dependent on in this network.</text>
      </transcript>
    </video>
    <video title="3c Second Answer" id="X1WygrN9ens" length="33">
      <transcript>
        <text start="1" dur="4">[Norvig] The answer is that alarm is dependent on both John and Mary.</text>
        <text start="5" dur="4">And so we can draw both nodes in, both arrows in.</text>
        <text start="9" dur="5">Intuitively that makes sense because if John calls,</text>
        <text start="14" dur="2">then it&amp;#39;s more likely that the alarm has occurred,</text>
        <text start="16" dur="4">likely as if Mary calls, and if both called, it&amp;#39;s really likely.</text>
        <text start="20" dur="3">So you can figure out the answer by intuitive reasoning,</text>
        <text start="23" dur="4">or you can figure it out by going to the conditional probability tables</text>
        <text start="27" dur="4">and seeing according to the definition of conditional probability</text>
        <text start="31" dur="2">whether the numbers work out.</text>
      </transcript>
    </video>
    <video title="3d Third Question" id="rTeQXHTu2_A" length="11">
      <transcript>
        <text start="1" dur="4">[Norvig] Now we&amp;#39;ll continue and we&amp;#39;ll add the node B for burglary</text>
        <text start="5" dur="6">and ask again, click on all the variables that B is dependent on.</text>
      </transcript>
    </video>
    <video title="3e Third Answer" id="_l7rPalYjmU" length="10">
      <transcript>
        <text start="0" dur="4">[Norvig] The answer is that B is dependent only on A.</text>
        <text start="4" dur="6">In other words, B is independent of J and M given A.</text>
      </transcript>
    </video>
    <video title="3f Fourth Question" id="DX1YTIQsjtU" length="7">
      <transcript>
        <text start="0" dur="4">[Norvig] And finally, we&amp;#39;ll add the last node, E,</text>
        <text start="4" dur="3">and ask you to click on all the nodes that E is dependent on.</text>
      </transcript>
    </video>
    <video title="3g Fourth Answer" id="T609y-a8bZc" length="26">
      <transcript>
        <text start="0" dur="4">[Norvig] And the answer is that E is dependent on A.</text>
        <text start="4" dur="2">That much is fairly obvious.</text>
        <text start="6" dur="2">But it&amp;#39;s also dependent on B.</text>
        <text start="8" dur="2">Now, why is that?</text>
        <text start="10" dur="3">E is dependent on A because if the earthquake did occur,</text>
        <text start="13" dur="3">then it&amp;#39;s more likely that the alarm would go off.</text>
        <text start="16" dur="3">On the other hand, E is also dependent on B</text>
        <text start="19" dur="4">because if a burglary occurred, then that would explain why the alarm is going off,</text>
        <text start="23" dur="3">and it would mean that the earthquake is less likely.</text>
      </transcript>
    </video>
    <video title="3h Causal Direction" id="YPmGGwlRqY0" length="18">
      <transcript>
        <text start="0" dur="4">[Norvig] The moral is that Bayes nets tend to be the most compact</text>
        <text start="4" dur="8">and thus the easier to do inference on when they&amp;#39;re written in the causal direction--</text>
        <text start="12" dur="6">that is, when the networks flow from causes to effects.</text>
      </transcript>
    </video>
    <video title="4 Variable Elimination" id="qyXspkUOhGc" length="280">
      <transcript>
        <text start="0" dur="6">Let&amp;#39;s return to this equation, which we use to show how to do inference by enumeration.</text>
        <text start="6" dur="4">In this equation, we join up the whole joint distribution</text>
        <text start="10" dur="5">before we sum out over the hidden variables.</text>
        <text start="15" dur="3">That&amp;#39;s slow, because we end up repeating a lot of work.</text>
        <text start="18" dur="7">Now we&amp;#39;re going to show a new technique called variable elimination,</text>
        <text start="25" dur="2">which in many networks operates much faster.</text>
        <text start="27" dur="3">It&amp;#39;s still a difficult computation, an NP-hard computation,</text>
        <text start="30" dur="4">to do inference over Bayes nets in general.</text>
        <text start="34" dur="4">Variable elimination works faster than inference by enumeration</text>
        <text start="38" dur="3">in most practical cases.</text>
        <text start="41" dur="4">It requires an algebra for manipulating factors,</text>
        <text start="45" dur="3">which are just names for multidimensional arrays</text>
        <text start="48" dur="5">that come out of these probabilistic terms.</text>
        <text start="53" dur="4">We&amp;#39;ll use another example to show how variable elimination works.</text>
        <text start="57" dur="3">We&amp;#39;ll start off with a network that has 3 boolean variables.</text>
        <text start="60" dur="4">R indicates whether or not it&amp;#39;s raining.</text>
        <text start="64" dur="8">T indicates whether or not there&amp;#39;s traffic,</text>
        <text start="72" dur="3">and T is dependent on whether it&amp;#39;s raining.</text>
        <text start="75" dur="4">And finally, L indicates whether or not I&amp;#39;ll be late for my next appointment,</text>
        <text start="79" dur="3">and that depends on whether or not there&amp;#39;s traffic.</text>
        <text start="82" dur="7">Now we&amp;#39;ll put up the conditional probability tables for each of these 3 variables.</text>
        <text start="89" dur="6">And then we can use inference to figure out the answer to questions like</text>
        <text start="95" dur="3">am I going to be late?</text>
        <text start="98" dur="4">And we know by definition that we could do that through enumeration</text>
        <text start="102" dur="5">by going through all the possible values for R and T</text>
        <text start="107" dur="7">and summing up the product of these 3 nodes.</text>
        <text start="114" dur="5">Now, in a simple network like this, straight enumeration would work fine,</text>
        <text start="119" dur="4">but in a more complex network, what variable elimination does is give us a way</text>
        <text start="123" dur="6">to combine together parts of the network into smaller parts</text>
        <text start="129" dur="4">and then enumerate over those smaller parts and then continue combining.</text>
        <text start="133" dur="2">So, we start with a big network.</text>
        <text start="135" dur="2">We eliminate some of the variables.</text>
        <text start="137" dur="7">We compute by marginalizing out, and then we have a smaller network to deal with,</text>
        <text start="144" dur="4">and we&amp;#39;ll show you how those 2 steps work.</text>
        <text start="148" dur="7">The first operation in variable elimination is called joining factors.</text>
        <text start="155" dur="4">A factor, again, is one of these tables.</text>
        <text start="159" dur="4">It&amp;#39;s a multidimensional matrix, and what we do is choose 2 of the factors,</text>
        <text start="163" dur="2">2 or more of the factors.</text>
        <text start="165" dur="4">In this case, we&amp;#39;ll choose these 2, and we&amp;#39;ll combine them together</text>
        <text start="169" dur="3">to form a new factor which represents</text>
        <text start="172" dur="4">the joint probability of all the variables in that factor.</text>
        <text start="176" dur="4">In this case, R and T.</text>
        <text start="180" dur="3">Now we&amp;#39;ll draw out that table.</text>
        <text start="183" dur="3">In each case, we just look up in the corresponding table,</text>
        <text start="186" dur="2">figure out the numbers, and multiply them together.</text>
        <text start="188" dur="5">For example, in this row we have a +r and a +t,</text>
        <text start="193" dur="6">so the +r is 0.1, and the entry for +r and +t  is 0.8,</text>
        <text start="199" dur="3">so multiply them together and you get 0.08.</text>
        <text start="202" dur="6">Go all the way down. For example, in the last row we have a -r and a -t.</text>
        <text start="208" dur="6">-r is 0.9. The entry for -r and -t is also 0.9.</text>
        <text start="214" dur="6">Multiply those together and you get 0.81.</text>
        <text start="220" dur="2">So, what have we done?</text>
        <text start="222" dur="3">We used the operation of joining factors on these 2 factors,</text>
        <text start="225" dur="5">getting us a new factor which is part of the existing network.</text>
        <text start="230" dur="6">Now we want to apply a second operation called elimination,</text>
        <text start="236" dur="6">also called summing out or marginalization, to take this table and reduce it.</text>
        <text start="242" dur="4">Right now, the tables we have look like this.</text>
        <text start="246" dur="4">We could sum out or marginalize over the variable R</text>
        <text start="250" dur="4">to give us a table that just operates on T.</text>
        <text start="254" dur="6">So, the question is to fill in this table for P(T)--</text>
        <text start="260" dur="3">there will be 2 entries in this table, the +t entry, formed by summing out</text>
        <text start="263" dur="5">all the entries here for all values of r for which t is positive,</text>
        <text start="268" dur="4">and the -t entry, formed the same way, by looking in this table</text>
        <text start="272" dur="5">and summing up all the rows over all values of r where t is negative.</text>
        <text start="277" dur="3">Put your answers in these boxes.</text>
      </transcript>
    </video>
    <video title="4a Answer" id="4lm-TI7APX0" length="27">
      <transcript>
        <text start="0" dur="5">The answer is that for +t we look up the 2 possible values for r,</text>
        <text start="5" dur="4">and we get 0.08 or 0.09.</text>
        <text start="9" dur="4">Sum those up, get 0.17,</text>
        <text start="13" dur="5">and then we look at the 2 possible values of R for -t,</text>
        <text start="18" dur="4">and we get 0.02 and 0.81.</text>
        <text start="22" dur="5">Add those up, and we get 0.83.</text>
      </transcript>
    </video>
    <video title="4b More Variable Elimination" id="Bk2S3ffdtsc" length="28">
      <transcript>
        <text start="0" dur="4">So, we took our network with RT and L. We summed out over R.</text>
        <text start="4" dur="5">That gives us a new network with T and L</text>
        <text start="9" dur="4">with these conditional probability tables.</text>
        <text start="13" dur="4">And now we want to do a join over T and L</text>
        <text start="17" dur="8">and give us a new table with the joint probability of P(T, L).</text>
        <text start="25" dur="3">And that table is going to look like this.</text>
      </transcript>
    </video>
    <video title="4c Answer" id="LU9gMODL04Y" length="38">
      <transcript>
        <text start="0" dur="5">The answer, again, for joining variables is determined by pointwise multiplication,</text>
        <text start="5" dur="7">so we have 0.17 times 0.3 is 0.051,</text>
        <text start="12" dur="9">+t and +l, 0.17 times 0.7 is 0.119.</text>
        <text start="21" dur="2">Then we go to the minuses.</text>
        <text start="23" dur="8">Minus 0.83 times 0.1 is 0.083.</text>
        <text start="31" dur="7">And finally, 0.83 times 0.9 is 0.747.</text>
      </transcript>
    </video>
    <video title="4d Even More Variable Elimination" id="5lImmoAK49A" length="30">
      <transcript>
        <text start="0" dur="6">Now we&amp;#39;re down to a network with a single node, T, L,</text>
        <text start="6" dur="6">with this joint probability table, and the only operation we have left to do</text>
        <text start="12" dur="5">is to sum out to give us a node with just L in it.</text>
        <text start="17" dur="9">So, the question is to compute P(L) for both values of L,</text>
        <text start="26" dur="4">+l and -l.</text>
      </transcript>
    </video>
    <video title="4e Answer" id="3lqdPCE-sg8" length="20">
      <transcript>
        <text start="0" dur="3">The answer is that the +l values,</text>
        <text start="3" dur="8">0.051 plus 0.083 equals 0.134.</text>
        <text start="11" dur="4">And the negative values, 0.119 plus 0.747</text>
        <text start="15" dur="5">equals 0.886.</text>
      </transcript>
    </video>
    <video title="4f Summary" id="hDdAZG4w5kA" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="4f Summary" id="-sFOKd_ZEJ8" length="21">
      <transcript>
        <text start="0" dur="3">So, that&amp;#39;s how variable elimination works.</text>
        <text start="3" dur="3">It&amp;#39;s a continued process of joining together factors</text>
        <text start="6" dur="5">to form a larger factor and then eliminating variables by summing out.</text>
        <text start="11" dur="4">If we make a good choice of the order in which we apply these operations,</text>
        <text start="15" dur="3">then variable elimination can be much more efficient</text>
        <text start="18" dur="3">than just doing the whole enumeration.</text>
      </transcript>
    </video>
    <video title="5 Approximate Inference Sampling" id="W5g-4a2PIcI" length="128">
      <transcript>
        <text start="0" dur="7">Now I want to talk about approximate inference</text>
        <text start="7" dur="5">by means of sampling.</text>
        <text start="12" dur="2">What do I mean by that?</text>
        <text start="14" dur="3">Say we want to deal with a joint probability distribution,</text>
        <text start="17" dur="7">say the distribution of heads and tails over these 2 coins.</text>
        <text start="24" dur="6">We can build a table and then start counting by sampling.</text>
        <text start="30" dur="2">Here we have our first sample.</text>
        <text start="32" dur="3">We flip the coins and the one-cent piece came up heads,</text>
        <text start="35" dur="4">and the five-cent piece came up tails,</text>
        <text start="39" dur="3">so we would mark down one count.</text>
        <text start="42" dur="3">Then we&amp;#39;d toss them again.</text>
        <text start="45" dur="5">This time the five cents is heads, and the one cent is tails,</text>
        <text start="50" dur="10">so we put down a count there, and we&amp;#39;d repeat that process</text>
        <text start="60" dur="6">and keep repeating it until we got enough counts that we could estimate</text>
        <text start="66" dur="5">the joint probability distribution by looking at the counts.</text>
        <text start="71" dur="4">Now, if we do a small number of samples, the counts might not be very accurate.</text>
        <text start="75" dur="4">There may be some random variation that causes them not to converge</text>
        <text start="79" dur="4">to their true values, but as we add more counts,</text>
        <text start="83" dur="2">the counts--as we add more samples,</text>
        <text start="85" dur="4">the counts we get will come closer to the true distribution.</text>
        <text start="89" dur="6">Thus, sampling has an advantage over inference in that we know a procedure</text>
        <text start="95" dur="7">for coming up with at least an approximate value for the joint probability distribution,</text>
        <text start="102" dur="8">as opposed to exact inference, where the computation may be very complex.</text>
        <text start="110" dur="3">There&amp;#39;s another advantage to sampling, which is if we don&amp;#39;t know</text>
        <text start="113" dur="6">what the conditional probability tables are, as we did in our other models,</text>
        <text start="119" dur="5">if we don&amp;#39;t know these numeric values, but we can simulate the process,</text>
        <text start="124" dur="4">we can still proceed with sampling, whereas we couldn&amp;#39;t with exact inference.</text>
      </transcript>
    </video>
    <video title="6 Sampling Example" id="mXgfRvRmDFI" length="135">
      <transcript>
        <text start="0" dur="5">Here&amp;#39;s a new network that we&amp;#39;ll use to investigate</text>
        <text start="5" dur="5">how sampling can be used to do inference.</text>
        <text start="10" dur="4">In this network, we have 4 variables. They&amp;#39;re all boolean.</text>
        <text start="14" dur="3">Cloudy tells us if it&amp;#39;s cloudy or not outside,</text>
        <text start="17" dur="4">and that can have an effect on whether the sprinklers are turned on,</text>
        <text start="21" dur="2">and whether it&amp;#39;s raining.</text>
        <text start="23" dur="5">And those 2 variables in turn have an effect on whether the grass gets wet.</text>
        <text start="28" dur="6">Now, to do inference over this network using sampling,</text>
        <text start="34" dur="4">we start off with a variable where all the parents are defined.</text>
        <text start="38" dur="4">In this case, there&amp;#39;s only one such variable, Cloudy.</text>
        <text start="42" dur="6">And it&amp;#39;s conditional probability table tells us that the probability is 50% for Cloudy,</text>
        <text start="48" dur="4">50% for not Cloudy, and so we sample from that.</text>
        <text start="52" dur="7">We generate a random number, and let&amp;#39;s say it comes up with positive for Cloudy.</text>
        <text start="59" dur="3">Now that variable is defined, we can choose another variable.</text>
        <text start="62" dur="6">In this case, let&amp;#39;s choose Sprinkler, and we look at the rows in the table</text>
        <text start="68" dur="5">for which Cloudy, the parent, is positive, and we see we should sample</text>
        <text start="73" dur="6">with probability 10% to +s and 90% a -s.</text>
        <text start="79" dur="4">And so let&amp;#39;s say we do that sampling with a random number generator,</text>
        <text start="83" dur="3">and it comes up negative for Sprinkler.</text>
        <text start="86" dur="3">Now let&amp;#39;s jump over here. Look at the Rain variable.</text>
        <text start="89" dur="5">Again, the parent, Cloudy, is positive,</text>
        <text start="94" dur="4">so we&amp;#39;re looking at this part of the table.</text>
        <text start="98" dur="3">We get a 0.8 probability for Rain being positive,</text>
        <text start="101" dur="3">and a 0.2 probability for Rain being negative.</text>
        <text start="104" dur="7">Let&amp;#39;s say we sample that randomly, and it comes up Rain is positive.</text>
        <text start="111" dur="3">And now we&amp;#39;re ready to sample the final variable,</text>
        <text start="114" dur="7">and what I want  you to do is tell me which of the rows</text>
        <text start="121" dur="6">of this table should we be considering and tell me what&amp;#39;s more likely.</text>
        <text start="127" dur="8">Is it more likely that we have a +w or a -w?</text>
      </transcript>
    </video>
    <video title="6a Sampling Example" id="K1ZyqpTJPK0" length="65">
      <transcript>
        <text start="0" dur="3">The answer to the question is that we look at the parents.</text>
        <text start="3" dur="3">We find that the Sprinkler variable is negative,</text>
        <text start="6" dur="3">so we&amp;#39;re looking at this part of the table.</text>
        <text start="9" dur="5">And the Rain variable is positive, so we&amp;#39;re looking at this part.</text>
        <text start="14" dur="4">So, it would be these 2 rows that we would consider,</text>
        <text start="18" dur="7">and thus, we&amp;#39;d find there&amp;#39;s a 0.9 probability for w, the grass being wet,</text>
        <text start="25" dur="3">and only 0.1 for it being negative,</text>
        <text start="28" dur="3">so the positive is more likely.</text>
        <text start="31" dur="3">And once we&amp;#39;ve done that, then we generated a complete sample,</text>
        <text start="34" dur="3">and we can write down the sample here.</text>
        <text start="37" dur="6">We had +c, -s, +r.</text>
        <text start="43" dur="8">And assuming we got a probability of 0.9 came out in favor of the +w,</text>
        <text start="51" dur="3">that would be the end of the sample.</text>
        <text start="54" dur="5">Then we could throw all this information out and start over again</text>
        <text start="59" dur="6">by having another 50/50 choice for cloudy and then working our way through the network.</text>
      </transcript>
    </video>
    <video title="6b More Sampling" id="fChe7bVEdHQ" length="111">
      <transcript>
        <text start="0" dur="4">Now, the probability of sampling a particular variable,</text>
        <text start="4" dur="6">choosing a +w or a -w, depends on the values of the parents.</text>
        <text start="10" dur="4">But those are chosen according to the conditional probability tables,</text>
        <text start="14" dur="4">so in the limit, the count of each sampled variable</text>
        <text start="18" dur="2">will approach the true probability.</text>
        <text start="20" dur="4">That is, with an infinite number of samples, this procedure computes the true</text>
        <text start="24" dur="3">joint probability distribution.</text>
        <text start="27" dur="6">We say that the sampling method is consistent.</text>
        <text start="33" dur="5">We can use this kind of sampling to compute the complete joint probability distribution,</text>
        <text start="38" dur="5">or we can use it to compute a value for an individual variable.</text>
        <text start="43" dur="4">But what if we wanted to compute a conditional probability?</text>
        <text start="47" dur="6">Say we wanted to compute the probability of wet grass</text>
        <text start="53" dur="5">given that it&amp;#39;s not cloudy.</text>
        <text start="58" dur="5">To do that, the sample that we generated here wouldn&amp;#39;t be helpful at all</text>
        <text start="63" dur="5">because it has to do with being cloudy, not with being not cloudy.</text>
        <text start="68" dur="3">So, we would cross this sample off the list.</text>
        <text start="71" dur="6">We would say that we reject the sample, and this technique is called rejection sampling.</text>
        <text start="77" dur="4">We go through ignoring any samples that don&amp;#39;t match</text>
        <text start="81" dur="3">the conditional probabilities that we&amp;#39;re interested in</text>
        <text start="84" dur="10">and keeping samples that do, say the sample -c, +s, +r, -w.</text>
        <text start="94" dur="3">We would just continue going through generating samples,</text>
        <text start="97" dur="4">crossing off the ones that don&amp;#39;t match, keeping the ones that do.</text>
        <text start="101" dur="5">And this procedure would also be consistent.</text>
        <text start="106" dur="5">We call this procedure rejection sampling.</text>
      </transcript>
    </video>
    <video title="7 Rejection Sampling" id="9IdjpH4xkGM" length="119">
      <transcript>
        <text start="0" dur="3">But there&amp;#39;s a problem with rejection sampling.</text>
        <text start="3" dur="5">If the evidence is unlikely, you end up rejecting a lot of the samples.</text>
        <text start="8" dur="8">Let&amp;#39;s go back to the alarm network where we had variables for burglary and for an alarm</text>
        <text start="16" dur="6">and say when arrested, in computing the probability of a burglary,</text>
        <text start="22" dur="3">given that the alarm goes off.</text>
        <text start="25" dur="3">The problem is that burglaries are very infrequent,</text>
        <text start="28" dur="4">so most of the samples we would get would end up being--</text>
        <text start="32" dur="7">we start with generating a B, and we get a -b and then a -a.</text>
        <text start="39" dur="4">We go back and say does this match?</text>
        <text start="43" dur="2">No, we have to reject this sample,</text>
        <text start="45" dur="5">so we generate another sample, and we get another -b, -a.</text>
        <text start="50" dur="4">We reject that. We get another -b, -a.</text>
        <text start="54" dur="6">And we keep rejecting, and eventually we get a +b,</text>
        <text start="60" dur="4">but we&amp;#39;d end up spending a lot of time rejecting samples.</text>
        <text start="64" dur="9">So, we&amp;#39;re going to introduce a new method called likelihood weighting</text>
        <text start="73" dur="4">that generates samples so that we can keep every one.</text>
        <text start="77" dur="3">With likelihood weighting, we fix the evidence variables.</text>
        <text start="80" dur="5">That is, we say that A will always be positive,</text>
        <text start="85" dur="3">and then we sample the rest of the variables,</text>
        <text start="88" dur="3">so then we get samples that we want.</text>
        <text start="91" dur="6">We would get a list like -b, +a,</text>
        <text start="97" dur="3">-b, +a,</text>
        <text start="100" dur="2">+b, +a.</text>
        <text start="102" dur="4">We get to keep every sample, but we have a problem.</text>
        <text start="106" dur="6">The resulting set of samples is inconsistent.</text>
        <text start="112" dur="4">We can fix that, however, by assigning a probability</text>
        <text start="116" dur="3">to each sample and weighing them correctly.</text>
      </transcript>
    </video>
    <video title="8 Likelihood Weighting" id="GYcIruSqT_k" length="115">
      <transcript>
        <text start="0" dur="5">In likelihood weighting, we&amp;#39;re going to be collecting samples just like before,</text>
        <text start="5" dur="6">but we&amp;#39;re going to add a probabilistic weight to each sample.</text>
        <text start="11" dur="6">Now, let&amp;#39;s say we want to compute the probability of rain</text>
        <text start="17" dur="5">given that the sprinklers are on, and the grass is wet.</text>
        <text start="22" dur="2">We start as before.</text>
        <text start="24" dur="6">We make a choice for Cloudy, and let&amp;#39;s say that, again,</text>
        <text start="30" dur="3">we choose Cloudy being positive.</text>
        <text start="33" dur="4">Now we want to make a choice for Sprinkler,</text>
        <text start="37" dur="4">but we&amp;#39;re constrained to always choose Sprinkler being positive,</text>
        <text start="41" dur="3">so we&amp;#39;ll make that choice.</text>
        <text start="44" dur="6">And we know we were dealing with Cloudy being positive,</text>
        <text start="50" dur="6">so we&amp;#39;re in this row, and we&amp;#39;re forced to make the choice of Sprinkler being positive,</text>
        <text start="56" dur="9">and that has a probability of only 0.1, so we&amp;#39;ll put that 0.1 into the weight.</text>
        <text start="65" dur="4">Next, we&amp;#39;ll look at the Rain variable,</text>
        <text start="69" dur="4">and here we&amp;#39;re not constrained in any way, so we make a choice</text>
        <text start="73" dur="6">according to the probability tables with Cloudy being positive.</text>
        <text start="79" dur="8">And let&amp;#39;s say that we choose the more popular choice, and Rain gets the positive value.</text>
        <text start="87" dur="3">Now, we look at Wet Grass.</text>
        <text start="90" dur="5">We&amp;#39;re constrained to choose positive, and we know that the parents</text>
        <text start="95" dur="6">are also positive, so we&amp;#39;re dealing with this row here.</text>
        <text start="101" dur="6">Since it&amp;#39;s a constrained choice, we&amp;#39;re going to add in or multiply in an additional weight,</text>
        <text start="107" dur="8">and I want you to tell me what that weight should be.</text>
      </transcript>
    </video>
    <video title="8a Answer" id="hvIL_fFvUGM" length="37">
      <transcript>
        <text start="0" dur="4">The answer is we&amp;#39;re looking for the probability</text>
        <text start="4" dur="5">of having a +w given a +s and a +r,</text>
        <text start="9" dur="7">so that&amp;#39;s in this row, so it&amp;#39;s 0.99.</text>
        <text start="16" dur="6">So, we take our old weight and multiply it by 0.99,</text>
        <text start="22" dur="6">gives us a final weight of 0.099</text>
        <text start="28" dur="9">for a sample of +c, +s, +r and +w.</text>
      </transcript>
    </video>
    <video title="8b Likelihood Weighting is Consistent" id="jKcp0uQ_rUo" length="20">
      <transcript>
        <text start="0" dur="3">When we include the weights,</text>
        <text start="3" dur="5">counting this sample that was forced to have a +s and a +w</text>
        <text start="8" dur="6">with a weight of 0.099, instead of counting it as a full one sample,</text>
        <text start="14" dur="6">we find that likelihood weighting is also consistent.</text>
      </transcript>
    </video>
    <video title="8c Likelihood Weighting Problems" id="ngGCGaIEvBU" length="56">
      <transcript>
        <text start="0" dur="3">Likelihood weighting is a great technique,</text>
        <text start="3" dur="2">but it doesn&amp;#39;t solve all our problems.</text>
        <text start="5" dur="9">Suppose we wanted to compute the probability of C given +s and +r.</text>
        <text start="14" dur="7">In other words, we&amp;#39;re constraining Sprinkler and Rain to always be positive.</text>
        <text start="21" dur="6">Since we use the evidence when we generate a node that has that evidence as parents,</text>
        <text start="27" dur="4">the Wet Grass node will always get good values based on that evidence.</text>
        <text start="31" dur="8">But the Cloudy node won&amp;#39;t, and so it will be generating values at random</text>
        <text start="39" dur="5">without looking at these values, and most of the time, or some of the time,</text>
        <text start="44" dur="4">it will be generating values that don&amp;#39;t go well with the evidence.</text>
        <text start="48" dur="3">Now, we won&amp;#39;t have to reject them like we do in rejection sampling,</text>
        <text start="51" dur="5">but they&amp;#39;ll have a low probability associated with them.</text>
      </transcript>
    </video>
    <video title="9 Gibbs Sampling" id="QaojSzk7Hpw" length="110">
      <transcript>
        <text start="0" dur="7">A technique called Gibbs sampling,</text>
        <text start="7" dur="3">named after the physicist Josiah Gibbs,</text>
        <text start="10" dur="4">takes all the evidence into account and not just the upstream evidence.</text>
        <text start="14" dur="12">It uses a method called Markov Chain Monte Carlo, or MCMC.</text>
        <text start="26" dur="5">The idea is that we resample just one variable at a time</text>
        <text start="31" dur="2">conditioned on all the others.</text>
        <text start="33" dur="4">That is, we have a set of variables,</text>
        <text start="37" dur="7">and we initialize them to random variables, keeping the evidence values fixed.</text>
        <text start="44" dur="4">Maybe we have values like this,</text>
        <text start="48" dur="6">and that constitutes one sample, and now, at each iteration through the loop,</text>
        <text start="54" dur="7">we select just one non-evidence variable and resample it</text>
        <text start="61" dur="3">based on all the other variables.</text>
        <text start="64" dur="7">And that will give us another sample, and repeat that again.</text>
        <text start="71" dur="4">Choose another variable.</text>
        <text start="75" dur="6">Resample that variable and repeat.</text>
        <text start="81" dur="6">We end up walking around in this space of assignments of variables randomly.</text>
        <text start="87" dur="3">Now, in rejection and likelihood sampling,</text>
        <text start="90" dur="4">each sample was independent of the other samples.</text>
        <text start="94" dur="3">In MCMC, that&amp;#39;s not true.</text>
        <text start="97" dur="3">The samples are dependent on each other, and in fact,</text>
        <text start="100" dur="2">adjacent samples are very similar.</text>
        <text start="102" dur="4">They only vary or differ in one place.</text>
        <text start="106" dur="4">However, the technique is still consistent. We won&amp;#39;t show the proof for that.</text>
      </transcript>
    </video>
    <video title="10 Monty Hall Problem" id="6uF6Fh0qpV0" length="79">
      <transcript>
        <text start="0" dur="2">Now, just one more thing.</text>
        <text start="2" dur="5">I can&amp;#39;t help but describe what is probably the most famous probability problem of all.</text>
        <text start="7" dur="4">It&amp;#39;s called the Monty Hall Problem after the game show host.</text>
        <text start="11" dur="4">And the idea is that  you&amp;#39;re on a game show, and there&amp;#39;s 3 doors:</text>
        <text start="15" dur="5">door #1, door #2, and door #3.</text>
        <text start="20" dur="6">And behind each door is a prize, and you know that one of the doors</text>
        <text start="26" dur="3">contains an expensive sports car, which  you would find desirable,</text>
        <text start="29" dur="6">and the other 2 doors contain a goat, which you would find less desirable.</text>
        <text start="35" dur="7">Now, say you&amp;#39;re given a choice, and let&amp;#39;s say you choose door #1.</text>
        <text start="42" dur="5">But according to the conventions of the game, the host, Monty Hall,</text>
        <text start="47" dur="5">will now open one of the doors, knowing that the door that he opens</text>
        <text start="52" dur="5">contains a goat, and he shows you door #3.</text>
        <text start="57" dur="5">And he now gives you the opportunity to stick with your choice</text>
        <text start="62" dur="3">or to switch to the other door.</text>
        <text start="65" dur="5">What I want you to tell me is, what is your probability of winning</text>
        <text start="70" dur="5">if you stick to door #1, and what is the probability of winning</text>
        <text start="75" dur="4">if you switched to door #2?</text>
      </transcript>
    </video>
    <video title="10a Answer" id="x7x6nHvQEQ4" length="105">
      <transcript>
        <text start="0" dur="8">The answer is that you have a 1/3 chance of winning if you stick with door #1</text>
        <text start="8" dur="4">and a 2/3 chance if  you switch to door #2.</text>
        <text start="12" dur="4">How do we explain that, and why isn&amp;#39;t it 50/50?</text>
        <text start="16" dur="2">Well, it&amp;#39;s true that there&amp;#39;s 2 possibilities,</text>
        <text start="18" dur="4">but we&amp;#39;ve learned from probability that just because there are 2 options</text>
        <text start="22" dur="4">doesn&amp;#39;t mean that both options are equally likely.</text>
        <text start="26" dur="4">It&amp;#39;s easier to explain why the first door has a 1/3 probability</text>
        <text start="30" dur="4">because when you started, the car could be in any one of 3 places.</text>
        <text start="34" dur="3">You chose one of them. That probability was 1/3.</text>
        <text start="37" dur="6">And that probability hasn&amp;#39;t been changed by the revealing of one of the other doors.</text>
        <text start="43" dur="2">Why is door #2 two-thirds?</text>
        <text start="45" dur="4">Well, one way to explain it is that the probability has to sum to 1,</text>
        <text start="49" dur="4">and if 1/3 is here, the 2/3 has to be here.</text>
        <text start="53" dur="5">But why doesn&amp;#39;t the same argument that you use for 1 hold for 2?</text>
        <text start="58" dur="5">Why can&amp;#39;t we say the probability of 2 holding the car</text>
        <text start="63" dur="4">was 1/3 before this door was revealed?</text>
        <text start="67" dur="4">Why has that changed 2 and has not changed 1?</text>
        <text start="71" dur="3">And the reason is because we&amp;#39;ve learned something about door #2.</text>
        <text start="74" dur="4">We&amp;#39;ve learned that it wasn&amp;#39;t the door that was flipped over by the host,</text>
        <text start="78" dur="4">and so that additional information has updated the probability,</text>
        <text start="82" dur="4">whereas we haven&amp;#39;t learned anything additional about door #1</text>
        <text start="86" dur="4">because it was never an option that the host might switch door #1.</text>
        <text start="90" dur="7">And in fact, in this case, if we reveal the door,</text>
        <text start="97" dur="3">we find that&amp;#39;s where the car actually is.</text>
        <text start="100" dur="5">So you see, learning probability may end up winning you something.</text>
      </transcript>
    </video>
    <video title="10b Monty Hall Letter" id="CIrfGiP65UI" length="44">
      <transcript>
        <text start="0" dur="7">Now, as a final epilogue, I have here a copy of a letter written by Monty Hall himself</text>
        <text start="7" dur="3">in 1990 to Professor Lawrence Denenberg of Harvard</text>
        <text start="10" dur="4">who, with Harry Lewis, wrote a statistics book</text>
        <text start="14" dur="4">in which they used the Monty Hall Problem as an example,</text>
        <text start="18" dur="5">and they wrote to Monty asking him for permission to use his name.</text>
        <text start="23" dur="3">Monty kindly granted the permission, but in his letter,</text>
        <text start="26" dur="5">he writes, &amp;quot;As I see it, it wouldn&amp;#39;t make any difference after the player</text>
        <text start="31" dur="3">has selected Door A, and having been shown Door C--</text>
        <text start="34" dur="4">why should he then attempt to switch to Door B?</text>
        <text start="38" dur="6">So, we see Monty Hall himself did not understand the Monty Hall Problem.</text>
      </transcript>
    </video>
  </group>
  <group title="Homework 2" count="12">
    <video title="Bayes Rule" id="_fJTJNK9ejY" length="16">
      <transcript>
        <text start="0" dur="6">[Thrun] Given the following Bayes network with P of A equal to 0.5,</text>
        <text start="6" dur="2">P of B given the A equals 0.2,</text>
        <text start="8" dur="4">and P of B given not A 0.8,</text>
        <text start="12" dur="4">calculate the following probability.</text>
      </transcript>
    </video>
    <video title="Simple Bayes Net" id="f6mq9rTj-Po" length="42">
      <transcript>
        <text start="0" dur="3">[Thrun] Consider a network of the following type:</text>
        <text start="3" dur="7">a variable, A, that is binary connects to three variables, X1, X2, and X3,</text>
        <text start="10" dur="2">that are also binary.</text>
        <text start="12" dur="12">The probability of A is 0.5, and for all variable XI we have the probability of XI given A is 0.2,</text>
        <text start="24" dur="5">and the probability of XI given not A equals 0.6.</text>
        <text start="29" dur="2">I would like to know from you the probability of A</text>
        <text start="31" dur="6">given that we observed X1, X2, and not X3.</text>
        <text start="37" dur="5">Notice that these variables over here are conditionally independent given A.</text>
      </transcript>
    </video>
    <video title="Simple Bayes Net 2 " id="P6WEObhmL_o" length="10">
      <transcript>
        <text start="0" dur="3">[Thrun] Let us consider the same network again.</text>
        <text start="3" dur="7">I would like to know the probability of X3 given that I observed X1.</text>
      </transcript>
    </video>
    <video title="Conditional Independence " id="pP7U6KIO9yE" length="29">
      <transcript>
        <text start="0" dur="4">[Thrun] In this next homework assignment I will be drawing you a Bayes network</text>
        <text start="4" dur="5">and will ask you some conditional independence questions.</text>
        <text start="9" dur="5">Is B conditionally independent of C? And say yes or no.</text>
        <text start="14" dur="5">Is B conditionally independent of C given D? And say yes or no.</text>
        <text start="19" dur="5">Is B conditionally independent of C given A? And say yes or no.</text>
        <text start="24" dur="5">And is B conditionally independent given A and D? And say yes or no.</text>
      </transcript>
    </video>
    <video title="Conditional Indepedence 2 " id="LMKW60DmJtc" length="28">
      <transcript>
        <text start="0" dur="2">[Thrun] Consider the following network.</text>
        <text start="2" dur="6">I would like to know whether the following statements are true or false.</text>
        <text start="8" dur="4">C is conditionally independent of E given A.</text>
        <text start="12" dur="6">B is conditionally independent of D given C and E.</text>
        <text start="18" dur="3">A is conditionally independent of C given E.</text>
        <text start="21" dur="4">And A is conditionally independent of C given B.</text>
        <text start="25" dur="3">Please check yes or no for each of these questions.</text>
      </transcript>
    </video>
    <video title="Parameter Count " id="8npZMwT0Sac" length="17">
      <transcript>
        <text start="0" dur="4">[Thrun] In my final question I&amp;#39;ll look at the exact same network as before,</text>
        <text start="4" dur="4">but I would like to know the minimum number of numerical parameters</text>
        <text start="8" dur="5">such as the values to define probabilities and conditional probabilities</text>
        <text start="13" dur="4">that are necessary to specify the joint distribution of all 5 variables.</text>
      </transcript>
    </video>
    <video title="1 ANSWER" id="RvxL71wd2Zg" length="36">
      <transcript>
        <text start="0" dur="3">[Thrun] The answer is 0.2,</text>
        <text start="3" dur="4">and this follows directly from Bayes&amp;#39; rule.</text>
        <text start="7" dur="4">In this formula, we can read off the first 2 values straight from the table over here,</text>
        <text start="11" dur="4">and we expand the denominator by total probability.</text>
        <text start="15" dur="4">Observing that this is exactly the same expression as up here,</text>
        <text start="19" dur="8">we get 0.1 divided by 0.1 plus this expression over here can be copied from over here,</text>
        <text start="27" dur="3">and P of not A is directly obtained up here.</text>
        <text start="30" dur="6">Hence we get 0.5 over here, and as a result we get 0.2.</text>
      </transcript>
    </video>
    <video title="2 ANSWER" id="nQxYA7vBbJc" length="196">
      <transcript>
        <text start="0" dur="3">[Thrun] For this question we will be exploring a little trick</text>
        <text start="3" dur="2">about non-normalized probability.</text>
        <text start="5" dur="6">We will observe that P of A given X1, X2 and not X3,</text>
        <text start="11" dur="5">the expression on the left can be resolved by Bayes&amp;#39; rule into this expression over here.</text>
        <text start="16" dur="4">We will take X3 to the left and replace it by A,</text>
        <text start="20" dur="3">both conditioned on the variables X1 and X2.</text>
        <text start="23" dur="6">Then we have PA given X1, X2 divided by P not X3, X1, X2.</text>
        <text start="29" dur="2">Next we employ 2 things.</text>
        <text start="31" dur="3">One is the denominator does not depend on A,</text>
        <text start="34" dur="5">so whether I put an A or not A has no bearing on any calculation here,</text>
        <text start="39" dur="5">which means I can defer its calculation until later, and it will turn out to be important.</text>
        <text start="44" dur="5">So I&amp;#39;m going to be proportional to just the stuff over here.</text>
        <text start="49" dur="3">And second, I export my conditional independence</text>
        <text start="52" dur="6">whereby I can omit X1 and X2 from the probability of not X3 conditioned on A.</text>
        <text start="58" dur="4">These variables are conditionally independent.</text>
        <text start="62" dur="3">This gives me the following recursion</text>
        <text start="65" dur="5">where I now removed the third variable from the estimation problem</text>
        <text start="70" dur="4">and just retained the first 2 relative to my initial expression.</text>
        <text start="74" dur="5">If I keep expanding this, I get the following solution.</text>
        <text start="79" dur="8">P of not X3 given A, P X2 given A, P X1 given A times P of A.</text>
        <text start="87" dur="3">You might take a minute to just verify this,</text>
        <text start="90" dur="2">but this is exploiting the conditional independence</text>
        <text start="92" dur="3">very much as in the first step I showed you over here.</text>
        <text start="95" dur="3">This step lacks the normalizer,</text>
        <text start="98" dur="6">so let me work on the normalizer by expressing the opposite probability,</text>
        <text start="104" dur="6">P of not A given the same events, X1, X2, and not X3,</text>
        <text start="110" dur="4">which resolves to P of not X3 given not A,</text>
        <text start="114" dur="6">P of X2 given not A, P of X1 given not A,</text>
        <text start="120" dur="2">and P of not A.</text>
        <text start="122" dur="2">I can now plug in the values from above.</text>
        <text start="124" dur="11">So the first term gives me 0.8 times 0.2 times 0.2 times 0.5.</text>
        <text start="135" dur="9">In the second term I get 0.4 times 0.6 times 0.6 times 0.5,</text>
        <text start="144" dur="7">which resolves to 0.016 and 0.072.</text>
        <text start="151" dur="5">This is clearly not a probability because we left out the normalizer.</text>
        <text start="156" dur="4">But as we know, the normalizer does not depend on whether I put A or not A in here.</text>
        <text start="160" dur="4">As a result, it will be the same for both of these expressions,</text>
        <text start="164" dur="3">and I can obtain it by just adding these non-normalized probabilities</text>
        <text start="167" dur="5">and then subsequently divide these non-normalized probabilities accordingly.</text>
        <text start="172" dur="3">So let me just do this.</text>
        <text start="175" dur="6">We get for the desired probability over here 0.1818</text>
        <text start="181" dur="7">and for the inverse probability over here 0.8182.</text>
        <text start="188" dur="6">Our desired answer therefore is 0.1818.</text>
        <text start="194" dur="2">This was not an easy question.</text>
      </transcript>
    </video>
    <video title="3 ANSWER" id="O4UT5ozSRGI" length="101">
      <transcript>
        <text start="0" dur="3">[Thrun] The answer is a little bit involved.</text>
        <text start="3" dur="5">We use total probability to re-express this by bringing in A.</text>
        <text start="8" dur="7">P of X3 given X1 is the sum of P of X3 given X1 and A</text>
        <text start="15" dur="7">times P of A given X1 plus the A complement, which is X3, conditional X1 and not A</text>
        <text start="22" dur="2">times P of not A given X1.</text>
        <text start="24" dur="2">That is just total probability.</text>
        <text start="26" dur="4">Next we utilized conditional independence by which we can simplify this expression</text>
        <text start="30" dur="3">to drop X1 in the conditional variables</text>
        <text start="33" dur="3">and we transform this expression by Bayes&amp;#39; rule again.</text>
        <text start="36" dur="5">The same applies to the right side with not A replacing A.</text>
        <text start="41" dur="4">All of those expressions over here can be found</text>
        <text start="45" dur="4">either in the table up there or just by their complements,</text>
        <text start="49" dur="3">with the exception of P of X1.</text>
        <text start="52" dur="6">But P of X1 can again be just obtained by total probability,</text>
        <text start="58" dur="13">which resolves to 0.2 times 0.5 plus 0.6 times 0.5,</text>
        <text start="71" dur="2">which gives me 0.4.</text>
        <text start="73" dur="6">We are now in a position to calculate the last term over here, which goes as follows.</text>
        <text start="79" dur="17">This expression is 0.2 times 0.2 times 0.5 over 0.4 plus 0.6 times 0.6 times 0.5 over 0.4,</text>
        <text start="96" dur="5">which gives us as a final result 0.5.</text>
      </transcript>
    </video>
    <video title="4 ANSWER" id="fksN-k4n_OM" length="46">
      <transcript>
        <text start="0" dur="2">[Thrun] And the answer is as follows.</text>
        <text start="2" dur="4">No, no, yes, and no.</text>
        <text start="6" dur="5">B and C in the absence of any other information are dependent through A,</text>
        <text start="11" dur="6">which is if you learn something about B, you can infer something about A,</text>
        <text start="17" dur="3">and then we&amp;#39;ll know more about C.</text>
        <text start="20" dur="2">If you know D, that doesn&amp;#39;t change a thing.</text>
        <text start="22" dur="2">You can just take D out of the pool.</text>
        <text start="24" dur="5">If you know A, B and C become conditionally independent.</text>
        <text start="29" dur="7">This dependence goes away, and ignorance of D doesn&amp;#39;t render B and C dependent.</text>
        <text start="36" dur="3">However, if we add D back to the mix,</text>
        <text start="39" dur="7">then knowledge of D will render B and C dependent by way of the explaining away effect.</text>
      </transcript>
    </video>
    <video title="5 ANSWER" id="jvOJ-6tF5y8" length="54">
      <transcript>
        <text start="0" dur="3">[Thrun] So the correct answer is tricky in this case.</text>
        <text start="3" dur="4">It is no, no, no, and yes.</text>
        <text start="7" dur="2">The first one is straightforward.</text>
        <text start="9" dur="4">C and E are conditionally independent based on D,</text>
        <text start="13" dur="2">and knowledge of A doesn&amp;#39;t change anything.</text>
        <text start="15" dur="5">B and D are conditionally independent through A,</text>
        <text start="20" dur="3">and knowledge of C or E doesn&amp;#39;t change that.</text>
        <text start="23" dur="2">A and C is interesting.</text>
        <text start="25" dur="4">A and C is independent. But if you know D, they become dependent.</text>
        <text start="29" dur="3">It turns out if you know E, you can know something about D,</text>
        <text start="32" dur="5">and as a result, A and C become dependent through the explain away effect.</text>
        <text start="37" dur="2">That doesn&amp;#39;t apply if you know B.</text>
        <text start="39" dur="3">Even though B tells you something about E,</text>
        <text start="42" dur="4">it tells you nothing about D because B and D are independent.</text>
        <text start="46" dur="3">Therefore, knowing B tells you nothing about D,</text>
        <text start="49" dur="3">and the explain away effect does not occur between A and C.</text>
        <text start="52" dur="2">The answer here is yes.</text>
      </transcript>
    </video>
    <video title="6 ANSWER" id="PEK4_jQnW10" length="37">
      <transcript>
        <text start="0" dur="3">[Thrun] The correct answer is 16.</text>
        <text start="3" dur="3">The probability of A and C require 1 parameter each.</text>
        <text start="6" dur="6">The complement of not A and not C follows by 1 minus that parameter.</text>
        <text start="12" dur="3">This guy over here requires 2 parameters.</text>
        <text start="15" dur="3">You need to know the probability of B given A and B given not A.</text>
        <text start="18" dur="2">The complements can be obtained easily.</text>
        <text start="20" dur="4">The probability of D is conditioned on 2 variables which can take 4 possible values.</text>
        <text start="24" dur="2">Hence the number is 4.</text>
        <text start="26" dur="4">And E is conditioned on 3 variables, so it can take a total of 8 different values,</text>
        <text start="30" dur="2">2 to the 3rd, which is 8.</text>
        <text start="32" dur="5">If you add 8 plus 4 plus 2 plus 1 plus 1, you get 16.</text>
      </transcript>
    </video>
  </group>
  <group title="Unit 5" count="55">
    <video title="1 Introduction" id="8o1fAcyhap4" length="71">
      <transcript>
        <text start="0" dur="3">Welcome to the machine learning unit.</text>
        <text start="3" dur="3">Machine learning is a fascinating area.</text>
        <text start="6" dur="3">The world has become immeasurably data-rich.</text>
        <text start="9" dur="3">The world wide web has come up over the last decade.</text>
        <text start="12" dur="3">The human genome is being sequenced.</text>
        <text start="15" dur="4">Vast chemical databases, pharmaceutical databases,</text>
        <text start="19" dur="3">and financial databases are now available</text>
        <text start="22" dur="4">on a scale unthinkable even 5 years ago.</text>
        <text start="26" dur="2">To make sense out of the data,</text>
        <text start="28" dur="2">to extract information from the data,</text>
        <text start="30" dur="3">machine learning is the discipline to go.</text>
        <text start="33" dur="4">Machine learning is an important subfeed of artificial intelligence,</text>
        <text start="37" dur="3">it&amp;#39;s my personal favorite next to robotics</text>
        <text start="40" dur="3">because I believe it has a huge impact on society</text>
        <text start="43" dur="4">and is absolutely necessary as we move forward.</text>
        <text start="47" dur="3">So in this class, I teach you some of the very basics of</text>
        <text start="50" dur="2">machine learning, and in our next unit</text>
        <text start="52" dur="4">Peter will tell you some more about machine learning.</text>
        <text start="56" dur="4">We&amp;#39;ll talk about supervised learning, which is one side of machine learning,</text>
        <text start="60" dur="2">and Peter will tell you about unsupervised learning,</text>
        <text start="62" dur="3">which is a different style.</text>
        <text start="65" dur="2">Later in this class we will also encounter reinforcement learning,</text>
        <text start="67" dur="3">which is yet another set of machine learning.</text>
        <text start="70" dur="1">Anyhow, let&amp;#39;s just dive in.</text>
      </transcript>
    </video>
    <video title="2 What is Machine Learning" id="tEzGdI9nQt4" length="113.076">
      <transcript>
        <text start="0" dur="3.999">Welcome to the first class on machine learning.</text>
        <text start="3.999" dur="3.575">So far we talked a lot about Bayes Networks.</text>
        <text start="7.574" dur="2.836">And the way we talked about them</text>
        <text start="10.41" dur="3.69">is all about reasoning within Bayes Networks</text>
        <text start="14.1" dur="0.982">that are known.</text>
        <text start="15.082" dur="2.035">Machine learning addresses the problem</text>
        <text start="17.117" dur="2.169">of how to find those networks</text>
        <text start="19.286" dur="0.867">or other models</text>
        <text start="20.153" dur="2.369">based on data.</text>
        <text start="22.522" dur="3.275">Learning models from data</text>
        <text start="25.797" dur="3.265">is a major, major area of artificial intelligence</text>
        <text start="29.062" dur="2.006">and it&amp;#39;s perhaps the one</text>
        <text start="31.068" dur="2.632">that had the most commercial success.</text>
        <text start="33.7" dur="3.304">In many commercial applications</text>
        <text start="37.004" dur="2.068">the models themselves are fitted</text>
        <text start="39.072" dur="1.402">based on data.</text>
        <text start="40.474" dur="1.702">For example, Google</text>
        <text start="42.176" dur="2.135">uses data to understand</text>
        <text start="44.311" dur="2.593">how to respond to each search query.</text>
        <text start="46.904" dur="2.379">Amazon uses data</text>
        <text start="49.283" dur="2.769">to understand how to place products on their website.</text>
        <text start="52.052" dur="1.635">And these machine learning techniques</text>
        <text start="53.687" dur="2.503">are the enabling techniques that make that possible.</text>
        <text start="56.19" dur="1.334">So this class</text>
        <text start="57.524" dur="1.635">which is about supervised learning</text>
        <text start="59.159" dur="3.37">will go through some very basic methods</text>
        <text start="62.529" dur="1.902">for learning models from data</text>
        <text start="64.431" dur="2.369">in particular, specific types of Bayes Networks.</text>
        <text start="66.8" dur="1.635">We will complement this</text>
        <text start="68.435" dur="2.435">with a class on unsupervised learning</text>
        <text start="70.87" dur="3.204">that will be taught next</text>
        <text start="74.074" dur="1.502">after this class.</text>
        <text start="75.576" dur="3.224">Let me start off with a quiz.</text>
        <text start="78.8" dur="1.814">The quiz is: What companies are famous</text>
        <text start="80.614" dur="3.503">for machine learning using data?</text>
        <text start="84.117" dur="5.533">Google for mining the web.</text>
        <text start="89.65" dur="1.953">Netflix for mining what people</text>
        <text start="91.603" dur="4.426">would like to rent on DVDs.</text>
        <text start="96.029" dur="4.605">Which is DVD recommendations.</text>
        <text start="100.634" dur="5.205">Amazon.com for product placement.</text>
        <text start="105.839" dur="2.102">Check any or all</text>
        <text start="107.941" dur="1.135">and if none of those apply</text>
        <text start="109.076" dur="4">check down here.</text>
      </transcript>
    </video>
    <video title="3 Answer" id="SnbvK3_ayWI" length="47">
      <transcript>
        <text start="0" dur="3">And, not surprisingly, the answer is</text>
        <text start="3" dur="3">all of those companies and many, many, many more</text>
        <text start="6" dur="3">use massive machine learning for making decisions</text>
        <text start="9" dur="3">that are really essential to the businesses.</text>
        <text start="12" dur="3">Google mines the web and uses machine learning for translation,</text>
        <text start="15" dur="3">as we&amp;#39;ve seen in the introductory level. Netflix has used</text>
        <text start="18" dur="4">machine learning extensively for understanding what type of DVD to recommend to you next.</text>
        <text start="22" dur="3">Amazon composes its entire product pages using</text>
        <text start="25" dur="3">machine learning by understanding how customers</text>
        <text start="28" dur="3">respond to different compositions and placements of their products,</text>
        <text start="31" dur="4">and many, many other examples exist.</text>
        <text start="35" dur="2">I would argue that in Silicon Valley,</text>
        <text start="37" dur="4">at least half the companies dealing with customers and online products</text>
        <text start="41" dur="2">do extensively use machine learning,</text>
        <text start="43" dur="4">so it makes machine learning a really exciting discipline.</text>
      </transcript>
    </video>
    <video title="4 Stanley DARPA Grand Challenge" id="Q1xFdQfq5Fk" length="93">
      <transcript>
        <text start="0" dur="5">In my own research, I&amp;#39;ve extensively used machine learning for robotics.</text>
        <text start="5" dur="3">What you see here is a robot my students and I built at Stanford</text>
        <text start="8" dur="4">called Stanley, and it won the DARPA Grand Challenge.</text>
        <text start="12" dur="4">It&amp;#39;s a self-driving car that drives without any human assistance whatsoever,</text>
        <text start="16" dur="5">and this vehicle extensively uses machine learning.</text>
        <text start="22" dur="3">The robot is equipped with a laser system</text>
        <text start="25" dur="3">I will talk more about lasers in my robotics class,</text>
        <text start="28" dur="3">but here you can see how the robot is able to build</text>
        <text start="31" dur="3">3-D models of the terrain ahead.</text>
        <text start="34" dur="3">These are almost like video game models that allow it to make</text>
        <text start="37" dur="2">assessments where to drive and where not to drive.</text>
        <text start="39" dur="4">Essentially, it&amp;#39;s trying to drive on flat ground.</text>
        <text start="43" dur="3">The problem with these lasers is that they don&amp;#39;t see very far.</text>
        <text start="46" dur="4">They see about 25 meters out, so to drive really fast</text>
        <text start="50" dur="3">the robot has to see further.</text>
        <text start="53" dur="3">This is where machine learning comes into play.</text>
        <text start="56" dur="2">What you see here is camera images delivered by the robot</text>
        <text start="58" dur="3">superimposed with laser data that doesn&amp;#39;t see very far,</text>
        <text start="61" dur="3">but the laser is good enough to extract samples</text>
        <text start="64" dur="4">of driveable road surface that can then be machine learned</text>
        <text start="68" dur="2">and extrapolated into the entire camera image.</text>
        <text start="70" dur="3">That enables the robot to use the camera</text>
        <text start="73" dur="3">to see driveable terrain all the way to the horizon</text>
        <text start="76" dur="6">up to like 200 meters out, enough to drive really, really fast.</text>
        <text start="82" dur="5">This ability to adapt its vision by driving its own training examples using lasers</text>
        <text start="87" dur="3">but seeing out 200 meters or more</text>
        <text start="90" dur="3">was a key factor in winning the race.</text>
      </transcript>
    </video>
    <video title="5 Taxonomy" id="m-hcAePIkWY" length="227.394">
      <transcript>
        <text start="0" dur="3.483">Machine learning is a very large field</text>
        <text start="3.483" dur="1.138">with many different methods</text>
        <text start="4.621" dur="1.652">and many different applications.</text>
        <text start="6.873" dur="3.576">I will now define some of the very basic terminology</text>
        <text start="10.449" dur="1.563">that is being used to distinguish</text>
        <text start="12.012" dur="1.301">different machine learning methods.</text>
        <text start="13.313" dur="4.471">Let&amp;#39;s start with the what.</text>
        <text start="17.784" dur="2.116">What is being learned?</text>
        <text start="19.9" dur="3.59">You can learn parameters</text>
        <text start="23.49" dur="2.603">like the probabilities of a Bayes Network.</text>
        <text start="26.093" dur="1.468">You can learn structure</text>
        <text start="27.561" dur="4.171">like the arc structure of a Bayes Network.</text>
        <text start="31.732" dur="2.369">And you might even discover hidden concepts.</text>
        <text start="34.401" dur="1.404">For example</text>
        <text start="35.805" dur="1.933">you might find that certain training example</text>
        <text start="37.738" dur="1.272">form a hidden group.</text>
        <text start="39.01" dur="2.064">For example Netflix</text>
        <text start="41.074" dur="2.58">you might find that there&amp;#39;s different types of customers</text>
        <text start="43.654" dur="1.927">some that care about classic movies</text>
        <text start="45.581" dur="1.566">some of them care about modern movies</text>
        <text start="47.147" dur="2.312">and those might form hidden concepts</text>
        <text start="49.459" dur="1.692">whose discovery can really help you</text>
        <text start="51.151" dur="2.169">make better sense of the data.</text>
        <text start="53.92" dur="3.571">Next is what from?</text>
        <text start="57.891" dur="2.225">Every machine learning method</text>
        <text start="60.116" dur="2.647">is driven by some sort of target information</text>
        <text start="62.763" dur="1.115">that you care about.</text>
        <text start="63.878" dur="2.288">In supervised learning</text>
        <text start="66.166" dur="2.236">which is the subject of today&amp;#39;s class</text>
        <text start="68.402" dur="2.169">we&amp;#39;re given specific target labels</text>
        <text start="70.571" dur="2.469">and I give you examples just in a second.</text>
        <text start="73.04" dur="2.836">We also talk about unsupervised learning</text>
        <text start="75.876" dur="3.37">where target labels are missing</text>
        <text start="79.246" dur="2.102">and we use replacement principles</text>
        <text start="81.348" dur="1.301">to find, for example</text>
        <text start="82.649" dur="1.869">hidden concepts.</text>
        <text start="84.518" dur="2.975">Later there will be a class in reinforcement learning</text>
        <text start="87.493" dur="5.2">when an agent learns from feedback with the physical environment</text>
        <text start="92.693" dur="2.068">by interacting and trying actions</text>
        <text start="94.761" dur="2.275">and receiving some sort of evaluation</text>
        <text start="97.036" dur="0.862">from the environment</text>
        <text start="97.898" dur="3.37">like &amp;quot;Well done&amp;quot; or &amp;quot;That works.&amp;quot;</text>
        <text start="101.268" dur="2.595">Again, we will talk about those in detail later.</text>
        <text start="103.863" dur="2.31">There&amp;#39;s different things you could try to do</text>
        <text start="106.173" dur="1.939">with machine learning technique.</text>
        <text start="108.112" dur="1.864">You might care about prediction.</text>
        <text start="109.976" dur="3.337">For example you might want to care about what&amp;#39;s going to happen with the future</text>
        <text start="113.313" dur="2.336">in the stockmarket for example.</text>
        <text start="115.649" dur="2.135">You might care to diagnose something</text>
        <text start="117.784" dur="2.008">which is you get data and you wish to explain it</text>
        <text start="119.792" dur="2.029">and you use machine learning for that.</text>
        <text start="121.821" dur="3.137">Sometimes your objective is to summarize something.</text>
        <text start="124.958" dur="2.403">For example if you read a long article</text>
        <text start="127.361" dur="1.903">your machine learning method might aim to</text>
        <text start="129.264" dur="2.801">produce a short article that summarizes the long article.</text>
        <text start="132.065" dur="2.536">And there&amp;#39;s many, many, many more different things.</text>
        <text start="134.601" dur="2.303">You can talk about the how to learn.</text>
        <text start="136.904" dur="2.546">We use the word passive</text>
        <text start="139.45" dur="3.55">if your learning agent is just an observer</text>
        <text start="143" dur="1.745">and has no impact on the data itself.</text>
        <text start="144.745" dur="2.105">Otherwise, you call it active.</text>
        <text start="146.85" dur="3.708">Sometimes learning occurs online</text>
        <text start="150.558" dur="2.244">which means while the data is being generated</text>
        <text start="152.802" dur="2.82">and some of it is offline</text>
        <text start="155.622" dur="2.036">which means learning occurs</text>
        <text start="157.658" dur="2.168">after the data has been generated.</text>
        <text start="159.826" dur="2.644">There&amp;#39;s different types of outputs</text>
        <text start="162.47" dur="2.195">of a machine learning algorithm.</text>
        <text start="164.665" dur="3.136">Today we&amp;#39;ll talk about classification</text>
        <text start="167.801" dur="2.703">versus regression.</text>
        <text start="170.504" dur="2.879">In classification the output is binary</text>
        <text start="173.383" dur="2.159">or a fixed number of classes</text>
        <text start="175.542" dur="1.635">for example something is either a chair or not.</text>
        <text start="177.177" dur="1.902">Regression is continuous.</text>
        <text start="179.079" dur="2.87">The temperature might be 66.5 degrees</text>
        <text start="181.949" dur="1.701">in our prediction.</text>
        <text start="183.65" dur="1.835">And there&amp;#39;s tons of internal details</text>
        <text start="185.485" dur="1.401">we will talk about.</text>
        <text start="187.886" dur="1.57">Just to name one.</text>
        <text start="189.456" dur="3.437">We will distinguish generative</text>
        <text start="192.893" dur="1.435">from discriminative.</text>
        <text start="194.328" dur="2.469">Generative seeks to model the data</text>
        <text start="196.797" dur="2.002">as generally as possible</text>
        <text start="198.799" dur="1.868">versus discriminative methods</text>
        <text start="200.667" dur="1.268">seek to distinguish data</text>
        <text start="201.935" dur="2.77">and this might sound like a superficial distinction</text>
        <text start="204.705" dur="1.802">but it has enormous ramification</text>
        <text start="206.507" dur="1.134">on the learning algorithm.</text>
        <text start="207.641" dur="1.548">Now to tell you the truth</text>
        <text start="209.189" dur="1.588">it took me many years</text>
        <text start="210.777" dur="3.204">to fully learn all these words here</text>
        <text start="213.981" dur="2.235">and I don&amp;#39;t expect you to pick them all up</text>
        <text start="216.216" dur="1.007">in one class</text>
        <text start="217.223" dur="2.438">but you should as well know that they exist.</text>
        <text start="219.661" dur="1.393">And as they come up</text>
        <text start="221.054" dur="1.068">I&amp;#39;ll emphasize them</text>
        <text start="222.122" dur="2.503">so you can resort any learning method</text>
        <text start="224.625" dur="2.769">I tell you back into the specific taxonomy over here.</text>
      </transcript>
    </video>
    <video title="6 Supervised Learning" id="nxX9Ihi4HZQ" length="192.60000000000002">
      <transcript>
        <text start="0" dur="2.8">The vast amount of work in the field</text>
        <text start="2.8" dur="3.514">falls into the area of supervised learning.</text>
        <text start="6.314" dur="2.228">In supervised learning</text>
        <text start="8.542" dur="2.418">you&amp;#39;re given for each training example</text>
        <text start="10.96" dur="2.654">a feature vector</text>
        <text start="13.614" dur="3.303">and a target label named Y.</text>
        <text start="16.917" dur="3.27">For example, for a credit rating agency</text>
        <text start="20.187" dur="3.003">X1, X2, X3 might be a feature</text>
        <text start="23.19" dur="1.902">such as is the person employed?</text>
        <text start="25.092" dur="2.569">What is the salary of the person?</text>
        <text start="27.661" dur="2.97">Has the person previously defaulted on a credit card?</text>
        <text start="30.631" dur="1.575">And so on.</text>
        <text start="32.206" dur="2.028">And Y is a predictor</text>
        <text start="34.234" dur="2.336">whether the person is to default</text>
        <text start="36.57" dur="1.743">on the credit or not.</text>
        <text start="38.313" dur="2.067">Now machine learning</text>
        <text start="40.38" dur="2.563">is to be carried out on past data</text>
        <text start="42.943" dur="1.435">where the credit rating agency</text>
        <text start="44.378" dur="2.269">might have collected features just like these</text>
        <text start="46.647" dur="3.322">and actual occurances of default or not.</text>
        <text start="49.969" dur="1.816">What it wishes to produce</text>
        <text start="51.785" dur="1.702">is a function that allows us</text>
        <text start="53.487" dur="1.902">to predict future customers.</text>
        <text start="55.389" dur="1.134">So the new person comes in</text>
        <text start="56.523" dur="2.202">with a different feature vector.</text>
        <text start="58.725" dur="1.702">Can we predict as good as possible</text>
        <text start="60.427" dur="1.602">the functional relationship</text>
        <text start="62.029" dur="3.683">between these features X1 to Xn all the way to Y?</text>
        <text start="65.712" dur="2.423">You can apply the exact same example</text>
        <text start="68.135" dur="1.153">in image recognition</text>
        <text start="69.288" dur="2.017">where X might be pixels of images</text>
        <text start="71.305" dur="2.969">or it might be features of things found in images</text>
        <text start="74.274" dur="2.036">and Y might be a label that says</text>
        <text start="76.31" dur="1.535">whether a certain object is contained</text>
        <text start="77.845" dur="1.267">in an image or not.</text>
        <text start="79.112" dur="1.183">Now in supervised learning</text>
        <text start="80.295" dur="2.021">you&amp;#39;re given many such examples.</text>
        <text start="85.352" dur="3.437">X21 to X2n</text>
        <text start="88.789" dur="3.737">leads to Y2</text>
        <text start="92.526" dur="3.28">all way the index m.</text>
        <text start="95.806" dur="2.292">This is called your data.</text>
        <text start="98.098" dur="4.905">If we call each input vector Xm</text>
        <text start="103.003" dur="1.568">and we wish to find out the function</text>
        <text start="104.571" dur="5.639">given any Xm or any future vector X</text>
        <text start="110.21" dur="2.836">produces as close as possible</text>
        <text start="113.046" dur="2.536">my target signal Y.</text>
        <text start="115.582" dur="2.102">Now this isn&amp;#39;t always possible</text>
        <text start="117.684" dur="2.015">and sometimes it&amp;#39;s acceptable</text>
        <text start="119.699" dur="1.088">in fact preferable</text>
        <text start="120.787" dur="3.045">to tolerate a certain amount of error</text>
        <text start="123.832" dur="1.231">in your training data.</text>
        <text start="125.063" dur="2.331">But the subject of machine learning</text>
        <text start="127.394" dur="2.87">is to identify this function over here.</text>
        <text start="130.264" dur="1.534">And once you identify it</text>
        <text start="131.798" dur="1.802">you can use it for future Xs</text>
        <text start="133.6" dur="2.736">that weren&amp;#39;t part of the training set</text>
        <text start="136.336" dur="3.103">to produce a prediction</text>
        <text start="139.439" dur="2.169">that hopefully is really, really good.</text>
        <text start="141.608" dur="3.3">So let me ask you a question.</text>
        <text start="144.908" dur="2.239">And this is a question</text>
        <text start="147.147" dur="1.763">for which I haven&amp;#39;t given you the answer</text>
        <text start="148.91" dur="2.475">but I&amp;#39;d like to appeal to your intuition.</text>
        <text start="151.385" dur="2.736">Here&amp;#39;s one data set</text>
        <text start="154.121" dur="3.87">where the X is one dimensionally plotted horizontally</text>
        <text start="157.991" dur="1.936">and the Y is vertically</text>
        <text start="159.927" dur="4.471">and suppose there looks like this.</text>
        <text start="164.398" dur="1.578">Suppose my machine learning algorithm</text>
        <text start="165.976" dur="1.592">gives me 2 hypotheses.</text>
        <text start="167.568" dur="3.47">One is this function over here</text>
        <text start="171.038" dur="0.967">which is a linear function</text>
        <text start="172.005" dur="1.68">and one is this function over here.</text>
        <text start="173.685" dur="3.826">I&amp;#39;d like to know which of the functions</text>
        <text start="177.511" dur="1.802">you find preferable</text>
        <text start="179.313" dur="2.002">as an explanation for the data.</text>
        <text start="181.315" dur="1.368">Is it function A?</text>
        <text start="182.683" dur="4.004">Or function B?</text>
        <text start="186.687" dur="1.434">Check here for A</text>
        <text start="188.121" dur="0.935">here for B</text>
        <text start="189.056" dur="3.544">and here for neither.</text>
      </transcript>
    </video>
    <video title="7 Occam's Razor" id="FHJx9RVVKFg" length="163.93099999999998">
      <transcript>
        <text start="0" dur="4.571">And I hope you guessed function A.</text>
        <text start="4.571" dur="3.771">Even though both perfectly describe the data</text>
        <text start="8.342" dur="2.569">B is much more complex than A.</text>
        <text start="10.911" dur="2.046">In fact, outside the data</text>
        <text start="12.957" dur="3.358">B seems to go to a minus infinity much faster</text>
        <text start="16.315" dur="1.203">than these data points</text>
        <text start="17.518" dur="2.135">and to plus infinity much faster</text>
        <text start="19.653" dur="1.709">with these data points over here.</text>
        <text start="21.362" dur="0.929">And in between</text>
        <text start="22.291" dur="1.672">we have wide oscillations</text>
        <text start="23.963" dur="1.996">that don&amp;#39;t correspond to any data.</text>
        <text start="25.959" dur="1.402">So I would argue</text>
        <text start="27.361" dur="1.468">A is preferable.</text>
        <text start="31.3" dur="1.633">The reason why I asked this question</text>
        <text start="32.933" dur="2.135">is because of something called Occam&amp;#39;s Razor.</text>
        <text start="35.068" dur="3.871">Occam can be spelled in many different ways.</text>
        <text start="38.939" dur="2.836">And what Occam says is that</text>
        <text start="41.775" dur="1.935">everything else being equal</text>
        <text start="43.71" dur="2.939">chose the less complex hypothesis.</text>
        <text start="46.649" dur="2.2">Now in practice</text>
        <text start="48.849" dur="2.003">there&amp;#39;s actually a trade-off</text>
        <text start="50.852" dur="2.301">between a really good data fit</text>
        <text start="53.153" dur="2.503">and low complexity.</text>
        <text start="55.656" dur="2.51">Let me illustrate this to you</text>
        <text start="58.166" dur="1.463">by a hypothetical example.</text>
        <text start="59.629" dur="2.466">Consider the following graph</text>
        <text start="62.095" dur="2.403">where the horizontal axis graphs</text>
        <text start="64.498" dur="3.236">complexity of the solution.</text>
        <text start="67.734" dur="2.369">For example, if you use polynomials</text>
        <text start="70.103" dur="2.169">this might be a high-degree polynomial over here</text>
        <text start="72.272" dur="2.171">and maybe a linear function over here</text>
        <text start="74.443" dur="2.067">which is a low-degree polynomial</text>
        <text start="76.51" dur="3.17">your training data error</text>
        <text start="79.68" dur="3.069">tends to go like this.</text>
        <text start="82.749" dur="2.97">The more complex the hypothesis you allow</text>
        <text start="85.719" dur="3.422">the more you can just fit your data.</text>
        <text start="89.141" dur="2.818">However, in reality</text>
        <text start="91.959" dur="2.035">your generalization error on unknown data</text>
        <text start="93.994" dur="3.37">tends to go like this.</text>
        <text start="97.364" dur="2.803">It is the sum of the training data error</text>
        <text start="100.167" dur="2.669">and another function</text>
        <text start="102.836" dur="3.671">which is called the overfitting error.</text>
        <text start="106.507" dur="1.001">Not surprisingly</text>
        <text start="107.508" dur="2.335">the best complexity is obtained</text>
        <text start="109.843" dur="2.403">where the generalization error is minimum.</text>
        <text start="112.246" dur="1.401">There are methods</text>
        <text start="113.647" dur="1.902">to calculate the overfitting error.</text>
        <text start="115.549" dur="2.269">They go into a statistical field</text>
        <text start="117.818" dur="3.321">under the name Bayes variance methods.</text>
        <text start="121.139" dur="1.016">However, in practice</text>
        <text start="122.155" dur="2.336">you&amp;#39;re often just given the training data error.</text>
        <text start="124.491" dur="4.071">You find if you don&amp;#39;t find the model</text>
        <text start="128.562" dur="2.602">that minimizes the training data error</text>
        <text start="131.164" dur="3.14">but instead pushes back the complexity</text>
        <text start="134.304" dur="3.334">your algorithm tends to perform better</text>
        <text start="137.638" dur="3.336">and that is something we will study a little bit</text>
        <text start="140.974" dur="1.835">in this class.</text>
        <text start="142.809" dur="3.27">However, this slide is really important</text>
        <text start="146.079" dur="3.037">for anybody doing machine learning in practice.</text>
        <text start="149.116" dur="2.035">If you deal with data</text>
        <text start="151.151" dur="2.036">and you have ways to fit your data</text>
        <text start="153.187" dur="3.103">be aware that overfitting</text>
        <text start="156.29" dur="2.929">is a major source of poor performance</text>
        <text start="159.219" dur="1.927">of a machine learning algorithm.</text>
        <text start="161.146" dur="2.785">And I give you examples in just one second.</text>
      </transcript>
    </video>
    <video title="8 SPAM Detection" id="wMMGexgmES4" length="255.331">
      <transcript>
        <text start="0" dur="2.001">So a really important example</text>
        <text start="2.001" dur="2.37">of machine learning is SPAM detection.</text>
        <text start="4.371" dur="2.136">We all get way too much email</text>
        <text start="6.507" dur="1.935">and a good number of those are SPAM.</text>
        <text start="8.442" dur="3.858">Here are 3 examples of email.</text>
        <text start="12.3" dur="1.981">Dear Sir: First I must solicit your confidence</text>
        <text start="14.281" dur="2.437">in this transaction, this is by virtue of its nature</text>
        <text start="16.718" dur="2.438">being utterly confidential and top secret...</text>
        <text start="19.156" dur="3.135">This is likely SPAM.</text>
        <text start="22.291" dur="1.633">Here&amp;#39;s another one.</text>
        <text start="23.924" dur="1.201">In upper caps.</text>
        <text start="25.125" dur="3.604">99 MILLION EMAIL ADDRESSES FOR ONLY $99</text>
        <text start="28.729" dur="2.302">This is very likely SPAM.</text>
        <text start="31.031" dur="2.669">And here&amp;#39;s another one.</text>
        <text start="33.7" dur="1.602">Oh, I know it&amp;#39;s blatantly OT</text>
        <text start="35.302" dur="2.035">but I&amp;#39;m beginning to go insane.</text>
        <text start="37.337" dur="2.77">Had an old Dell Dimension XPS sitting in the corner</text>
        <text start="40.107" dur="1.301">and decided to put it to use.</text>
        <text start="41.408" dur="1.572">And so on and so on.</text>
        <text start="42.98" dur="2.508">Now this is likely not SPAM.</text>
        <text start="45.488" dur="1.726">How can a computer program</text>
        <text start="47.214" dur="2.602">distinguish between SPAM and not SPAM?</text>
        <text start="49.816" dur="2.169">Let&amp;#39;s use this as an example</text>
        <text start="51.985" dur="3.637">to talk about machine learning for discrimination</text>
        <text start="55.622" dur="3.437">using Bayes Networks.</text>
        <text start="59.059" dur="2.035">In SPAM detection</text>
        <text start="61.094" dur="2.403">we get an email</text>
        <text start="63.497" dur="1.702">and we wish to categorize it</text>
        <text start="65.199" dur="1.935">either as SPAM</text>
        <text start="67.134" dur="2.969">in which case we don&amp;#39;t even show as to the where</text>
        <text start="70.103" dur="2.575">or what we call HAM</text>
        <text start="72.678" dur="2.731">which is the technical word for</text>
        <text start="75.409" dur="4.304">an email worth passing on to the person being emailed.</text>
        <text start="79.713" dur="1.668">So the function over here</text>
        <text start="81.381" dur="1.802">is the function we&amp;#39;re trying to learn.</text>
        <text start="83.183" dur="3.137">Most SPAM filters use human input.</text>
        <text start="86.32" dur="2.239">When you go through email</text>
        <text start="88.559" dur="3.566">you have a button called IS SPAM</text>
        <text start="92.125" dur="2.473">which allows you as a user to flag SPAM</text>
        <text start="94.598" dur="3.2">and occasionally you will say an email is SPAM.</text>
        <text start="97.798" dur="2.436">If you look at this</text>
        <text start="100.234" dur="2.979">you have a typical supervised machine learning situation</text>
        <text start="103.213" dur="1.825">where the input is an email</text>
        <text start="105.038" dur="2.369">and the output is whether you flag it as SPAM</text>
        <text start="107.407" dur="1.869">or if we don&amp;#39;t flag it</text>
        <text start="109.276" dur="2.97">we just think it&amp;#39;s HAM.</text>
        <text start="112.246" dur="2.002">Now to make this amenable to</text>
        <text start="114.248" dur="0.9">a machine learning algorithm</text>
        <text start="115.148" dur="2.043">we have to talk about how to represent emails.</text>
        <text start="117.191" dur="3.196">They&amp;#39;re all using different words and different characters</text>
        <text start="120.387" dur="2.336">and they might have different graphics included.</text>
        <text start="122.723" dur="3.537">Let&amp;#39;s pick a representation that&amp;#39;s easy to process.</text>
        <text start="126.26" dur="3.069">And this representation is often called</text>
        <text start="129.329" dur="1.569">Bag of Words.</text>
        <text start="130.898" dur="3.803">Bag of Words is a representation</text>
        <text start="134.701" dur="1.168">of a document</text>
        <text start="135.869" dur="1.802">that just counts the frequency</text>
        <text start="137.671" dur="1.168">of words.</text>
        <text start="138.839" dur="3.47">If an email were to say Hello</text>
        <text start="142.309" dur="2.073">I will say Hello.</text>
        <text start="144.382" dur="2.165">The Bag of Words representation</text>
        <text start="146.547" dur="1.368">is the following.</text>
        <text start="147.915" dur="3.77">2-1-1-1</text>
        <text start="151.685" dur="2.054">for the dictionary</text>
        <text start="153.739" dur="2.551">that contains the 4 words</text>
        <text start="156.29" dur="2.669">Hello I will say.</text>
        <text start="158.959" dur="2.436">Now look at the subtlety here.</text>
        <text start="161.395" dur="2.335">Rather than representing each individual word</text>
        <text start="163.73" dur="2.336">we have a count of each word</text>
        <text start="166.066" dur="3.036">and the count is oblivious</text>
        <text start="169.102" dur="3.12">to the order in which the words were stated.</text>
        <text start="172.222" dur="2.953">A Bag of Words representation</text>
        <text start="175.175" dur="2.236">relative to a fixed dictionary</text>
        <text start="177.411" dur="3.603">represents the counts of each word</text>
        <text start="181.014" dur="2.803">relative to the words in the dictionary.</text>
        <text start="183.817" dur="3.003">If you were to use a different dictionary</text>
        <text start="186.82" dur="1.668">like hello and good-bye</text>
        <text start="188.488" dur="1.802">our counts would be</text>
        <text start="190.29" dur="2.903">2 and 0.</text>
        <text start="193.193" dur="1.602">However, in most cases</text>
        <text start="194.795" dur="2.369">you make sure that all the words found</text>
        <text start="197.164" dur="0.925">in messages</text>
        <text start="198.089" dur="1.811">are actually included in the dictionary.</text>
        <text start="199.9" dur="2.536">So the dictionary might be very, very large.</text>
        <text start="202.436" dur="3.409">Let me make up an unofficial example</text>
        <text start="205.845" dur="4.298">of a few SPAM and a few HAM messages.</text>
        <text start="210.143" dur="2.636">Offer is secret.</text>
        <text start="212.779" dur="2.837">Click secret link.</text>
        <text start="215.616" dur="2.21">Secret sports link.</text>
        <text start="217.826" dur="2.728">Obviously those are contrived</text>
        <text start="220.554" dur="2.369">and I tried to retain the recovery</text>
        <text start="222.923" dur="1.15">to a small number of words</text>
        <text start="224.073" dur="1.953">to make this example workable.</text>
        <text start="226.026" dur="1.902">In practice we need thousands</text>
        <text start="227.928" dur="0.968">of such messages</text>
        <text start="228.896" dur="1.601">to get good information.</text>
        <text start="230.497" dur="1.902">Play sports today.</text>
        <text start="232.399" dur="1.969">Went play sports.</text>
        <text start="234.368" dur="2.435">Secret sports event.</text>
        <text start="236.803" dur="3.106">Sport is today.</text>
        <text start="239.909" dur="2.934">Sport costs money.</text>
        <text start="242.843" dur="3.403">My first quiz is</text>
        <text start="246.246" dur="2.336">What is the size of the vocabulary</text>
        <text start="248.582" dur="3.749">that contains all words in these messages?</text>
        <text start="252.331" dur="3">Please enter the value in this box over here.</text>
      </transcript>
    </video>
    <video title="9 Answer" id="fPkxtmxRt5k" length="28">
      <transcript>
        <text start="0" dur="2">Well let&amp;#39;s count.</text>
        <text start="2" dur="6">Offer is secret click.</text>
        <text start="8" dur="2">Secret occurs over here already</text>
        <text start="10" dur="2">so we don&amp;#39;t have to count it twice.</text>
        <text start="12" dur="6">Link, sports, play, today, went, event</text>
        <text start="18" dur="2">costs money.</text>
        <text start="20" dur="2">So the answer is</text>
        <text start="22" dur="2">12.</text>
        <text start="24" dur="2">There&amp;#39;s 12 different words</text>
        <text start="26" dur="2">contained in these 8 messages.</text>
      </transcript>
    </video>
    <video title="10 Question" id="Diqx3Z20YWc" length="16">
      <transcript>
        <text start="0" dur="3">[Narrator] Another quiz.</text>
        <text start="3" dur="3">What is the probability that a random message</text>
        <text start="6" dur="3">that arrives to fall into the spam bucket?</text>
        <text start="9" dur="2">Assuming that those messages</text>
        <text start="11" dur="2">are all drawn at random.</text>
        <text start="13" dur="3">[writing on page]</text>
      </transcript>
    </video>
    <video title="11 Answer" id="WFE-dmEJZF8" length="16">
      <transcript>
        <text start="0" dur="2">[Narrator] And the answer is:</text>
        <text start="2" dur="2">there&amp;#39;s 8 different messages</text>
        <text start="4" dur="2">of which 3 are spam.</text>
        <text start="6" dur="3">So the maximum likelihood estimate</text>
        <text start="9" dur="2">is 3/8.</text>
        <text start="11" dur="5">[writing on paper]</text>
      </transcript>
    </video>
    <video title="12 Maximum Likelihood" id="QBlERVSlFx4" length="271">
      <transcript>
        <text start="0" dur="3">So, let&amp;#39;s look at this a little bit more formally and talk about maximum likelihood.</text>
        <text start="3" dur="9">Obviously, we&amp;#39;re observing 8 messages: spam, spam, spam, and 5 times ham.</text>
        <text start="12" dur="5">And what we care about is what&amp;#39;s our prior probability of spam</text>
        <text start="17" dur="3">that maximizes the likelihood of this data?</text>
        <text start="20" dur="4">So, let&amp;#39;s assume we&amp;#39;re going to assign a value of pi to this,</text>
        <text start="24" dur="5">and we wish to find the pi that maximizes the likelihood of this data over here,</text>
        <text start="29" dur="4">assuming that each email is drawn independently</text>
        <text start="33" dur="4">according to an identical distribution.</text>
        <text start="37" dur="11">The probability of the p(yi) data item is then pi if yi = spam,</text>
        <text start="48" dur="5">and 1 - pi if yi = ham.</text>
        <text start="53" dur="6">If we rewrite the data as 1, 1, 1, 0, 0, 0, 0, 0,</text>
        <text start="59" dur="14">we can write p(yi) as follows: pi to the yi times (1 - pi) to the 1 - yi.</text>
        <text start="73" dur="3">It&amp;#39;s not that easy to see that this is equivalent,</text>
        <text start="76" dur="3">but say yi = 1.</text>
        <text start="79" dur="3">Then this term will fall out.</text>
        <text start="82" dur="6">It&amp;#39;s not proficient by 1 because the exponent is zero, and we get pi as over here.</text>
        <text start="88" dur="8">If yi = 0, then this term falls out, and this one here becomes 1 - pi as over here.</text>
        <text start="96" dur="8">Now assuming independence, we get for the entire data set</text>
        <text start="104" dur="5">that the joint probability of all data items is the product</text>
        <text start="109" dur="3">of the individual data items over here,</text>
        <text start="112" dur="4">which can now be written as follows:</text>
        <text start="116" dur="7">pi to the count of instances where yi = 1 times</text>
        <text start="123" dur="6">1 - pi to the count of the instances where yi = 0.</text>
        <text start="129" dur="4">And we know in our example, this count over here is 3,</text>
        <text start="133" dur="9">and this count over here is 5, so we get pi to the 3rd times 1 - pi to the 5th.</text>
        <text start="142" dur="6">We now wish to find the pi that maximizes this expression over  here.</text>
        <text start="148" dur="5">We can also maximize the logarithm of this expression,</text>
        <text start="153" dur="9">which is 3 times log pi + 5 times log (1 - pi)</text>
        <text start="162" dur="8">Optimizing the log is the same as optimizing p because the log is monotonic to p.</text>
        <text start="170" dur="4">The maximum of this function is attained with a derivative of 0,</text>
        <text start="174" dur="6">so let&amp;#39;s compute with a derivative and set it to 0.</text>
        <text start="180" dur="5">This is the derivative, 3 over pi - 5 over 1 - pi.</text>
        <text start="185" dur="4">We now bring this expression to the right side,</text>
        <text start="189" dur="9">multiply the denominators up, and sort all the expressions containing pi to the left,</text>
        <text start="198" dur="8">which gives us pi = 3/8, exactly the number we were at before.</text>
        <text start="206" dur="7">We just derived mathematically that the data likelihood maximizing number</text>
        <text start="213" dur="4">for the probability is indeed the empirical count,</text>
        <text start="217" dur="4">which means when we looked at this quiz before</text>
        <text start="221" dur="8">and we said a maximum likelihood for the prior probability of spam is 3/8,</text>
        <text start="229" dur="5">by simply counting 3 over 8 emails were spam,</text>
        <text start="234" dur="3">we actually followed proper mathematical principles</text>
        <text start="237" dur="2">to do maximum likelihood estimation.</text>
        <text start="239" dur="4">Now, you might not fully have gotten the derivation of this,</text>
        <text start="243" dur="4">and I recommend you to watch it again, but it&amp;#39;s not that important</text>
        <text start="247" dur="2">for the progress in this class.</text>
        <text start="249" dur="2">So, here&amp;#39;s another quiz.</text>
        <text start="251" dur="6">I&amp;#39;d like the maximum likelihood, or ML solutions,</text>
        <text start="257" dur="2">for the following probabilities.</text>
        <text start="259" dur="2">The probability that the word &amp;quot;secret&amp;quot; comes up,</text>
        <text start="261" dur="4">assuming that we already know a message is spam,</text>
        <text start="265" dur="3">and the probability that the same word &amp;quot;secret&amp;quot; comes up</text>
        <text start="268" dur="3">if we happen to know the message is not spam, it&amp;#39;s ham.</text>
      </transcript>
    </video>
    <video title="13 Answer" id="4q4Tk-4Long" length="26.689999999999998">
      <transcript>
        <text start="0" dur="2.436">And just as before</text>
        <text start="2.436" dur="2.102">we count the word secret</text>
        <text start="4.538" dur="1.601">in SPAM and in HAM</text>
        <text start="6.139" dur="1.669">as I&amp;#39;ve underlined here.</text>
        <text start="7.808" dur="3.603">Three out of 9 words in SPAM</text>
        <text start="11.411" dur="1.569">are the word secret</text>
        <text start="12.98" dur="1.801">so we have a third over here</text>
        <text start="14.781" dur="3.307">or 0.333</text>
        <text start="18.088" dur="2.966">and only 1 out of all the 15 words in HAM</text>
        <text start="21.054" dur="0.968">are secret</text>
        <text start="22.022" dur="1.878">so you get a fifteenth</text>
        <text start="23.9" dur="2.79">or 0.0667.</text>
      </transcript>
    </video>
    <video title="14 Relationship to Bayes Networks" id="MvwZNmJQIJw" length="79">
      <transcript>
        <text start="0" dur="6">By now, you might have recognized what we&amp;#39;re really building up is a Bayes network</text>
        <text start="6" dur="4">where the parameters of the Bayes networks are estimated using supervised learning</text>
        <text start="10" dur="5">by a maximum likelihood estimator based on training data.</text>
        <text start="15" dur="5">The Bayes network has at its root an unobservable variable called spam,</text>
        <text start="20" dur="8">which is binary, and it has as many children as there are words in a message,</text>
        <text start="28" dur="5">where each word has an identical conditional distribution</text>
        <text start="33" dur="6">of the word occurrence given the class spam or not spam.</text>
        <text start="39" dur="3">If you write on our dictionary over here,</text>
        <text start="42" dur="6">you might remember the dictionary had 12 different words,</text>
        <text start="48" dur="4">so here is 5 of the 12, offer, is, secret, click and sports.</text>
        <text start="52" dur="7">Then for the spam class, we found the probability of secret given spam is 1/3,</text>
        <text start="59" dur="6">and we also found that the probability of secret given  ham is 1/15,</text>
        <text start="65" dur="2">so here&amp;#39;s a quiz.</text>
        <text start="67" dur="5">Assuming a vocabulary size of 12, or put differently,</text>
        <text start="72" dur="4">the dictionary has 12 words, how many parameters</text>
        <text start="76" dur="3">do we need to specify this Bayes network?</text>
      </transcript>
    </video>
    <video title="15 Answer" id="-Pms2FiJQIA" length="29">
      <transcript>
        <text start="0" dur="3">And the correct answer is 23.</text>
        <text start="3" dur="4">We need 1 parameter for the prior p (spam),</text>
        <text start="7" dur="5">and then we have 2 dictionary distributions of any word,</text>
        <text start="12" dur="4">i given spam, and the same for  ham.</text>
        <text start="16" dur="2">Now, there&amp;#39;s 12 words in a dictionary,</text>
        <text start="18" dur="2">but this distribution only needs 11 parameters,</text>
        <text start="20" dur="4">so 12 can be figured out because they have to add up to 1.</text>
        <text start="24" dur="3">And the same is true over here, so if you add all these together,</text>
        <text start="27" dur="2">we get 23.</text>
      </transcript>
    </video>
    <video title="16 Question" id="2BFCqec6n04" length="26">
      <transcript>
        <text start="0" dur="2">So, here&amp;#39;s a quiz.</text>
        <text start="2" dur="4">Let&amp;#39;s assume we fit all the 23 parameters of the Bayes network</text>
        <text start="6" dur="3">as explained using maximum likelihood.</text>
        <text start="9" dur="5">Let&amp;#39;s now do classification and see what class and message it ends up with.</text>
        <text start="14" dur="4">Let me start with a very simple message, and it contains a single word</text>
        <text start="18" dur="3">just to make it a little bit simpler.</text>
        <text start="21" dur="5">What&amp;#39;s the probability that we classify this one word message as spam?</text>
      </transcript>
    </video>
    <video title="17 Answer" id="lQe4iNP6HDA" length="62">
      <transcript>
        <text start="0" dur="7">And the answer is 0.1667 or 3/18.</text>
        <text start="7" dur="6">How do I get there? Well, let&amp;#39;s apply Bayes rule.</text>
        <text start="13" dur="6">This form is easily transformed into this expression over here,</text>
        <text start="19" dur="6">the probability of the message given spam times the prior probability of spam</text>
        <text start="25" dur="4">over the normalizer over here.</text>
        <text start="29" dur="5">Now, we know that the word &amp;quot;sports&amp;quot; occurs 1 in our 9 words of spam,</text>
        <text start="34" dur="4">and our prior probability for spam is 3/8,</text>
        <text start="38" dur="2">which gives us this expression over here.</text>
        <text start="40" dur="5">We now have to add the same probabilities for the class ham.</text>
        <text start="45" dur="6">&amp;quot;Sports&amp;quot; occurs 5 times out of 15 in the ham class,</text>
        <text start="51" dur="4">and the prior probability for ham is 5/8,</text>
        <text start="55" dur="7">which gives us 3/72 divided by 18/72, which is 3/18 or 1/6.</text>
      </transcript>
    </video>
    <video title="18 Question" id="qVdxj8XOB00" length="21">
      <transcript>
        <text start="0" dur="3">This gets to a more complicated quiz.</text>
        <text start="3" dur="3">Say the message now contains 3 words.</text>
        <text start="6" dur="4">&amp;quot;Secret is secret,&amp;quot; not a particularly meaningful email,</text>
        <text start="10" dur="6">but the frequent occurrence of &amp;quot;secret&amp;quot; seems to suggest it might be spam.</text>
        <text start="16" dur="5">What&amp;#39;s the probability you&amp;#39;re going to judge this to be spam?</text>
      </transcript>
    </video>
    <video title="19 Answer" id="eSbURIQ6pSQ" length="63">
      <transcript>
        <text start="0" dur="10">And the answer is surprisingly high. It&amp;#39;s 25/26, or 0.9615.</text>
        <text start="10" dur="6">To see if we apply Bayes rule, which multiples the prior for spam-ness</text>
        <text start="16" dur="3">with the conditional probability of each word given spam.</text>
        <text start="19" dur="7">&amp;quot;Secret&amp;quot; carries 1/3, &amp;quot;is&amp;quot; 1/9, and &amp;quot;secret&amp;quot; 1/3 again.</text>
        <text start="26" dur="6">We normalize this by the same expression plus the probability for</text>
        <text start="32" dur="4">the non-spam case.</text>
        <text start="36" dur="2">5/8 is a prior.</text>
        <text start="38" dur="4">&amp;quot;Secret&amp;quot; is 1/15.</text>
        <text start="42" dur="3">&amp;quot;Is&amp;quot; is 1/15,</text>
        <text start="45" dur="3">and &amp;quot;secret&amp;quot; again.</text>
        <text start="48" dur="9">This resolves to 1/216 over this expression plus 1/5400,</text>
        <text start="57" dur="6">and when you work it all out is 25/26.</text>
      </transcript>
    </video>
    <video title="20 Question" id="dfVAnFFxFP4" length="21">
      <transcript>
        <text start="0" dur="8">The final quiz, let&amp;#39;s assume our message is &amp;quot;Today is secret.&amp;quot;</text>
        <text start="8" dur="4">And again, it might look like spam because the word &amp;quot;secret&amp;quot; occurs.</text>
        <text start="12" dur="9">I&amp;#39;d like you to compute for me the probability of spam given this message.</text>
      </transcript>
    </video>
    <video title="21 Answer and Laplace Smoothing" id="0BpC-cLDCIE" length="199">
      <transcript>
        <text start="0" dur="7">And surprisingly, the probability for this message to be spam is 0.</text>
        <text start="7" dur="4">It&amp;#39;s not 0.001. It&amp;#39;s flat 0.</text>
        <text start="11" dur="3">In other words, it&amp;#39;s impossible, according to our model,</text>
        <text start="14" dur="3">that this text could be a spam message.</text>
        <text start="17" dur="2">Why is this?</text>
        <text start="19" dur="5">When we apply the same rule as before, we get the prior for spam which is 3/8.</text>
        <text start="24" dur="4">And we multiple the conditional for each word into this.</text>
        <text start="28" dur="3">For &amp;quot;secret,&amp;quot; we know it to be 1/3.</text>
        <text start="31" dur="8">For &amp;quot;is,&amp;quot; to be 1/9, but for today, it&amp;#39;s 0.</text>
        <text start="39" dur="6">It&amp;#39;s 0 because the maximum of the estimate for the probability of &amp;quot;today&amp;quot; in spam is 0.</text>
        <text start="45" dur="4">&amp;quot;Today&amp;quot; just never occurred in a spam message so far.</text>
        <text start="49" dur="6">Now, this 0 is troublesome because as we compute the outcome--</text>
        <text start="55" dur="5">and I&amp;#39;m plugging in all the numbers as before--</text>
        <text start="60" dur="3">none of the words matter anymore, just the 0 matters.</text>
        <text start="63" dur="7">So, we get 0 over something which is plain 0.</text>
        <text start="70" dur="3">Are we overfitting? You bet.</text>
        <text start="73" dur="2">We are clearly overfitting.</text>
        <text start="75" dur="6">It can&amp;#39;t be that a single word determines the entire outcome of our analysis.</text>
        <text start="81" dur="5">The reason is that our model, to assign a probability of 0 for the word &amp;quot;today&amp;quot;</text>
        <text start="86" dur="3">to be in the class of spam is just too aggressive.</text>
        <text start="89" dur="5">Let&amp;#39;s change this.</text>
        <text start="94" dur="5">One technique to deal with the overfitting problem is called Laplace smoothing.</text>
        <text start="99" dur="6">In maximum likelihood estimation, we assign towards our probability</text>
        <text start="105" dur="6">the quotient of the count of this specific event over all events in our data set.</text>
        <text start="111" dur="6">For example, for the prior probability, we found that 3/8 messages are spam.</text>
        <text start="117" dur="3">Therefore, our maximum likelihood estimate</text>
        <text start="120" dur="5">for the prior probability of spam was 3/8.</text>
        <text start="125" dur="5">In Laplace Smoothing, we use a different estimate.</text>
        <text start="130" dur="5">We add the value k to the count</text>
        <text start="135" dur="5">and normalize as if we added k to every single class</text>
        <text start="140" dur="3">that we&amp;#39;ve tried to estimate something over.</text>
        <text start="143" dur="5">This is equivalent to assuming we have a couple of fake training examples</text>
        <text start="148" dur="4">where we add k to each observation count.</text>
        <text start="152" dur="4">Now, if k equals 0, we get our maximum likelihood estimator.</text>
        <text start="156" dur="5">But if k is larger than 0 and n is finite, we get different answers.</text>
        <text start="161" dur="6">Let&amp;#39;s say k equals 1,</text>
        <text start="167" dur="4">and let&amp;#39;s assume we get one message,</text>
        <text start="171" dur="5">and that message was spam, so we&amp;#39;re going to write it one message, one spam.</text>
        <text start="176" dur="7">What is p (spam) for the Laplace smoothing of k + 1?</text>
        <text start="183" dur="6">Let&amp;#39;s do the same with 10 messages, and we get 6 spam.</text>
        <text start="189" dur="7">And 100 messages, of which 60 are spam.</text>
        <text start="196" dur="3">Please enter your numbers into the boxes over here.</text>
      </transcript>
    </video>
    <video title="22 Answer" id="2sKSZHkQPrc" length="74">
      <transcript>
        <text start="0" dur="10">The answer here is 2/3 or 0.667 and is computed as follows.</text>
        <text start="10" dur="6">We have 1 message with 1 as spam, but we&amp;#39;re going to add k =1.</text>
        <text start="16" dur="6">We&amp;#39;re going to add k = 2 over here because there&amp;#39;s 2 different classes.</text>
        <text start="22" dur="6">K = 1 times 2 = 2, which gives us 2/3.</text>
        <text start="28" dur="4">The answer over here is 7/12.</text>
        <text start="32" dur="9">Again, we have 6/10 but we add 2 down here and 1 over here, so you get 7/12.</text>
        <text start="41" dur="8">And correspondingly, we get 61/102 is 60 + 1 over 100 +2.</text>
        <text start="49" dur="7">If we look at the numbers over here, we get 0.5833</text>
        <text start="56" dur="3">and 0.5986.</text>
        <text start="59" dur="4">Interestingly, the maximum likelihood on the last 2 cases over here</text>
        <text start="63" dur="6">will give us .6, but we only get a value that&amp;#39;s closer to .5,</text>
        <text start="69" dur="5">which is the effect of our smoothing prior for the Laplacian smoothing.</text>
      </transcript>
    </video>
    <video title="23 Question" id="2Ar6jFKZhUM" length="25">
      <transcript>
        <text start="0" dur="5">Let&amp;#39;s use the Laplacian smoother with K=1</text>
        <text start="5" dur="4">to calculate the few interesting probabilities--</text>
        <text start="9" dur="3">P of SPAM, P of HAM,</text>
        <text start="12" dur="3">and then the probability of the words &amp;quot;today&amp;quot;,</text>
        <text start="15" dur="4">given that it&amp;#39;s in the SPAM class or the HAM class.</text>
        <text start="19" dur="3">And you might assume that our recovery size</text>
        <text start="22" dur="3">is about 12 different words here.</text>
      </transcript>
    </video>
    <video title="24 Answer" id="DjvGl1qRVdE" length="77">
      <transcript>
        <text start="0" dur="3">This one is easy to calculate for SPAM and HAM.</text>
        <text start="3" dur="2">For SPAM, it&amp;#39;s 2/5,</text>
        <text start="5" dur="3">and the reason is, we had previously</text>
        <text start="8" dur="4">3 out of 8 messages assigned to SPAM.</text>
        <text start="12" dur="3">But thanks to the Laplacian smoother, we add 1 over here.</text>
        <text start="15" dur="4">And there are 2 classes, so we add 2 times 1 over here,</text>
        <text start="19" dur="3">which gives us 4/10, which is 2/5.</text>
        <text start="22" dur="4">Similarly to get 3/5 over here.</text>
        <text start="26" dur="3">Now the tricky part comes up over here.</text>
        <text start="29" dur="4">Before, we had 0 occurances of the word &amp;quot;today&amp;quot; in the SPAM class,</text>
        <text start="33" dur="2">and we had 9 data points.</text>
        <text start="35" dur="3">But now we are going to add 1 for Laplacian smoother,</text>
        <text start="38" dur="2">and down here, we are going to add 12.</text>
        <text start="40" dur="2">And the reason that we add 12 is because</text>
        <text start="42" dur="2">there&amp;#39;s 12 different words in our dictionary</text>
        <text start="44" dur="3">Hence, for each word in the dictonary, we are going to add 1.</text>
        <text start="47" dur="3">So we have a total of 12, which gives us the 12 over here.</text>
        <text start="50" dur="3">That makes 1/21.</text>
        <text start="53" dur="3">In the HAM class, we had 2 occurrences</text>
        <text start="56" dur="3">of the word &amp;quot;today&amp;quot;--over here and over here.</text>
        <text start="59" dur="5">We add 1, normalize by 15,</text>
        <text start="64" dur="3">plus 12 for the dictionary size,</text>
        <text start="67" dur="7">which is 3/27 or 1/9.</text>
        <text start="74" dur="3">This was not an easy question.</text>
      </transcript>
    </video>
    <video title="25 Question" id="RJAFdBfGOrY" length="21">
      <transcript>
        <text start="0" dur="3">We come now to the final quiz here,</text>
        <text start="3" dur="2">which is--I would like to compute the probability</text>
        <text start="5" dur="3">that the message &amp;quot;today is secret&amp;quot;</text>
        <text start="8" dur="2">falls into the SPAM box with</text>
        <text start="10" dur="3">Laplacian smoother using K=1.</text>
        <text start="13" dur="3">Please just enter your number over here.</text>
        <text start="16" dur="2">This is a non-trivia question.</text>
        <text start="18" dur="3">It might take you a while to calculate this.</text>
      </transcript>
    </video>
    <video title="26 Answer" id="oh4uc-8O6Pc" length="58">
      <transcript>
        <text start="0" dur="6">In the approximate probabilities--0.4858.</text>
        <text start="6" dur="2">How did we get this?</text>
        <text start="8" dur="4">Well, the prior probability for SPAM</text>
        <text start="12" dur="3">under the Laplacian smoothing is 2/5.</text>
        <text start="15" dur="7">&amp;quot;Today&amp;quot; doesn&amp;#39;t occur, but we have already calculated this to be 1/21.</text>
        <text start="22" dur="4">&amp;quot;Is&amp;quot; occurs once, so we get 2 over here over 21.</text>
        <text start="26" dur="6">&amp;quot;Secret&amp;quot; occurs 3 times, so we get a 4 over here over 21,</text>
        <text start="32" dur="5">and we normalize this by the same expression over here.</text>
        <text start="37" dur="5">Plus the prior for HAM, which is 3/5,</text>
        <text start="42" dur="5">we have 2 occurrences of &amp;quot;today&amp;quot;, plus 1, equals 3/27.</text>
        <text start="47" dur="3">&amp;quot;Is&amp;quot; occurs once--2/27.</text>
        <text start="50" dur="4">And &amp;quot;secret&amp;quot; occurs once--again 2/27.</text>
        <text start="54" dur="4">When you work this all out, you get this number over here.</text>
      </transcript>
    </video>
    <video title="27 Summary Naive Bayes" id="c2yFCp6BrEA" length="107">
      <transcript>
        <text start="0" dur="2">So we learned quite a bit.</text>
        <text start="2" dur="2">We learned about Naive Bayes</text>
        <text start="4" dur="2">as our first supervised learning methods.</text>
        <text start="6" dur="2">The setup was that we had</text>
        <text start="8" dur="6">features of documents or trading examples and labels.</text>
        <text start="14" dur="3">In this case, SPAM or not SPAM.</text>
        <text start="17" dur="2">And from those pieces,</text>
        <text start="19" dur="4">we made a generative model for the SPAM class</text>
        <text start="23" dur="2">and the non-SPAM class</text>
        <text start="25" dur="3">that described the condition of probability</text>
        <text start="28" dur="2">of each individual feature.</text>
        <text start="30" dur="3">We then used first maximum likelihood</text>
        <text start="33" dur="3">and then a Laplacian smoother</text>
        <text start="36" dur="2">to fit those primers over here.</text>
        <text start="38" dur="3">And then using Bayes rule,</text>
        <text start="41" dur="3">we could take any training examples over here</text>
        <text start="44" dur="4">and figure out what the class probability was over here.</text>
        <text start="48" dur="3">This is called a generative model</text>
        <text start="51" dur="4">in that the condition of probabilities all aim to maximize</text>
        <text start="55" dur="5">the probability of individual features as if those</text>
        <text start="60" dur="2">describe the physical world.</text>
        <text start="62" dur="4">We also used what is called a bag of words model,</text>
        <text start="66" dur="3">in which our representation of each email</text>
        <text start="69" dur="3">was such that we just counted the occurrences of words,</text>
        <text start="72" dur="3">irrespective of their order.</text>
        <text start="75" dur="4">Now this is a very powerful method for fighting SPAM.</text>
        <text start="79" dur="2">Unfortunately, it is not powerful enough.</text>
        <text start="81" dur="3">It turns out spammers know about Naive Bayes,</text>
        <text start="84" dur="3">and they&amp;#39;ve long learned to come up with messages</text>
        <text start="87" dur="4">that are fooling your SPAM filter if it uses Naive Bayes.</text>
        <text start="91" dur="2">So companies like Google and others</text>
        <text start="93" dur="2">have become much more involved</text>
        <text start="95" dur="3">in methods for SPAM filtering.</text>
        <text start="98" dur="4">Now I can give you some more examples how to filter SPAM,</text>
        <text start="102" dur="5">but all of those quite easily fit with the same Naive Bayes model.</text>
      </transcript>
    </video>
    <video title="28 Advanced SPAM Filtering" id="GSHJspQH15c" length="87">
      <transcript>
        <text start="0" dur="3">[Narrator] So here features that you might consider when you write</text>
        <text start="3" dur="2">in an advance spam filter.</text>
        <text start="5" dur="2">For example,</text>
        <text start="7" dur="2">does the email come from</text>
        <text start="9" dur="3">a known spamming IP or computer?</text>
        <text start="12" dur="4">Have you emailed this person before?</text>
        <text start="16" dur="3">In which case it is less likely to be spam.</text>
        <text start="19" dur="3">Here&amp;#39;s a powerful one:</text>
        <text start="22" dur="3">have 1000 other people</text>
        <text start="25" dur="4">recently received the same message?</text>
        <text start="29" dur="3">Is the email header consistent?</text>
        <text start="32" dur="3">So example if the from field says your bank</text>
        <text start="35" dur="3">is the IP address really your bank?</text>
        <text start="38" dur="4">Surprisingly is the email all caps?</text>
        <text start="42" dur="2">Strangely many spammers believe if you write</text>
        <text start="44" dur="4">things in all caps you&amp;#39;ll pay more attention to it.</text>
        <text start="48" dur="3">Do the inline URLs point to those pages</text>
        <text start="51" dur="3">where they say they&amp;#39;re pointing to?</text>
        <text start="54" dur="2">Are you addressed by your correct name?</text>
        <text start="56" dur="2">Now these are some features,</text>
        <text start="58" dur="2">I&amp;#39;m sure you can think of more.</text>
        <text start="60" dur="2">You can toss them easily into the</text>
        <text start="62" dur="3">naive base model and get better classification.</text>
        <text start="65" dur="3">In fact model spam filters keep learning</text>
        <text start="68" dur="2">as people flag emails as spam, and</text>
        <text start="70" dur="3">of course spammers keep learning as well</text>
        <text start="73" dur="3">and trying to fool modern spam filters.</text>
        <text start="76" dur="2">Who&amp;#39;s going to win?</text>
        <text start="78" dur="3">Well so far the spam filters are clearly winning.</text>
        <text start="81" dur="2">Most of my spam I never see, but who knows</text>
        <text start="83" dur="2">what&amp;#39;s going to happen with the future?</text>
        <text start="85" dur="2">It&amp;#39;s a really fascinating machine learning problem.</text>
      </transcript>
    </video>
    <video title="29 Digit Recognition" id="kD2wD_MDVk4" length="141">
      <transcript>
        <text start="0" dur="2">[Narrator] Naive Bayes can also be applied to</text>
        <text start="2" dur="3">the problem of hand written digits recognition.</text>
        <text start="5" dur="4">This is a sample of hand-written digits taken</text>
        <text start="9" dur="3">from a U.S. postal data set</text>
        <text start="12" dur="5">where hand written zip codes on letters are</text>
        <text start="17" dur="4">being scanned and automatically classified.</text>
        <text start="21" dur="2">The machine-learning problem here is</text>
        <text start="23" dur="5">taken a symbol just like this.</text>
        <text start="28" dur="2">What is the corresponding number?</text>
        <text start="30" dur="2">Here it&amp;#39;s obviously 0.</text>
        <text start="32" dur="2">Here it&amp;#39;s obviously 1.</text>
        <text start="34" dur="2">Here it&amp;#39;s obviously 2, 1.</text>
        <text start="36" dur="2">For the one down here,</text>
        <text start="38" dur="3">it&amp;#39;s a little bit harder to tell.</text>
        <text start="41" dur="3">Now when you apply Naive Bayes,</text>
        <text start="44" dur="2">the input vector</text>
        <text start="46" dur="2">could be the pixel values</text>
        <text start="48" dur="2">of each individual pixel so we have</text>
        <text start="50" dur="4">a 16 x 16 input resolution.</text>
        <text start="54" dur="5">You would get 256 different values</text>
        <text start="59" dur="3">corresponding to the brightness of each pixel.</text>
        <text start="62" dur="3">Now obviously given sufficiently made</text>
        <text start="65" dur="2">training example, you might hope</text>
        <text start="67" dur="2">to recognize digits,</text>
        <text start="69" dur="3">but one of the deficiencies of this approach is</text>
        <text start="72" dur="3">it is not particularly shifted range.</text>
        <text start="75" dur="3">So for example a pattern like this</text>
        <text start="79" dur="2">will look fundamentally different</text>
        <text start="81" dur="3">from a pattern like this.</text>
        <text start="84" dur="3">Even though the pattern on the right is obtained</text>
        <text start="87" dur="2">by shifting the pattern on the left</text>
        <text start="89" dur="2">by 1 to the right.</text>
        <text start="91" dur="3">There&amp;#39;s many different solutions, but a common one could be</text>
        <text start="94" dur="2">to use smoothing in a different way from</text>
        <text start="96" dur="2">the way we discussed it before.</text>
        <text start="98" dur="2">Instead of just counting 1 pixel value&amp;#39;s count,</text>
        <text start="100" dur="2">you could mix it with counts of the</text>
        <text start="102" dur="2">neighboring pixel values so if</text>
        <text start="104" dur="2">all pixels are slightly shifted,</text>
        <text start="106" dur="2">we get about the same statistics</text>
        <text start="108" dur="2">as the pixel itself.</text>
        <text start="110" dur="2">Such a method is called input smoothing.</text>
        <text start="112" dur="3">You can what&amp;#39;s technically called convolve</text>
        <text start="115" dur="2">the input vector equals pixel value variable, and</text>
        <text start="117" dur="3">you might get better results than if you</text>
        <text start="120" dur="2">do Naive Bayes on the raw pixels.</text>
        <text start="122" dur="2">Now to tell you the truth for</text>
        <text start="124" dur="2">digit recognition of this type,</text>
        <text start="126" dur="2">Naive Bayes is not a good choice.</text>
        <text start="128" dur="2">The conditional independence assumption</text>
        <text start="130" dur="2">of each pixel, given the class,</text>
        <text start="132" dur="2">is too strong an assumption in this case,</text>
        <text start="134" dur="3">but it&amp;#39;s fun to talk about image recognition</text>
        <text start="137" dur="4">in the context of Naive Bayes regardless.</text>
      </transcript>
    </video>
    <video title="30 Overfitting Prevention" id="-jswWk8YLro" length="210">
      <transcript>
        <text start="0" dur="4">So, let me step back a step and talk a bit about</text>
        <text start="4" dur="3">overfitting prevention in machine learning</text>
        <text start="7" dur="2">because it&amp;#39;s such an important topic.</text>
        <text start="9" dur="3">We talked about Occam&amp;#39;s Razor,</text>
        <text start="12" dur="4">which in a generalized way suggests there is</text>
        <text start="16" dur="6">a tradeoff between how well we can fit the data</text>
        <text start="22" dur="6">and how smooth our learning algorithm is.</text>
        <text start="28" dur="4">In our class in smoothing, we already found 1 way</text>
        <text start="32" dur="2">to let Occam&amp;#39;s Razor play, which is by</text>
        <text start="34" dur="6">selecting the value K to make our statistical counts smoother.</text>
        <text start="40" dur="4">I alluded to a similar way in the image recognition domain</text>
        <text start="44" dur="5">where we smoothed the image so the neighboring pixels count similar.</text>
        <text start="49" dur="4">This all raises the question of how to choose the smoothing parameter.</text>
        <text start="53" dur="5">So, in particular, in Laplacian smoothing, how to choose the K.</text>
        <text start="58" dur="4">There is a method called cross-validation</text>
        <text start="62" dur="3">which can help you find an answer.</text>
        <text start="65" dur="4">This method assumes there is plenty of training examples, but</text>
        <text start="69" dur="5">to tell you the truth, in spam filtering there is more than you&amp;#39;d ever want.</text>
        <text start="74" dur="3">Take your training data</text>
        <text start="77" dur="2">and divide it into 3 buckets.</text>
        <text start="79" dur="5">Train, cross-validate, and test.</text>
        <text start="84" dur="3">Typical ratios will be 80% goes into train,</text>
        <text start="87" dur="3">10% into cross-validate,</text>
        <text start="90" dur="3">and 10% into test.</text>
        <text start="93" dur="4">You use the train to find all your parameters.</text>
        <text start="97" dur="3">For example, the probabilities of a base network.</text>
        <text start="100" dur="3">You use your cross-validation set</text>
        <text start="103" dur="3">to find the optimal K, and the way you do this is</text>
        <text start="106" dur="3">you train for different values of K,</text>
        <text start="109" dur="6">you observe how well the training model performs on the CV data,</text>
        <text start="115" dur="3">not touching the test data,</text>
        <text start="118" dur="3">and then you maximize over all the Ks to get the best performance</text>
        <text start="121" dur="2">on the cross-validation set.</text>
        <text start="123" dur="3">You iterate this many times until you find the best K.</text>
        <text start="126" dur="3">When you&amp;#39;re done with the best K,</text>
        <text start="129" dur="3">you train again, and then finally</text>
        <text start="132" dur="3">only one you touch the test data</text>
        <text start="135" dur="2">to verify the performance,</text>
        <text start="137" dur="3">and this is the performance you report.</text>
        <text start="140" dur="3">It&amp;#39;s really important in cross-validation</text>
        <text start="143" dur="5">split apart a cross-validation set that&amp;#39;s different from the test set.</text>
        <text start="148" dur="3">If you were to use the test set to find the optimal K,</text>
        <text start="151" dur="4">then your test set becomes an effective part of your training routine,</text>
        <text start="155" dur="3">and you might overfit your test data,</text>
        <text start="158" dur="2">and you wouldn&amp;#39;t even know.</text>
        <text start="160" dur="3">By keeping the test data separate from the beginning,</text>
        <text start="163" dur="3">and train on the training data, you use</text>
        <text start="166" dur="3">the cross-validation data to find how good your train data is doing,</text>
        <text start="169" dur="4">and the unknown parameters of K to fine-tune the K.</text>
        <text start="173" dur="3">Finally, only once you use the test data</text>
        <text start="176" dur="3">do you get a fair answer to the question,</text>
        <text start="179" dur="3">&amp;quot;How well will your model perform on future data?&amp;quot;</text>
        <text start="182" dur="3">So, pretty much everybody in machine learning</text>
        <text start="185" dur="3">uses this model.</text>
        <text start="188" dur="4">You can redo the split between training and the cross-validation part,</text>
        <text start="192" dur="3">people often use the word 10-fold cross-validation</text>
        <text start="195" dur="2">where they do 10 different forwardings</text>
        <text start="197" dur="3">and run the model 10 times to find the optimal K</text>
        <text start="200" dur="2">or smoothing parameter.</text>
        <text start="202" dur="3">No matter which way you do it, find the optimal smoothing parameter</text>
        <text start="205" dur="5">and then use a test set exactly once to verify in a report.</text>
      </transcript>
    </video>
    <video title="31 Classification vs Regression" id="5RLRKkzYWuQ" length="120">
      <transcript>
        <text start="0" dur="3">Let me back up a step further,</text>
        <text start="3" dur="3">and let&amp;#39;s look at supervised learning more generally.</text>
        <text start="6" dur="3">Our example so far was one of classification.</text>
        <text start="9" dur="3">The characteristic of classifcation is</text>
        <text start="12" dur="4">that the target labels or the target class is discrete.</text>
        <text start="16" dur="2">In our case it was actually binary.</text>
        <text start="18" dur="5">In many problems, we try to predict a continuous quantity.</text>
        <text start="23" dur="6">For example, in the interval 0 to 1 or perhaps a real number.</text>
        <text start="29" dur="4">Those machine learning problems are called regression problems.</text>
        <text start="33" dur="4">Regression problems are fundamentally different from classification problems.</text>
        <text start="37" dur="5">For example, our base network doesn&amp;#39;t afford us an answer</text>
        <text start="42" dur="3">to a problem where the target value could be at 0,1.</text>
        <text start="45" dur="3">A regression problem, for example, would be one to</text>
        <text start="48" dur="2">predict the weather tomorrow.</text>
        <text start="50" dur="3">Temperature is a continuous value. Our base number would not be able</text>
        <text start="53" dur="5">to predict the temperature, it only can predict discrete classes.</text>
        <text start="58" dur="3">A regression algorithm is able to give us a continuous prediction</text>
        <text start="61" dur="3">about the temperature tomorrow.</text>
        <text start="64" dur="3">So let&amp;#39;s look at the regression next.</text>
        <text start="67" dur="3">So here&amp;#39;s my first quiz for you on regression.</text>
        <text start="70" dur="8">This scatter plot shows for Berkeley California for a period of time</text>
        <text start="78" dur="3">the data for each house that was sold.</text>
        <text start="81" dur="3">Each dot is a sold house.</text>
        <text start="84" dur="3">It graphs the size of the house in square feet</text>
        <text start="87" dur="5">to the sales price in thousands of dollars.</text>
        <text start="92" dur="2">As you can see, roughly speaking,</text>
        <text start="94" dur="3">as the size of the house goes up,</text>
        <text start="97" dur="3">so does the sales price.</text>
        <text start="100" dur="5">I wonder, for a house of about 2500 square feet,</text>
        <text start="105" dur="4">what is the approximate sales price you would assume</text>
        <text start="109" dur="3">based just on the scatter plot data?</text>
        <text start="112" dur="8">Is it 400k, 600k, 800k, or 1000k?</text>
      </transcript>
    </video>
    <video title="32 Answer" id="4kXyi3KWcSw" length="26">
      <transcript>
        <text start="0" dur="5">My answer is, there seems to be a roughly linear relationship,</text>
        <text start="5" dur="6">maybe not quite linear, between the house size and the price.</text>
        <text start="11" dur="4">So we look at a linear graph that best describes the data--</text>
        <text start="15" dur="3">you get this dashed line over here.</text>
        <text start="18" dur="4">And for the dashed line, if you walk up the 2500 square feet,</text>
        <text start="22" dur="2">you end up with roughly 800K.</text>
        <text start="24" dur="2">So this would have been the best answer.</text>
      </transcript>
    </video>
    <video title="33 Linear Regression" id="4bGWN67R9G0" length="166">
      <transcript>
        <text start="0" dur="5">Now obviously you can answer this question without understanding anything about regression.</text>
        <text start="5" dur="5">But what you find is this is different from classification as before.</text>
        <text start="10" dur="3">This is not a binary concept anymore of like expensive and cheap.</text>
        <text start="13" dur="4">It really is a relationship between two variables.</text>
        <text start="17" dur="3">One you care about--the house price, and one that you can observe,</text>
        <text start="20" dur="3">which is the house size in square feet.</text>
        <text start="23" dur="5">And your goal is to fit a curve that best explains the data.</text>
        <text start="28" dur="3">Once again, we have a case where we can play Occam&amp;#39;s razor.</text>
        <text start="31" dur="4">There clearly is a data fit that is not linear that might be better,</text>
        <text start="35" dur="2">like this one over here.</text>
        <text start="37" dur="3">And when you go to hide the linear curves,</text>
        <text start="40" dur="4">you might even be inclined to draw a curve like this.</text>
        <text start="44" dur="5">Now of course the curve I&amp;#39;m drawing right now is likely an overfit.</text>
        <text start="49" dur="5">And you don&amp;#39;t want to postulate that this is the general relationship</text>
        <text start="54" dur="3">between the size of a house and the sales price.</text>
        <text start="57" dur="4">So even though my black curve might describe the data better,</text>
        <text start="61" dur="7">the blue curve or the dashed linear curve over here might be a better explanation overture of Occam&amp;#39;s razor.</text>
        <text start="68" dur="7">So let&amp;#39;s look a little bit deeper into what we call regression.</text>
        <text start="75" dur="4">As in all regression problems, our data will be comprised of</text>
        <text start="79" dur="6">input vectors of length in that map to another continuous value.</text>
        <text start="85" dur="5">And we might be given a total of M data points.</text>
        <text start="90" dur="6">This is from the classification case, except this time the Ys are continuous.</text>
        <text start="96" dur="8">Once again, we&amp;#39;re looking for function f that maps our vector x into y.</text>
        <text start="104" dur="10">In linear regression, the function has a particular form which is W1 times X plus W0.</text>
        <text start="114" dur="5">In this case X is one dimensional which is N = 1.</text>
        <text start="119" dur="8">Or in the high-dimensional space, we might just write W times X plus W0,</text>
        <text start="127" dur="5">where W is a vector and X is a vector.</text>
        <text start="132" dur="4">And this is the inner product of these 2 vectors over here.</text>
        <text start="136" dur="4">Let&amp;#39;s for now just consider the one-dimensional case.</text>
        <text start="140" dur="7">In this quiz, I&amp;#39;ve given you a linear regression form with 2 unknown parameters, W1 and W0.</text>
        <text start="147" dur="3">I&amp;#39;ve given you a data set.</text>
        <text start="150" dur="6">And this data set happens to be fittable by a linear regression model without any residual error.</text>
        <text start="156" dur="10">Without any math, can you look at this and find out to me what the 2 parameters, W0 and W1 are?</text>
      </transcript>
    </video>
    <video title="34 Answer" id="pLwMXAPKdas" length="77">
      <transcript>
        <text start="0" dur="3">This is a suprisingly challenging question.</text>
        <text start="3" dur="4">If you look at these numbers from 3 to 6.</text>
        <text start="7" dur="7">When we increase X by 3, Y decreases by 3,</text>
        <text start="14" dur="4">which suggests W1 is -1.</text>
        <text start="18" dur="2">Now let&amp;#39;s see if this holds.</text>
        <text start="20" dur="4">If we increase X by 3, it decreases Y by 3.</text>
        <text start="24" dur="4">If we increase X by 1, we decrease Y by 1.</text>
        <text start="28" dur="4">If we increase X by 2, we decrease Y by 2.</text>
        <text start="32" dur="4">So this number seems to be an exact fit.</text>
        <text start="36" dur="5">Next we have to get the constant W0 right.</text>
        <text start="41" dur="7">For X = 3, we get -3 as an expression over here,</text>
        <text start="48" dur="2">because we know W1 = -1.</text>
        <text start="50" dur="7">So if this has to equal zero in the end, then W0 has to be 3.</text>
        <text start="57" dur="2">Let&amp;#39;s do a quick check.</text>
        <text start="59" dur="3">-3 plus 3 is 0.</text>
        <text start="62" dur="3">-6 plus 3 is -3.</text>
        <text start="65" dur="4">And if we plug in any of the numbers, you find those are correct.</text>
        <text start="69" dur="3">Now this is the case of an exact data set.</text>
        <text start="72" dur="5">It gets much more challenging if the data set cannot be fit with a linear function.</text>
      </transcript>
    </video>
    <video title="35 More Linear Regression" id="v4XIkABA1N0" length="60">
      <transcript>
        <text start="0" dur="2">To define linear regression,</text>
        <text start="2" dur="3">we need to understand what we are trying to minimize.</text>
        <text start="5" dur="3">The word is called here, are loss function</text>
        <text start="8" dur="4">and the loss function is the amount of residual error we obtain</text>
        <text start="12" dur="4">after fitting the linear function as good as possible.</text>
        <text start="16" dur="4">The residual error is the sum of all training examples,</text>
        <text start="20" dur="5">J of YJ, which is the target label,</text>
        <text start="25" dur="9">minus our prediction, which is W1 XJ minus W0 to the square.</text>
        <text start="34" dur="3">This is the quadratic error between our target tables</text>
        <text start="37" dur="4">and what our best hypothesis can produce.</text>
        <text start="41" dur="2">The minimizing of loss</text>
        <text start="43" dur="3">is used for linear regression of a new regression problem,</text>
        <text start="46" dur="4">and you can write it as follows:</text>
        <text start="50" dur="2">Our solution to the regression problem W*</text>
        <text start="52" dur="8">is the arg min of the loss over all possible vectors W.</text>
      </transcript>
    </video>
    <video title="36 Quadratic Loss" id="wUFYzzrd6TQ" length="244">
      <transcript>
        <text start="0" dur="7">The problem of minimizing quadratic loss for linear functions can be solved in closed form.</text>
        <text start="7" dur="5">When I reduce, I will do this for the one-dimensional case on paper.</text>
        <text start="12" dur="5">I will also give you the solution for the case where your input space is multidimensional,</text>
        <text start="17" dur="4">which is often called &amp;quot;multivariant regression.&amp;quot;</text>
        <text start="22" dur="4">We seek to minimize a sum of a quadratic expression</text>
        <text start="26" dur="7">where the target labels are subtracted with the output of our linear regression model</text>
        <text start="33" dur="3">parameterized by w1 and w2.</text>
        <text start="36" dur="4">The summation here is overall training examples,</text>
        <text start="40" dur="5">and I leave the index of the summation out if not necessary.</text>
        <text start="45" dur="5">The minimum of this is obtained where the derivative of this function equals zero.</text>
        <text start="50" dur="3">Let&amp;#39;s call this function &amp;quot;L.&amp;quot;</text>
        <text start="53" dur="6">For the partial derivative with respect to w0, we get this expression over here,</text>
        <text start="59" dur="3">which we have to set to zero.</text>
        <text start="62" dur="4">We can easily get rid of the -2 and transform this as follows:</text>
        <text start="71" dur="4">Here M is the number of training examples.</text>
        <text start="77" dur="4">This expression over here gives us w0 as a function of w1,</text>
        <text start="81" dur="5">but we don&amp;#39;t know w1. Let&amp;#39;s do the same trick for w1</text>
        <text start="88" dur="2">and set this to zero as well,</text>
        <text start="92" dur="6">which gets us the expression over here.</text>
        <text start="98" dur="6">We can now plug in the w0 over here into this expression over here</text>
        <text start="104" dur="3">and obtain this expression over here,</text>
        <text start="107" dur="3">which looks really involved but is relatively straightforward.</text>
        <text start="112" dur="4">With a few steps of further calculation, which I&amp;#39;ll spare you for now,</text>
        <text start="116" dur="4">we get for w1 the following important formula:</text>
        <text start="122" dur="3">This is the final quotient for w1,</text>
        <text start="125" dur="5">where we take the number of training examples times of the sum of all xy</text>
        <text start="130" dur="6">minus the sum of x times the sum of y divided by this expression over here.</text>
        <text start="136" dur="3">Once we&amp;#39;ve computed w1,</text>
        <text start="139" dur="4">we can go back to our original articulation of w0 over here</text>
        <text start="143" dur="7">and plug w1 into w0 and obtain w0.</text>
        <text start="150" dur="7">These are the two important formulas we can also find in the textbook.</text>
        <text start="159" dur="5">I&amp;#39;d like to go back and use those formulas to calculate these two coefficients over here.</text>
        <text start="165" dur="9">You get 4 times the sum of x and the sum of y, which is -32</text>
        <text start="176" dur="9">minus the product of the sum of x, which is 18, and the sum of y, which is -6,</text>
        <text start="185" dur="11">divided by the sum of x squared, which is 86, times 4, minus the sum of x squared,</text>
        <text start="196" dur="4">which is 18 times 18, which is 324.</text>
        <text start="200" dur="5">If you work this all out, it becomes -1, which is w1.</text>
        <text start="205" dur="6">W0 is now obtained by completing the quarter times sum of all y,</text>
        <text start="211" dur="8">which is -6, minus -1/4 times sum of all x.</text>
        <text start="219" dur="7">If you plug this all in, you get 3, as over here. Our formula is actually correct.</text>
        <text start="226" dur="4">Here is another quiz for linear regression. We have the follow data:</text>
        <text start="231" dur="2">Here is the data plotted graphically.</text>
        <text start="233" dur="3">I wonder what the best regression is.</text>
        <text start="236" dur="8">Give me w0 and w1. Apply the formulas I just gave you.</text>
      </transcript>
    </video>
    <video title="37 Answer" id="ocviSEb04bk" length="87">
      <transcript>
        <text start="0" dur="9">And the answer is W0 = 0.5, and W1 = 0.9.</text>
        <text start="9" dur="5">If I were to draw a line, it would go about like this.</text>
        <text start="14" dur="5">It doesn&amp;#39;t really hit the two points at the end.</text>
        <text start="19" dur="5">If you were thinking of something like this, you were wrong.</text>
        <text start="24" dur="4">If you draw a curve like this, your quadratic error becomes 2.</text>
        <text start="28" dur="2">One over here, and one over here.</text>
        <text start="30" dur="5">The quadratic error is smaller for the line that goes in between those points.</text>
        <text start="35" dur="6">This is easily seen by computing as shown in the previous slide.</text>
        <text start="41" dur="14">W1 equals (4 x 118 - 20 x 20) / (4 x 120 - 400) which is 0.9.</text>
        <text start="55" dur="5">This is merely plugging in those numbers into the formulas I gave you.</text>
        <text start="60" dur="5">W0 then becomes  x 20.</text>
        <text start="65" dur="7">Now we plug in W1-- 0.9 / 4  x  20 equals 0.5.</text>
        <text start="72" dur="4">This is an example of linear regression,</text>
        <text start="76" dur="2">in which case there is a residual error,</text>
        <text start="78" dur="4">and the best-fitting curve is the one that minimizes</text>
        <text start="82" dur="5">the total of the residual vertical error in this graph over here.</text>
      </transcript>
    </video>
    <video title="38 Problems with Linear Regression" id="w7Ip8r0EIJQ" length="130">
      <transcript>
        <text start="0" dur="3">So linear regression works well</text>
        <text start="3" dur="2">if the data is approximately linear,</text>
        <text start="5" dur="4">but there are many examples when linear regression performs poorly.</text>
        <text start="9" dur="3">Here&amp;#39;s one where we have a</text>
        <text start="12" dur="3">curve that is really nonlinear.</text>
        <text start="15" dur="3">This is an interesting one where we seem to have a linear relationship</text>
        <text start="18" dur="3">that is flatter than the linear regression indicates,</text>
        <text start="21" dur="2">but there is one outlier.</text>
        <text start="23" dur="3">Because if you are minimizing quadratic error,</text>
        <text start="26" dur="4">outliers penalize you over-proportionately.</text>
        <text start="30" dur="4">So outliers are particularly bad for linear regression.</text>
        <text start="34" dur="1">And here is a case,</text>
        <text start="35" dur="2">where the data clearly suggests</text>
        <text start="37" dur="3">a very different phenomena for linear.</text>
        <text start="40" dur="2">We have only two ?? variables even being used,</text>
        <text start="42" dur="3">and this one has a strong frequency</text>
        <text start="45" dur="2">and a strong vertical spread.</text>
        <text start="47" dur="2">Clearly a linear regression model</text>
        <text start="49" dur="2">is a very poor one to explain</text>
        <text start="51" dur="2">this data over here.</text>
        <text start="53" dur="2">Another problem with linear regression</text>
        <text start="55" dur="4">is that as you go to infinity in the X space,</text>
        <text start="59" dur="3">your Ys also become infinite.</text>
        <text start="62" dur="3">In some problems that isn&amp;#39;t a plausible model.</text>
        <text start="65" dur="3">For example, if you wish to predict the weather</text>
        <text start="68" dur="2">anytime into the future,</text>
        <text start="70" dur="3">it&amp;#39;s implausible to assume the further the prediction goes out,</text>
        <text start="73" dur="2">the hotter or the cooler it becomes.</text>
        <text start="75" dur="2">For such situations there is a</text>
        <text start="77" dur="3">model called logistic regression,</text>
        <text start="80" dur="2">which uses a slightly more complicated</text>
        <text start="82" dur="2">model than linear regression,</text>
        <text start="84" dur="1">which goes as follows:.</text>
        <text start="85" dur="5">Let F of XP, or linear function,</text>
        <text start="90" dur="2">and the output of logistic regression</text>
        <text start="92" dur="2">is obtained by the following function:</text>
        <text start="94" dur="6">One over one plus exponential of minus F of X.</text>
        <text start="100" dur="3">So here&amp;#39;s a quick quiz for you.</text>
        <text start="103" dur="5">What is the range in which Z might fall</text>
        <text start="108" dur="1">given this function over here,</text>
        <text start="109" dur="4">and ??? the linear function of F or X over here.</text>
        <text start="113" dur="3">Is it zero, one?</text>
        <text start="116" dur="3">Is it minus one, one?</text>
        <text start="119" dur="3">Is it minus one, zero?</text>
        <text start="122" dur="2">Minus two, two?</text>
        <text start="124" dur="6">Or none of the above?</text>
      </transcript>
    </video>
    <video title="39 Answer" id="PYZ-7YS5T0k" length="60">
      <transcript>
        <text start="0" dur="2">The answer is zero, one.</text>
        <text start="2" dur="3">If this expression over here,</text>
        <text start="5" dur="2">F of X,</text>
        <text start="7" dur="2">grows to positive infinity,</text>
        <text start="9" dur="5">then Z becomes one.</text>
        <text start="14" dur="2">And the reason is</text>
        <text start="16" dur="3">as this term over here becomes very large,</text>
        <text start="19" dur="3">E to the minus of that term approaches zero;</text>
        <text start="22" dur="3">one over one equals one.</text>
        <text start="25" dur="5">If F of X goes to minus infinity,</text>
        <text start="30" dur="3">then Z goes to zero.</text>
        <text start="33" dur="1">And the reason is,</text>
        <text start="34" dur="4">if this expression over here goes to minus infinity,</text>
        <text start="38" dur="3">E to the infinity becomes very large;</text>
        <text start="41" dur="3">one over something very large becomes zero.</text>
        <text start="44" dur="5">When we plot the logistic function it looks like this:</text>
        <text start="49" dur="2">So it&amp;#39;s approximately linear</text>
        <text start="51" dur="3">around F of X equals zero,</text>
        <text start="54" dur="4">but it levels off to zero and one</text>
        <text start="58" dur="2">as we go to the extremes.</text>
      </transcript>
    </video>
    <video title="40 Linear Regression and Complexity Control" id="4G5mH4FW-WY" length="99">
      <transcript>
        <text start="0" dur="4">Another problem with linear regression has to do with the regularization</text>
        <text start="4" dur="2">or complexity control.</text>
        <text start="6" dur="2">Just like before, we sometimes wish to have</text>
        <text start="8" dur="2">a less complex model.</text>
        <text start="10" dur="5">So in regularization, the loss function is either the sum</text>
        <text start="15" dur="6">of the loss of a data function and a complexity control term,</text>
        <text start="21" dur="3">which is often called the loss of the parameters.</text>
        <text start="24" dur="5">The loss of the data is simply curvatic loss, as we discussed before.</text>
        <text start="29" dur="6">The loss of parameters might just be a function that penalizes</text>
        <text start="35" dur="2">the parameters to become large</text>
        <text start="37" dur="6">up to some known P, where P is usually either 1 or 2.</text>
        <text start="43" dur="3">If you draw this graphically,</text>
        <text start="46" dur="3">in a parameter space comprised of 2 parameters,</text>
        <text start="49" dur="4">your curvatic term for minimizing the data error</text>
        <text start="53" dur="4">might look like this, where the minimum sits over here.</text>
        <text start="57" dur="5">Your term for regularization might pull these parameters toward 0.</text>
        <text start="62" dur="7">It pulls it toward 0, along the circle if you use curvatic error,</text>
        <text start="69" dur="5">and it does it in a diamond-shaped way.</text>
        <text start="74" dur="6">For L1 regularization--either one works well.</text>
        <text start="80" dur="4">L1 has the advantage in that parameters tend to get really sparse.</text>
        <text start="84" dur="6">If you look at this diagram, there is a tradeoff between W-0 and W-1.</text>
        <text start="90" dur="3">In the L1 case, that allows one of them to be driven to 0.</text>
        <text start="93" dur="4">In the L2 case, parameters tend not to be as sparse.</text>
        <text start="97" dur="2">So L1 is often preferred.</text>
      </transcript>
    </video>
    <video title="41 Minimizing Complicated Loss Functions" id="0RmqLOxexh4" length="106">
      <transcript>
        <text start="0" dur="3">This all raises the question,</text>
        <text start="3" dur="3">how to minimize more complicated loss functions</text>
        <text start="6" dur="3">than the one we discussed so far.</text>
        <text start="9" dur="5">Are there closed-form solutions of the type we found for linear regression?</text>
        <text start="14" dur="3">Or do we have to resort to iterative methods?</text>
        <text start="17" dur="6">The general answer is, unfortunantly, we have to resort to iterative methods.</text>
        <text start="23" dur="5">Even though there are special cases in which corresponding solutions may exist,</text>
        <text start="28" dur="4">in general, our loss functions now become complicated enough</text>
        <text start="32" dur="3">that all we can do is iterate.</text>
        <text start="35" dur="5">Here is a prototypical loss function</text>
        <text start="40" dur="4">and the method for interation will be called gradient descent.</text>
        <text start="44" dur="4">In gradient descent, you start with an initial guess,</text>
        <text start="48" dur="5">W-0, where 0 is your iteration number,</text>
        <text start="53" dur="2">and then you up with it iteratively.</text>
        <text start="55" dur="9">Your i plus 1st parameter guess will be obtained by taking your i-th guess</text>
        <text start="64" dur="6">and subtracting from it the gradient of your loss function,</text>
        <text start="70" dur="5">and that guess multiplied by a small learning weight alpha,</text>
        <text start="75" dur="4">where alpha is often as small as 0.01.</text>
        <text start="79" dur="2">I have a couple of questions for you.</text>
        <text start="81" dur="4">Consider the following 3 points.</text>
        <text start="85" dur="2">We call them A, B, C.</text>
        <text start="87" dur="7">I wish to know, for points A, B, and C,</text>
        <text start="94" dur="6">Is the gradient at this point positive, about zero, or negative?</text>
        <text start="100" dur="6">For each of those, check exactly one of those cases.</text>
      </transcript>
    </video>
    <video title="42 Answer" id="rAcwpZJqAZA" length="47">
      <transcript>
        <text start="0" dur="3">In case A, the gradient is negative.</text>
        <text start="3" dur="3">If you move to the right in the X space,</text>
        <text start="6" dur="3">then your loss decreases.</text>
        <text start="9" dur="3">In B, it&amp;#39;s about zero.</text>
        <text start="12" dur="3">In C, it&amp;#39;s pointing up; it&amp;#39;s positive.</text>
        <text start="15" dur="3">So if you apply the rule over here,</text>
        <text start="18" dur="3">if you were to start at A as your W-zero,</text>
        <text start="21" dur="2">then your gradient is negative.</text>
        <text start="23" dur="3">Therefore, you would add something to the value of W.</text>
        <text start="26" dur="3">You move to the right, and your loss has decreased.</text>
        <text start="29" dur="2">You do this until you find yourself</text>
        <text start="31" dur="3">with what&amp;#39;s called a local minimum, where B resides.</text>
        <text start="34" dur="3">In this instance over here, gradient descent starting at A</text>
        <text start="37" dur="2">would not get you to the global minimum,</text>
        <text start="39" dur="3">which sits over here because there&amp;#39;s a bump in between.</text>
        <text start="42" dur="5">Gradient methods are known to be subject to local minimum.</text>
      </transcript>
    </video>
    <video title="43 Question" id="dKKigX6nhyU" length="28">
      <transcript>
        <text start="0" dur="3">I have another gradient quiz.</text>
        <text start="3" dur="3">Consider the following quadratic arrow function.</text>
        <text start="6" dur="3">We are considering the gradient in 3 different places.</text>
        <text start="9" dur="4">a. b. and c.</text>
        <text start="13" dur="4">And they ask you which gradient is the largest.</text>
        <text start="17" dur="6">a, b, or c or are they all equal?</text>
        <text start="23" dur="5">In which case, you would want to check the last box over here</text>
      </transcript>
    </video>
    <video title="44 Answer" id="5Vm8ibmxroE" length="20">
      <transcript>
        <text start="0" dur="4">And the answer is C.</text>
        <text start="4" dur="4">The derivative of a quadratic function is a linear function.</text>
        <text start="8" dur="3">Which would look about like this.</text>
        <text start="11" dur="4">And as we go outside, our gradient becomes larger and larger.</text>
        <text start="15" dur="5">This over here is much steeper than this curve over here.</text>
      </transcript>
    </video>
    <video title="45 Question" id="2oy1QoXsvGQ" length="21">
      <transcript>
        <text start="0" dur="4">[Thrun] Here is a final gradient descent quiz.</text>
        <text start="4" dur="4">Suppose we have a loss function like this</text>
        <text start="8" dur="4">and our gradient descent starts over here.</text>
        <text start="12" dur="3">Will it likely reach the global minimum?</text>
        <text start="15" dur="2">Yes or no.</text>
        <text start="17" dur="4">Please check one of those boxes.</text>
      </transcript>
    </video>
    <video title="46 Answer" id="R1o9wbhnv94" length="60">
      <transcript>
        <text start="0" dur="2">[Thrun] And the answer is yes,</text>
        <text start="2" dur="4">although, technically speaking, to reach the absolute global minimum</text>
        <text start="6" dur="5">we need the learning rates to become smaller and smaller over time.</text>
        <text start="11" dur="4">If they stay constant, there is a chance this thing might bounce around</text>
        <text start="15" dur="3">between 2 points in the end and never reach the global minimum.</text>
        <text start="18" dur="4">But assuming that we implement gradient descent correctly,</text>
        <text start="22" dur="2">we will finally reach the global minimum.</text>
        <text start="24" dur="5">That&amp;#39;s not the case if you start over here, where we can get stuck over here</text>
        <text start="29" dur="3">and settle for the minimum over here, which is a local minimum</text>
        <text start="32" dur="3">and not the best solution to our optimization problem.</text>
        <text start="35" dur="3">So one of the important points to take away from this is</text>
        <text start="38" dur="5">gradient descent is universally applicable to more complicated problems--</text>
        <text start="43" dur="3">problems that don&amp;#39;t have a plausible solution.</text>
        <text start="46" dur="3">But you have to check whether there is many local minima,</text>
        <text start="49" dur="2">and if so, you have to worry about this.</text>
        <text start="51" dur="4">Any optimization book can tell you tricks how to overcome this.</text>
        <text start="55" dur="5">I won&amp;#39;t go into any more depth here in this class.</text>
      </transcript>
    </video>
    <video title="47 Gradient Descent Implementation" id="Iy9gzbQ7_3g" length="101">
      <transcript>
        <text start="0" dur="5">[Thrun] It&amp;#39;s interesting to see how to minimize a loss function using gradient descent.</text>
        <text start="5" dur="7">In our linear case, we have L equals sum over the correct labels</text>
        <text start="12" dur="4">minus our linear function to the square,</text>
        <text start="16" dur="2">which we seek to minimize.</text>
        <text start="18" dur="3">We already know that this has a closed form solution,</text>
        <text start="21" dur="4">but just for the fun of it, let&amp;#39;s look at gradient descent.</text>
        <text start="25" dur="8">The gradient of L with respect to W1 is minus 2, sum of all J</text>
        <text start="33" dur="6">of the difference as before but without the square times Xj.</text>
        <text start="39" dur="4">The gradient with respect to W0 is very similar.</text>
        <text start="43" dur="6">So in gradient descent we start with W1 0 and W0 0</text>
        <text start="49" dur="6">where the upper cap 0 corresponds to the iteration index of gradient descent.</text>
        <text start="55" dur="2">And then we iterate.</text>
        <text start="57" dur="9">In the M iteration we get our new estimate by using the old estimate</text>
        <text start="66" dur="4">minus a learning rate of this gradient over here</text>
        <text start="70" dur="5">taking the position of the old estimate W1, M minus 1.</text>
        <text start="75" dur="5">Similarly, for W0 we get this expression over here.</text>
        <text start="80" dur="4">And these expressions look nasty,</text>
        <text start="84" dur="4">but what it really means is we subtract an expression like this</text>
        <text start="88" dur="3">every time we do gradient descent from W1</text>
        <text start="91" dur="5">and an expression like this every time we do gradient descent from W0,</text>
        <text start="96" dur="5">which is easy to implement, and that implements gradient descent.</text>
      </transcript>
    </video>
    <video title="48 Perceptron" id="yOSGC67bOIk" length="255">
      <transcript>
        <text start="0" dur="8">Now, there are many different ways to apply linear functions in machine learning.</text>
        <text start="8" dur="4">We so far have studied linear functions for regression,</text>
        <text start="12" dur="4">but linear functions are also used for classification,</text>
        <text start="16" dur="5">and specifically for an algorithm called the perceptron algorithm.</text>
        <text start="21" dur="6">This algorithm happens to be a very early model of a neuron,</text>
        <text start="27" dur="3">as in the neurons we have in our brains,</text>
        <text start="30" dur="3">and was invented in the 1940s.</text>
        <text start="33" dur="8">Suppose we give a data set of positive samples and negative samples.</text>
        <text start="41" dur="8">A linear separator is a linear equation that separates positive from negative examples.</text>
        <text start="49" dur="6">Obviously, not all sets possess a linear separator, but some do.</text>
        <text start="55" dur="7">For those we can define the algorithm of the perceptron and it actually converges.</text>
        <text start="62" dur="5">To define a linear separator, let&amp;#39;s start with our linear equation as before--</text>
        <text start="67" dur="11">w1x + w0 in cases where x is higher dimensional this might actually be a vector--never mind.</text>
        <text start="78" dur="8">If this is larger or equal to zero, then we call our classification 1.</text>
        <text start="86" dur="4">Otherwise, we call it zero.</text>
        <text start="90" dur="5">Here&amp;#39;s our linear separation classification function</text>
        <text start="95" dur="4">where this is our common linear function.</text>
        <text start="99" dur="6">Now, as I said, perceptron only converges if the data is linearly separable,</text>
        <text start="105" dur="4">and then it converges to a linear separation of the data,</text>
        <text start="109" dur="3">which is quite amazing.</text>
        <text start="112" dur="4">Perceptron is an iterative algorithm that is not dissimilar from grade descent.</text>
        <text start="116" dur="7">In fact, the update rule echoes that of grade descent, and here&amp;#39;s how it goes.</text>
        <text start="123" dur="6">We start with a random guess for w1 and w0,</text>
        <text start="129" dur="4">which may correspond to a random separation line,</text>
        <text start="133" dur="4">but usually is inaccurate.</text>
        <text start="137" dur="12">Then the mth weight-i is obtained by using the old weight plus some learning rate alpha</text>
        <text start="149" dur="4">times the difference between the desired target label</text>
        <text start="153" dur="6">and the target label produced by our function at the point m-1.</text>
        <text start="159" dur="6">Now, this is an online learning rule, which is we don&amp;#39;t process all the data in batch.</text>
        <text start="165" dur="5">We process one data at a time, and we might go through the data many, many times--</text>
        <text start="170" dur="2">hence the j over here--</text>
        <text start="172" dur="3">but every time we do this, we apply this rule over here.</text>
        <text start="175" dur="8">What this rule gives us is a method to adapt our weights in proportion to the error.</text>
        <text start="183" dur="4">If the prediction of our function f equals our target label,</text>
        <text start="187" dur="4">and the error is zero, then no update occurs.</text>
        <text start="191" dur="7">If there is a difference, however, we update in a way so as to minimize the error.</text>
        <text start="198" dur="4">Alpha is a small learning weight.</text>
        <text start="202" dur="6">Once again, perceptron converges to a correct linear separator</text>
        <text start="208" dur="3">if such linear separator exists.</text>
        <text start="211" dur="5">Now, the case of linear separation has recently received a lot of attention in machine learning.</text>
        <text start="216" dur="6">If you look at the picture over here, you&amp;#39;ll find there are many different linear separators.</text>
        <text start="222" dur="5">There is one over here. There is one over here. There is one over here.</text>
        <text start="227" dur="6">One of the questions that has recently been researched extensively is which one to prefer.</text>
        <text start="233" dur="4">Is it a, b, or c?</text>
        <text start="237" dur="4">Even though you probably have never seen this literature,</text>
        <text start="241" dur="4">I will just ask your intuition in this following quiz.</text>
        <text start="245" dur="5">Which linear separator would you prefer if you look at these three different linear separators--</text>
        <text start="250" dur="5">a, b, c, or none of them?</text>
      </transcript>
    </video>
    <video title="49 Answer and SVMs" id="xRf9wAeU1kI" length="338">
      <transcript>
        <text start="0" dur="4">[Narrator] And intuitively I would argue it&amp;#39;s B,</text>
        <text start="4" dur="2">and the reason why is</text>
        <text start="6" dur="3">C comes really close to examples.</text>
        <text start="9" dur="3">So if these examples are noisy,</text>
        <text start="12" dur="2">it&amp;#39;s quite likely that</text>
        <text start="14" dur="3">by being so close to these examples</text>
        <text start="17" dur="3">that future examples cross the line.</text>
        <text start="20" dur="3">Similarly A comes close to examples.</text>
        <text start="23" dur="3">B is the one that stays really far away</text>
        <text start="26" dur="2">from any example.</text>
        <text start="28" dur="3">So there&amp;#39;s this entire region over here</text>
        <text start="31" dur="3">where there&amp;#39;s no example anywhere near B.</text>
        <text start="34" dur="3">This region is often called the margin.</text>
        <text start="37" dur="3">The margin of the linear separator</text>
        <text start="40" dur="3">is the distance of the separator</text>
        <text start="43" dur="2">to the closest training example.</text>
        <text start="45" dur="2">The margin is a really important concept</text>
        <text start="47" dur="2">in machine learning.</text>
        <text start="49" dur="2">There is an entire class of maximum margin</text>
        <text start="51" dur="2">learning algorithms,</text>
        <text start="53" dur="3">and the 2 most popular are</text>
        <text start="56" dur="4">support vector machines and boosting.</text>
        <text start="60" dur="2">If you are familiar with machine learning,</text>
        <text start="62" dur="2">you&amp;#39;ve come across these terms.</text>
        <text start="64" dur="3">These are very frequently used these days</text>
        <text start="67" dur="3">in actual discrimination learning tasks.</text>
        <text start="70" dur="2">I will not go into any details because it would go</text>
        <text start="72" dur="4">way beyond the scope of this introduction</text>
        <text start="76" dur="2">to artificial intelligence class, but let&amp;#39;s see</text>
        <text start="78" dur="3">a few abstract words specifically about</text>
        <text start="81" dur="4">support vector machines or SVMs.</text>
        <text start="85" dur="5">As I said before a support vector machine</text>
        <text start="90" dur="4">derives a linear separator, and it takes</text>
        <text start="94" dur="5">the one that actually maximizes the margin</text>
        <text start="99" dur="3">as shown over here.</text>
        <text start="102" dur="2">By doing so it attains additional robost-ness</text>
        <text start="104" dur="2">over perceptron which only picks</text>
        <text start="106" dur="2">a linear separator without</text>
        <text start="108" dur="3">consideration of the margin.</text>
        <text start="111" dur="2">Now the problem of finding the</text>
        <text start="113" dur="2">margin maximizing linear separator</text>
        <text start="115" dur="4">can be solved by a quadratic program</text>
        <text start="119" dur="4">which is an integer method for finding the best</text>
        <text start="123" dur="3">linear separator that maximizes the margin.</text>
        <text start="126" dur="2">One of the nice things that support</text>
        <text start="128" dur="4">vector machines do in practice is</text>
        <text start="132" dur="4">they use linear techniques to solve</text>
        <text start="136" dur="3">nonlinear separation problems,</text>
        <text start="139" dur="3">and I&amp;#39;m just going to give you a glimpse of</text>
        <text start="142" dur="3">what&amp;#39;s happening without going into any detail.</text>
        <text start="145" dur="3">Suppose the data looks as follows:</text>
        <text start="148" dur="3">we have a positive class</text>
        <text start="151" dur="2">which is near the origin of a coordinate system</text>
        <text start="153" dur="4">and a negative class that surrounds the positive class.</text>
        <text start="157" dur="2">Clearly these 2 classes</text>
        <text start="159" dur="2">are not linearly separable</text>
        <text start="161" dur="2">because there&amp;#39;s no line I can draw that</text>
        <text start="163" dur="4">separates the negative examples from the positive examples.</text>
        <text start="167" dur="2">An idea that underlies SVMs,</text>
        <text start="169" dur="2">that will ultimately be known as</text>
        <text start="171" dur="2">the kernel trick,</text>
        <text start="173" dur="3">is to augment the feature set by new features.</text>
        <text start="176" dur="2">Suppose this is X1, and this is X2,</text>
        <text start="178" dur="2">and normally X1 and X2</text>
        <text start="180" dur="3">will be the input features.</text>
        <text start="183" dur="2">In this example, you might derive</text>
        <text start="185" dur="2">a 3rd one.</text>
        <text start="187" dur="2">Let me pick a 3rd one</text>
        <text start="189" dur="4">Suppose X3 equals the square root of</text>
        <text start="193" dur="5">X1 square + X2 square.</text>
        <text start="198" dur="4">In other words X3 is the distance</text>
        <text start="202" dur="3">of any data point from the center</text>
        <text start="205" dur="2">of the coordinate system.</text>
        <text start="207" dur="4">Then things do become linearly separable</text>
        <text start="211" dur="2">so that just along the 3rd dimension</text>
        <text start="213" dur="3">all the positive examples end up</text>
        <text start="216" dur="3">to be close to the origin,</text>
        <text start="219" dur="2">and all the negative examples</text>
        <text start="221" dur="2">are further away, and the line is</text>
        <text start="223" dur="3">orthogonal to the 3rd input feature</text>
        <text start="226" dur="3">solves the separation problem.</text>
        <text start="229" dur="3">Map back into the space over here</text>
        <text start="232" dur="3">is actually a circle which is a set of all</text>
        <text start="235" dur="5">values of X3 that are equidistant</text>
        <text start="240" dur="2">to the center of the origin.</text>
        <text start="242" dur="4">Now this trick could be done in any linear learning algorithm,</text>
        <text start="246" dur="2">and it&amp;#39;s really an amazing trick.</text>
        <text start="248" dur="2">You can take any nonlinear problem, add</text>
        <text start="250" dur="3">features of this type or any other type,</text>
        <text start="253" dur="2">and use linear techniques</text>
        <text start="255" dur="2">and get better solutions.</text>
        <text start="257" dur="2">This is a very deep machine learning insight</text>
        <text start="259" dur="2">that you can extend your feature space</text>
        <text start="261" dur="2">in this way, and there&amp;#39;s numerous</text>
        <text start="263" dur="2">papers written about this.</text>
        <text start="265" dur="6">In SVMs, the extension of the feature space is mathematically done by</text>
        <text start="271" dur="2">what&amp;#39;s called a kernel.</text>
        <text start="273" dur="3">I can&amp;#39;t really tell you about this in this class,</text>
        <text start="276" dur="2">but it makes it possible to write</text>
        <text start="278" dur="3">very large new feature spaces including</text>
        <text start="281" dur="3">infinitely dimensional new feature spaces.</text>
        <text start="284" dur="2">These messages are very powerful.</text>
        <text start="286" dur="2">It turns out you never</text>
        <text start="288" dur="2">really compute all those features.</text>
        <text start="290" dur="2">They are implicitly represented by</text>
        <text start="292" dur="3">so called kernels, and if you care about this,</text>
        <text start="295" dur="2">I recommend you to dive</text>
        <text start="297" dur="2">deeper into the literature</text>
        <text start="299" dur="2">of support vector machines.</text>
        <text start="301" dur="2">This is meant to just give you</text>
        <text start="303" dur="2">an overview of the essence of</text>
        <text start="305" dur="3">what support vector machines are all about.</text>
        <text start="308" dur="2">So in summary,</text>
        <text start="310" dur="2">linear methods we learned about</text>
        <text start="312" dur="3">using them for regression</text>
        <text start="315" dur="2">and also classification.</text>
        <text start="317" dur="2">We learned about exact solutions</text>
        <text start="319" dur="4">versus iterative solutions.</text>
        <text start="323" dur="2">We talked about smoothing,</text>
        <text start="325" dur="2">and we even talked about</text>
        <text start="327" dur="3">using linear methods for nonlinear problems.</text>
        <text start="330" dur="3">So we covered quite a bit of ground.</text>
        <text start="333" dur="2">This is a really significant cross section</text>
        <text start="335" dur="3">of machine learning.</text>
      </transcript>
    </video>
    <video title="50 k Nearest Neighbors" id="ZLEilYyt28c" length="121">
      <transcript>
        <text start="0" dur="6">As the final method in this unit, I&amp;#39;d like now to talk about k-nearest neighbors.</text>
        <text start="6" dur="3">And the distinguishing factor of k-nearest neighbors</text>
        <text start="9" dur="4">is that it is a nonparametric machine learning method.</text>
        <text start="13" dur="3">So far we&amp;#39;ve talked about parametric methods.</text>
        <text start="16" dur="5">Parametric methods have parameters, like probabilities or weights,</text>
        <text start="21" dur="4">and the number of parameters is constant.</text>
        <text start="25" dur="4">Or to put it differently, the number of parameters is independent of the training set size.</text>
        <text start="29" dur="5">So for example in the Naive Bayes, if we bring up more data,</text>
        <text start="34" dur="3">the number of condition probabilities will stay the same.</text>
        <text start="37" dur="4">Well, that wasn&amp;#39;t technically always the case.</text>
        <text start="41" dur="5">Our vocabulary might increase and as such the number of parameters.</text>
        <text start="46" dur="7">But for any fixed dictionary, the number of parameters are truly independent of the training set size.</text>
        <text start="53" dur="3">The same was true, for example, in our regression cases</text>
        <text start="56" dur="6">where the number of regression weights is independent of the number of data points.</text>
        <text start="62" dur="4">Now this is very different from non-parametric</text>
        <text start="66" dur="4">where the number of parameters can grow.</text>
        <text start="70" dur="3">In fact, it can grow a lot over time.</text>
        <text start="73" dur="3">Those techniques are called non-parametric.</text>
        <text start="76" dur="4">Nearest neighbor is so straightforward.</text>
        <text start="80" dur="3">I&amp;#39;d really like to introduce you using a quiz.</text>
        <text start="83" dur="2">So here&amp;#39;s my quiz.</text>
        <text start="85" dur="4">Suppose we have a number of data points.</text>
        <text start="89" dur="8">I want you for 1-nearest neighbor to check those squared areas</text>
        <text start="97" dur="4">that you believe will carry a positive label.</text>
        <text start="101" dur="4">And I will give you the label of the existing data points.</text>
        <text start="105" dur="5">So please check any of those boxes that you believe are now</text>
        <text start="110" dur="4">1-nearest neighbor that carry a positive label.</text>
        <text start="114" dur="7">And the algorithm, of course, searches for the nearest point in this Euclidean space and just copies its label.</text>
      </transcript>
    </video>
    <video title="51 kNN Definition" id="r1PWSm6xMUk" length="68">
      <transcript>
        <text start="0" dur="3">And the answer was: This is a positive point,</text>
        <text start="3" dur="2">and this is a positive point.</text>
        <text start="5" dur="3">These 2 points over here are negative.</text>
        <text start="8" dur="4">So let&amp;#39;s define k-nearest neighbors.</text>
        <text start="12" dur="4">The algorithm is really blatantly simple.</text>
        <text start="16" dur="4">In the learning step, you simply memorize all data.</text>
        <text start="20" dur="3">If a new example comes along with the input value you know</text>
        <text start="23" dur="5">but which you wish to classify, you do the following.</text>
        <text start="28" dur="3">You first find the k-nearest neighbors.</text>
        <text start="31" dur="7">And then you return the majority class label as your final class label for the new example.</text>
        <text start="38" dur="3">Simple, isn&amp;#39;t it?</text>
        <text start="41" dur="4">So here&amp;#39;s a somewhat contrived situation of the data point we wish to classify</text>
        <text start="45" dur="8">where the label data lies on the spiral of increasing diameter as it goes outwards.</text>
        <text start="53" dur="4">Please answer for me in this quiz what class label you&amp;#39;d assign</text>
        <text start="57" dur="11">for k = 1, k = 3, 5, 7, and all the way to 9.</text>
      </transcript>
    </video>
    <video title="52 Answer" id="PoRpuj4bijU" length="41">
      <transcript>
        <text start="0" dur="2">And this is an easy answer.</text>
        <text start="2" dur="2">The nearest neighbor is this point over here,</text>
        <text start="4" dur="2">so for 1 we say plus.</text>
        <text start="6" dur="3">For 3 neighbors, we get 2 positive, 1 negative.</text>
        <text start="9" dur="2">It&amp;#39;s still plus.</text>
        <text start="11" dur="3">For 5 neighbors--1, 2, 3, 4, 5--</text>
        <text start="14" dur="2">we get 3 negative, 2 positive.</text>
        <text start="16" dur="2">It&amp;#39;s a minus.</text>
        <text start="18" dur="3">For 7, we get 3 positive but still 4 negative,</text>
        <text start="21" dur="2">so it&amp;#39;s negative.</text>
        <text start="23" dur="3">And for 9, the positives outweigh the negative,</text>
        <text start="26" dur="2">so you get a plus.</text>
        <text start="28" dur="5">Obviously, as you can see, as K increases,</text>
        <text start="33" dur="2">more and more data points are being consulted.</text>
        <text start="35" dur="2">So when K finally becomes 9,</text>
        <text start="37" dur="4">all those data points are in and make a much smoother result.</text>
      </transcript>
    </video>
    <video title="53 k as Smoothing Parameter" id="mhrG7atAn4Q" length="104">
      <transcript>
        <text start="0" dur="5">Just as in the Laplacian smoothing example before,</text>
        <text start="5" dur="3">the value of k is a smoothing parameter.</text>
        <text start="8" dur="3">It makes the function less scattered.</text>
        <text start="11" dur="4">Here is an example of k=1</text>
        <text start="15" dur="3">for a 2-class nearest neighbor problem.</text>
        <text start="18" dur="7">You can see the separation boundary is what&amp;#39;s called a Voronoi diagram</text>
        <text start="25" dur="4">between the positive and negative class, and</text>
        <text start="29" dur="4">in cases where there is noise between these class boundaries,</text>
        <text start="33" dur="5">you&amp;#39;ll find really funny, complex boundaries as indicated over here.</text>
        <text start="38" dur="7">Particularly interesting is this guy over here where the class of this circle over here</text>
        <text start="45" dur="5">protrudes way into the otherwise solid class.</text>
        <text start="50" dur="5">Now, as you go to k=3, you get this graph over here,</text>
        <text start="55" dur="2">which is smoother.</text>
        <text start="57" dur="4">So if you are over here, your two nearest neighbors are of this type over there,</text>
        <text start="61" dur="4">and you get a uniform class over here.</text>
        <text start="65" dur="4">In this region over here, you get uniform classes as solid classes</text>
        <text start="69" dur="2">as shown over here.</text>
        <text start="71" dur="4">The more you drive up k, the more clean this decision boundary becomes,</text>
        <text start="75" dur="4">but the more outliers are actually misclassified as well.</text>
        <text start="79" dur="3">So if I go back to my k-nearest neighbor method,</text>
        <text start="82" dur="4">we just learned that k is a regularizer.</text>
        <text start="86" dur="4">It controls the complexity of the k-nearest neighbor algorithm.</text>
        <text start="90" dur="4">and the larger k is, the smoother the output.</text>
        <text start="94" dur="4">We can, once again, use cross-validation to find the optimal k</text>
        <text start="98" dur="4">because there is an inherent trade off--between the complexity of what we want to fit</text>
        <text start="102" dur="2">and the goodness of the fit.</text>
      </transcript>
    </video>
    <video title="54 Problems with kNN" id="tOSoqfK9UNE" length="128">
      <transcript>
        <text start="0" dur="2">What are the problems of kNN?</text>
        <text start="2" dur="2">Well, I would argue that there&amp;#39;re two.</text>
        <text start="4" dur="3">One is very large data sets,</text>
        <text start="7" dur="3">and one is very large feature spaces.</text>
        <text start="10" dur="4">Now the first one results in lengthy searches</text>
        <text start="14" dur="3">when you try to find K&amp;#39;s nearest neighbors.</text>
        <text start="17" dur="2">Now, fortunately there are</text>
        <text start="19" dur="3">methods to search efficiently.</text>
        <text start="22" dur="2">Often you represent your data</text>
        <text start="24" dur="3">not by a linear list, in which case the search</text>
        <text start="27" dur="2">would be linear in the number of data points,</text>
        <text start="29" dur="5">but by a tree, where the search becomes logarithmic.</text>
        <text start="34" dur="4">The method of choice is called kDD trees</text>
        <text start="38" dur="2">where there are many other ways</text>
        <text start="40" dur="3">to represent data points as trees.</text>
        <text start="43" dur="2">Now very large feature spaces</text>
        <text start="45" dur="3">cause more of a problem.</text>
        <text start="48" dur="3">It turns out computing nearest neighbors,</text>
        <text start="51" dur="3">as the feature space for the input vector increases,</text>
        <text start="54" dur="3">becomes increasingly difficult,</text>
        <text start="57" dur="3">and the tree methods become increasingly brittle.</text>
        <text start="60" dur="3">And the reason is shown in the following graph:</text>
        <text start="63" dur="3">If your graph input dimension to</text>
        <text start="66" dur="3">the average edge length of your neighborhood</text>
        <text start="69" dur="3">you&amp;#39;ll find that for randomly chosen points</text>
        <text start="72" dur="4">very quickly all points are really far away.</text>
        <text start="76" dur="3">The edge length of one is obtained</text>
        <text start="79" dur="4">if your query point</text>
        <text start="83" dur="3">is unit one away from the nearest neighbor.</text>
        <text start="86" dur="2">If you have one hundred dimensions,</text>
        <text start="88" dur="1">that is almost certain.</text>
        <text start="89" dur="2">Why is that?</text>
        <text start="91" dur="2">Well, in one hundred dimensions,</text>
        <text start="93" dur="2">they are to be one where just by chance</text>
        <text start="95" dur="2">your&amp;#39;re far away.</text>
        <text start="97" dur="2">The number of points you need</text>
        <text start="99" dur="1">to get something close</text>
        <text start="100" dur="5">grows exponentially with the number of dimensions.</text>
        <text start="105" dur="2">So, for any fixed data set size</text>
        <text start="107" dur="2">you will find yourself in a situation</text>
        <text start="109" dur="3">where all your neighbors are far away.</text>
        <text start="112" dur="2">Nearest neighbor works really well</text>
        <text start="114" dur="4">for small input spaces like three or four dimensions.</text>
        <text start="118" dur="1">It works very poorly</text>
        <text start="119" dur="2">if your input space is twenty, twenty-five,</text>
        <text start="121" dur="2">or maybe one hundred dimensions.</text>
        <text start="123" dur="3">So don&amp;#39;t trust nearest neighbor to do a good job</text>
        <text start="126" dur="2">if your input and measure spaces are high.</text>
      </transcript>
    </video>
    <video title="55 Congratulations" id="Ta7tyUB-EqM" length="73.006">
      <transcript>
        <text start="0" dur="2.069">So congratulations.</text>
        <text start="2.069" dur="2.702">You&amp;#39;ve just learned a lot about machine learning.</text>
        <text start="4.771" dur="2.822">We focused on supervised machine learning</text>
        <text start="7.593" dur="2.417">which deals with situations</text>
        <text start="10.01" dur="1.835">where you have input vectors</text>
        <text start="11.845" dur="1.935">and given output labels</text>
        <text start="13.78" dur="3.008">and your goal is to predict the output label</text>
        <text start="16.788" dur="1.831">from an input vector.</text>
        <text start="18.619" dur="3.136">And we looked into parametric models</text>
        <text start="21.755" dur="1.906">like Naive Bayes</text>
        <text start="23.661" dur="1.798">non-parametric models.</text>
        <text start="25.459" dur="2.302">We talked about classification</text>
        <text start="27.761" dur="1.769">where the output is discrete</text>
        <text start="29.53" dur="2.568">versus regression where the output is continuous</text>
        <text start="32.098" dur="2.503">and we looked at samples of techniques</text>
        <text start="34.601" dur="2.002">for each of these situations.</text>
        <text start="36.603" dur="1.569">Now obviously</text>
        <text start="38.172" dur="2.402">we just scratched the surface on machine learning.</text>
        <text start="40.574" dur="1.175">There&amp;#39;s books written about it</text>
        <text start="41.749" dur="1.561">and courses taught about it.</text>
        <text start="43.31" dur="2.736">Machine learning is a super fascinating topic.</text>
        <text start="46.046" dur="2.603">It&amp;#39;s the one within the artificial intelligence</text>
        <text start="48.649" dur="1.468">I love the most.</text>
        <text start="50.117" dur="2.836">It&amp;#39;s really great about the real world</text>
        <text start="52.953" dur="1.916">as we gain more data</text>
        <text start="54.869" dur="0.859">like the world wide web</text>
        <text start="55.728" dur="1.162">or medical data sets</text>
        <text start="56.89" dur="1.402">or financial data sets.</text>
        <text start="58.292" dur="1.601">Machine learning is poised</text>
        <text start="59.893" dur="2.244">to become more and more important.</text>
        <text start="62.137" dur="3.361">I hope that the things you learned in this class so far</text>
        <text start="65.498" dur="1.538">really excite you</text>
        <text start="67.036" dur="2.634">and entice you to apply machine learning</text>
        <text start="69.67" dur="1.546">to problems that you face</text>
        <text start="71.216" dur="1.79">in your professional life.</text>
      </transcript>
    </video>
  </group>
  <group title="Unit 6" count="46">
    <video title="1 Unsupervised Learning" id="s4Ou3NRJc-s" length="71">
      <transcript>
        <text start="0" dur="2">[Narrator] So welcome to the class</text>
        <text start="2" dur="2">on unsupervised learning.</text>
        <text start="4" dur="2">We talked a lot about supervised learning</text>
        <text start="6" dur="3">in which we are given data and target labels.</text>
        <text start="9" dur="3">In unsupervised learning we&amp;#39;re just given data.</text>
        <text start="12" dur="3">So here&amp;#39;s a data matrix of</text>
        <text start="15" dur="2">data items of N features each.</text>
        <text start="17" dur="2">There&amp;#39;s M and total.</text>
        <text start="19" dur="2">So the task of unsupervised learning is</text>
        <text start="21" dur="4">to find structure in data of this type.</text>
        <text start="25" dur="3">To illustrate why this is an interesting problem</text>
        <text start="28" dur="3">let me start with a quiz.</text>
        <text start="31" dur="3">Suppose we have 2 feature values.</text>
        <text start="34" dur="3">One over here, and one over here,</text>
        <text start="37" dur="2">and our data looks as follows.</text>
        <text start="39" dur="2">Even though we haven&amp;#39;t been told about</text>
        <text start="41" dur="2">anything in unsupervised learning, I&amp;#39;d like to</text>
        <text start="43" dur="3">quiz your intuition on the following 2 questions:</text>
        <text start="46" dur="2">1. Is there structure?</text>
        <text start="48" dur="3">Or put differently do you think there&amp;#39;s</text>
        <text start="51" dur="2">something to be learned about data like this,</text>
        <text start="53" dur="4">or is it entirely random?</text>
        <text start="57" dur="4">And second, to narrow this down,</text>
        <text start="61" dur="2">it feels that there are clusters</text>
        <text start="63" dur="2">of data the way I do it.</text>
        <text start="65" dur="3">So how many clusters can you see?</text>
        <text start="68" dur="3">And I give you a couple of choices,                                             1, 2, 3, 4, or none.</text>
      </transcript>
    </video>
    <video title="1a Answer" id="kFwsW2VtWWA" length="26">
      <transcript>
        <text start="0" dur="3">[Narrator] The answer to the first question is yes, there is structure.</text>
        <text start="3" dur="3">Obviously these data are seen not to be completely random determinants.</text>
        <text start="6" dur="3">They seem to be for me 2 clusters.</text>
        <text start="9" dur="3">So the correct answer for                                        the second question is 2.</text>
        <text start="12" dur="3">There&amp;#39;s a cluster over here, and                                            there&amp;#39;s a cluster over here.</text>
        <text start="15" dur="2">So one of the tasks of unsupervised learning</text>
        <text start="17" dur="4">will be to recover the number of clusters, and</text>
        <text start="21" dur="2">the center of these clusters, and the variances of these clusters in data</text>
        <text start="23" dur="3">of the type I&amp;#39;ve just shown you.</text>
      </transcript>
    </video>
    <video title="1b Question" id="GxeyaI9_P4o" length="43">
      <transcript>
        <text start="0" dur="3">[Narrator] Let me ask you a second quiz.</text>
        <text start="3" dur="3">Again, we haven&amp;#39;t talked about any details.</text>
        <text start="6" dur="2">I would like to get your intuition                                                  on the following question.</text>
        <text start="8" dur="2">Suppose in a two dimensional space,</text>
        <text start="10" dur="2">all data lies as follows.</text>
        <text start="12" dur="2">This may be reminiscent of the question I</text>
        <text start="14" dur="3">asked you for housing prices                                   and square footage.</text>
        <text start="17" dur="3">Suppose we have 2 axes, X1 and X2.</text>
        <text start="20" dur="2">I&amp;#39;m going to ask you 2 questions here.</text>
        <text start="22" dur="3">One is what is the dimensionality of this space</text>
        <text start="25" dur="2">in which this data falls, and the second one</text>
        <text start="27" dur="2">is an intuitive question which is</text>
        <text start="29" dur="3">how many dimensions do you need</text>
        <text start="32" dur="3">to represent this data to capture the essence,</text>
        <text start="35" dur="3">and, again, this is not a clear                                           crisp 0 or 1 type question,</text>
        <text start="38" dur="2">but give me your best guess.</text>
        <text start="40" dur="3">How many dimensions are intuitively needed?</text>
      </transcript>
    </video>
    <video title="1c Answer" id="4uj36iX1Pkk" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="2 Terminology" id="EZEOXNFgu8M" length="87">
      <transcript>
        <text start="0" dur="3">[Narrator] So to start with some lingo                          about unsupervised learning.</text>
        <text start="3" dur="3">If you look at this as a probabilist,                                                 you&amp;#39;re  given data, and</text>
        <text start="6" dur="3">we interpretively assume the data is IID,</text>
        <text start="9" dur="2">which means identically distributed and independently drawn</text>
        <text start="11" dur="2">from the same distribution.</text>
        <text start="13" dur="2">So a good chunk of unsupervised learning</text>
        <text start="15" dur="3">seeks to recover the underlying--the density of</text>
        <text start="18" dur="3">probability distribution that generated the data.</text>
        <text start="21" dur="2">It&amp;#39;s called density estimation.</text>
        <text start="23" dur="2">As we find out our methods for clustering,</text>
        <text start="25" dur="2">our versions of density estimation</text>
        <text start="27" dur="2">using what&amp;#39;s called mixture models.</text>
        <text start="29" dur="2">Dimensionality reduction is also a method</text>
        <text start="31" dur="2">for doing density estimation,</text>
        <text start="33" dur="2">and there are many others.</text>
        <text start="35" dur="2">Unsupervised learning can be applied to find</text>
        <text start="37" dur="2">structure and data.</text>
        <text start="39" dur="2">One of the fascinating ones that</text>
        <text start="41" dur="2">I believe exists is called</text>
        <text start="43" dur="2">blind signals separation.</text>
        <text start="45" dur="3">Suppose you are given a microphone, and</text>
        <text start="48" dur="3">two people simultaneously talk, and you&amp;#39;re</text>
        <text start="51" dur="3">record the joint of both of those speakers.</text>
        <text start="54" dur="2">Blind source separation or                                                     blind signal separation</text>
        <text start="56" dur="3">addresses the question of can you recover</text>
        <text start="59" dur="2">those two speakers and filter</text>
        <text start="61" dur="2">the data into two separate streams.</text>
        <text start="63" dur="2">One for each speaker.</text>
        <text start="65" dur="2">Now this is a really complicated unsupervised</text>
        <text start="67" dur="2">learning task, but is one of the many things</text>
        <text start="69" dur="2">that don&amp;#39;t require target signals as</text>
        <text start="71" dur="2">unsupervised learning yet make for</text>
        <text start="73" dur="2">really interesting learning problems.</text>
        <text start="75" dur="2">This can be construed as an example</text>
        <text start="77" dur="2">of what&amp;#39;s called factor analysis where each</text>
        <text start="79" dur="4">speaker is a factor in the drawing signal                that your microphone records.</text>
        <text start="83" dur="2">There are many other examples of unsupervised learning.</text>
        <text start="85" dur="2">I will show you a few in a second.</text>
      </transcript>
    </video>
    <video title="3 Google Street View and Clustering" id="W2dkDmHFMWg" length="126">
      <transcript>
        <text start="0" dur="3">Here is one of my favorite examples of unsupervised learning--</text>
        <text start="3" dur="2">one that is yet unsolved.</text>
        <text start="5" dur="3">At Google, I had the opportunity to participate--</text>
        <text start="8" dur="2">in the building of Street View,</text>
        <text start="10" dur="3">which is a huge photographic database--</text>
        <text start="13" dur="3">of many, many streets in the world.</text>
        <text start="16" dur="2">As you dive into Street View--</text>
        <text start="18" dur="2">you can get ground imagery--</text>
        <text start="20" dur="3">of almost any location in the world--</text>
        <text start="23" dur="3">like this house here, that I chose at random.</text>
        <text start="26" dur="3">In these images, there is vast regularities.</text>
        <text start="29" dur="2">You can go somewhere else--</text>
        <text start="31" dur="2">and you&amp;#39;ll find that the type of objects--</text>
        <text start="33" dur="2">visible in Street View--</text>
        <text start="35" dur="2">is not entirely random.</text>
        <text start="37" dur="2">For example, there is many images of homes--</text>
        <text start="39" dur="2">many images of cars--</text>
        <text start="41" dur="3">trees, pavement, lane markers--</text>
        <text start="44" dur="3">stop sign, just to name a few.</text>
        <text start="47" dur="5">So one of the fascinating, unsolved, unsupervised learning tasks is:</text>
        <text start="52" dur="3">Can you take hundreds of billions of images--</text>
        <text start="55" dur="3">as comprised in the Street View data set--</text>
        <text start="58" dur="3">and discover from it that there are concepts such as--</text>
        <text start="61" dur="4">trees, lane markers, stop signs, cars, and pedestrians?</text>
        <text start="65" dur="2">It seems to be tedious to hand label each image--</text>
        <text start="67" dur="2">for the occurrence of such objects.</text>
        <text start="69" dur="2">And attempts to do so--</text>
        <text start="71" dur="3">has resulted in very small image data sets.</text>
        <text start="74" dur="2">Humans can learn from data--</text>
        <text start="76" dur="2">even without explicit target labels.</text>
        <text start="78" dur="2">We often just observe.</text>
        <text start="80" dur="3">In observing, we apply unsupervised learning techniques.</text>
        <text start="83" dur="4">So one of the great, great open questions of artificial intelligence is:</text>
        <text start="87" dur="5">Can you observe many intersections and many streets and many roads--</text>
        <text start="92" dur="3">and learn from it what concepts are contained in the imagery?</text>
        <text start="95" dur="4">Of course, I can&amp;#39;t teach you anything as complex in this class.</text>
        <text start="99" dur="2">I don&amp;#39;t even know the answer myself.</text>
        <text start="101" dur="2">So let me start with something simple.</text>
        <text start="103" dur="4">Clustering. Clustering is the most basic form of unsupervised learning.</text>
        <text start="107" dur="3">And I will tell you about two algorithms that are very related.</text>
        <text start="110" dur="2">One is called k-means,</text>
        <text start="112" dur="3">one is called expectation maximization.</text>
        <text start="115" dur="4">K-means is a nice, intuitive algorithm to derive clusterings.</text>
        <text start="119" dur="3">Expectation maximization is a probabilistic--</text>
        <text start="122" dur="2">generalization of k-means.</text>
        <text start="124" dur="2">They were derived from first principles.</text>
      </transcript>
    </video>
    <video title="4 k-Means Clustering Example" id="zaKjh2N8jN4" length="112">
      <transcript>
        <text start="0" dur="3">Let me explain k-means by an example.</text>
        <text start="3" dur="4">Suppose we&amp;#39;re given the following data points in a 2-dimensional space.</text>
        <text start="7" dur="5">K-means estimates for a fixed number of k. Here k = 2.</text>
        <text start="12" dur="5">The best centers of clusters representing those data points.</text>
        <text start="17" dur="3">Those are found interatively by the following algorithm.</text>
        <text start="20" dur="5">Step 1: Guess cluster centers at random, as shown over here with the 2 stars.</text>
        <text start="25" dur="5">Step 2: Assign to each cluster center, even though they are randomly chosen,</text>
        <text start="30" dur="3">the most likely corresponding data points.</text>
        <text start="33" dur="3">This is done by minimizing Euclidian distance.</text>
        <text start="36" dur="5">In particular, each cluster center represents half of the space.</text>
        <text start="41" dur="4">And the line that separates the space between the left and right cluster center</text>
        <text start="45" dur="3">is the equidistant line, often called a Voronoi graph.</text>
        <text start="48" dur="5">All the data points on the left correspond to the red cluster,</text>
        <text start="53" dur="2">and the ones on the right to the green cluster.</text>
        <text start="55" dur="5">Step 3: Given now we have a correspondence between the data points and cluster centers,</text>
        <text start="60" dur="6">find the optimal cluster center that corresponds to the points associated with the cluster center.</text>
        <text start="66" dur="3">Our red cluster center has only 2 data points attached.</text>
        <text start="69" dur="4">So the optimal cluster center would be the halfway point in the middle.</text>
        <text start="73" dur="3">Our right cluster center has more than 2 points attached;</text>
        <text start="76" dur="5">yet it isn&amp;#39;t placed optimally, as you can see as they move with the animation back and forth.</text>
        <text start="81" dur="4">By minimizing the joint quadratic distance to all of those points,</text>
        <text start="85" dur="4">the new cluster center has attained the center of those data points.</text>
        <text start="89" dur="6">Now the final step is iterate. Go back and reassign cluster centers.</text>
        <text start="95" dur="4">Now the Voronoi diagram has shifted, and the points are associated differently,</text>
        <text start="99" dur="6">and then reevaluate what the optimal cluster center looks like given the associated points.</text>
        <text start="105" dur="2">And in both cases we see significant motion.</text>
        <text start="107" dur="2">Repeat. Now this is the clustering.</text>
        <text start="109" dur="3">The point association doesn&amp;#39;t change, and as a result, we just converged.</text>
      </transcript>
    </video>
    <video title="4a k-Means Algorithm" id="myqnyxkdQpc" length="116">
      <transcript>
        <text start="0" dur="3">You just learned about an exciting clustering algorithm</text>
        <text start="3" dur="4">that&amp;#39;s really easy to implement called k-means.</text>
        <text start="7" dur="2">To give you the algorithm in pseudocode,</text>
        <text start="9" dur="6">initially we select k cluster centers at random and then we repeat.</text>
        <text start="15" dur="6">In a corresponding step, we correspond all the data points to the nearest cluster center,</text>
        <text start="21" dur="5">and then we calculate the new cluster center by the mean of the corresponding data points.</text>
        <text start="26" dur="4">We repeat this until nothing changes any more.</text>
        <text start="30" dur="7">Now special care has to be taken if a cluster center becomes empty--that means no data point is associated.</text>
        <text start="37" dur="6">In which case, we just restart cluster centers at random that have no corresponding points.</text>
        <text start="43" dur="3">Empty cluster centers restart at random.</text>
        <text start="46" dur="8">This algorithm is known to converge to a locally optimal clustering of data ponts.</text>
        <text start="54" dur="4">The general clustering problem is known to be NP-hard.</text>
        <text start="58" dur="5">So a locally optimal solution, in a way, is the best we can hope for.</text>
        <text start="63" dur="3">Now let me talk about problems with k-means.</text>
        <text start="66" dur="3">First we need to know k, the number of cluster centers.</text>
        <text start="69" dur="1">As I mentioned, the local minimum.</text>
        <text start="70" dur="6">For example, for 4 data points like this and 2 cluster centers that happen to be just over here,</text>
        <text start="76" dur="4">with the separation line like this there would be no motion of k means.</text>
        <text start="80" dur="5">Even though moving one over here and one over there would give a better solution.</text>
        <text start="85" dur="3">There&amp;#39;s a general problem of high dimensionality of the space</text>
        <text start="88" dur="4">that is not dissimilar from the way k-nearest neighbor suffers from high dimensionality.</text>
        <text start="92" dur="3">And then there&amp;#39;s lack of a mathematical basis.</text>
        <text start="95" dur="3">Now if you&amp;#39;re a partitioner, you might not care about a mathematical basis.</text>
        <text start="98" dur="4">But for the sake of this class, let&amp;#39;s just care about it.</text>
        <text start="102" dur="3">So here&amp;#39;s a first quiz for k-means.</text>
        <text start="105" dur="5">Given the following two cluster centers, C1 and C2,</text>
        <text start="110" dur="6">click on exactly those points that are associated with C1 and not with C2.</text>
      </transcript>
    </video>
    <video title="4b Answer" id="0RMhiWfe73M" length="17">
      <transcript>
        <text start="0" dur="5">And the answer is these 4 points over here.</text>
        <text start="5" dur="6">And the reason is, if you draw the line of equal distance between C1 and C2,</text>
        <text start="11" dur="4">the separation of these 2 cluster areas falls over here.</text>
        <text start="15" dur="2">C2 is down there. C1 is up here.</text>
      </transcript>
    </video>
    <video title="4c Question" id="oQYC32jKCvg" length="17">
      <transcript>
        <text start="0" dur="1.05">So here&amp;#39;s my second quiz.</text>
        <text start="1.05" dur="4.95">Given the association that we just derived for C1, where do you think the new cluster center,</text>
        <text start="6" dur="7">C1, will be found after a single step of estimating its best location given the associated points?</text>
        <text start="13" dur="1">I&amp;#39;ll give you a couple of choices.</text>
        <text start="14" dur="3">Please click on the one that you find most plausible.</text>
      </transcript>
    </video>
    <video title="4d Answer" id="uxdSfp9n2CY" length="34">
      <transcript>
        <text start="0" dur="2">And the answer is, over here.</text>
        <text start="2" dur="6">These 4 data points are associated with C1, so we can safely ignore all the other ones.</text>
        <text start="8" dur="4">This one over here would be at the center of the 3 data points over here,</text>
        <text start="12" dur="5">but this one pulls back this data point drastically towards it.</text>
        <text start="17" dur="5">This is about the best trade-off between these 3 points over here that all have a string</text>
        <text start="22" dur="4">attached and pull in this direction, compared to this point over here.</text>
        <text start="26" dur="3">Any of the other ones don&amp;#39;t even lie between those points,</text>
        <text start="29" dur="3">and therefore won&amp;#39;t be good cluster centers.</text>
        <text start="32" dur="2">The one over here is way too far to the right.</text>
      </transcript>
    </video>
    <video title="4e Question" id="3zlXl82LUVI" length="13">
      <transcript>
        <text start="0" dur="3">In our next quiz let&amp;#39;s assume we&amp;#39;ve done one interation,</text>
        <text start="3" dur="4.5">and the cluster center of C1 moved over there and C2 moved over here.</text>
        <text start="7.5" dur="5.5">Can you once again click on all those data points that correspond to C1?</text>
      </transcript>
    </video>
    <video title="4f Answer" id="LgxZJ7GAB3o" length="24">
      <transcript>
        <text start="0" dur="3">And the answer is now simple. It&amp;#39;s this one over here.</text>
        <text start="3" dur="2">This one, this one, and this one.</text>
        <text start="5" dur="5">And the reason is, the line separating both clusters runs around here.</text>
        <text start="10" dur="6">That means all the area over here is C2 territory, and the area over here is C1 territory.</text>
        <text start="16" dur="4">Obvioulsy as we now iterate k-means, these clusters that have been moved straight over</text>
        <text start="20" dur="4">here will be able to stay, whereas C2 will end up somewhere over here.</text>
      </transcript>
    </video>
    <video title="5 Expectation Maximization" id="_DhelJs0BFc" length="252">
      <transcript>
        <text start="0" dur="5">So, let&amp;#39;s now generalize k-means into expectation maximization.</text>
        <text start="5" dur="5">Expectation maximization is an algorithm that uses actual probability distributions</text>
        <text start="10" dur="4">to describe what we&amp;#39;re doing, and it&amp;#39;s in many ways more general,</text>
        <text start="14" dur="3">and it&amp;#39;s also nice in that it really has a probabilistic basis.</text>
        <text start="17" dur="4">To get there, I have to take the discourse and tell you all about Gaussians,</text>
        <text start="21" dur="3">or the normal distribution, and the reason is so far,</text>
        <text start="24" dur="2">we&amp;#39;ve just encountered discrete distributions,</text>
        <text start="26" dur="4">and Gaussians will be the first example of a continuous distribution.</text>
        <text start="30" dur="4">Many of you know that a Gaussian is described by an identity that looks as follows,</text>
        <text start="34" dur="7">where the mean is called mu, and the variance is called sigma or sigma squared.</text>
        <text start="41" dur="6">And for any X along the horizontal access, the density is given by the following function:</text>
        <text start="47" dur="5">1 over square root of 2 pi times sigma, and then an exponential function</text>
        <text start="52" dur="4">of minus  of x - mu squared over sigma squared.</text>
        <text start="56" dur="5">This function might look complex, but it&amp;#39;s also very, very beautiful.</text>
        <text start="61" dur="6">It peaks at X = mu where the value in the exponent becomes 0.</text>
        <text start="67" dur="4">And towards plus or minus infinity, it goes to 0 quickly.</text>
        <text start="71" dur="3">In fact, exponentially fast.</text>
        <text start="74" dur="2">The argument inside is a quadratic function.</text>
        <text start="76" dur="4">The exponential function makes it exponential.</text>
        <text start="80" dur="3">And this over here is a normalizer to make sure that the area underneath</text>
        <text start="83" dur="6">sums up to one, which is characteristic of any probability density function.</text>
        <text start="89" dur="3">If you map this back to our discrete random variables,</text>
        <text start="92" dur="5">for each possible X, we can now assign a density value,</text>
        <text start="97" dur="4">which is the function of this, and that&amp;#39;s effectively</text>
        <text start="101" dur="2">the probability that this X might be drawn.</text>
        <text start="103" dur="5">Now, the space itself is infinite, so any individual value will have a probability of 0,</text>
        <text start="108" dur="4">but what you can do is you can make an interval, A and B,</text>
        <text start="112" dur="4">and the area underneath this function is the total probability</text>
        <text start="116" dur="4">that an experiment will come up between A and B.</text>
        <text start="120" dur="3">Clearly, it&amp;#39;s more likely to generate values around mu</text>
        <text start="123" dur="4">then it is to generate values in the periphery summary over here.</text>
        <text start="127" dur="2">And just for completeness, I&amp;#39;m going to give you the formula</text>
        <text start="129" dur="3">for what&amp;#39;s called the multi-variate Gaussian</text>
        <text start="132" dur="5">where multi-variate means nothing else but we have more than one input variable.</text>
        <text start="137" dur="4">You might have a Gaussian over a 2-dimensional space or a 3-dimensional space.</text>
        <text start="141" dur="3">Often, these Gaussians are drawn by what&amp;#39;s called level sets,</text>
        <text start="144" dur="2">sets of equal probability.</text>
        <text start="146" dur="4">Here&amp;#39;s one in a 2-dimensional space, X1 and X2.</text>
        <text start="150" dur="5">The Gaussian itself can be thought of as coming out of the paper towards me</text>
        <text start="155" dur="4">where the most likely or highest point of probability is the center over here.</text>
        <text start="159" dur="4">And these rings measure areas of equal probability.</text>
        <text start="163" dur="6">The formula for a multi-variate Gaussian looks as follows:</text>
        <text start="169" dur="4">N is the number of dimensions in the input space.</text>
        <text start="173" dur="4">Sigma is a covariance matrix that generalizes the value over here.</text>
        <text start="177" dur="5">And the inner product inside the exponential</text>
        <text start="182" dur="6">is now done using linear algebra where this is the difference between</text>
        <text start="188" dur="4">a probe point and the mean vector mu</text>
        <text start="192" dur="4">transposed sigma to the minus 1 times X - mu.</text>
        <text start="196" dur="5">You can find this formula in any textbook or web page</text>
        <text start="201" dur="4">on Gaussians or multi-variate normal distributions.</text>
        <text start="205" dur="4">It looks cryptic at first, but the key thing to remember is</text>
        <text start="209" dur="4">it&amp;#39;s just a generalization of the 1-dimensional case.</text>
        <text start="213" dur="3">We have a quadratic area over here as manifested by the product</text>
        <text start="216" dur="2">of this guy and this guy.</text>
        <text start="218" dur="4">We have a normalization by a variance or covariance</text>
        <text start="222" dur="6">as shown by this number over here or the inverse matrix over here.</text>
        <text start="228" dur="3">And then this entire thing is an exponential form in both cases,</text>
        <text start="231" dur="4">and the normalizer looks a little more different in the multi-variate case,</text>
        <text start="235" dur="4">but all it does is make sure that the volume underneath adds up to 1</text>
        <text start="239" dur="3">to make it a legitimate probability density function.</text>
        <text start="242" dur="5">For most of this explanation, I will stick with 1-dimensional Gaussians,</text>
        <text start="247" dur="3">so all you have to do is to worry about this formula over here,</text>
        <text start="250" dur="2">but this is given just for completeness.</text>
      </transcript>
    </video>
    <video title="5a Gaussian Learning" id="S4-694lgERs" length="132">
      <transcript>
        <text start="0" dur="6">I will now talk about fitting Gaussians to data or Gaussian learning.</text>
        <text start="6" dur="3">You may be given some data points, and you might worry about</text>
        <text start="9" dur="3">what is the best Guassian fitting the data?</text>
        <text start="12" dur="6">Now, to explain this, let me first tell you what parameters characterizes a Gaussian.</text>
        <text start="18" dur="6">In the 1-dimensional case, it is mu and sigma squared.</text>
        <text start="24" dur="4">Mu is the mean. Sigma squared is called the variance.</text>
        <text start="28" dur="6">If we look at the formula of a Gaussian, it&amp;#39;s a function over any possible input X,</text>
        <text start="34" dur="4">and it requires knowledge of mu and sigma squared.</text>
        <text start="38" dur="4">And as before, I&amp;#39;m just restating what I said before.</text>
        <text start="42" dur="6">We get this function over here that specifies any probability</text>
        <text start="48" dur="5">for a value X given a specific mu and sigma squared.</text>
        <text start="53" dur="8">Suppose we wish to fit data, and our data is 1-dimensional, and it looks as follows.</text>
        <text start="61" dur="2">Just looking at this diagram makes me believe</text>
        <text start="63" dur="3">that there&amp;#39;s a high density of data points over here</text>
        <text start="66" dur="3">and a fading density of data points over there,</text>
        <text start="69" dur="4">so maybe the most likely Gaussian will look a little bit like this</text>
        <text start="73" dur="4">where this is mu and this is sigma.</text>
        <text start="77" dur="4">They are really easy formulas for fitting data to Gaussians,</text>
        <text start="81" dur="2">and I&amp;#39;ll give you the result right now.</text>
        <text start="83" dur="7">The optimal or most likely mean is just the average of the data points.</text>
        <text start="90" dur="3">There&amp;#39;s M data points, X1 to Xm.</text>
        <text start="93" dur="2">The average will look like this.</text>
        <text start="95" dur="6">The sum of all data points divided by the total number of data points.</text>
        <text start="101" dur="3">That&amp;#39;s called  the average, and once you calculate the average,</text>
        <text start="104" dur="4">the sigma squared is obtained by a similar normalization</text>
        <text start="108" dur="3">in a slightly more complex sum.</text>
        <text start="111" dur="3">We sum the deviation from the mean</text>
        <text start="114" dur="4">and compute the average deviation to the square from the mean,</text>
        <text start="118" dur="2">and that gives us sigma squared.</text>
        <text start="120" dur="3">So, intuitively speaking, the formulas are really easy.</text>
        <text start="123" dur="3">Mu is the mean, or the average.</text>
        <text start="126" dur="6">Sigma squared is the average quadratic deviation from the mean, as shown over here.</text>
      </transcript>
    </video>
    <video title="5b Maximum Likelihood" id="rMcw3uu4efY" length="250">
      <transcript>
        <text start="0" dur="3">Now I want take a second to convince ourselves</text>
        <text start="3" dur="3">this is indeed the maximum likelihood estimate</text>
        <text start="6" dur="3">of the mean and the variance.</text>
        <text start="9" dur="3">Suppose our data looks like this--</text>
        <text start="12" dur="3">There&amp;#39;s &amp;quot;M&amp;quot; data points.</text>
        <text start="15" dur="3">And the probability of those data points</text>
        <text start="18" dur="4">for any Gaussian model--mu and sigma squared</text>
        <text start="22" dur="7">is the product of any individual of data likelihood--x,i.</text>
        <text start="29" dur="5">And if you plug in our Gaussian formula, you get the following--</text>
        <text start="34" dur="3">This is the normalizer multiplied &amp;quot;M&amp;quot; times</text>
        <text start="37" dur="6">where the square root is now drawn into the half over here,</text>
        <text start="43" dur="2">and here is our joint exponential.</text>
        <text start="45" dur="4">We took the product of the individual exponentials</text>
        <text start="49" dur="4">and moved it up straight in here where it becomes a sum.</text>
        <text start="53" dur="5">So the best estimates for mu and sigma squared</text>
        <text start="58" dur="3">are those that maximize this entire expression over here</text>
        <text start="61" dur="4">for given data set X1 to Xm.</text>
        <text start="65" dur="3">So we seek to maximize this over the unknown parameters</text>
        <text start="68" dur="2">mu and sigma squared.</text>
        <text start="70" dur="2">And now I will apply a trick.</text>
        <text start="72" dur="2">Instead of maximizing this expression,</text>
        <text start="74" dur="3">I will maximize the logarithm of this expression.</text>
        <text start="77" dur="2">The logarithm is a monotonic function.</text>
        <text start="79" dur="4">So let&amp;#39;s maximize instead the logarithm</text>
        <text start="83" dur="4">where this expression over here resolves to this expression over here.</text>
        <text start="87" dur="5">The multiplication becomes a minus sign from over here,</text>
        <text start="92" dur="3">and this is the argument inside the exponent</text>
        <text start="95" dur="2">written slightly differently,</text>
        <text start="97" dur="3">but pulling the 2 sigma squared to the left.</text>
        <text start="100" dur="2">So let&amp;#39;s maximize this one instead.</text>
        <text start="102" dur="3">The maximum was obtained where the first</text>
        <text start="105" dur="3">derivative is zero.</text>
        <text start="108" dur="3">If we do this for our variable mu,</text>
        <text start="111" dur="2">we take the &amp;quot;log f&amp;quot; expression and</text>
        <text start="113" dur="3">complete the derivative for spectrum  mu,</text>
        <text start="116" dur="2">we get following--</text>
        <text start="118" dur="3">This expression does not depend on mu at all, so it falls out.</text>
        <text start="121" dur="4">And we can still get this expression over here, which we&amp;#39;ve set to zero.</text>
        <text start="125" dur="6">And now we can multiply everything by sigma squared next to zero,</text>
        <text start="131" dur="4">and then bring the Xi to the right and the mu to the left.</text>
        <text start="135" dur="9">The sum over all &amp;quot;E&amp;quot; of the mu is mu equals sum over i, xi.</text>
        <text start="144" dur="7">Hence, we proved that the mean is indeed the maximum  likelihood estimate</text>
        <text start="151" dur="2">for the Gaussian.</text>
        <text start="153" dur="5">This is now easily repeated for the variance.</text>
        <text start="158" dur="3">If you compute the derivative of this expression over here</text>
        <text start="161" dur="2">with respect to the variance,</text>
        <text start="163" dur="5">we get minus &amp;quot;m&amp;quot; over sigma, which happens to be the derivative</text>
        <text start="168" dur="2">of this expression over here.</text>
        <text start="170" dur="3">Keep in mind that the derivative of</text>
        <text start="173" dur="4">a logarithm stresses internal argument</text>
        <text start="177" dur="4">times by chain rule--the derivative of  the internal argument,</text>
        <text start="181" dur="4">which if you work out becomes this expression over here.</text>
        <text start="185" dur="3">And this guy over here changes signs</text>
        <text start="188" dur="2">but becomes the following.</text>
        <text start="190" dur="3">And again, you move this guy to the left side,</text>
        <text start="193" dur="5">multiply by sigma cubed, and divide by &amp;quot;m&amp;quot;.</text>
        <text start="198" dur="4">So we get the following result over here.</text>
        <text start="202" dur="3">You might take a moment to verify these steps over here,</text>
        <text start="205" dur="2">I was a little bit fast,</text>
        <text start="207" dur="5">but this is relatively straight forward mathematics.</text>
        <text start="212" dur="2">And if you will verify them,</text>
        <text start="214" dur="2">you will find that the maximum likelihood estimate</text>
        <text start="216" dur="3">for sigma squared is the average</text>
        <text start="219" dur="4">deviation of data points from the mean mu.</text>
        <text start="223" dur="2">This gives us a very nice basis to fit</text>
        <text start="225" dur="3">Gaussians to data points.</text>
        <text start="228" dur="4">So keeping these formulas in mind, here&amp;#39;s a quick quiz,</text>
        <text start="232" dur="6">which I ask you to actually calculate the mean and variance for a data sequence.</text>
        <text start="238" dur="4">So suppose the data you observe is 3, 4, 5, 6, and 7.</text>
        <text start="242" dur="2">There is 5 data points.</text>
        <text start="244" dur="3">Compute for me the mean and the variance</text>
        <text start="247" dur="3">using the maximum likelihood estimator I just gave you.</text>
      </transcript>
    </video>
    <video title="5c Answer" id="n1Ikbbe1g5M" length="33">
      <transcript>
        <text start="0" dur="2">So the mean is obviously 5,</text>
        <text start="2" dur="2">it&amp;#39;s the middle value over here.</text>
        <text start="4" dur="4">If I add those things together, I get 25 and divide by 5.</text>
        <text start="8" dur="2">The average value over here is 5.</text>
        <text start="10" dur="2">The more interesting case is sigma square,</text>
        <text start="12" dur="2">and I do this in the following steps--</text>
        <text start="14" dur="2">I subtract 5 from each of the data points</text>
        <text start="16" dur="4">for which I get -2, -1, 0, 1, and 2.</text>
        <text start="20" dur="2">I square those differences,</text>
        <text start="22" dur="2">which gives me 4, 1, 0, 1, 4.</text>
        <text start="24" dur="3">And now I compute the mean of those square differences.</text>
        <text start="27" dur="3">To do so, I add them all up, which is 10.</text>
        <text start="30" dur="3">10 divided by 5 is 2, and sigma square equals 2.</text>
      </transcript>
    </video>
    <video title="5d Question" id="R4izy_dyQzA" length="10">
      <transcript>
        <text start="0" dur="2">Here is another quiz--Suppose my DATA</text>
        <text start="2" dur="4">looks as follows--3,9,9,3.</text>
        <text start="6" dur="2">Compute for me mu and sigma squared</text>
        <text start="8" dur="2">using the maximum likelihood estimator I just gave you.</text>
      </transcript>
    </video>
    <video title="5e Answer" id="Fr33yWlbvLk" length="21.756999999999998">
      <transcript>
        <text start="0" dur="2.879">And the answer is relatively easy.</text>
        <text start="2.879" dur="2.871">3 + 9 + 9 + 3 = 24</text>
        <text start="5.75" dur="2.759">divided by m = 4 is 6</text>
        <text start="8.509" dur="1.701">so the mean value is 6</text>
        <text start="10.21" dur="4.705">subtracting the mean from the data gives us -3, 3, 3, and -3</text>
        <text start="14.915" dur="3.904">squaring those gives us 9, 9, 9, 9</text>
        <text start="18.819" dur="2.938">and the mean of 4 nines equals 9.</text>
      </transcript>
    </video>
    <video title="5f Question" id="pRGEQy7BgiY" length="50.047">
      <transcript>
        <text start="0" dur="3.337">I now have a more challenging quiz for you</text>
        <text start="3.337" dur="3.236">in which I give you multivariant data</text>
        <text start="6.573" dur="1.67">in this case 2-dimensional data.</text>
        <text start="8.243" dur="3.002">So suppose my data goes as follows.</text>
        <text start="11.245" dur="4.638">In the first column I get 3, 4, 5, 6, 7</text>
        <text start="15.883" dur="2.369">these are 5 data points and this is the first feature</text>
        <text start="18.252" dur="6.206">and the second feature will be 8, 7, 5, 3, 2.</text>
        <text start="24.458" dur="2.202">The formulas for calculating Mu</text>
        <text start="26.66" dur="2.853">and the covariance matrix Sigma</text>
        <text start="29.513" dur="2.185">generalize the ones we studied before</text>
        <text start="31.698" dur="1.969">and they are given over here.</text>
        <text start="33.667" dur="2.836">So what I would like you to compute is the vector Mu</text>
        <text start="36.503" dur="1.802">which now has 2 values</text>
        <text start="38.305" dur="3.37">one for the first and one for the second column</text>
        <text start="41.675" dur="2.605">and the variance Sigma</text>
        <text start="44.28" dur="2.767">which now has 4 different values</text>
        <text start="47.047" dur="3">using the formula shown over here.</text>
      </transcript>
    </video>
    <video title="5g Answer" id="FWOa3qoYOd8" length="36.867000000000004">
      <transcript>
        <text start="0" dur="3.036">Now the mean is calculated as before</text>
        <text start="3.036" dur="3.103">independently for each of the 2 features here.</text>
        <text start="6.139" dur="2.77">Three, 4, 5, 6, 7, the mean is 5.</text>
        <text start="8.909" dur="3.136">Eight, 7, 5, 3, 2, the mean is 5 again.</text>
        <text start="12.045" dur="2.909">Easy calculation. If you subtract the mean</text>
        <text start="14.954" dur="4.11">from the data we get the following matrix</text>
        <text start="19.064" dur="2.09">and now we just have to plug it in.</text>
        <text start="21.154" dur="3.604">For the main diagonal elements you get the same formula as before.</text>
        <text start="24.758" dur="3.07">You can do this separately for each of the 2 columns.</text>
        <text start="27.828" dur="2.736">But for the off-diagonal elements you just have to plug it in.</text>
        <text start="30.564" dur="1.902">So this is the result after plugging it in</text>
        <text start="32.466" dur="4.401">and you might just want to verify it using a computer.</text>
      </transcript>
    </video>
    <video title="5h Gaussian Summary" id="mlz-1yfyeoU" length="18.082">
      <transcript>
        <text start="0" dur="2.771">So this finishes the lecture on Gaussians.</text>
        <text start="2.771" dur="2">You learned about what a Gaussian is.</text>
        <text start="4.771" dur="1.87">We talked about the fit from data</text>
        <text start="6.641" dur="2.335">and we even talked about multivariate Gaussians.</text>
        <text start="8.976" dur="2.035">But even though I asked you to fit one of those</text>
        <text start="11.011" dur="2.085">the one we are going to focus on right now</text>
        <text start="13.096" dur="1.704">is the one-dimensional Gaussian.</text>
        <text start="14.8" dur="3.282">So let&amp;#39;s now move back to the expectation maximization algorithm.</text>
      </transcript>
    </video>
    <video title="5i EM as Generalization of k-Means" id="1CWDWmF0i2s" length="74.23899999999999">
      <transcript>
        <text start="0" dur="4.07">It is now really easy to explain expectation maximization</text>
        <text start="4.07" dur="2.303">as a generalization of K-means.</text>
        <text start="6.373" dur="2.703">Again, we have a couple of data points here</text>
        <text start="9.076" dur="3.203">and 2 randomly chosen cluster centers.</text>
        <text start="12.279" dur="4.104">But in the correspondence step instead of making a hard correspondence</text>
        <text start="16.383" dur="2.002">we make a soft correspondence.</text>
        <text start="18.385" dur="3.767">Each data point is attracted to a cluster center</text>
        <text start="22.152" dur="2.806">in proportion to the posterior likelihood</text>
        <text start="24.958" dur="2.002">which we will define in a minute.</text>
        <text start="26.96" dur="3.203">In the adjustment step or the maximization step</text>
        <text start="30.163" dur="4.372">the cluster centers are being optimized just like before</text>
        <text start="34.535" dur="2.502">but now the correspondence is a soft variable</text>
        <text start="37.037" dur="2.836">and they correspond to all data points in different strengths</text>
        <text start="39.873" dur="1.669">not just the nearest ones.</text>
        <text start="41.542" dur="2.535">As a result, in EM the cluster centers</text>
        <text start="44.077" dur="2.177">tend not to move as far as in K-means.</text>
        <text start="46.254" dur="1.794">Their movement is smooth away.</text>
        <text start="48.048" dur="2.002">A new correspondence over here gives us different strength</text>
        <text start="50.05" dur="3.337">as indicated by the different coloring of the links</text>
        <text start="53.387" dur="3.837">and another relaxation step gives us better cluster centers.</text>
        <text start="57.224" dur="2.369">And as you can see over time, gradually</text>
        <text start="59.593" dur="3.77">the EM will then converge to about the same solution as K-means.</text>
        <text start="63.363" dur="2.536">However, all the correspondences are still alive.</text>
        <text start="65.899" dur="2.101">Which means there is not a 0, 1 correspondence.</text>
        <text start="68" dur="1.883">There is a soft correspondence</text>
        <text start="69.883" dur="4.356">which relates to a posterior probability, which I will explain next.</text>
      </transcript>
    </video>
    <video title="5j EM Algorithm" id="tTr7547zVCc" length="194.72400000000002">
      <transcript>
        <text start="0" dur="2.603">The model of expectation maximization</text>
        <text start="2.603" dur="2.035">is that each data point</text>
        <text start="4.638" dur="1.869">is generated from what&amp;#39;s called a mixture.</text>
        <text start="6.507" dur="2.435">The sum of all possible classes</text>
        <text start="8.942" dur="2.036">or clusters, of which there are K</text>
        <text start="10.978" dur="2.335">we draw a class at random</text>
        <text start="13.313" dur="3.971">with a prior probability of p of the class C = i</text>
        <text start="17.284" dur="2.302">and then we draw data point X</text>
        <text start="19.586" dur="2.57">from the distribution correspondent with its class over here.</text>
        <text start="22.156" dur="5.939">The way to think about this if there is K different cluster centers shown over here</text>
        <text start="28.095" dur="2.803">each one of those has a generic Gaussian attached.</text>
        <text start="30.898" dur="3.169">In the generative version of expectation maximization</text>
        <text start="34.067" dur="2">you first draw a cluster center</text>
        <text start="36.067" dur="3.139">and then we draw from the Gaussian attached to this cluster center.</text>
        <text start="39.206" dur="4.237">The unknowns here are the prior probabilities for each cluster center</text>
        <text start="43.443" dur="5.94">should we call P-i and the Mu-i and in the general case Sigma-i</text>
        <text start="49.383" dur="2.072">for each of the individual Gaussian.</text>
        <text start="51.455" dur="3.333">Where i = 1 all the way to K.</text>
        <text start="54.788" dur="4.438">Expectation maximization iterates 2 steps just like K-means.</text>
        <text start="59.226" dur="2.736">One is called the E-step or expectation step</text>
        <text start="61.962" dur="6.24">for which we assume that we know the Gaussian parameters and the P-i.</text>
        <text start="68.202" dur="3.61">With those known values calculating the sum over here</text>
        <text start="71.812" dur="2.029">is a fairly trivial exercise.</text>
        <text start="73.841" dur="3.505">This is our known formula for a Gaussian</text>
        <text start="77.346" dur="4.236">we just plug that in and this is a fixed probability.</text>
        <text start="81.582" dur="3.31">The sum of all possible classes.</text>
        <text start="84.892" dur="2.438">So you get for e-ij</text>
        <text start="87.33" dur="3.297">the probability that the j-th data point</text>
        <text start="90.627" dur="2.366">corresponds to cluster center number i</text>
        <text start="92.993" dur="3.37">P-i times the normalizer</text>
        <text start="96.363" dur="2.436">times the Gaussian expression.</text>
        <text start="98.799" dur="3.603">Where we have a quadratic of Xj minus Mu-i</text>
        <text start="102.402" dur="5.072">times Sigma-i to the -1 times the same thing again over here.</text>
        <text start="107.474" dur="2.269">These are the probabilities</text>
        <text start="109.743" dur="2.302">that the j-th data point</text>
        <text start="112.045" dur="2.837">corresponds to the i-th cluster center</text>
        <text start="114.882" dur="2.235">under the assumption that we do know</text>
        <text start="117.117" dur="3.837">the parameters P-i, Mu-i, and Sigma-i.</text>
        <text start="120.954" dur="2.971">In the M-step we now figure out where these parameters should have been.</text>
        <text start="123.925" dur="3.002">For the prior probability of each cluster center</text>
        <text start="126.927" dur="4.438">we just take the sum over all the e-ijs, over all data points</text>
        <text start="131.365" dur="3.036">divided by the total number of data points.</text>
        <text start="134.401" dur="6.607">The mean is obtained by the weighted mean of the x-js</text>
        <text start="141.008" dur="4.838">normalized by the sum over e-ijs</text>
        <text start="145.846" dur="4.237">and finally the sigma is obtained as a sum</text>
        <text start="150.083" dur="3.037">over the weighted expression like this</text>
        <text start="153.12" dur="2.135">and this is the same expression as before</text>
        <text start="155.255" dur="5.172">and now again we are normalizing over the sum over all e-ijs.</text>
        <text start="160.427" dur="2.002">And these are exactly the same calculations</text>
        <text start="162.429" dur="4.271">as before when we fit a Gaussian but just weighted by</text>
        <text start="166.7" dur="4.571">the soft correspondence of a data point to each Gaussian.</text>
        <text start="171.271" dur="4.505">And this weighting is relatively straightforward to apply in Gaussian fitting.</text>
        <text start="175.776" dur="2.436">Let&amp;#39;s do a very quick quiz for EM.</text>
        <text start="178.212" dur="3.436">Suppose we&amp;#39;re given 3 data points and 2 cluster centers.</text>
        <text start="181.648" dur="3.07">And the question is, does this point over here</text>
        <text start="184.718" dur="4.409">called X1 correspond to C1 or C2 or both of them?</text>
        <text start="189.127" dur="5.597">Please check exactly one of these 3 different check boxes here.</text>
      </transcript>
    </video>
    <video title="5k Answer" id="JW74VRSnZAk" length="16">
      <transcript>
        <text start="0" dur="2">[Thrun] And the answer is both of them,</text>
        <text start="2" dur="3">and the reason is X1 might be closer to C2 than C1,</text>
        <text start="5" dur="2">but the correspondence in EM is soft,</text>
        <text start="7" dur="4">which means each data point always corresponds to all cluster centers.</text>
        <text start="11" dur="2">It is just that this correspondence over here</text>
        <text start="13" dur="3">is much stronger than the correspondence over here.</text>
      </transcript>
    </video>
    <video title="5l Question" id="TFViJ3P6NwM" length="21">
      <transcript>
        <text start="0" dur="2">[Thrun] Here is another EM quiz.</text>
        <text start="2" dur="6">For this quiz we will assume a degenerative case of 3 data points and just 1 cluster center.</text>
        <text start="8" dur="3">My question pertains to the shape of the Gaussian after fitting,</text>
        <text start="11" dur="2">specifically M1 sigma.</text>
        <text start="13" dur="5">And the question is, is sigma circular, which would be like this,</text>
        <text start="18" dur="3">or elongated, which would be like this or like this?</text>
      </transcript>
    </video>
    <video title="5m Answer" id="ZcTAhLG4OSs" length="8">
      <transcript>
        <text start="0" dur="2">[Thrun] And the answer is, of course, elongated.</text>
        <text start="2" dur="4">As you look over here, what you find is that this is the best Gaussian describing the data points,</text>
        <text start="6" dur="2">and this is what EM will calculate.</text>
      </transcript>
    </video>
    <video title="5n Question" id="0HENenZeAsE" length="47">
      <transcript>
        <text start="0" dur="5">[Thrun] This is a quiz in which I compare EM versus K-means.</text>
        <text start="5" dur="3">Suppose we are giving you 4 data points, as indicated by those circles.</text>
        <text start="8" dur="3">Suppose we have 2 initial cluster centers, shown here in red,</text>
        <text start="11" dur="6">and those converge to possible places that are indicated by those 4 squares.</text>
        <text start="17" dur="2">Of course they won&amp;#39;t take all 4 of them; they will just take 2 of them.</text>
        <text start="19" dur="2">But for now I&amp;#39;m going to give you 4 choices.</text>
        <text start="21" dur="5">We call this cluster 1, cluster 2, A, B, C, and D.</text>
        <text start="26" dur="6">In EM will C1 move towards A or will C1 move towards B?</text>
        <text start="32" dur="4">And in contrast, in K-means will C1 move towards A</text>
        <text start="36" dur="2">or will C1 move towards B?</text>
        <text start="38" dur="3">This is just asking about the left side of the diagram.</text>
        <text start="41" dur="3">So the question is will K-means find itself in the more extreme situation,</text>
        <text start="44" dur="3">or will EM find itself in the more extreme situation?</text>
      </transcript>
    </video>
    <video title="5o Answer" id="DODedtJZ3FA" length="41">
      <transcript>
        <text start="0" dur="5">[Thrun] And the answer is that while K-means will go all the way to the extreme, A,</text>
        <text start="5" dur="3">which is this one over here, EM will not.</text>
        <text start="8" dur="5">And this has to do with the soft versus hard nature of the correspondence.</text>
        <text start="13" dur="4">In K-means the correspondence is hard.</text>
        <text start="17" dur="3">So after the first situation, only these 2 data points over here</text>
        <text start="20" dur="2">correspond to cluster center 1,</text>
        <text start="22" dur="3">and they will find themselves straight in the middle where A is located.</text>
        <text start="25" dur="4">In EM, however, we find that there will still be a soft correspondence</text>
        <text start="29" dur="4">to these further away points which will then lead to a small shift of the cluster center</text>
        <text start="33" dur="3">to the right side, as indicated by B.</text>
        <text start="36" dur="5">That means K-means and EM will converge at different models of the data.</text>
      </transcript>
    </video>
    <video title="5p Choosing k" id="_-Ol1cXIWvQ" length="118">
      <transcript>
        <text start="0" dur="3">[Thrun] One of the remaining open questions pertains to the number of clusters.</text>
        <text start="3" dur="3">So far I&amp;#39;ve assumed it&amp;#39;s simply constant and you know it.</text>
        <text start="6" dur="2">But in reality, you don&amp;#39;t know it.</text>
        <text start="8" dur="4">Practical implementations often guess the number of clusters along with the parameters.</text>
        <text start="12" dur="5">And the way this works is that you periodically evaluate which data is poorly covered</text>
        <text start="17" dur="4">by the existing mixture, you generate new cluster centers</text>
        <text start="21" dur="4">at random near unexplained points, and then you run the algorithm for a while</text>
        <text start="25" dur="4">to see whether the existence of your clusters is still justified.</text>
        <text start="29" dur="4">And the justification test is based on a memorization of a criterion</text>
        <text start="33" dur="4">that combines the negative log likelihood of your data itself</text>
        <text start="37" dur="3">and a penalty for each cluster.</text>
        <text start="40" dur="3">In particular, you&amp;#39;re going to minimize the negative log likelihood of your data</text>
        <text start="43" dur="3">given the model plus a constant penalty per cluster.</text>
        <text start="46" dur="5">If we look at this expression, this is the expression that EM already minimizes.</text>
        <text start="51" dur="2">We maximized the posterior probability of data</text>
        <text start="53" dur="4">logarithmic is a monotonic function, and I put a minus sign over here</text>
        <text start="57" dur="3">so the optimization problem becomes a minimization problem.</text>
        <text start="60" dur="4">This one over here, we have a constant cost per cluster is new.</text>
        <text start="64" dur="3">If you increase the number of clusters, you would pay a penalty</text>
        <text start="67" dur="3">that is in the way of your attempted minimization.</text>
        <text start="70" dur="4">Typically, this expression balances out at a certain number of clusters,</text>
        <text start="74" dur="2">and it is generically the best explanation for your data.</text>
        <text start="76" dur="2">So the algorithm looks as follows.</text>
        <text start="78" dur="4">Guess an initial K, run EM, remove unnecessary clusters</text>
        <text start="82" dur="2">that will make this quote over here go up,</text>
        <text start="84" dur="3">create some new random clusters, and go back and run EM.</text>
        <text start="87" dur="3">There is all kinds of variants of this algorithm.</text>
        <text start="90" dur="3">One of the nice things here is this algorithm also overcomes local minima problems</text>
        <text start="93" dur="2">to some extent.</text>
        <text start="95" dur="4">If, for example, 2 clusters end up grabbing the same data,</text>
        <text start="99" dur="3">then your tests would show you that 1 of the clusters can be omitted;</text>
        <text start="102" dur="2">thereby the score can be improved.</text>
        <text start="104" dur="3">That cluster can later be restarted somewhere else,</text>
        <text start="107" dur="4">and by randomly restarting clusters, you tend to get a much, much better solution</text>
        <text start="111" dur="3">than if you run EM just once with a fixed number of clusters.</text>
        <text start="114" dur="4">So this trick is highly recommended for any implementation of expectation maximization.</text>
      </transcript>
    </video>
    <video title="5q Clustering Summary" id="DH7FWwCgx5M" length="41">
      <transcript>
        <text start="0" dur="3">[Thrun] This finishes my unit on clustering,</text>
        <text start="3" dur="2">at least so far.</text>
        <text start="5" dur="2">I just want to briefly summarize what we&amp;#39;ve learned.</text>
        <text start="7" dur="3">We talked about K-means, and we talked about expectation maximization.</text>
        <text start="10" dur="4">K-means is a very simple almost binary algorithm</text>
        <text start="14" dur="2">that allows you to find cluster centers.</text>
        <text start="16" dur="3">EM is a probabilistic generalization that also allows you to find clusters</text>
        <text start="19" dur="4">but also modifies the shapes of the clusters by modifying the covariance matrix.</text>
        <text start="23" dur="3">EM is probabilistically sound, and you can prove convergence</text>
        <text start="26" dur="3">in a log likelihood space. K-means also converges.</text>
        <text start="29" dur="2">Both are prone to local minima.</text>
        <text start="31" dur="3">In both cases you need to know the number of cluster centers, K.</text>
        <text start="34" dur="5">I showed you a brief trick how to estimate the K as you go,</text>
        <text start="39" dur="2">which also overcomes local minima to some extent.</text>
      </transcript>
    </video>
    <video title="6 Dimensionality Reduction" id="lDyEk72TezE" length="26">
      <transcript>
        <text start="0" dur="4">Let&amp;#39;s now talk about a 2nd class of unsupervised learning avenues</text>
        <text start="4" dur="2">that are called dimensionality reduction.</text>
        <text start="6" dur="4">We&amp;#39;re going to start with a little quiz, in which I will check your intuition.</text>
        <text start="10" dur="4">Suppose we&amp;#39;re given a 2-dimensional data field, and our data lines up as follows.</text>
        <text start="14" dur="3">My quiz is: How many dimensions do we really need?</text>
        <text start="17" dur="2">The key is the word really,</text>
        <text start="19" dur="3">which means we&amp;#39;re willing to tolerate a certain amount of error in accuracy,</text>
        <text start="22" dur="4">because we&amp;#39;re going to capture the essence of the problem.</text>
      </transcript>
    </video>
    <video title="6a Answer" id="AaSibhWmkQM" length="11">
      <transcript>
        <text start="0" dur="2">The answer is obviously 1.</text>
        <text start="2" dur="2">This is the key dimension over here.</text>
        <text start="4" dur="3">The orthogonal dimension in this direction carries alomst information,</text>
        <text start="7" dur="4">so it suffices, in most cases, to project the data onto this 1 dimensional space.</text>
      </transcript>
    </video>
    <video title="6b Question" id="0I4p7lyKo4k" length="8">
      <transcript>
        <text start="0" dur="2">Here is a quiz that is a little bit more tricky.</text>
        <text start="2" dur="2">I&amp;#39;m going to draw data for you like this.</text>
        <text start="4" dur="2">I&amp;#39;m going to ask the same question.</text>
        <text start="6" dur="2">How many dimensions do we really need?</text>
      </transcript>
    </video>
    <video title="6c Answer" id="wVkPH0eC4z0" length="30">
      <transcript>
        <text start="0" dur="5">This answer is not at all trivial, and I don&amp;#39;t blame you if you get it wrong.</text>
        <text start="5" dur="5">The answer is actually 1, but the projection itself is nonlinear.</text>
        <text start="10" dur="5">I can draw, really easily, a nice 1-dimensional space that follows these data points.</text>
        <text start="15" dur="4">If I am able to project all the data points on this 1-dimensional space,</text>
        <text start="19" dur="2">I capture the essence of the data.</text>
        <text start="21" dur="4">The trick, of course, is to find the nonlinear 1-dimensional space and describe it.</text>
        <text start="25" dur="5">This is what&amp;#39;s going on in the state-of-the-art in dimensionality reduction research.</text>
      </transcript>
    </video>
    <video title="6d Linear Dimensionality Reduction" id="5m6TeKw_e1M" length="177">
      <transcript>
        <text start="0" dur="2">For the remainder of this unit,</text>
        <text start="2" dur="3">I am going to talk about linear dimensionality reduction.</text>
        <text start="5" dur="3">Where the idea is that the given data points like this,</text>
        <text start="8" dur="5">and we seek to find a linear subspace in which to perfect the data.</text>
        <text start="13" dur="4">In this case, I would submit this is probably the most suitable linear subspace.</text>
        <text start="17" dur="6">So we remap the data onto the space over here, with x1 over here and x2 over here.</text>
        <text start="23" dur="2">Then we can capture the data in just 1 dimension.</text>
        <text start="25" dur="3">The algorithm is amazingly simple.</text>
        <text start="28" dur="3">Number 1: Fit a gaussian; we now know how this works.</text>
        <text start="31" dur="3">The gaussian will look something like this.</text>
        <text start="34" dur="5">Number 2: Caluclate the eigenvalues and eigenvectors of this gaussian.</text>
        <text start="39" dur="3">In this gaussian this would be the dominant eigenvector,</text>
        <text start="42" dur="3">and this would be the 2nd eigenvector over here.</text>
        <text start="45" dur="5">Step 3 is take those eigenvectors whose eigenvalues are the largest.</text>
        <text start="50" dur="5">Step 4 is to project the data onto the subspace of eigenvectors you chose.</text>
        <text start="55" dur="4">Now to understand this, you have to be familiar with eigenvectors and eigenvalues.</text>
        <text start="59" dur="3">I give you an intuitive familiarity with those.</text>
        <text start="62" dur="5">This is standard statistics material, and you will find this in many linear algebra classes.</text>
        <text start="67" dur="2">So let me just go through this very quickly</text>
        <text start="69" dur="5">and give you an intuition how to do linear dimensionality reduction.</text>
        <text start="74" dur="2">Suppose you&amp;#39;re given the following data points:</text>
        <text start="76" dur="4">Your axes are 0, 1, 2, 3, and 4,</text>
        <text start="80" dur="8">4 x1, and 1.9, 3.1, 4, 5.1, and 5.9.</text>
        <text start="88" dur="5">These are essentially 2, 3, 4, 5, 6,</text>
        <text start="93" dur="5">but slightly modified to define actual variance over this dimension.</text>
        <text start="98" dur="2">So I draw this in here.</text>
        <text start="100" dur="4">What I get is a set of points that doesn&amp;#39;t quite fit a line, but almost.</text>
        <text start="104" dur="3">There is a little error over here, a little error over here, and here and here.</text>
        <text start="107" dur="3">The mean is easily calculated; it&amp;#39;s 2 and 4.</text>
        <text start="110" dur="3">The covairance matrix looks as follows.</text>
        <text start="113" dur="6">Notice the slightly different covairance for the 1st variable, which is exactly 2,</text>
        <text start="119" dur="3">to the 2nd variable, which is 2.008.</text>
        <text start="122" dur="11">The eigenvectors happen to be 0.7064 and 0.7078 with an eigenvalue of 4.004,</text>
        <text start="133" dur="5">and the 2nd one is orthogonal with an eigenvalue much smaller.</text>
        <text start="138" dur="4">So obviously this is the eigenvector that dominates the spread of the data points.</text>
        <text start="142" dur="5">If you look at this vector over here, it is centered around the mean,</text>
        <text start="147" dur="4">which sits over here, and is exactly this vector shown over here.</text>
        <text start="151" dur="3">Where this one is the orthogonal vector shown over here.</text>
        <text start="154" dur="5">So this single dimension with a large weight explains the data relative to</text>
        <text start="159" dur="2">any other dimension, which is a very small eidenvalue.</text>
        <text start="161" dur="6">I should mention why these numerical examples might look confusing.</text>
        <text start="167" dur="2">This is very standard linear algebra.</text>
        <text start="169" dur="4">When you estimate covariance from data and try to understand which direction they point,</text>
        <text start="173" dur="4">this kind of eigenvalue anylysis gives you the right answer.</text>
      </transcript>
    </video>
    <video title="6e Face Example" id="KuSZmepQA_s" length="131">
      <transcript>
        <text start="0" dur="4">The dimensionality reduction looks a little bit silly when you go</text>
        <text start="4" dur="1">from 2 dimensions to 1 dimension.</text>
        <text start="5" dur="4">But in truly high-dimensional space it has a very strong utility.</text>
        <text start="9" dur="4">Here&amp;#39;s an example that goes back to MIT several decades ago</text>
        <text start="13" dur="2">on something called eigenfaces.</text>
        <text start="15" dur="2">These are all well-aligned faces.</text>
        <text start="17" dur="4">The objective in eigenface research has been to find</text>
        <text start="21" dur="4">simple ways to describe different people in a parameter space,</text>
        <text start="25" dur="2">in which we can easily identify the same person again.</text>
        <text start="27" dur="4">Images like these are very high-dimensional statistics.</text>
        <text start="31" dur="2">If each image is 50 by 50 pixels,</text>
        <text start="33" dur="6">each image itself becomes a data point in a 2500 dimensional feature space.</text>
        <text start="39" dur="4">Now obviously, we don&amp;#39;t have random images.</text>
        <text start="43" dur="5">We don&amp;#39;t fill the space of 2500 dimensions with all face images.</text>
        <text start="48" dur="6">Instead, it is reasonable to assume that all the faces live on a small subspace in that space.</text>
        <text start="54" dur="4">Obviously, you as a human can easily distinguish what is a valid image of a face</text>
        <text start="58" dur="4">and what is a valid image of a non face, like a car or a cloud or the sky.</text>
        <text start="62" dur="2">Therefore, there are many, many images that you can</text>
        <text start="64" dur="4">represent with 2500 pixels that are not faces.</text>
        <text start="68" dur="2">So research on eigenfaces has applied</text>
        <text start="70" dur="5">principle component analysis and eigenvalues to the space of faces.</text>
        <text start="75" dur="4">Here is a database in which faces are aligned.</text>
        <text start="79" dur="4">A researcher at Santiago Serrano extracted from it</text>
        <text start="83" dur="4">the average face after alignment on the right side.</text>
        <text start="87" dur="4">The truly interesting phenomenon occurs when you look at the eigenvalues.</text>
        <text start="91" dur="3">The face on the top left, over here, is the average face,</text>
        <text start="94" dur="3">and these are the variations,</text>
        <text start="97" dur="4">the eigenvectors that correspond to the largest eigenvalues over here.</text>
        <text start="101" dur="1">This is the strongest variation.</text>
        <text start="102" dur="4">You see a certain amount of different regions in and around the head shape</text>
        <text start="106" dur="2">and the hair that gets excited.</text>
        <text start="108" dur="2">That&amp;#39;s the 2nd strongest one, where the shirt gets more excited.</text>
        <text start="110" dur="1">As you go down,</text>
        <text start="111" dur="5">you find more and more interesting variations that can be used to reconstruct faces.</text>
        <text start="116" dur="5">Typically a dozen or so will suffice to make a face completely reconstructable,</text>
        <text start="121" dur="4">which means you&amp;#39;ve just mapped a 2500 dimensional feature space</text>
        <text start="125" dur="3">into a, perhaps, 12 dimensional feature space</text>
        <text start="128" dur="3">on which we can now learn much, much easier.</text>
      </transcript>
    </video>
    <video title="6f Scan Example" id="XNCHCncvDto" length="241">
      <transcript>
        <text start="0" dur="6">In our own reserch, we also have applied eigenvector decomposition</text>
        <text start="6" dur="5">to relatively challenging problems that don&amp;#39;t look like a linear problem at the surface.</text>
        <text start="11" dur="4">We scanned a good number of people with different physiques:</text>
        <text start="15" dur="4">Some thin, some not so thin, some tall, some short, some male, some female.</text>
        <text start="19" dur="4">We also scanned them in 3-D in different body postures:</text>
        <text start="23" dur="5">The arms down, the arms up, walking, throwing a ball, and so on.</text>
        <text start="28" dur="5">We applied eigenvector decomposition of the type I&amp;#39;ve just shown you</text>
        <text start="33" dur="4">to understand whether there is a latent low-dimensional space</text>
        <text start="37" dur="4">that is sufficient to represent the different physiques that people have,</text>
        <text start="41" dur="5">like thin or thick, and the different postures people can assume, like standing and so on.</text>
        <text start="46" dur="5">It turns out if you apply eigenvector decomposition</text>
        <text start="51" dur="4">to the space of all the formations of your body,</text>
        <text start="55" dur="5">you can find relatively low dimensional linear spaces,</text>
        <text start="60" dur="5">in which you can express different physiques and different body postures.</text>
        <text start="65" dur="6">For the space of all different physiques it turns only 3-dimensions sufficed</text>
        <text start="71" dur="4">to explain different heights, different thicknesses or body weights,</text>
        <text start="75" dur="3">and also different genders.</text>
        <text start="78" dur="4">That is, even though our surfaces themselves are representive</text>
        <text start="82" dur="3">of tens of thousands of data points, the underlying dimensionality</text>
        <text start="85" dur="4">when scanning people is really small.</text>
        <text start="89" dur="2">I&amp;#39;ll let you watch the entire movie.</text>
        <text start="91" dur="1">Please enjoy.</text>
        <text start="92" dur="2">[SCAPE: Shape Completion and Animation of People]</text>
        <text start="94" dur="4">We present a method named SCAPE for simultaneously modeling</text>
        <text start="98" dur="3">the space of all human shapes and poses.</text>
        <text start="101" dur="3">Further, we demonstrate the method&amp;#39;s usefulness</text>
        <text start="104" dur="4">for both shape completion and animation.</text>
        <text start="108" dur="3">The model is computed from an example set of surface meshes.</text>
        <text start="111" dur="4">We require only a limited set of training data:</text>
        <text start="115" dur="3">Examples of posed variation from a single subject</text>
        <text start="118" dur="4">and examples of the shape variation between subjects.</text>
        <text start="122" dur="4">The resulting model can represent both articulated motion</text>
        <text start="126" dur="4">and, importantly, the nonrigid muscle deformations</text>
        <text start="130" dur="4">required for natural appearance in a wide variety of poses.</text>
        <text start="134" dur="4">The model can also represent a wide variety of different body shapes,</text>
        <text start="138" dur="2">spanning both men and women.</text>
        <text start="140" dur="3">Because SCAPE incorporates both shape and pose</text>
        <text start="143" dur="5">we can jointly vary both shape and pose to create people who never existed</text>
        <text start="148" dur="3">and poses that were never observed.</text>
        <text start="151" dur="5">We demonstrate the use of this model 1st for shape completion of scanned meshes.</text>
        <text start="156" dur="3">Even when a subject has only been partially observed,</text>
        <text start="159" dur="3">we can use the model to estimate a complete surface.</text>
        <text start="162" dur="5">In this case, the entire front half of the subject has been synthesized.</text>
        <text start="167" dur="4">Note that the synthesized data both conforms to the individual subject&amp;#39;s</text>
        <text start="171" dur="3">specific shape and faithfully represents</text>
        <text start="174" dur="5">the nonrigid muscle deformations associated with a specific pose.</text>
        <text start="179" dur="2">Mesh completion is possible even when</text>
        <text start="181" dur="4">neither the person or the pose exists in the original training set.</text>
        <text start="185" dur="2">None of the women in our example set</text>
        <text start="187" dur="4">look similar to the woman in this sequence.</text>
        <text start="191" dur="4">Shape completion can also be used to synthesize complete</text>
        <text start="195" dur="3">animated surface meshes.</text>
        <text start="198" dur="2">Starting from a single scanned mesh of an actor</text>
        <text start="200" dur="4">and a timed series of motion capture markers</text>
        <text start="204" dur="2">we can treat the markers themselves</text>
        <text start="206" dur="3">as a very sparse sampling of surface geometry</text>
        <text start="209" dur="5">and complete the surface which best fits the available data at each point in time.</text>
        <text start="214" dur="2">Using this method, animated surface models</text>
        <text start="216" dur="4">for a wide variety of motions can be created with relative ease.</text>
        <text start="220" dur="5">In addition, the target identity of the surface model can easily be changed</text>
        <text start="225" dur="5">simply by replacing the subject portion of our factorized model with a different vector.</text>
        <text start="230" dur="4">The new identity need not be present in our training set</text>
        <text start="234" dur="2">or even correspond to a real person.</text>
        <text start="236" dur="5">An artist is free to alter the identity arbitrarily.</text>
      </transcript>
    </video>
    <video title="6g Piece-Wise Linear Projection" id="bIZrRYKN_RY" length="32">
      <transcript>
        <text start="0" dur="5">[Thrun] In modern dimensionality reduction, the trick has been to define nonlinear,</text>
        <text start="5" dur="4">sometimes piece-wise linear, subspaces on which data is being projected.</text>
        <text start="9" dur="3">This is not dissimilar from K nearest neighbors,</text>
        <text start="12" dur="4">where local regions are being defined based on local data neighborhoods.</text>
        <text start="16" dur="2">But here we need ways to interpret leveraging neighbors</text>
        <text start="18" dur="4">to make sure that the subspace itself becomes a feasible subspace.</text>
        <text start="22" dur="5">Common methods include local linear embedding, or LLE, or the Isomap method.</text>
        <text start="27" dur="2">If you&amp;#39;re interested in this, check the Web.</text>
        <text start="29" dur="3">There&amp;#39;s tons of information on these methods on the World Wide Web.</text>
      </transcript>
    </video>
    <video title="7 Spectral Clustering" id="VxAMBkDUfeg" length="42">
      <transcript>
        <text start="0" dur="4">We now talk about spectral clustering.</text>
        <text start="4" dur="3">The fundamental idea of spectral clustering</text>
        <text start="7" dur="2">is to cluster by affinity.</text>
        <text start="9" dur="3">And to understand the  importance of spectral clustering,</text>
        <text start="12" dur="4">let me ask you a simple intuitive quiz.</text>
        <text start="16" dur="2">Suppose you are given data like this,</text>
        <text start="18" dur="4">and you wish to learn that there&amp;#39;s 2 clusters--</text>
        <text start="22" dur="3">a cluster over here and a cluster over here.</text>
        <text start="25" dur="3">So my question is, from what you understand,</text>
        <text start="28" dur="2">do you think that &amp;quot;EM&amp;quot; or &amp;quot;K&amp;quot; means</text>
        <text start="30" dur="3">we would do a great job finding those clusters</text>
        <text start="33" dur="3">or do you think they will likely fail to find those clusters?</text>
        <text start="36" dur="2">So what were the questions--Do &amp;quot;EM&amp;quot; or &amp;quot;K&amp;quot;</text>
        <text start="38" dur="2">mean succeed in finding the 2 clusters?</text>
        <text start="40" dur="2">There is a likely yes and a likely no.</text>
      </transcript>
    </video>
    <video title="7a Answer" id="fuMoXRHxjTg" length="34">
      <transcript>
        <text start="0" dur="2">And the answer is likely no.</text>
        <text start="2" dur="3">The reason being that these aren&amp;#39;t clusters</text>
        <text start="5" dur="3">defined by a center of data points,</text>
        <text start="8" dur="2">but they&amp;#39;re clusters define by affinity,</text>
        <text start="10" dur="4">which means they&amp;#39;re defined by the presence of nearby points.</text>
        <text start="14" dur="3">So take for example the area over here, which I&amp;#39;m going to circle,</text>
        <text start="17" dur="3">and ask yourself, what&amp;#39;s the best cluster center?</text>
        <text start="20" dur="3">It&amp;#39;s likely somewhere over here where I drew the red dot.</text>
        <text start="23" dur="2">This is the cluster center for this cluster,</text>
        <text start="25" dur="3">and perhaps this is the cluster center for the other cluster.</text>
        <text start="28" dur="2">And these points over here will likely</text>
        <text start="30" dur="2">be classified as belonging to the cluster center over here.</text>
        <text start="32" dur="2">So, &amp;quot;EM&amp;quot; will likely do a bad job.</text>
      </transcript>
    </video>
    <video title="7b Spectral Clustering Algorithm" id="P-LEH-AFovE" length="324">
      <transcript>
        <text start="0" dur="3">So let&amp;#39;s look at this example again--let me redraw the data.</text>
        <text start="3" dur="2">What makes these clusters so different</text>
        <text start="5" dur="3">is not the absolute location of each data point,</text>
        <text start="8" dur="3">but the connectedness of these data points.</text>
        <text start="11" dur="2">The fact that these 2 points belong together</text>
        <text start="13" dur="3">is likely because there&amp;#39;s lots of points in-between.</text>
        <text start="16" dur="2">In other words, it&amp;#39;s the affinity</text>
        <text start="18" dur="3">that defines those clusters, not the absolute location.</text>
        <text start="21" dur="4">So spectral clustering gets annotation of affinity</text>
        <text start="25" dur="2">to make clustering happen.</text>
        <text start="27" dur="3">So let me look at the simple example for spectral clustering</text>
        <text start="30" dur="3">that would also work for K-means or EM,</text>
        <text start="33" dur="3">but they&amp;#39;ll be useful to illustrate spectral clustering.</text>
        <text start="36" dur="3">Let&amp;#39;s assume there&amp;#39;s 9 data points as shown over here,</text>
        <text start="39" dur="4">and I&amp;#39;ve colored them differently in blue, red, and black.</text>
        <text start="43" dur="3">But to clustering algorithms, they all come with the same color.</text>
        <text start="46" dur="2">Now the key element of spectral clustering</text>
        <text start="48" dur="2">is called the affinity martrix,</text>
        <text start="50" dur="3">which is a 9 by 9 matrix in this case,</text>
        <text start="53" dur="3">where each data point gets graphed</text>
        <text start="56" dur="2">realtive to each other data point.</text>
        <text start="58" dur="2">So let me write down all the 9 data points</text>
        <text start="60" dur="3">into the different rows of this matrix--</text>
        <text start="63" dur="2">the red ones, the black ones, and the blue ones.</text>
        <text start="65" dur="4">And in the columns, I graphed the exact same 9 data points.</text>
        <text start="69" dur="4">I then calculate for each pair of data points their affinity,</text>
        <text start="73" dur="3">where I use for now affinity as the</text>
        <text start="76" dur="3">quadratic distance in this diagram over here.</text>
        <text start="79" dur="3">Clearly, the red dots to each other have a high affinity,</text>
        <text start="82" dur="2">which means a small quadratic distance.</text>
        <text start="84" dur="2">Let me indicate this as follows--</text>
        <text start="86" dur="3">But realtive to all the other points, the affinity is weak.</text>
        <text start="89" dur="3">So there&amp;#39;s a very small value in these elements over here.</text>
        <text start="92" dur="2">Similarly, the affinity of the black</text>
        <text start="94" dur="2">data points to each other is very high,</text>
        <text start="96" dur="2">which means that the following block diagonal</text>
        <text start="98" dur="3">in this matrix will have a very large value.</text>
        <text start="101" dur="3">Yet the affinity to all the other data points will be low.</text>
        <text start="104" dur="3">And of course, the same is true for the blue data points.</text>
        <text start="107" dur="2">The interesting thing to notice now</text>
        <text start="109" dur="3">is that this is an approximately rank-deficient matrix.</text>
        <text start="112" dur="4">And further, the data points that belong to the same class--</text>
        <text start="116" dur="3">like the 3 red dots or the 3 black dots,</text>
        <text start="119" dur="4">have a singular affinitive vector to all the other data points.</text>
        <text start="123" dur="3">So this vector over here is similar to this vector over here.</text>
        <text start="126" dur="2">It&amp;#39;s similar to this vector over here,</text>
        <text start="128" dur="2">but it&amp;#39;s very different to this vector over here,</text>
        <text start="130" dur="3">which then itself is similar to the vector over here,</text>
        <text start="133" dur="2">yet different to the previous ones.</text>
        <text start="135" dur="2">Such a situation is easily addressed by what&amp;#39;s called</text>
        <text start="137" dur="4">principal component analysis, or PCA.</text>
        <text start="141" dur="4">PCA is a method to identify vectors that are similar</text>
        <text start="145" dur="3">in an approximate rank-deficient matrix.</text>
        <text start="148" dur="3">Consider once again our affinity matrix</text>
        <text start="151" dur="2">with prinicple component analysis,</text>
        <text start="153" dur="3">which is a standard linear trick,</text>
        <text start="156" dur="2">we can re-represent this matrix</text>
        <text start="158" dur="4">by the most dominant tivectors you&amp;#39;ll find there.</text>
        <text start="162" dur="2">And the first one, might look like this.</text>
        <text start="164" dur="3">The second one, which would be orthogonal, may look like this.</text>
        <text start="167" dur="2">The third one, like this.</text>
        <text start="169" dur="2">These are called eigenvectors, and the principle component</text>
        <text start="171" dur="2">now is each eigenvector has an item of value</text>
        <text start="173" dur="4">that states how prevalent this vector is in the original data.</text>
        <text start="177" dur="3">And for these 3 vectors, you&amp;#39;re going to find a large eigenvalue</text>
        <text start="180" dur="3">because there&amp;#39;s a number data points that represent</text>
        <text start="183" dur="3">these vectors quite prevalently</text>
        <text start="186" dur="3">like the first 3 does for this guy over here.</text>
        <text start="189" dur="3">There might be additional eigenvectors like something like this,</text>
        <text start="192" dur="3">but such eigenvectors will have a small eigenvalue</text>
        <text start="195" dur="2">simply because this vector isn&amp;#39;t really</text>
        <text start="197" dur="2">required to explain the data over here.</text>
        <text start="199" dur="2">It might just be explaining some of the noise</text>
        <text start="201" dur="2">in the affinity matrix</text>
        <text start="203" dur="2">that I didn&amp;#39;t even dare draw in here.</text>
        <text start="205" dur="2">Now if you take the eigenvectors with the largest</text>
        <text start="207" dur="2">eigenvalues--3 in this case,</text>
        <text start="209" dur="3">you first discover that the dimensionality</text>
        <text start="212" dur="2">of the underlying data space.</text>
        <text start="214" dur="3">The dimensionality equals the number of large eigenvalues.</text>
        <text start="217" dur="3">Further, if you re-represent each data vector</text>
        <text start="220" dur="2">using those eigenvectors,</text>
        <text start="222" dur="2">you&amp;#39;ll find a 3 dimensional  space</text>
        <text start="224" dur="4">where original data falls into a varity of different places.</text>
        <text start="228" dur="3">And these places are easily told apart by conventional clustering.</text>
        <text start="231" dur="2">So in summary, spectral clustering builds</text>
        <text start="233" dur="2">an affinity matrix of the data points.</text>
        <text start="235" dur="3">It strikes the eigenvectors with the largest eigenvalues,</text>
        <text start="238" dur="3">and then re-map those vecotrs into a new space</text>
        <text start="241" dur="4">with the data points easily clustering the conventional way.</text>
        <text start="245" dur="4">This is called affinity-based clustering or spectral clustering.</text>
        <text start="249" dur="2">Let me illustrate this once again with the</text>
        <text start="251" dur="2">data set that has a different spectral clustering</text>
        <text start="253" dur="2">than a conventional clustering.</text>
        <text start="255" dur="2">In this data set, the different clusters belong</text>
        <text start="257" dur="2">together because they&amp;#39;re affinity is similar.</text>
        <text start="259" dur="2">These 2 points belong together</text>
        <text start="261" dur="2">because there is a point in-between.</text>
        <text start="263" dur="3">If we now draw the affinity matrix for those data points,</text>
        <text start="266" dur="3">you find that the first and second data points are close together</text>
        <text start="269" dur="3">and the second and the third, but not the first and the third.</text>
        <text start="272" dur="3">Hence these 2 off diagonal elements here have remained small.</text>
        <text start="275" dur="3">Similarly for the red points as shown here</text>
        <text start="278" dur="2">with these 2 elements over here relatively small.</text>
        <text start="280" dur="2">And also for the black points</text>
        <text start="282" dur="2">where these 2 elements over here are small.</text>
        <text start="284" dur="3">And interestingly enough, even though these aren&amp;#39;t blocked diagonal,</text>
        <text start="287" dur="3">your first 3 largest eigenvectors</text>
        <text start="290" dur="2">will still look the same as before.</text>
        <text start="292" dur="2">I find this quite remarkable</text>
        <text start="294" dur="2">that even though these aren&amp;#39;t exactly blocks,</text>
        <text start="296" dur="3">those vecotrs still represent the 3 most</text>
        <text start="299" dur="2">important vectors for which to recover</text>
        <text start="301" dur="3">the data using principle component analysis.</text>
        <text start="304" dur="2">So in this case, spectral clustering would easily</text>
        <text start="306" dur="4">assign those guys and those guys and those guys</text>
        <text start="310" dur="2">to the respective same cluster,</text>
        <text start="312" dur="2">which wouldn&amp;#39;t be quite as easily the case for</text>
        <text start="314" dur="2">expectation-maximization or k-means.</text>
        <text start="316" dur="2">So let me ask you the following quiz.</text>
        <text start="318" dur="2">Suppose we have 8 data points.</text>
        <text start="320" dur="4">How many elements will the affinity matrix have?</text>
      </transcript>
    </video>
    <video title="7c Answer" id="VG8F24TAwzg" length="5">
      <transcript>
        <text start="0" dur="2">And the answer is 64.</text>
        <text start="2" dur="3">There&amp;#39;s 8 data points--8 times 8 is 64.</text>
      </transcript>
    </video>
    <video title="7d Question" id="1FZjz9O65ZU" length="17">
      <transcript>
        <text start="0" dur="4">My second question is, how many large  eigenvalues</text>
        <text start="4" dur="2">will PCA find?</text>
        <text start="6" dur="4">Now I understand this doesn&amp;#39;t have a unique answer,</text>
        <text start="10" dur="2">but in the best possible case</text>
        <text start="12" dur="3">where spectral clustering works well,</text>
        <text start="15" dur="2">how many large eigenvalues do you find?</text>
      </transcript>
    </video>
    <video title="7e Answer" id="924fCzIWetY" length="13">
      <transcript>
        <text start="0" dur="2">And the answer is 2.</text>
        <text start="2" dur="4">There&amp;#39;s a cluster over here and a cluster over here.</text>
        <text start="6" dur="2">And while it might happen that it&amp;#39;s as many as 8,</text>
        <text start="8" dur="2">if you adjust you&amp;#39;re affinity matrix well,</text>
        <text start="10" dur="3">those 2 should correspond with the 2 larger eigenvalues.</text>
      </transcript>
    </video>
    <video title="8 Supervised vs Unsupervised Learning" id="qkcFRr7LqAw" length="115">
      <transcript>
        <text start="0" dur="2">So, congratulations.</text>
        <text start="2" dur="3">You just made it through the unsupervised learning section of this class.</text>
        <text start="5" dur="2">I think you&amp;#39;ve learned a lot.</text>
        <text start="7" dur="3">You learned about K-means, you learned about expectation maximization,</text>
        <text start="10" dur="4">about dimensionality reduction and even spectral clustering.</text>
        <text start="14" dur="3">The first 3 items--K-means, EM, and dimensionality reduction--</text>
        <text start="17" dur="5">are used very frequently, and spectral clustering is a rarer used method</text>
        <text start="22" dur="4">that shows some of the most recent research going on in the field.</text>
        <text start="26" dur="4">I hope you have fun applying these methods in practice.</text>
        <text start="30" dur="5">I&amp;#39;d like to say a few final words about supervised versus unsupervised learning.</text>
        <text start="35" dur="4">In both cases you&amp;#39;re given data, but in 1 case you have labeled data,</text>
        <text start="39" dur="2">in another you have unlabeled data.</text>
        <text start="41" dur="4">The supervised learning paradigm is the dominant paradigm in machine learning,</text>
        <text start="45" dur="3">and there are a vast amount of papers being written about it.</text>
        <text start="48" dur="3">We talked about classification and regression</text>
        <text start="51" dur="2">and different methods to do supervised learning.</text>
        <text start="53" dur="3">The unsupervised paradigm is much less explored,</text>
        <text start="56" dur="4">even though I think it&amp;#39;s at least equally important--possibly even more important.</text>
        <text start="60" dur="5">Many systems can collect vast amounts of data such as web crawlers,</text>
        <text start="65" dur="3">robots, I told you about street view,</text>
        <text start="68" dur="3">and getting the data is cheap, but getting labels is hard.</text>
        <text start="71" dur="3">So to me, unsupervised is the method of the future.</text>
        <text start="74" dur="3">It&amp;#39;s one of the most interesting open research topics</text>
        <text start="77" dur="4">to see whether we can make sense out of large amounts of unlabeled or poorly labeled data.</text>
        <text start="81" dur="5">In between, there are techniques that do both: supervised and unsupervised.</text>
        <text start="86" dur="3">They are called semi-supervised or self-supervised,</text>
        <text start="89" dur="3">and they use elements of unsupervised learning and pair them with supervised learning.</text>
        <text start="92" dur="3">Those are fascinating by their own rights.</text>
        <text start="95" dur="3">Our robot Stanley, for example, that won the DARPA Grand Challenge</text>
        <text start="98" dur="5">used its own sensors to produce labels on the fly to other data.</text>
        <text start="103" dur="3">And I&amp;#39;ll talk about this when I talk about robotics in more detail.</text>
        <text start="106" dur="5">But for the time being, understand that the paradigms supervised and unsupervised</text>
        <text start="111" dur="4">span 2 very large areas of machine learning, and you learn quite a bit about it.</text>
      </transcript>
    </video>
  </group>
  <group title="Homework 3" count="18">
    <video title="1 Introduction" id="8zwpDAXxCJk" length="5">
      <transcript>
        <text start="0" dur="5">Welcome to the third homework assignment covering topics of machine learning.</text>
      </transcript>
    </video>
    <video title="2a Naive Bayes Laplacian Smoothing" id="Lj9ku_w8JAE" length="68">
      <transcript>
        <text start="0" dur="6">[Thrun] This question is about naive Bayes and Laplacian smoothing.</text>
        <text start="6" dur="6">Our training data is a set of movie titles: A Perfect World,</text>
        <text start="12" dur="4">My Perfect Woman, and Pretty Woman.</text>
        <text start="16" dur="10">We also have a song class of song titles: A Perfect Day, Electric Storm,</text>
        <text start="26" dur="2">Another Rainy Day.</text>
        <text start="28" dur="5">Suppose we get a new title, the query Perfect Storm,</text>
        <text start="33" dur="7">and we wish to know whether Perfect Storm is more likely a movie or a song.</text>
        <text start="40" dur="4">Compute for me the following model probabilities:</text>
        <text start="44" dur="6">the probability for movie class and song class,</text>
        <text start="50" dur="3">the probability of the word &amp;quot;perfect&amp;quot; conditioned on the movie class,</text>
        <text start="53" dur="5">the probability of the word &amp;quot;perfect&amp;quot; conditioned on the song class,</text>
        <text start="58" dur="3">and the same for the word &amp;quot;storm.&amp;quot;</text>
        <text start="61" dur="5">Please use Laplacian smoothing for this with K equals 1.</text>
        <text start="66" dur="2">Don&amp;#39;t compute the maximum likelihood estimate.</text>
      </transcript>
    </video>
    <video title="2a Naive Bayes Laplacian Smoothing ANSWER" id="evtCdmjcZ4I" length="110">
      <transcript>
        <text start="0" dur="3">[Thrun] Remember in Laplacian smoothing our best estimate</text>
        <text start="3" dur="6">is the count of the occurrence of the words divided by N,</text>
        <text start="9" dur="4">but we add our Laplacian smoother over here,</text>
        <text start="13" dur="3">and down here we add K times number of classes.</text>
        <text start="16" dur="8">For the movie prior we have 3 examples of movie titles over 6 total titles,</text>
        <text start="24" dur="4">which gives us 3 over 6.</text>
        <text start="28" dur="2">We add our Laplacian prior, 1 over here.</text>
        <text start="30" dur="3">There&amp;#39;s 2 classes, movie and song, 2 over here.</text>
        <text start="33" dur="2">We get 4 over 8, which is a half.</text>
        <text start="35" dur="3">The same is the case for song.</text>
        <text start="38" dur="4">It gets more interesting for this probability over here.</text>
        <text start="42" dur="6">In our movie class there&amp;#39;s 2 occurrences of the word &amp;quot;perfect&amp;quot; out of 8 words,</text>
        <text start="48" dur="2">so we get 2 over 8.</text>
        <text start="50" dur="3">But in adding the Laplacian prior, 1 over here</text>
        <text start="53" dur="2">and 1 number to add down here,</text>
        <text start="55" dur="6">the number of classes here is the size of the vocabulary.</text>
        <text start="61" dur="5">In total for this model there is 11 different words.</text>
        <text start="66" dur="4">There are 16 total words in both titles,</text>
        <text start="70" dur="4">but because of repetition there&amp;#39;s only 11 distinct words:</text>
        <text start="74" dur="12">a, perfect, world, my, woman, pretty, day, electric, storm, another, rainy.</text>
        <text start="86" dur="4">So we add the number of classes over here, which is 11.</text>
        <text start="90" dur="3">We obtain 3 over 19.</text>
        <text start="93" dur="4">For the song class there&amp;#39;s 1 occurrence of perfect.</text>
        <text start="97" dur="4">Adding 1 we get 2 over 19.</text>
        <text start="101" dur="2">There&amp;#39;s no occurrence of storm in the movie class.</text>
        <text start="103" dur="3">However, our Laplacian prior gives us 1 over 19.</text>
        <text start="106" dur="4">And there&amp;#39;s 1 occurrence of storm over here, which gives us 2 over 19.</text>
      </transcript>
    </video>
    <video title="2b Naive Bayes Laplacian Smoothing" id="VqJVQlsuGoA" length="11">
      <transcript>
        <text start="0" dur="4">[Thrun] For the same example I now would like to know the probability</text>
        <text start="4" dur="5">of movie title for my query.</text>
        <text start="9" dur="2">So please write this into the following box.</text>
      </transcript>
    </video>
    <video title="2b Naive Bayes Laplacian Smoothing ANSWER" id="LRQKhmXpDLI" length="61">
      <transcript>
        <text start="0" dur="4">[Thrun] As usual, we can resolve this using Bayes&amp;#39; rule.</text>
        <text start="4" dur="5">Probability of Perfect Storm given movie times P of movie</text>
        <text start="9" dur="6">divided by the same expression plus this expression for the opposite class, song.</text>
        <text start="15" dur="6">Here I simply write 3 dots for the text Perfect Storm.</text>
        <text start="21" dur="3">Plugging in the values over here and assuming conditional independence,</text>
        <text start="24" dur="5">as is the case when I use Bayes, we get the probably of &amp;quot;perfect&amp;quot; given movie,</text>
        <text start="29" dur="6">which is 3/19 and &amp;quot;storm&amp;quot; given movie, 1/19, times the prior over half,</text>
        <text start="35" dur="8">and we divide this by the same number plus probability of &amp;quot;perfect&amp;quot; given song,</text>
        <text start="43" dur="8">which is 2/19, and the probability of &amp;quot;storm&amp;quot; given song, which is 2/19 times the prior of half.</text>
        <text start="51" dur="10">Now, all the enumerators fall out, and we get 3 over 3 plus 2, which is 3 over 7.</text>
      </transcript>
    </video>
    <video title="2c Maximum Likelihood" id="9SDMNmgIhBE" length="16">
      <transcript>
        <text start="0" dur="3">[Thrun] I would now like to ask the exact same question</text>
        <text start="3" dur="2">for the maximum likelihood estimator.</text>
        <text start="5" dur="4">So let&amp;#39;s not assume we have Laplacian smoothing</text>
        <text start="9" dur="3">and instead use the maximum likelihood estimator.</text>
        <text start="12" dur="4">Simply compute for me the probability of movie for the title Perfect Storm.</text>
      </transcript>
    </video>
    <video title="2c Maximum Likelihood ANSWER" id="3lA9jrqw7_4" length="44">
      <transcript>
        <text start="0" dur="4">[Thrun] And the answer is simply 0, without much math.</text>
        <text start="4" dur="5">The word &amp;quot;perfect&amp;quot; occurs in movie, but the word &amp;quot;storm&amp;quot; has never been seen before.</text>
        <text start="9" dur="5">Therefore, the maximum likelihood estimate we will assign a 0 probability to the word &amp;quot;storm,&amp;quot;</text>
        <text start="14" dur="7">which will make the total product of the various factors involved in &amp;quot;storm&amp;quot; just 0.</text>
        <text start="21" dur="2">That is not the case for song.</text>
        <text start="23" dur="4">There is a non-zero probability for &amp;quot;perfect&amp;quot; and a non-zero probability for &amp;quot;storm.&amp;quot;</text>
        <text start="27" dur="2">Hence, it will have a non-zero probability.</text>
        <text start="29" dur="5">After normalization this will become 1 and this will become 0.</text>
        <text start="34" dur="4">So without much math I can calculate the correct posterior</text>
        <text start="38" dur="3">under the maximum likelihood model, which of course is disappointing</text>
        <text start="41" dur="3">because Perfect Storm is actually a movie title.</text>
      </transcript>
    </video>
    <video title="3a Linear Regression" id="rIO9zynD__M" length="15">
      <transcript>
        <text start="0" dur="4">[Thrun] In this question I quiz you about linear regression.</text>
        <text start="4" dur="3">Given the following data, my first question is,</text>
        <text start="7" dur="6">can this data be fit exactly using a linear function that maps from X to Y?</text>
        <text start="13" dur="2">Yes or no.</text>
      </transcript>
    </video>
    <video title="3a Linear Regression ANSWER" id="yTYQg1XiBEQ" length="40">
      <transcript>
        <text start="0" dur="2">[Thrun] And the answer is no.</text>
        <text start="2" dur="6">To see, let&amp;#39;s look at the slope of the linear function if it existed.</text>
        <text start="8" dur="3">From 0 to 1 we increment Y by 3.</text>
        <text start="11" dur="2">We go from 3 to 6.</text>
        <text start="13" dur="3">Therefore, the slope of it must be 3.</text>
        <text start="16" dur="5">However, from 1 to 2 we only increase the function by 1, from 6 to 7.</text>
        <text start="21" dur="3">Therefore, it can&amp;#39;t be fit linearly.</text>
        <text start="24" dur="4">We can see the same if we plot the linear points.</text>
        <text start="28" dur="4">Over here we could fit a linear function, but it&amp;#39;s very shallow,</text>
        <text start="32" dur="4">whereas those points over here have a much steeper situation.</text>
        <text start="36" dur="4">So any linear function would probably miss these points in between.</text>
      </transcript>
    </video>
    <video title="3b Linear Regression" id="5gIXtI82Olk" length="16">
      <transcript>
        <text start="0" dur="5">[Thrun] I would now like to ask you to perform linear regression on these data points</text>
        <text start="5" dur="4">and calculate for me W0 and W1.</text>
        <text start="9" dur="3">As defined in this class, we might have to go back</text>
        <text start="12" dur="4">and look over the exact formula from the lecture that I taught on linear regression.</text>
      </transcript>
    </video>
    <video title="3b Linear Regression ANSWER" id="ynxLGEE_Bgo" length="99">
      <transcript>
        <text start="0" dur="5">[Thrun] For answering these questions, let me restate the essential formulas.</text>
        <text start="5" dur="7">W1 is obtained by M times sum of XY minus sum of X times sum of Y</text>
        <text start="12" dur="7">over M times sum Xi square minus sum of Xi in brackets square.</text>
        <text start="19" dur="6">And if you plug in these numbers over here for M equals 5</text>
        <text start="25" dur="9">because there&amp;#39;s 5 training examples, we get 5 times 88 minus 10 times 35</text>
        <text start="34" dur="6">over 5 times 30 minus 100, which is 1.8.</text>
        <text start="40" dur="3">That is the correct answer for W1.</text>
        <text start="43" dur="9">W0 was obtained by 1 over M times sum over Ys minus W1 over M times sum over X.</text>
        <text start="52" dur="10">And plugging in the table over here gives us 1/5 times 35 minus 1.8 over 5 times 10,</text>
        <text start="62" dur="5">and that is 3.4, which would have been the correct answer over here.</text>
        <text start="67" dur="3">And again here are the data points with the solution.</text>
        <text start="70" dur="4">So if you take the axis where X equals 0,</text>
        <text start="74" dur="6">the Y value is actually 3.4, and the slope is 1.8.</text>
        <text start="80" dur="3">It&amp;#39;s a little smaller than if you just click at the end points,</text>
        <text start="83" dur="4">which gave us a slope of 2, because there is a residual arrow over here,</text>
        <text start="87" dur="3">residual arrow over here, residual arrow over here, and a residual arrow over here.</text>
        <text start="90" dur="7">The resulting linear function ends up splitting in a quadratically optimal way</text>
        <text start="97" dur="2">the arrows between these different data points.</text>
      </transcript>
    </video>
    <video title="4 k Nearest Neighbors" id="MhDJ47KG_Oc" length="30">
      <transcript>
        <text start="0" dur="4">In my next question I would like to ask you about K-nearest neighbors.</text>
        <text start="4" dur="3">Consider the following data set</text>
        <text start="7" dur="3">where plus indicates a positive traning example</text>
        <text start="10" dur="4">and minus a negative training example in this 2-dimensional space.</text>
        <text start="14" dur="4">I want you, for the following places,</text>
        <text start="18" dur="3">to check for those boxes over here</text>
        <text start="21" dur="5">whether they will be plus for K=5.</text>
        <text start="26" dur="4">Only check those boxes for which the label will be positive.</text>
      </transcript>
    </video>
    <video title="4 k Nearest Neighbors ANSWER" id="01qBi27m3Ss" length="49">
      <transcript>
        <text start="0" dur="3">And the answer would be this box over here</text>
        <text start="3" dur="3">and this box over here, nothing else.</text>
        <text start="6" dur="4">This guy has clearly 4 positive nearest neighbors,</text>
        <text start="10" dur="4">so no matter what the 5th one is we stay positive.</text>
        <text start="14" dur="2">Similarly, this guy over here,</text>
        <text start="16" dur="2">when you draw a circle,</text>
        <text start="18" dur="3">has probably these 4 guys as nearest neighbors,</text>
        <text start="21" dur="3">perhaps this one as well, but it is a little further away.</text>
        <text start="24" dur="3">With those 4 ones, it already has 3 pluses,</text>
        <text start="27" dur="3">so whatever the 5th one is it can&amp;#39;t overturn, it must be positive.</text>
        <text start="30" dur="4">All of these are negative, even this one over here has just 2 pluses as neighbors</text>
        <text start="34" dur="3">that are positive, and those guys over here are all negative.</text>
        <text start="37" dur="4">Similarly, over here there are possibly 2 pluses</text>
        <text start="41" dur="2">in the 5 nearest neighbors,</text>
        <text start="43" dur="3">but these guys over here are all negative, and this guy is</text>
        <text start="46" dur="3">surrounded by negative examples, so they will just be negative.</text>
      </transcript>
    </video>
    <video title="5 k Nearest Neighbors" id="SAG4-uC9BnE" length="31">
      <transcript>
        <text start="0" dur="5">Here&amp;#39;s another nearest neighbor example, and now I&amp;#39;m going to ask a different question.</text>
        <text start="5" dur="2">Given all the black data points,</text>
        <text start="7" dur="3">I want to make sure that the red ones are classified as indicated</text>
        <text start="10" dur="4">and I am free to choose a different value for K.</text>
        <text start="14" dur="5">Say I can choose K to be 1, 3, 5, 7, or 9.</text>
        <text start="19" dur="4">Check any or all of the K values</text>
        <text start="23" dur="3">for which you believe these 3 data points</text>
        <text start="26" dur="5">are classified correctly relative to the black training data set.</text>
      </transcript>
    </video>
    <video title="5 k Nearest Neighbors ANSWER" id="IjzpuYn7Szc" length="74">
      <transcript>
        <text start="0" dur="4">And the answer is just 5.</text>
        <text start="4" dur="3">If you look carefully for K=1,</text>
        <text start="7" dur="3">this guy will be mis-classified.</text>
        <text start="10" dur="3">It&amp;#39;s closer to a plus than a minus.</text>
        <text start="13" dur="4">Similarly, for K=3, this guy has 2 nearby pluses and 1 minus,</text>
        <text start="17" dur="2">so it would be positive.</text>
        <text start="19" dur="3">For K=5, to get the correct answer,</text>
        <text start="22" dur="3">the 5 nearest neighbors of this guy are</text>
        <text start="25" dur="5">those 3 minuses plus perhaps those 2 pluses over here.</text>
        <text start="30" dur="3">This guy has in his 5 neighborhood</text>
        <text start="33" dur="3">these 3 pluses over here, plus a minus, plus a plus.</text>
        <text start="36" dur="5">This data point over here has 2 pluses with 3 of the surrounding minuses,</text>
        <text start="41" dur="2">and they are all classified correctly.</text>
        <text start="43" dur="5">For K=7, this minus data point will have</text>
        <text start="48" dur="3">4 pluses, 3 minuses over here,</text>
        <text start="51" dur="3">and then everything in the vicinity becomes positive,</text>
        <text start="54" dur="3">so it must be 4 plus and it will be mis-classified.</text>
        <text start="57" dur="3">The same is true for K=9.</text>
        <text start="60" dur="4">The minus over here will have 1, 2, 3 minuses,</text>
        <text start="64" dur="3">5 pluses, and the minus over here,</text>
        <text start="67" dur="3">which makes 4 minuses.</text>
        <text start="70" dur="2">It will be classified as positive.</text>
        <text start="72" dur="2">So K=5 would have been the only correct answer.</text>
      </transcript>
    </video>
    <video title="6 Perceptron" id="-fpVTLGoxZ4" length="27">
      <transcript>
        <text start="0" dur="5">But nobody asked about the perceptron algorithm, suppose you have the following</text>
        <text start="5" dur="3">2 dimensional linear set where plus indicates</text>
        <text start="8" dur="5">a positive class label and minus a negative class label, and my first question is,</text>
        <text start="13" dur="2">&amp;quot;Are these data linearly separable?&amp;quot;</text>
        <text start="15" dur="3">I&amp;#39;d also like to know if we start perceptron</text>
        <text start="18" dur="3">with an initial separating plane like this,</text>
        <text start="21" dur="4">will it actually converge?</text>
        <text start="25" dur="2">Please check the appropriate boxes yes or no, and yes or no.</text>
      </transcript>
    </video>
    <video title="6 Perceptron ANSWER" id="P88qJlIRnwI" length="22">
      <transcript>
        <text start="0" dur="3">[Narrator] And the answer is yes in both cases.</text>
        <text start="3" dur="2">There is a linear separation that</text>
        <text start="5" dur="4">goes along here that separates the positive class from the negative class,</text>
        <text start="9" dur="3">and it&amp;#39;s been shown in the 60s,</text>
        <text start="12" dur="2">field perceptron algorithm always</text>
        <text start="14" dur="2">converges after finally many steps</text>
        <text start="16" dur="2">if such linear separator exists.</text>
        <text start="18" dur="2">I&amp;#39;m not going to prove this, and I did prove this</text>
        <text start="20" dur="2">in class, but I clearly said this in class.</text>
      </transcript>
    </video>
    <video title="7 Congratulations" id="VBw64HT6FlU" length="3">
      <transcript>
        <text start="0" dur="3">Congratulations! You just finished the third homework assignment.</text>
      </transcript>
    </video>
  </group>
  <group title="Unit 7" count="19">
    <video title="1 Introduction" id="pszEzBql4bw" length="68">
      <transcript>
        <text start="0" dur="2">Welcome back.</text>
        <text start="2" dur="2">So far we&amp;#39;ve talked about AI</text>
        <text start="4" dur="4">as managing complexity and uncertainty.</text>
        <text start="8" dur="3">We&amp;#39;ve seen how a search can discover sequences</text>
        <text start="11" dur="2">of actions to solve problems.</text>
        <text start="13" dur="2">We&amp;#39;ve seen how probability theory</text>
        <text start="15" dur="3">can represent in reason with uncertainty.</text>
        <text start="18" dur="2">And we&amp;#39;ve seen how machine learning</text>
        <text start="20" dur="4">can be used to learn and improve.</text>
        <text start="24" dur="2">AI is a big and dynamic field</text>
        <text start="26" dur="2">because we are pushing against complexity</text>
        <text start="28" dur="2">in at least 3 directions.</text>
        <text start="30" dur="2">First, in terms of agent design,</text>
        <text start="32" dur="3">we start with a simple reflex-based agent</text>
        <text start="35" dur="4">and move into goal-based and utility-based agents.</text>
        <text start="39" dur="3">Secondly, in terms of the complexity of the environment,</text>
        <text start="42" dur="2">we start with simple environments</text>
        <text start="44" dur="3">and then start looking at partial observability,</text>
        <text start="47" dur="4">estocastic actions at multiple agents, and so on.</text>
        <text start="51" dur="3">And finally, in terms of representation,</text>
        <text start="54" dur="2">the agents model of the world</text>
        <text start="56" dur="2">becomes increasingly complex.</text>
        <text start="58" dur="2">And this unit will concentrate</text>
        <text start="60" dur="3">on that third aspect of representation,</text>
        <text start="63" dur="2">showing how the tools of logic</text>
        <text start="65" dur="3">can be used by an agent to better model the world.</text>
      </transcript>
    </video>
    <video title="2 Propositional Logic" id="_VjyktjNMoM" length="223">
      <transcript>
        <text start="0" dur="7">The first logic we will consider is called propositional logic.</text>
        <text start="7" dur="5">Let&amp;#39;s jump right into an example, recasting the alarm problem in propositional logic.</text>
        <text start="12" dur="11">We have propositional symbols B, E, A, M, and J</text>
        <text start="23" dur="5">corresponding to the events of a burglary occurring, of\ the earthquake occurring,</text>
        <text start="28" dur="6">of the alarm going off, of Mary calling, and of John calling.</text>
        <text start="34" dur="3">And just as in the probabalistic models,</text>
        <text start="37" dur="3">these can be either true or false,</text>
        <text start="40" dur="4">but unlike improbability, our degree of belief in propositional logic</text>
        <text start="44" dur="3">is not a number.</text>
        <text start="47" dur="6">Rather, our belief is that each of these is either true or false or unknown.</text>
        <text start="53" dur="4">Now, we can make logical sentences using these symbols</text>
        <text start="57" dur="7">and also using the logical constants true and false</text>
        <text start="64" dur="4">by combining them together using logical operators.</text>
        <text start="68" dur="4">For example, we can say that the alarm is true</text>
        <text start="72" dur="4">whenever the earthquake or burglary is true with this sentence.</text>
        <text start="76" dur="12">(E V B) E or B implies A.</text>
        <text start="88" dur="7">So that says whenever the earthquake or the burglary is true,</text>
        <text start="95" dur="3">then the alarm will be true.</text>
        <text start="98" dur="2">We use this V symbol to mean or</text>
        <text start="100" dur="3">and a right arrow to mean implies.</text>
        <text start="103" dur="4">We could also say that it would be true that both John and Mary call</text>
        <text start="107" dur="3">when the alarm is true.</text>
        <text start="110" dur="11">We write that as A implies (J ^ M)</text>
        <text start="121" dur="4">and we use this symbol ^ to indicate an and,</text>
        <text start="125" dur="4">so that this upward-facing wedge looks kind of like an A</text>
        <text start="129" dur="5">with the crossbar missing, and so you can remember A is for &amp;quot;and&amp;quot;</text>
        <text start="134" dur="5">where with this downward-facing V symbol is the opposite of and,</text>
        <text start="139" dur="3">so that&amp;#39;s the symbol for or.</text>
        <text start="142" dur="3">Now, there&amp;#39;s 2 more connectors we haven&amp;#39;t seen yet.</text>
        <text start="145" dur="4">There&amp;#39;s a double arrow for equivalent, also known as a biconditional,</text>
        <text start="149" dur="3">and a not sign for negation,</text>
        <text start="152" dur="7">so we could say if we wanted to that John calls if and only if Mary calls.</text>
        <text start="159" dur="6">We would write that as J &amp;lt;=&amp;gt; M.</text>
        <text start="165" dur="3">John is equivalent to Mary--when one is true, the other is true;</text>
        <text start="168" dur="3">when one is false, the other is false.</text>
        <text start="171" dur="5">Or we could say that when John calls, Mary doesn&amp;#39;t, and vice versa.</text>
        <text start="176" dur="8">We could write that as John is equivalent J&amp;lt;=&amp;gt; to not Mary,</text>
        <text start="184" dur="4">and this is the not sign.</text>
        <text start="188" dur="3">Now, how do we know what the sentences mean?</text>
        <text start="191" dur="3">A propositional logic sentence is either true or false</text>
        <text start="194" dur="3">with respect to a model of the world.</text>
        <text start="197" dur="4">Now, a model is just a set of true/false values for all the propositional symbols,</text>
        <text start="201" dur="13">so a model might be the set B is true, E is false, and so on.</text>
        <text start="214" dur="5">We can define the truth of the sentence in terms of the truth of the symbols</text>
        <text start="219" dur="4">with respect to the models using truth tables.</text>
      </transcript>
    </video>
    <video title="2a Truth Tables" id="eOp4UJl0ZIA" length="162">
      <transcript>
        <text start="0" dur="5">[Male narrator] Here are the truth tables for all the logical connectives.</text>
        <text start="5" dur="5">What a truth table does is list all the possibilities for the propositional symbols,</text>
        <text start="10" dur="6">so P and Q can be false and false, false and true, true and false, or true and true.</text>
        <text start="16" dur="3">Those are the only 4 possibilities,</text>
        <text start="19" dur="5">and then for each of those possibilities, the truth table lists the truth value</text>
        <text start="24" dur="2">of the compound sentence.</text>
        <text start="26" dur="6">So the sentence not P is true when P is false and false when P is true.</text>
        <text start="32" dur="9">The sentence P and Q is true only when both P and Q are true and false otherwise.</text>
        <text start="41" dur="6">The sentence P or Q is true when either P or Q is true</text>
        <text start="47" dur="3">and false when both are false.</text>
        <text start="50" dur="7">Now, so far, those mostly correspond to the English meaning of those sentences</text>
        <text start="57" dur="5">with one exception, which is that in English, the word &amp;quot;or&amp;quot; is somewhat ambiguous</text>
        <text start="62" dur="5">between the inclusive and exclusive or,</text>
        <text start="67" dur="5">and this &amp;quot;or&amp;quot; means either or both.</text>
        <text start="72" dur="7">We translate this mark into English P implies Q; or as if P, then Q,</text>
        <text start="79" dur="5">but the meaning in logic is not quite the same as the meaning in ordinary English.</text>
        <text start="84" dur="5">The meaning in logic is defined explicitly by this truth table</text>
        <text start="89" dur="5">and by nothing else, but let&amp;#39;s look at some examples in ordinary English.</text>
        <text start="94" dur="10">If we have the proposition O and have that mean 5 is an odd number</text>
        <text start="104" dur="6">and P meaning Paris is the capital of France,</text>
        <text start="110" dur="4">then under the ordinary model of the truth in the real world,</text>
        <text start="114" dur="7">what could we say about the sentence O implies P?</text>
        <text start="121" dur="7">That is, 5 is an odd number implies Paris is the capital of France.</text>
        <text start="128" dur="6">Would that be true or false?</text>
        <text start="134" dur="3">And let&amp;#39;s look at one more example.</text>
        <text start="137" dur="4">If E is the proposition that 5 is an even number</text>
        <text start="141" dur="5">and M is the proposition that Moscow is the capital of France,</text>
        <text start="146" dur="5">what about E implies M?</text>
        <text start="151" dur="5">5 is an even number implies Moscow is the capital of France.</text>
        <text start="156" dur="6">Is that true or false?</text>
      </transcript>
    </video>
    <video title="2b Answer" id="4HWzU7RhfZE" length="47">
      <transcript>
        <text start="0" dur="3">[Male narrator] The answers are first,</text>
        <text start="3" dur="3">the sentence if 5 is an odd number,</text>
        <text start="6" dur="4">then Paris is the capital of France, is true</text>
        <text start="10" dur="2">in propositional logic.</text>
        <text start="12" dur="3">It may sound odd in ordinary English,</text>
        <text start="15" dur="6">but in propositional logic, this is the same as true implies true</text>
        <text start="21" dur="4">and if we look on this line--the final line for P and Q,</text>
        <text start="25" dur="3">P implies Q is true.</text>
        <text start="28" dur="7">The second sentence, 5 is an even number, implies Moscow is the capital of France.</text>
        <text start="35" dur="3">That&amp;#39;s the same as false implies false,</text>
        <text start="38" dur="9">and false implies false according to the definition is also true.</text>
      </transcript>
    </video>
    <video title="2c Question" id="ae_9TnTNPU0" length="31">
      <transcript>
        <text start="0" dur="2">[Male narrator] Here&amp;#39;s a quiz.</text>
        <text start="2" dur="4">Use truth tables or whatever other method you want</text>
        <text start="6" dur="3">to fill in the values of these tables.</text>
        <text start="9" dur="5">For each of the values of P and Q--false/false, false/true, true/false, or true/true--</text>
        <text start="14" dur="4">look at each of these boxes and click on just the boxes</text>
        <text start="18" dur="4">in which the formula for that column will be true.</text>
        <text start="22" dur="6">So which of these 4 boxes, if any, will this formula be true,</text>
        <text start="28" dur="3">and this formula and this formula?</text>
      </transcript>
    </video>
    <video title="2d Answer" id="vGfOrh8ERXo" length="80">
      <transcript>
        <text start="0" dur="3">[Male narrator] Here are the answers.</text>
        <text start="3" dur="5">For P and P implies Q, we know that P is true</text>
        <text start="8" dur="6">in these bottom 2 cases, and P implies Q, we saw the truth table for P implies Q</text>
        <text start="14" dur="5">is true in the first, second, and fourth case.</text>
        <text start="19" dur="9">So the only case that&amp;#39;s true for both P and P implies Q is the fourth case.</text>
        <text start="28" dur="9">Now, this formula, not the quantity, not P or not Q, can work that out to be the same</text>
        <text start="37" dur="9">as P and Q, and we know that P and Q is true only when both are true,</text>
        <text start="46" dur="5">so that would be true only in the fourth case and none of the other cases.</text>
        <text start="51" dur="6">And now, we&amp;#39;re asking for an equivalent or biconditional between these 2 cases.</text>
        <text start="57" dur="2">Is this one the same as this one?</text>
        <text start="59" dur="4">And we see that it is the same because they match up in all 4 cases.</text>
        <text start="63" dur="4">They&amp;#39;re false for each of the first 3 and true in the fourth one,</text>
        <text start="67" dur="4">so that means that this is going to be true no matter what.</text>
        <text start="71" dur="4">They&amp;#39;re always equivalent, either both false or both true,</text>
        <text start="75" dur="5">and so we should check all 4 boxes.</text>
      </transcript>
    </video>
    <video title="2e Question" id="DDKhgqEWBps" length="56">
      <transcript>
        <text start="0" dur="4">[Male narrator] Here&amp;#39;s one more example of reasoning in propositional logic.</text>
        <text start="4" dur="4">In a particular model of the world, we know the following 3 sentences are true.</text>
        <text start="8" dur="7">E or B implies A,</text>
        <text start="15" dur="8">A implies J and M,</text>
        <text start="23" dur="3">and B.</text>
        <text start="26" dur="5">We know those 3 senetences to be true, and that&amp;#39;s all we know.</text>
        <text start="31" dur="7">Now, I want you to tell me for each of the 5 propositional symbols,</text>
        <text start="38" dur="7">is that symbol true or false, or unknown in this model,</text>
        <text start="45" dur="11">and tell me for the symbols E, B, A, J, and M.</text>
      </transcript>
    </video>
    <video title="2f Answer" id="pxGxSt58kg0" length="39">
      <transcript>
        <text start="0" dur="4">The answer is that B is true.</text>
        <text start="4" dur="4">And we know that because it was one of the 3 sentences that was given to us.</text>
        <text start="8" dur="7">And now, according to the first sentence, says that if E or B is true then A is true.</text>
        <text start="15" dur="2">So now we know that A is true.</text>
        <text start="17" dur="7">And the second sentence says if A is true then J and M are true.</text>
        <text start="24" dur="2">What about E? That wasn&amp;#39;t mentioned.</text>
        <text start="26" dur="2">Does that mean E is false? No.</text>
        <text start="28" dur="6">It means that it is unknown that a model where E is true and a model where E is false</text>
        <text start="34" dur="5">would both satisfy these 3 sentences. So we mark E as unknown.</text>
      </transcript>
    </video>
    <video title="2g Terminology" id="nGZ2-EZnSh4" length="91">
      <transcript>
        <text start="0" dur="3">Now for a little more terminology.</text>
        <text start="3" dur="6">We say that a valid sentence is one that is true in every possible model,</text>
        <text start="9" dur="5">for every combination of values of the propositional symbols.</text>
        <text start="14" dur="10">And a satisfiable sentence is one that is true in some models, but not necessarily in all the models.</text>
        <text start="24" dur="6">So what I want you to do is tell me for each of these sentences,</text>
        <text start="30" dur="12">whether it is valid, satisfiable but not valid, or unsatisfiable, in other words, false for all models.</text>
        <text start="42" dur="9">And the sentences are P or not P, P and not P,</text>
        <text start="51" dur="19">P or Q or P is equivalent to Q, P implies Q or Q implies P.</text>
        <text start="70" dur="21">And finally, Food implies Party or Drinks implies party implies Food and Drinks implies Party.</text>
      </transcript>
    </video>
    <video title="2h Answer" id="WOYA5kQ_6gI" length="100">
      <transcript>
        <text start="0" dur="5">The answers are P and not P is valid.</text>
        <text start="5" dur="8">That is, it&amp;#39;s true when P is true because of this, and it&amp;#39;s true when P is false because of this clause.</text>
        <text start="13" dur="4">P and not P is unsatisfiable.</text>
        <text start="17" dur="5">A symbol can&amp;#39;t be both true and false at the same time.</text>
        <text start="22" dur="6">P or Q or P is equivalent to Q is valid.</text>
        <text start="28" dur="6">So we know that it&amp;#39;s true when either P or Q is true, so that&amp;#39;s 3 out of the 4 cases.</text>
        <text start="34" dur="6">In the fourth case, both P and Q are false, and that means P is equivalent to Q.</text>
        <text start="40" dur="4">And therefore, in all 4 cases, it&amp;#39;s true.</text>
        <text start="44" dur="4">P implies Q or Q implies P, that&amp;#39;s also valid.</text>
        <text start="48" dur="3">Now in ordinary English that wouldn&amp;#39;t be valid.</text>
        <text start="51" dur="7">If the 2 clauses or the 2 symbols P and Q were irrelevant to each other we wouldn&amp;#39;t say that either one of those was true.</text>
        <text start="58" dur="6">But in logic, one or the other must be true, according to the definitions of the truth tables.</text>
        <text start="64" dur="4">And finally, this one&amp;#39;s more complicated,</text>
        <text start="68" dur="9">if Food then Party or if Drinks then Party implies if Food and Drinks then Party.</text>
        <text start="77" dur="12">You can work it all out and both sides of the main implication work out to be equivalent to Not Food or Not Drinks or Party.</text>
        <text start="89" dur="6">So that&amp;#39;s the same as saying P implies P, saying one side is equivalent to the other side.</text>
        <text start="95" dur="5">And if they&amp;#39;re equivalent, then the implication relation holds.</text>
      </transcript>
    </video>
    <video title="2i Propositional Logic Limitations" id="WQ7-B4H6-aE" length="76">
      <transcript>
        <text start="0" dur="4">Propositional logic. It&amp;#39;s a powerful language for what it does.</text>
        <text start="4" dur="3">And there are very efficient inference mechanisms for determining</text>
        <text start="7" dur="5">validity and satisfiability, alhough we haven&amp;#39;t discussed them.</text>
        <text start="12" dur="3">But propositional logic has a few limitations.</text>
        <text start="15" dur="4">First, it can only handle true and false values.</text>
        <text start="19" dur="8">No capability to handle uncertainty like we did in probability theory.</text>
        <text start="27" dur="4">And second, we can only talk about events that are true or false in the world.</text>
        <text start="31" dur="6">We can&amp;#39;t talk about objects that have properties,</text>
        <text start="37" dur="3">such as size, weight, color, and so on.</text>
        <text start="40" dur="4">Nor can we talk about the relations between objects.</text>
        <text start="44" dur="9">And third, there are no shortcuts to succinctly talk about a lot of different things happening.</text>
        <text start="53" dur="6">Say if we had a vacuum world with a thousand  locations, and we wanted to say that every location is free of dirt.</text>
        <text start="59" dur="4">We would need a conjunction of a thousand propositions.</text>
        <text start="63" dur="6">There&amp;#39;s no way to have a single sentence saying that all the locations are clean all at once.</text>
        <text start="69" dur="7">So, we will next cover first-order logic which addresses these two limitations.</text>
      </transcript>
    </video>
    <video title="3 First Order Logic" id="hFzVZzMPy8Q" length="222">
      <transcript>
        <text start="0" dur="4">[Norvig] I&amp;#39;m going to talk about first order logic</text>
        <text start="4" dur="5">and its relation to the other logics we&amp;#39;ve seen so far--</text>
        <text start="9" dur="9">namely, propositional logic and probability theory.</text>
        <text start="18" dur="5">We&amp;#39;re going to talk about them in terms of what they say about the world,</text>
        <text start="23" dur="6">which we call the ontological commitment of these logics,</text>
        <text start="29" dur="6">and what types of beliefs agents can have using these logics,</text>
        <text start="35" dur="4">which we call the epistemological commitments.</text>
        <text start="39" dur="7">So in first order logic we have relations about things in the world,</text>
        <text start="46" dur="3">objects, and functions on those objects.</text>
        <text start="49" dur="10">And what we can believe about those relations is that they&amp;#39;re true or false or unknown.</text>
        <text start="59" dur="3">So this is an extension of propositional logic</text>
        <text start="62" dur="4">in which all we had was facts about the world</text>
        <text start="66" dur="7">and we could believe that those facts were true or false or unknown.</text>
        <text start="73" dur="8">In probability theory we had the same types of facts as in propositional logic--</text>
        <text start="81" dur="9">the symbols or variables--but the beliefs could be a real number in the range 0 to 1.</text>
        <text start="90" dur="4">So logics vary both in what you can say about the world</text>
        <text start="94" dur="4">and what you can believe about what&amp;#39;s been said about the world.</text>
        <text start="98" dur="3">Another way to look at representation</text>
        <text start="101" dur="9">is to break the world up into representations that are atomic,</text>
        <text start="110" dur="4">meaning that a representation of the state is just an individual state</text>
        <text start="114" dur="3">with no pieces inside of it.</text>
        <text start="117" dur="6">And that&amp;#39;s what we used for search and problem solving.</text>
        <text start="123" dur="3">We had a state, like state A,</text>
        <text start="126" dur="5">and then we transitioned to another state, like state B,</text>
        <text start="131" dur="4">and all we could say about those states was are they identical to each other or not</text>
        <text start="135" dur="4">and maybe is one of them a goal state or not.</text>
        <text start="139" dur="5">But there wasn&amp;#39;t any internal structure to those states.</text>
        <text start="144" dur="4">In propositional logic, as well as in probability theory,</text>
        <text start="148" dur="5">we break up the world into a set of facts that are true or false,</text>
        <text start="153" dur="4">so we call this a factored representation--</text>
        <text start="157" dur="4">that is, the representation of an individual state of the world</text>
        <text start="161" dur="6">is factored into several variables--the B and E and A and M and J, for example--</text>
        <text start="167" dur="4">and those could be Boolean variables or in some types of representations--</text>
        <text start="171" dur="8">not in propositional logic--they can be other types of variables besides Boolean.</text>
        <text start="179" dur="7">Then the third type--the most complex type of representation--we call structured.</text>
        <text start="186" dur="8">And in a structured representation, an individual state is not just a set of values for variables,</text>
        <text start="194" dur="3">but it can include relationships between objects,</text>
        <text start="197" dur="5">a branching structure, and complex representations and relations</text>
        <text start="202" dur="3">between one object and another.</text>
        <text start="205" dur="3">And that&amp;#39;s what we see in traditional programming languages,</text>
        <text start="208" dur="4">it&amp;#39;s what we see in databases--they&amp;#39;re called structured databases,</text>
        <text start="212" dur="4">and we have structured query languages over those databases--</text>
        <text start="216" dur="3">and that&amp;#39;s a more powerful representation,</text>
        <text start="219" dur="3">and that&amp;#39;s what we get in first order logic.</text>
      </transcript>
    </video>
    <video title="3a Models" id="TZ8iD-Rofk8" length="236">
      <transcript>
        <text start="0" dur="4">[Norvig] How does first order logic work? What does it do?</text>
        <text start="4" dur="4">Like propositional logic, we start with a model.</text>
        <text start="8" dur="5">In propositional logic a model was a value for each propositional symbol.</text>
        <text start="13" dur="5">So we might say that the symbol P was true</text>
        <text start="18" dur="4">and the symbol Q was false,</text>
        <text start="22" dur="8">and that would be a model that corresponds to what&amp;#39;s going on in a possible world.</text>
        <text start="30" dur="2">In first order logic the models are more complex.</text>
        <text start="32" dur="3">We start off with a set of objects.</text>
        <text start="35" dur="4">Here I&amp;#39;ve shown 4 objects, these 4 tiles,</text>
        <text start="39" dur="3">but we could have more objects than that.</text>
        <text start="42" dur="4">We could say, for example, that the numbers 1, 2, and 3</text>
        <text start="46" dur="3">were also objects in our model.</text>
        <text start="49" dur="2">So we have a set of objects.</text>
        <text start="51" dur="7">We can also have a set of constants that refer to those objects.</text>
        <text start="58" dur="10">So I could use the constant names A, B, C, D, 1, 2, 3,</text>
        <text start="68" dur="2">but I don&amp;#39;t have to have a one-to-one correspondence</text>
        <text start="70" dur="3">between constants and objects.</text>
        <text start="73" dur="5">I could have 2 different constant names that refer to the same object.</text>
        <text start="78" dur="6">I could also have, say, the name C that refers to this object,</text>
        <text start="84" dur="4">or I could have some of the objects that don&amp;#39;t have any names at all.</text>
        <text start="88" dur="10">But I&amp;#39;ve got a set of constants, and I also have a set of functions.</text>
        <text start="98" dur="8">A function is defined as a mapping from objects to objects.</text>
        <text start="106" dur="6">And so, for example, I might have the Number Of function</text>
        <text start="112" dur="4">that maps from a tile to the number on that tile,</text>
        <text start="116" dur="8">and that function then would be defined by the mapping from A to 1</text>
        <text start="124" dur="9">and B to 3 and C to 3 and D to 2,</text>
        <text start="133" dur="4">and I could have other functions as well.</text>
        <text start="137" dur="6">In addition to functions, I can have relations.</text>
        <text start="143" dur="5">For example, I could have the Above relation,</text>
        <text start="148" dur="8">and I could say in this model of the world the Above relation is a set of tuples.</text>
        <text start="156" dur="5">Say A is above B and C is above D.</text>
        <text start="161" dur="5">So that was a binary relation holding between 2 objects.</text>
        <text start="166" dur="4">Say 1 block is above another block.</text>
        <text start="170" dur="2">We can have other types of relations.</text>
        <text start="172" dur="5">For example, here is a unary relation--vowel--</text>
        <text start="177" dur="7">and if we want to say the relation Vowel is true only of the object that we call A,</text>
        <text start="184" dur="7">then that&amp;#39;s a set of tuples of length 1 that contains just A.</text>
        <text start="191" dur="5">We can even have relations over no objects.</text>
        <text start="196" dur="4">Say we wanted to have the relation Rainy, which doesn&amp;#39;t refer to any objects at all</text>
        <text start="200" dur="4">but just refers to the current situation.</text>
        <text start="204" dur="6">Then since it&amp;#39;s not rainy today, we would represent that as the empty set.</text>
        <text start="210" dur="4">There&amp;#39;s no tuples corresponding to that relation.</text>
        <text start="214" dur="8">Or, if it was rainy, we could say that it&amp;#39;s represented by a singleton set,</text>
        <text start="222" dur="8">and since the arity of Rainy is 0, there would be 0 elements in each one of those tuples.</text>
        <text start="230" dur="6">So that&amp;#39;s what a model in first order logic looks like.</text>
      </transcript>
    </video>
    <video title="3b Syntax" id="Th_wM93aF94" length="244">
      <transcript>
        <text start="0" dur="5">[Man] Now let&amp;#39;s talk about the syntax of first order logic,</text>
        <text start="5" dur="4">and like in propositional logic,</text>
        <text start="9" dur="5">we have sentences which describe facts that are true or false.</text>
        <text start="14" dur="6">But unlike propositional logic, we also have terms</text>
        <text start="20" dur="2">which describe objects.</text>
        <text start="22" dur="7">Now, the atomic sentences are predicates corresponding to relations,</text>
        <text start="29" dur="8">so we can say vowel (A) is an atomic sentence</text>
        <text start="37" dur="6">or above (A, B).</text>
        <text start="43" dur="6">And we also have a distinguished relation--the equality relation.</text>
        <text start="49" dur="9">We can say 2 = 2 and the equality relation is always in every model,</text>
        <text start="58" dur="9">and sentences can be combined with all the operators from propositional logic</text>
        <text start="67" dur="13">so that&amp;#39;s and, or, not, implies, equivalent, and parentheses.</text>
        <text start="80" dur="6">Now, terms, which refer to objects, can be constants,</text>
        <text start="86" dur="4">like A, B, and 2.</text>
        <text start="90" dur="2">They can be variables.</text>
        <text start="92" dur="4">We normally use lowercase, like x and y.</text>
        <text start="96" dur="5">And they can be functions, like number of A,</text>
        <text start="101" dur="7">which is just another name or another expression that refers to the same object as 1,</text>
        <text start="108" dur="2">at least in the model that we showed previously.</text>
        <text start="110" dur="3">And then, there&amp;#39;s 1 more type of complex sentence</text>
        <text start="113" dur="4">besides the sentences we get by combining operators,</text>
        <text start="117" dur="6">that makes first order logic unique, and these are the quantifiers.</text>
        <text start="123" dur="6">And there are two quantifiers for all, which we write with an upside-down A</text>
        <text start="129" dur="4">followed by a variable that it introduces</text>
        <text start="133" dur="5">and there exists, which we write with an upside-down E</text>
        <text start="138" dur="3">followed by the variable that it introduces.</text>
        <text start="141" dur="7">So for example, we could say for all x, if x is a vowel,</text>
        <text start="148" dur="5">then the number of (x) is equal to 1,</text>
        <text start="153" dur="3">and that&amp;#39;s the valid sentence in first order logic.</text>
        <text start="156" dur="9">Or we could say there exists in x such that the number of (x)</text>
        <text start="165" dur="2">is equal to 2,</text>
        <text start="167" dur="4">and this is saying that there&amp;#39;s some object in the domain</text>
        <text start="171" dur="4">to which the number of function applies and has a value of 2,</text>
        <text start="175" dur="3">but we&amp;#39;re not saying what that object is.</text>
        <text start="178" dur="3">Now, another note is that sometimes as an abbreviation,</text>
        <text start="181" dur="5">we&amp;#39;ll omit the quantifier, and when we do that,</text>
        <text start="186" dur="7">you can just assume that it means for all; that&amp;#39;s left out just as a shortcut.</text>
        <text start="193" dur="3">And I should say that these forms, or these sentences are typical,</text>
        <text start="196" dur="3">and you&amp;#39;ll see these form over and over again,</text>
        <text start="199" dur="5">so typically, whenever we have a &amp;quot;for all&amp;quot; quantifier introduced,</text>
        <text start="204" dur="7">it tends to go with a conditional like vowel of (x) implies number of (x) =1,</text>
        <text start="211" dur="4">and the reason is because we usually don&amp;#39;t want to say something about every object</text>
        <text start="215" dur="4">in the domain, since the objects can be so different,</text>
        <text start="219" dur="4">but rather, we want to say something about a particular type of object,</text>
        <text start="223" dur="2">say, in this case, vowels.</text>
        <text start="225" dur="9">And also, typically, when we have an exists an x, or an exists any variable,</text>
        <text start="234" dur="4">that typically goes with just a form like this,</text>
        <text start="238" dur="4">and not with a conditional, because we&amp;#39;re talking about just 1 object</text>
        <text start="242" dur="2">that we want to describe.</text>
      </transcript>
    </video>
    <video title="3c Vacuum World" id="nkRYz5Omcr0" length="196">
      <transcript>
        <text start="0" dur="3">[man] Now let&amp;#39;s go back to the 2-location vacuum world</text>
        <text start="3" dur="3">and represent it in first order logic.</text>
        <text start="6" dur="3">So first of all, we can have locations.</text>
        <text start="9" dur="6">We can call the left location A and the right location B</text>
        <text start="15" dur="8">and the vacuum V, and the dirt--say, D1 and D2.</text>
        <text start="23" dur="4">Then, we can have relations.</text>
        <text start="27" dur="5">The relation loc, which is true of any location;</text>
        <text start="32" dur="2">vacuum, which is true of the vacuum;</text>
        <text start="34" dur="3">dirt, which is true of dirt;</text>
        <text start="37" dur="7">and at, which is true of an object and a location.</text>
        <text start="44" dur="5">And so if we wanted to say the vacuum is at location A,</text>
        <text start="49" dur="5">we just say at (V, A).</text>
        <text start="54" dur="6">If we want to say there&amp;#39;s no dirt in any location, it&amp;#39;s a little bit more complicated.</text>
        <text start="60" dur="7">We can say for all dirt and for all locations,</text>
        <text start="67" dur="6">if D is a dirt, and L is a location,</text>
        <text start="73" dur="5">then D is not at L.</text>
        <text start="78" dur="3">So that says there&amp;#39;s no dirt in any location.</text>
        <text start="81" dur="5">Now, note if there were thousands of locations instead of just 2,</text>
        <text start="86" dur="6">this sentence would still hold, and that&amp;#39;s really the power of first order logic.</text>
        <text start="92" dur="3">Let&amp;#39;s keep going and try some more examples.</text>
        <text start="95" dur="7">If I want to say the vacuum is in a location with dirt without specifying what location it&amp;#39;s in,</text>
        <text start="102" dur="2">I can do that.</text>
        <text start="104" dur="9">I can say there exists an L and there exists a D</text>
        <text start="113" dur="8">such that D is a dirt and L is a location</text>
        <text start="121" dur="6">and the vacuum is at the location</text>
        <text start="127" dur="4">and the dirt is at that same location.</text>
        <text start="131" dur="3">and that&amp;#39;s the power of first order logic.</text>
        <text start="134" dur="2">Now one final thing.</text>
        <text start="136" dur="3">You might ask what &amp;quot;first order&amp;quot; means.</text>
        <text start="139" dur="5">It means that the relations are on objects, but not on relations,</text>
        <text start="144" dur="2">and that would be called &amp;quot;higher order.&amp;quot;</text>
        <text start="146" dur="7">In higher order logic, we could, say, define the notion of a transitive relation</text>
        <text start="153" dur="5">talking about relations itself, and so we could say</text>
        <text start="158" dur="14">for all R, transitive of R is equivalent to for all A, B, and C;</text>
        <text start="172" dur="14">R of (A, B) and R of (B, C) implies R (A, C).</text>
        <text start="186" dur="4">So that would be a valid statement in higher order logic</text>
        <text start="190" dur="3">that would define the notion of a transitive relation,</text>
        <text start="193" dur="3">but this would be invalid in first order logic.</text>
      </transcript>
    </video>
    <video title="3d Question" id="JcQrAin3_V8" length="74">
      <transcript>
        <text start="0" dur="3">[Man] Now let&amp;#39;s get some practice in first order logic.</text>
        <text start="3" dur="3">I&amp;#39;m going to give you some sentences, and for each one,</text>
        <text start="6" dur="6">I want you to tell me if it is valid--that is, O is true--</text>
        <text start="12" dur="7">satisfiable, but not valid; that is, there&amp;#39;s some models for which it is true;</text>
        <text start="19" dur="6">or unsatisfiable, meaning there are no models for which it is true.</text>
        <text start="25" dur="6">And the first sentence is there exists an x and a y</text>
        <text start="31" dur="4">such that x = y.</text>
        <text start="35" dur="8">Second sentence: there exists an x such that x = x,</text>
        <text start="43" dur="13">implies for all y there exists a z such that y = z.</text>
        <text start="56" dur="10">Third sentence: for all x, p of x or not p of x.</text>
        <text start="66" dur="8">And fourth: there exists an x, P of x.</text>
      </transcript>
    </video>
    <video title="3e Answer" id="vlbyPKhayiE" length="80">
      <transcript>
        <text start="0" dur="4">[Man] The answers are the first sentence is valid.</text>
        <text start="4" dur="2">It&amp;#39;s always true.</text>
        <text start="6" dur="1">Why is that?</text>
        <text start="7" dur="3">Because every model has to have at least 1 object</text>
        <text start="10" dur="4">and we can have both x and y refer to that same object,</text>
        <text start="14" dur="3">and so that object must be equal to itself.</text>
        <text start="17" dur="3">Second, let&amp;#39;s see.</text>
        <text start="20" dur="3">The left-hand side of this implication has to be true.</text>
        <text start="23" dur="2">X is always equal to x,</text>
        <text start="25" dur="6">and the right-hand side says for every y, does there exist a z</text>
        <text start="31" dur="3">such that y equals z?</text>
        <text start="34" dur="1">And we can say yes, there is.</text>
        <text start="35" dur="3">We can always choose y itself for the value of z,</text>
        <text start="38" dur="4">and then y = y, so true implies true.</text>
        <text start="42" dur="3">That&amp;#39;s always true.</text>
        <text start="45" dur="1">Valid.</text>
        <text start="46" dur="4">Third sentence: for all x, P of x or not P of x,</text>
        <text start="50" dur="5">and that&amp;#39;s always true because everything has to be either in the relation for P</text>
        <text start="55" dur="5">or out of the relation for P, so that&amp;#39;s valid.</text>
        <text start="60" dur="5">And the fourth: there exists an x, P of x, and that&amp;#39;s true for the models</text>
        <text start="65" dur="4">in which there is some x that is a member of P,</text>
        <text start="69" dur="2">but it doesn&amp;#39; t necessarily have to be any at all.</text>
        <text start="71" dur="5">P might be an empty relation, so this is satisfiable.</text>
        <text start="76" dur="4">True in some models, but not true in all models.</text>
      </transcript>
    </video>
    <video title="3f Question" id="upyRNIh1LyE" length="179">
      <transcript>
        <text start="0" dur="5">[Man] Now I&amp;#39;m going to give you some sentences or axioms in first order logic,</text>
        <text start="5" dur="6">and I want you to tell me if they correctly or incorrectly represent the English</text>
        <text start="11" dur="2">that I&amp;#39;m asking about.</text>
        <text start="13" dur="6">So tell me yes or no, are these good representations?</text>
        <text start="19" dur="4">And the first, I want to represent the English sentence</text>
        <text start="23" dur="6">&amp;quot;Sam has 2 jobs,&amp;quot; and the first order logic sentence is</text>
        <text start="29" dur="10">there exists an x and y such that job of Sam x</text>
        <text start="39" dur="12">and job of Sam y and not x = y.</text>
        <text start="51" dur="6">And so tell me yes, that correctly represents Sam has 2 jobs,</text>
        <text start="57" dur="2">or no, there&amp;#39;s a problem.</text>
        <text start="59" dur="5">And secondly, I want to represent the idea of set membership.</text>
        <text start="64" dur="6">Now, assume I&amp;#39;ve already defined the notion of adding an element to a set.</text>
        <text start="70" dur="3">Can I define set membership with these 2 axioms?</text>
        <text start="73" dur="13">For all x and s, x is a member of the result of adding x to any set s,</text>
        <text start="86" dur="13">and for all x and s, x is a member of s implies that for all y,</text>
        <text start="99" dur="11">x is a member of the set that you get when you add y to s.</text>
        <text start="110" dur="6">And third, I&amp;#39;m going to try to define the notion of adjacent squares</text>
        <text start="116" dur="6">on, say, a checkerboard, where the squares are numbered with x and y coordinates</text>
        <text start="122" dur="6">and we want to just talk about adjacency in the horizontal and vertical direction.</text>
        <text start="128" dur="3">Can I define that as follows?</text>
        <text start="131" dur="15">For all x and y, the square x, y is adjacent to the square +(x,1), y,</text>
        <text start="146" dur="14">and the square (x, y) is adjacent to the square (x, +(y, 1)</text>
        <text start="160" dur="4">and assume that we&amp;#39;ve defined the notion of + somewhere</text>
        <text start="164" dur="9">and that the character set allows + to occur as the character for a function.</text>
        <text start="173" dur="6">Tell me yes or no, is that a good representation of the notion of adjacency?</text>
      </transcript>
    </video>
    <video title="3g Answer" id="PY9d8qJ4BSY" length="124">
      <transcript>
        <text start="0" dur="6">[Man] The first answer is yes, this is a good representation</text>
        <text start="6" dur="3">of the sentence &amp;quot;Sam has 2 jobs.&amp;quot;</text>
        <text start="9" dur="4">It says there exists an x and y, and one of them is a job of Sam.</text>
        <text start="13" dur="5">The other one is a job of Sam, and crucially, we have to say that x is not equal to y.</text>
        <text start="18" dur="5">Otherwise, this would be satisfied and we could have the same job</text>
        <text start="23" dur="3">represented by the variables x and y.</text>
        <text start="26" dur="4">Is this a good representation of the member function?</text>
        <text start="30" dur="1">No.</text>
        <text start="31" dur="3">It does do a good job of telling you what is a member,</text>
        <text start="34" dur="6">so if x is a member of a set because it&amp;#39;s one member</text>
        <text start="40" dur="4">and then we can always add other members and it&amp;#39;s still a member of that set,</text>
        <text start="44" dur="4">but it doesn&amp;#39;t tell you anything about what x is not a member of.</text>
        <text start="48" dur="5">So for example, we want to know that 3 is not a member of the empty set,</text>
        <text start="53" dur="4">but we can&amp;#39;t prove that with what we have here.</text>
        <text start="57" dur="3">And we have a similar problem down here.</text>
        <text start="60" dur="5">This is not a good representation of adjacent relation.</text>
        <text start="65" dur="11">So it will tell you, for example, that square (1,1) is adjacent to square (2,1)</text>
        <text start="76" dur="4">and also to square (1,2).</text>
        <text start="80" dur="5">So it&amp;#39;s doing something right, but one problem is that it doesn&amp;#39;t tell you in the other direction.</text>
        <text start="85" dur="4">It doesn&amp;#39;t tell you that (2,1) is adjacent to (1,1)</text>
        <text start="89" dur="8">and another problem is that it doesn&amp;#39;t tell you that (1,1) is not adjacent to (8,9)</text>
        <text start="97" dur="3">because again, there&amp;#39;s no way to prove the negative.</text>
        <text start="100" dur="3">And the moral is that when you&amp;#39;re trying to do a definition,</text>
        <text start="103" dur="4">like adjacent or member, what you usually want to do</text>
        <text start="107" dur="5">is have a sentence with the equivalent or the biconditional sign</text>
        <text start="112" dur="9">to say this is true if and only if rather than to just have an assertion</text>
        <text start="121" dur="3">or to have an implication in one direction.</text>
      </transcript>
    </video>
  </group>
  <group title="Unit 8" count="25">
    <video title="1 Introduction" id="dqeEg5V_IPM" length="39">
      <transcript>
        <text start="0" dur="2">[Narrator] Hi, and welcome back.</text>
        <text start="2" dur="2">This unit is about planning.</text>
        <text start="4" dur="2">We defined AI to be the study</text>
        <text start="6" dur="2">and process of finding appropriate</text>
        <text start="8" dur="2">actions for an agent.</text>
        <text start="10" dur="2">So in some sense planning is really</text>
        <text start="12" dur="2">the core of all of AI.</text>
        <text start="14" dur="2">The technique we looked at so far</text>
        <text start="16" dur="2">was problem solving search</text>
        <text start="18" dur="2">over a state space using techniques</text>
        <text start="20" dur="3">like A star.</text>
        <text start="23" dur="2">Given a state space and a problem description,</text>
        <text start="25" dur="2">we can find a solution,</text>
        <text start="27" dur="2">a path to the goal.</text>
        <text start="29" dur="2">Those approaches are great                                                             for a variety of environments,</text>
        <text start="31" dur="2">but they only work when the environment</text>
        <text start="33" dur="3">is deterministic and fully observable.</text>
        <text start="36" dur="3">In this unit, we will see how                                                                       to relax those constraints.</text>
      </transcript>
    </video>
    <video title="2 Problem Solving vs Planning" id="gZza8lZr1Oc" length="146">
      <transcript>
        <text start="0" dur="3">[Narrator] You remember our                                                                    problem-solving work?</text>
        <text start="3" dur="3">We have a state space like this, and</text>
        <text start="6" dur="3">we&amp;#39;re given a start space and</text>
        <text start="9" dur="2">a goal to reach,</text>
        <text start="11" dur="2">and then we&amp;#39;d search for a path</text>
        <text start="13" dur="3">to find that goal, and maybe we find</text>
        <text start="16" dur="3">this path.</text>
        <text start="19" dur="2">Now the way a problem-solving agent</text>
        <text start="21" dur="3">would work is first it does all the work</text>
        <text start="24" dur="2">to figure out the path to the goal</text>
        <text start="26" dur="3">just doing by thinking,</text>
        <text start="29" dur="2">and then it starts to execute that path</text>
        <text start="31" dur="4">to drive or walk, however you want to get there,</text>
        <text start="35" dur="2">from the start state to the end state,</text>
        <text start="37" dur="2">but think about what would happen</text>
        <text start="39" dur="2">if you did that in real life; if you did all</text>
        <text start="41" dur="2">your planning ahead of time,                                                                   you had the complete goal,</text>
        <text start="43" dur="3">and then without interacting with the world,</text>
        <text start="46" dur="2">without sensing it at all,</text>
        <text start="48" dur="2">you started to execute that path.</text>
        <text start="50" dur="3">Well this has, in fact, been studied.</text>
        <text start="53" dur="3">People have gone out and</text>
        <text start="56" dur="3">blindfolded walkers, put them in a field</text>
        <text start="59" dur="2">and told them to walk in a straight line,</text>
        <text start="61" dur="3">and the results are not pretty.</text>
        <text start="64" dur="3">Here are the GPS tracks to prove it.</text>
        <text start="67" dur="2">So we take a hiker, we put him at a</text>
        <text start="69" dur="2">start location, say here,</text>
        <text start="71" dur="2">and we blindfold him so that he can&amp;#39;t</text>
        <text start="73" dur="2">see anything in the horizon,</text>
        <text start="75" dur="3">but just has enough to see his or her feet</text>
        <text start="78" dur="2">so that they won&amp;#39;t stumble over something,</text>
        <text start="80" dur="3">and tell them execute the plan of going forward.</text>
        <text start="83" dur="3">Put one foot in front of each other and walk forward in a straight line,</text>
        <text start="86" dur="2">and these are the typical paths we see.</text>
        <text start="88" dur="2">They start out going straight for awhile</text>
        <text start="90" dur="2">but then go in loop de loops</text>
        <text start="92" dur="3">and end up not at a straight path at all.</text>
        <text start="95" dur="2">These ones over here, starting in this location,</text>
        <text start="97" dur="2">are even more convoluted.</text>
        <text start="99" dur="2">They get going straight for a little bit</text>
        <text start="101" dur="2">and then go in very tight loops.</text>
        <text start="103" dur="2">So people are incapable of                                              walking a straight line</text>
        <text start="105" dur="3">without any feedback from the environment.</text>
        <text start="108" dur="3">Now here on this yellow path,                                                                this one did much better,</text>
        <text start="111" dur="2">and why was that?</text>
        <text start="113" dur="3">Well it&amp;#39;s because these paths                                                                                       were on overcast days,</text>
        <text start="116" dur="3">and so there was no input to make sense of.</text>
        <text start="119" dur="3">Whereas on this path was                                                  on a very sunny day,</text>
        <text start="122" dur="2">and so even though the hiker couldn&amp;#39;t</text>
        <text start="124" dur="3">see farther than a few feet in front of him,</text>
        <text start="127" dur="3">he could see shadows and say,</text>
        <text start="130" dur="2">&amp;quot;As long as I keep the shadows pointing                                                    in the right direction then</text>
        <text start="132" dur="3">I can go in a relatively straight line.&amp;quot;</text>
        <text start="135" dur="3">So the moral is we need some                                                           feedback from the environment.</text>
        <text start="138" dur="3">We can&amp;#39;t just plan ahead and come up                                                    with a whole plan.</text>
        <text start="141" dur="3">We&amp;#39;ve got to interleave planning</text>
        <text start="144" dur="2">and executing.</text>
      </transcript>
    </video>
    <video title="3 Planning vs Execution" id="BmqedPZZA4A" length="199">
      <transcript>
        <text start="0" dur="2">[Narrator] Now why do we have to interleave</text>
        <text start="2" dur="2">planning and execution?</text>
        <text start="4" dur="2">Mostly because of properties of the</text>
        <text start="6" dur="2">environment that make it difficult to deal with.</text>
        <text start="8" dur="2">The most important one is</text>
        <text start="10" dur="2">if the environment is</text>
        <text start="12" dur="2">stochastic.</text>
        <text start="14" dur="2">That is if we don&amp;#39;t know for sure what</text>
        <text start="16" dur="2">an action is going to do.</text>
        <text start="18" dur="2">If we know what everything is going to do,</text>
        <text start="20" dur="2">we can plan it our right from the start,                                  but if we don&amp;#39;t, we have to</text>
        <text start="22" dur="2">be able to deal with contingencies of</text>
        <text start="24" dur="2">say I tried to move forward,</text>
        <text start="26" dur="3">and the wheels slipped, and                                                            I went someplace else,</text>
        <text start="29" dur="2">or the brakes might skid, or</text>
        <text start="31" dur="3">if we&amp;#39;re walking our feet don&amp;#39;t go 100% straight,</text>
        <text start="34" dur="3">or consider the problem of traffic lights.</text>
        <text start="37" dur="2">If the traffic light is red,</text>
        <text start="39" dur="2">then the result of the action of go</text>
        <text start="41" dur="2">forward through the intersection</text>
        <text start="43" dur="3">is bound to be different than                                                       if the traffic light is green.</text>
        <text start="46" dur="2">Another difficulty we have to deal with</text>
        <text start="48" dur="3">is multi-agent environments.</text>
        <text start="51" dur="3">If there are other cars and people                                                                that can get in our way,</text>
        <text start="54" dur="3">we have to plan about what they&amp;#39;re going to do,</text>
        <text start="57" dur="3">and we have to react when                                                                   they do something unexpected,</text>
        <text start="60" dur="2">and we can only know that</text>
        <text start="62" dur="3">at execution time, not at planning time.</text>
        <text start="65" dur="2">The other big problem is with</text>
        <text start="67" dur="4">partial observability.</text>
        <text start="71" dur="3">Suppose we&amp;#39;ve come up with a plan</text>
        <text start="74" dur="5">to go from A to S to F to B.</text>
        <text start="79" dur="2">That plan looks like it will work,</text>
        <text start="81" dur="3">but we know that at S,</text>
        <text start="84" dur="3">the road to F is sometimes closed,</text>
        <text start="87" dur="2">and there will be a sign there</text>
        <text start="89" dur="2">telling us whether it&amp;#39;s closed or not,</text>
        <text start="91" dur="2">but when we start off, we can&amp;#39;t read that sign.</text>
        <text start="93" dur="2">So that&amp;#39;s partial observability.</text>
        <text start="95" dur="2">Another way to look at it is when we start off</text>
        <text start="97" dur="2">we don&amp;#39;t know what state we&amp;#39;re in.</text>
        <text start="99" dur="2">We know we&amp;#39;re in A, but we don&amp;#39;t know</text>
        <text start="101" dur="2">if we&amp;#39;re in A in the state where</text>
        <text start="103" dur="3">the road is closed or if we&amp;#39;re in A</text>
        <text start="106" dur="2">in the state where the road is open,</text>
        <text start="108" dur="2">and it&amp;#39;s not until we get to S</text>
        <text start="110" dur="3">that we discover what state we&amp;#39;re actually in,</text>
        <text start="113" dur="2">and then we know if we can continue along</text>
        <text start="115" dur="3">that route or if we have to take a detour south.</text>
        <text start="118" dur="2">Now in addition to these properties of</text>
        <text start="120" dur="2">the environment, we can also have</text>
        <text start="122" dur="2">difficulty because of</text>
        <text start="124" dur="2">lack of knowledge on our own part.</text>
        <text start="126" dur="6">So if some model of the world is unknown,</text>
        <text start="132" dur="2">that is, for example,</text>
        <text start="134" dur="2">we have map or GPS software</text>
        <text start="136" dur="2">that&amp;#39;s inaccurate or incomplete,</text>
        <text start="138" dur="2">then we won&amp;#39;t be able to</text>
        <text start="140" dur="3">executive a straight-line plan,</text>
        <text start="143" dur="3">and, similarly, often we want to deal with</text>
        <text start="146" dur="3">a case where the plans have to be</text>
        <text start="149" dur="2">hierarchical.</text>
        <text start="151" dur="2">And, certainly, a plan like this</text>
        <text start="153" dur="4">is at a very high level.</text>
        <text start="157" dur="2">We can&amp;#39;t really execute the action</text>
        <text start="159" dur="2">of going from A to S</text>
        <text start="161" dur="2">when we&amp;#39;re in a car.</text>
        <text start="163" dur="2">All the actions that we can actually execute</text>
        <text start="165" dur="2">are things like turn the steering wheel a little bit</text>
        <text start="167" dur="3">to the right, press on the pedal a little bit more.</text>
        <text start="170" dur="4">So those are the low-level steps of the plan,</text>
        <text start="174" dur="3">but those aren&amp;#39;t sketched out                                          in detail when we start,</text>
        <text start="177" dur="3">when we only have the                                                     high-level parts of the plan,</text>
        <text start="180" dur="3">and then it&amp;#39;s during execution that we schedule</text>
        <text start="183" dur="2">the rest of the low-level parts of the plan.</text>
        <text start="185" dur="3">Now most of these difficulties can be</text>
        <text start="188" dur="2">addressed by changing our point of view.</text>
        <text start="190" dur="3">Instead of planning in                                                                                 the space of world states,</text>
        <text start="193" dur="3">we plan in the space of belief states.</text>
        <text start="196" dur="3">To understand that let&amp;#39;s look at a state.</text>
      </transcript>
    </video>
    <video title="4 Vacuum Cleaner Example" id="lb1bEUa9WXg" length="131">
      <transcript>
        <text start="0" dur="2">[Narrator] Here&amp;#39;s a state space</text>
        <text start="2" dur="2">diagram for a simple problem.</text>
        <text start="4" dur="3">It involves a room with 2 locations.</text>
        <text start="7" dur="4">The left we call A, and the right we call B,</text>
        <text start="11" dur="2">and in that environment</text>
        <text start="13" dur="2">there&amp;#39;s a vacuum cleaner, and there</text>
        <text start="15" dur="3">may or may not be dirt in either                                                               of the 2 locations,</text>
        <text start="18" dur="4">and so that gives us 8 total states.</text>
        <text start="22" dur="3">Dirt is here or not, here or not, and</text>
        <text start="25" dur="2">the vacuum cleaner is here or here.</text>
        <text start="27" dur="2">So that&amp;#39;s 2 times 2 times 2</text>
        <text start="29" dur="2">is 8 possible states, and I&amp;#39;ve drawn</text>
        <text start="31" dur="2">here the states based diagram</text>
        <text start="33" dur="2">with all the transitions</text>
        <text start="35" dur="3">for the 3 possible actions, and                                           the actions are moving right.</text>
        <text start="38" dur="2">So we&amp;#39;d go from this state to this state.</text>
        <text start="40" dur="3">Moving left, we&amp;#39;d go from this state to this state,</text>
        <text start="43" dur="2">and sucking up dirt, we&amp;#39;d go from this state</text>
        <text start="45" dur="3">to this state for example, and</text>
        <text start="48" dur="3">in this state space diagram,</text>
        <text start="51" dur="2">if we have a fully deterministic,</text>
        <text start="53" dur="3">fully observable world, it&amp;#39;s easy to plan.</text>
        <text start="56" dur="3">Say we start in this state, and we want to be--</text>
        <text start="59" dur="3">end up in a goal state where                                                                          both sides are clean.</text>
        <text start="62" dur="2">We can execute the suck-dirt action</text>
        <text start="64" dur="2">and get here and then move right,</text>
        <text start="66" dur="2">and then suck dirt again,</text>
        <text start="68" dur="3">and now we end up in a goal state</text>
        <text start="71" dur="3">where everything is clean.</text>
        <text start="74" dur="2">Now suppose our robot vacuum cleaner&amp;#39;s</text>
        <text start="76" dur="2">sensors break down, and so the robot</text>
        <text start="78" dur="2">can no longer perceive either</text>
        <text start="80" dur="2">which location its in</text>
        <text start="82" dur="2">or whether there&amp;#39;s any dirt.</text>
        <text start="84" dur="2">So we now have an unobservable</text>
        <text start="86" dur="2">or sensor-less world rather</text>
        <text start="88" dur="2">than a fully observable one,</text>
        <text start="90" dur="3">and how does the agent then represent the state of the world?</text>
        <text start="93" dur="3">Well it could be in any one of these 8 states,</text>
        <text start="96" dur="3">and so all we can do to represent</text>
        <text start="99" dur="3">the current state is draw a big circle</text>
        <text start="102" dur="2">or box around everything, and say,</text>
        <text start="104" dur="4">&amp;quot;I know I&amp;#39;m somewhere inside here.&amp;quot;</text>
        <text start="108" dur="2">Now that doesn&amp;#39;t seem like it helps very much.</text>
        <text start="110" dur="2">What good is it to know that</text>
        <text start="112" dur="2">we don&amp;#39;t really know anything at all?</text>
        <text start="114" dur="3">But the point is that we can search in the state</text>
        <text start="117" dur="2">space of the least states rather</text>
        <text start="119" dur="3">than in the state space of actual spaces.</text>
        <text start="122" dur="3">So we believe that we&amp;#39;re in 1 of these 8 states,</text>
        <text start="125" dur="2">and now when we execute an action,</text>
        <text start="127" dur="2">we&amp;#39;re going to get to another belief state.</text>
        <text start="129" dur="2">Let&amp;#39;s take a look at how that works.</text>
      </transcript>
    </video>
    <video title="5 Sensorless Vacumm Cleaner Problem-" id="hyjwEymVfL4" length="142">
      <transcript>
        <text start="0" dur="3">[Narrator] This is the belief state space</text>
        <text start="3" dur="2">for the sensor-less vacuum problem.</text>
        <text start="5" dur="2">So we started off here.</text>
        <text start="7" dur="3">We drew the circle around this belief state.</text>
        <text start="10" dur="3">So we don&amp;#39;t anything about where we are,</text>
        <text start="13" dur="2">but the amazing thing is,</text>
        <text start="15" dur="2">if we execute actions, we can gain knowledge</text>
        <text start="17" dur="3">about the world even without sensing.</text>
        <text start="20" dur="2">So let&amp;#39;s say we move right,</text>
        <text start="22" dur="4">then we&amp;#39;ll know we&amp;#39;re in the right-hand location.</text>
        <text start="26" dur="2">Either we were in the left, and we moved right</text>
        <text start="28" dur="2">and arrived there, or we were in the right</text>
        <text start="30" dur="2">to begin with, and we bumped against the wall</text>
        <text start="32" dur="2">and stayed there.</text>
        <text start="34" dur="3">So now we end up in this state.</text>
        <text start="37" dur="3">We now know more about the world.</text>
        <text start="40" dur="3">We&amp;#39;re down to 4 possibilities rather than 8,</text>
        <text start="43" dur="3">even though we haven&amp;#39;t observed anything,</text>
        <text start="46" dur="2">and now note something interesting,</text>
        <text start="48" dur="2">that in the real world, the operations</text>
        <text start="50" dur="2">of going left and going right are</text>
        <text start="52" dur="2">inverses of each other, but</text>
        <text start="54" dur="2">in the belief state world</text>
        <text start="56" dur="3">going right and going left are not inverses.</text>
        <text start="59" dur="2">If we go right, and then we go left,</text>
        <text start="61" dur="2">we don&amp;#39;t end up back where we were</text>
        <text start="63" dur="2">in a state of total uncertainty, rather</text>
        <text start="65" dur="3">going left takes us over here</text>
        <text start="68" dur="2">where we still know we&amp;#39;re in 1 of 4 states</text>
        <text start="70" dur="3">rather than in 1 of 8 states.</text>
        <text start="73" dur="2">Note that it&amp;#39;s possible to form a plan that</text>
        <text start="75" dur="3">reaches a goal without ever                                                                observing the world.</text>
        <text start="78" dur="3">Plans like that are called conform-it plans.</text>
        <text start="81" dur="2">For example, if the goal is to be</text>
        <text start="83" dur="2">in a clean location</text>
        <text start="85" dur="3">all we have to do is suck.</text>
        <text start="88" dur="2">So we go from one of these 8 states</text>
        <text start="90" dur="2">to one of these 4 states and,</text>
        <text start="92" dur="2">every one of those 4,</text>
        <text start="94" dur="2">we&amp;#39;re in a clean location.</text>
        <text start="96" dur="2">We don&amp;#39;t know which of the 4 we&amp;#39;re in,</text>
        <text start="98" dur="3">but we know we&amp;#39;ve achieved the goal.</text>
        <text start="101" dur="2">It&amp;#39;s also possible to arrive</text>
        <text start="103" dur="2">at a completely known state.</text>
        <text start="105" dur="2">For example, if we start here,</text>
        <text start="107" dur="3">we go left; we suck up the dirt there.</text>
        <text start="110" dur="3">If we go right and suck up the dirt,</text>
        <text start="113" dur="2">now we&amp;#39;re down to a belief state</text>
        <text start="115" dur="2">consisting of 1 single state that is</text>
        <text start="117" dur="3">we know exactly where we are.</text>
        <text start="120" dur="2">Here&amp;#39;s a question for you:</text>
        <text start="122" dur="2">How do I get from the state where I know</text>
        <text start="124" dur="2">my current square is clean,</text>
        <text start="126" dur="2">but know nothing else, to the belief state</text>
        <text start="128" dur="2">where I know that I&amp;#39;m in the right-hand side</text>
        <text start="130" dur="4">location and that that location is clean?</text>
        <text start="134" dur="2">What I want you to do is click on the</text>
        <text start="136" dur="2">sequence of actions, left, right, or suck</text>
        <text start="138" dur="4">that will take us from that start to that goal.</text>
      </transcript>
    </video>
    <video title="6 Sensorless Vacuum Cleaner Answer" id="Bxd-j9s82Z8" length="23">
      <transcript>
        <text start="0" dur="3">[Narrator] And the answer is that the state</text>
        <text start="3" dur="3">of knowing that you&amp;#39;re current square is clean</text>
        <text start="6" dur="2">corresponds to this state.</text>
        <text start="8" dur="2">This belief state with 4 possible world states,</text>
        <text start="10" dur="3">and if I then execute the right action,</text>
        <text start="13" dur="2">followed by the suck action,</text>
        <text start="15" dur="2">then I end up in this belief state,</text>
        <text start="17" dur="2">and that satisfies the goal.</text>
        <text start="19" dur="2">I know I&amp;#39;m in the right-hand-side location</text>
        <text start="21" dur="2">and I know that location is clean.</text>
      </transcript>
    </video>
    <video title="7 Partially Observable Vacuum Cleaner Example" id="-6GtASYhMvo" length="151">
      <transcript>
        <text start="0" dur="5">[Narrator] We&amp;#39;ve been considering sensor-less planning in a deterministic world.</text>
        <text start="5" dur="3">Now I want to turn our attention to                                    partially observable planning</text>
        <text start="8" dur="2">but still in a deterministic world.</text>
        <text start="10" dur="3">Suppose we have what&amp;#39;s called local sensing,</text>
        <text start="13" dur="2">that is our vacuum can see what location</text>
        <text start="15" dur="2">it is in and it can see</text>
        <text start="17" dur="4">what&amp;#39;s going on in the current location, that is</text>
        <text start="21" dur="2">whether there&amp;#39;s dirt in the                                                                   current location or not,</text>
        <text start="23" dur="2">but it can&amp;#39;t see anything about</text>
        <text start="25" dur="4">whether there&amp;#39;s dirt in any other location.</text>
        <text start="29" dur="2">So here&amp;#39;s a partial diagram of the--</text>
        <text start="31" dur="4">part of the belief state from that world,</text>
        <text start="35" dur="2">and I want it to show</text>
        <text start="37" dur="2">how the belief state unfolds</text>
        <text start="39" dur="2">as 2 things happen.</text>
        <text start="41" dur="2">First, as we take action,</text>
        <text start="43" dur="3">so we start in this state,</text>
        <text start="46" dur="3">and we take the action of going right,</text>
        <text start="49" dur="4">and in this case we still go</text>
        <text start="53" dur="3">from 2 world states in our belief state</text>
        <text start="56" dur="2">to 2 new ones,</text>
        <text start="58" dur="2">but then, after we do an action,</text>
        <text start="60" dur="3">we do an observation, and we have the act</text>
        <text start="63" dur="2">precept cycle, and now,</text>
        <text start="65" dur="2">once we get the observation,</text>
        <text start="67" dur="2">we can split that world,</text>
        <text start="69" dur="2">we can split our belief state to say,</text>
        <text start="71" dur="2">&amp;quot;If we observe that we&amp;#39;re in</text>
        <text start="73" dur="2">location B and it&amp;#39;s dirty, then we know</text>
        <text start="75" dur="3">we&amp;#39;re in this belief state here,</text>
        <text start="78" dur="3">which happens to have                                                                    exactly 1 world state in it,</text>
        <text start="81" dur="2">and if we observe that we&amp;#39;re clean</text>
        <text start="83" dur="2">then we know that we&amp;#39;re in this state,</text>
        <text start="85" dur="2">which also has exactly 1 in it.</text>
        <text start="87" dur="2">Now what is the act-observe cycle do</text>
        <text start="89" dur="3">to the sizes of the belief states?</text>
        <text start="92" dur="2">Well in a deterministic world,</text>
        <text start="94" dur="2">each of the individual world states within</text>
        <text start="96" dur="4">a belief state maps into exactly 1 other one.</text>
        <text start="100" dur="2">That&amp;#39;s what we mean by deterministic,</text>
        <text start="102" dur="3">and so that means the size of the belief state</text>
        <text start="105" dur="3">will either stay the same or it might decrease</text>
        <text start="108" dur="2">if 2 of the actions sort of accidentally</text>
        <text start="110" dur="3">end up bringing you to the same place.</text>
        <text start="113" dur="2">On the other hand, the observation</text>
        <text start="115" dur="3">works in kind of the opposite way.</text>
        <text start="118" dur="2">When we observe the world, what we&amp;#39;re doing</text>
        <text start="120" dur="2">is we&amp;#39;re taking the current belief state and</text>
        <text start="122" dur="3">partitioning it up into pieces.</text>
        <text start="125" dur="2">Observations alone can&amp;#39;t introduce</text>
        <text start="127" dur="3">a new state--a new world state                                             into the belief state.</text>
        <text start="130" dur="3">All they can do is say,</text>
        <text start="133" dur="3">&amp;quot;Some of them go here and                                                                  some of them go here.&amp;quot;</text>
        <text start="136" dur="2">Now maybe that for some observation</text>
        <text start="138" dur="3">all the belief states go into 1 bin,</text>
        <text start="141" dur="2">and so we make an observation</text>
        <text start="143" dur="2">that we don&amp;#39;t learn anything new, but at least</text>
        <text start="145" dur="3">the observation can&amp;#39;t make us more confused</text>
        <text start="148" dur="3">than we were before the observation.</text>
      </transcript>
    </video>
    <video title="8 Stocastic Environment Problem" id="Rgn1RW0fcec" length="174">
      <transcript>
        <text start="0" dur="3">[Norvig] Now let&amp;#39;s move on to stochastic environments.</text>
        <text start="3" dur="3">Let&amp;#39;s consider a robot that has slippery wheels</text>
        <text start="6" dur="4">so that sometimes when you make a movement--a left or a right action--</text>
        <text start="10" dur="3">the wheels slip and you stay in the same location.</text>
        <text start="13" dur="4">And sometimes they work and you arrive where you expected to go.</text>
        <text start="17" dur="4">And let&amp;#39;s assume that the suck action always works perfectly.</text>
        <text start="21" dur="4">We get a belief state space that looks something like this.</text>
        <text start="25" dur="5">Notice that the results of actions will often result in a belief state</text>
        <text start="30" dur="4">that&amp;#39;s larger than it was before--that is, the action will increase uncertainty</text>
        <text start="34" dur="3">because we don&amp;#39;t know what the result of the action is going to be.</text>
        <text start="37" dur="5">And so here for each of the individual world states belonging to a belief state,</text>
        <text start="42" dur="5">we have multiple outcomes for the action, and that&amp;#39;s what stochastic means.</text>
        <text start="47" dur="3">And so we end up with a larger belief state here.</text>
        <text start="50" dur="5">But in terms of the observation, the same thing holds as in the deterministic world.</text>
        <text start="55" dur="6">The observation partitions the belief state into smaller belief states.</text>
        <text start="61" dur="3">So in a stochastic partially observable environment,</text>
        <text start="64" dur="3">the actions tend to increase uncertainty,</text>
        <text start="67" dur="4">and the observations tend to bring that uncertainty back down.</text>
        <text start="71" dur="3">Now, how would we do planning in this type of environment?</text>
        <text start="74" dur="3">I haven&amp;#39;t told you yet, so you won&amp;#39;t know the answer for sure,</text>
        <text start="77" dur="4">but I want you to try to figure it out anyways, even if you might get the answer wrong.</text>
        <text start="81" dur="6">Imagine I had the whole belief state from which I&amp;#39;ve diagrammed just a little bit here</text>
        <text start="87" dur="4">and I wanted to know how to get from this belief state</text>
        <text start="91" dur="3">to one in which all squares are clean.</text>
        <text start="94" dur="2">So I&amp;#39;m going to give you some possible plans,</text>
        <text start="96" dur="6">and I want you to tell me whether you think each of these plans will always work</text>
        <text start="102" dur="5">or maybe sometimes work depending on how the stochasticity works out.</text>
        <text start="107" dur="2">Here are the possible plans.</text>
        <text start="109" dur="5">Remember I&amp;#39;m starting here, and I want to know how to get to a belief state</text>
        <text start="114" dur="3">in which all the squares are clean.</text>
        <text start="117" dur="9">One possibility is suck right and suck, one is right suck left suck,</text>
        <text start="126" dur="5">one is suck right right suck,</text>
        <text start="131" dur="7">and the other is suck right suck right suck.</text>
        <text start="138" dur="4">So some of these actions might take you out of this little belief state here,</text>
        <text start="142" dur="5">but just use what you knew from the previous definition of the state space</text>
        <text start="147" dur="2">and the results of each of those actions</text>
        <text start="149" dur="5">and the fact that the right and left actions are nondeterministic</text>
        <text start="154" dur="5">and tell me which of these you think will always achieve the goal</text>
        <text start="159" dur="3">or will maybe achieve the goal.</text>
        <text start="162" dur="6">And then I want you to also answer for the fill-in-the-blank plan--</text>
        <text start="168" dur="6">that is, is there some plan, some ideal plan, which always or maybe achieves the goal?</text>
      </transcript>
    </video>
    <video title="9 Stochastic Environment Answer" id="uBBfv13Ky4I" length="50">
      <transcript>
        <text start="0" dur="3">And the answer is that any plan that would work</text>
        <text start="3" dur="4">in the deterministic world might work in the stochastic world</text>
        <text start="7" dur="3">if everything works out okay</text>
        <text start="10" dur="3">and all of these plans meet that criteria.</text>
        <text start="13" dur="5">But no finite plan is guaranteed to always work</text>
        <text start="18" dur="5">because a successful plan has to include at least 1 move action.</text>
        <text start="23" dur="4">And if we try a  move action a finite number of times,</text>
        <text start="27" dur="3">each of those times, the wheels might slip, and it won&amp;#39;t move,</text>
        <text start="30" dur="3">and so we can never be guaranteed to achieve the goal</text>
        <text start="33" dur="3">with a finite sequence of actions.</text>
        <text start="36" dur="3">Now, what about an infinite sequence of actions?</text>
        <text start="39" dur="3">Well, we can&amp;#39;t represent that in the language we have so far</text>
        <text start="42" dur="3">where a plan is a linear sequence.</text>
        <text start="45" dur="2">But we can introduce a new notion of plans</text>
        <text start="47" dur="3">in which we do have infinite sequences.</text>
      </transcript>
    </video>
    <video title="10 Infinite Sequences" id="h3_8OLOhtG4" length="125">
      <transcript>
        <text start="0" dur="3">In this new notation, instead of writing plans</text>
        <text start="3" dur="6">as a linear sequence of, say, suck, move right, and suck,</text>
        <text start="9" dur="3">I&amp;#39;m going to write them as a tree structure.</text>
        <text start="12" dur="3">We start off in this belief state here,</text>
        <text start="15" dur="3">which we&amp;#39;ll diagram like this.</text>
        <text start="18" dur="4">And then we do a suck action.</text>
        <text start="22" dur="5">We end up in a new state.</text>
        <text start="27" dur="6">And then we do a right action,</text>
        <text start="33" dur="3">and now we have to observe the world,</text>
        <text start="36" dur="5">and if we observe that we&amp;#39;re still in state A,</text>
        <text start="41" dur="5">we loop back to this part of the plan.</text>
        <text start="46" dur="3">And if we observe that we&amp;#39;re in B,</text>
        <text start="49" dur="7">we go on and then execute the suck action.</text>
        <text start="56" dur="3">And now we&amp;#39;re at the end of the plan.</text>
        <text start="59" dur="4">So, we see that there&amp;#39;s a choice point here,</text>
        <text start="63" dur="3">which we indicate with this sort of tie</text>
        <text start="66" dur="3">to say we&amp;#39;re following a straight line, but now we can branch.</text>
        <text start="69" dur="3">There&amp;#39;s a conditional, and we can either loop,</text>
        <text start="72" dur="2">or we can continue on,</text>
        <text start="74" dur="3">so we see that this finite representation</text>
        <text start="77" dur="4">represents an infinite sequence of plans.</text>
        <text start="81" dur="5">We could write it in a more sort of linear notation</text>
        <text start="86" dur="6">as S, while we observe A,</text>
        <text start="92" dur="4">do R, and then do S.</text>
        <text start="96" dur="2">Now, what can we say about this plan?</text>
        <text start="98" dur="2">Does this plan achieve the goal?</text>
        <text start="100" dur="4">Well, what we can say is that if the stochasticity</text>
        <text start="104" dur="3">is independent, that is, if sometimes it works</text>
        <text start="107" dur="2">and sometimes it doesn&amp;#39;t,</text>
        <text start="109" dur="4">then with probability 1 in the limit,</text>
        <text start="113" dur="2">this plan will, in fact, achieve the goal,</text>
        <text start="115" dur="5">but we can&amp;#39;t state any bounded number of steps</text>
        <text start="120" dur="3">under which it&amp;#39;s guaranteed to achieve the goal.</text>
        <text start="123" dur="2">We can only say it&amp;#39;s guaranteed at infinity.</text>
      </transcript>
    </video>
    <video title="11 Finding a Successful Plan-" id="ffGFIoOhN3U" length="99">
      <transcript>
        <text start="0" dur="3">Now, I&amp;#39;ve told you what a successful plan looks like,</text>
        <text start="3" dur="3">but I haven&amp;#39;t told you how to find one.</text>
        <text start="6" dur="2">The process of finding it can be done through search</text>
        <text start="8" dur="2">just as we did in problem solving.</text>
        <text start="10" dur="2">So, remember in problem solving,</text>
        <text start="12" dur="3">we start off in a state, and it&amp;#39;s a single state, not a belief state.</text>
        <text start="15" dur="4">And then we start searching a tree,</text>
        <text start="19" dur="4">and we have a big triangle of possible states</text>
        <text start="23" dur="4">that we search through, and then we find</text>
        <text start="27" dur="4">one path that gets us all the way to a goal state.</text>
        <text start="31" dur="5">And we pick from this big tree a single path.</text>
        <text start="36" dur="4">So, with belief states and with branching</text>
        <text start="40" dur="3">plan structures, we do the same sort of process,</text>
        <text start="43" dur="3">only the tree is just a little bit more complicated.</text>
        <text start="46" dur="2">Here we show one of these trees,</text>
        <text start="48" dur="4">and it has different possibilities.</text>
        <text start="52" dur="3">For example, we start off here, and we have one possibility</text>
        <text start="55" dur="2">that the first action will be going right,</text>
        <text start="57" dur="2">or another possibility that the first action</text>
        <text start="59" dur="3">will be performing a suck.</text>
        <text start="62" dur="4">But then it also has branches that are part of the plan itself.</text>
        <text start="66" dur="3">This branch here is actually part of the plan</text>
        <text start="69" dur="2">as we saw before.</text>
        <text start="71" dur="3">It&amp;#39;s not a branch in the search space.</text>
        <text start="74" dur="3">It&amp;#39;s a branch in the plan, so what we do</text>
        <text start="77" dur="2">is we search through this tree.</text>
        <text start="79" dur="2">We try right as a first action.</text>
        <text start="81" dur="2">We try suck as a first action.</text>
        <text start="83" dur="2">We keep expanding nodes</text>
        <text start="85" dur="3">until we find a portion of the tree</text>
        <text start="88" dur="3">like this path is a portion of this search tree.</text>
        <text start="91" dur="4">We find that portion which is a successful plan</text>
        <text start="95" dur="4">according to the criteria of reaching the goal.</text>
      </transcript>
    </video>
    <video title="12 Finding a Successful Plan Question" id="vjOY2OEu_ng" length="130">
      <transcript>
        <text start="0" dur="3">Let&amp;#39;s say we performed that search.</text>
        <text start="3" dur="3">We had a big search tree, and then we threw out</text>
        <text start="6" dur="3">all the branches except one, and this branch of the search tree</text>
        <text start="9" dur="4">does itself have branches, but this branch of the search tree</text>
        <text start="13" dur="4">through the belief state represents a single plan,</text>
        <text start="17" dur="2">not multiple possible plans.</text>
        <text start="19" dur="3">Now, what I want to know is, for this single plan,</text>
        <text start="22" dur="2">what can we guarantee about it?</text>
        <text start="24" dur="5">So, say we wanted to know is this plan guaranteed to find the goal</text>
        <text start="29" dur="3">in an unbounded number of steps?</text>
        <text start="32" dur="3">And what do we need to guarantee that?</text>
        <text start="35" dur="3">So, it&amp;#39;s an unbounded solution.</text>
        <text start="38" dur="5">Do we need to guarantee that</text>
        <text start="43" dur="4">some leaf node is a goal?</text>
        <text start="47" dur="2">So, for example, here&amp;#39;s a plan to go through,</text>
        <text start="49" dur="4">and at the bottom, there&amp;#39;s a leaf node.</text>
        <text start="53" dur="4">Now, if this were in problem solving,</text>
        <text start="57" dur="4">then remember, it would be a sequence of steps</text>
        <text start="61" dur="3">with no branches in it, and we know it&amp;#39;s a solution</text>
        <text start="64" dur="3">if the one leaf node is a goal.</text>
        <text start="67" dur="3">But for these with branches, do we need to guarantee</text>
        <text start="70" dur="3">that some leaf is a goal,</text>
        <text start="73" dur="4">or do we need to guarantee</text>
        <text start="77" dur="5">that every leaf is a goal,</text>
        <text start="82" dur="5">or is there no possible guarantee</text>
        <text start="87" dur="4">that will mean that for sure we&amp;#39;ve got a solution,</text>
        <text start="91" dur="2">although the solution may be of unbounded length?</text>
        <text start="93" dur="3">Then I also want you to answer</text>
        <text start="96" dur="2">what does it take to guarantee</text>
        <text start="98" dur="3">that we have a bounded solution?</text>
        <text start="101" dur="4">That is, a solution that is guaranteed to reach the goal</text>
        <text start="105" dur="4">in a bounded, finite number of steps.</text>
        <text start="109" dur="4">Do we need to have a plan that has</text>
        <text start="113" dur="4">no branches in it, like this branch?</text>
        <text start="117" dur="5">Or a plan that has no loops in it,</text>
        <text start="122" dur="3">like this loop that goes back to a previous state?</text>
        <text start="125" dur="5">Or is there no guarantee that we have a bounded solution?</text>
      </transcript>
    </video>
    <video title="13 Finding a Successful Plan Answer" id="Q4g4E824PRE" length="58">
      <transcript>
        <text start="0" dur="3">And the answer is we have an unbounded solution</text>
        <text start="3" dur="4">if every leaf in the plan ends up in a goal.</text>
        <text start="7" dur="2">So, if we follow through the plan, no matter what path</text>
        <text start="9" dur="3">we execute based on the observations--</text>
        <text start="12" dur="4">and remember, we don&amp;#39;t get to pick the observations.</text>
        <text start="16" dur="2">The observations come into us, and we follow one path or another</text>
        <text start="18" dur="2">based on what we observe.</text>
        <text start="20" dur="3">So, we can&amp;#39;t guide it in one direction or another,</text>
        <text start="23" dur="3">and so we need every possible leaf node.</text>
        <text start="26" dur="4">This one only has one, but if a plan had multiple leaf nodes,</text>
        <text start="30" dur="3">every one of them would have to be a goal.</text>
        <text start="33" dur="2">Now, in terms of a bounded solution,</text>
        <text start="35" dur="4">it&amp;#39;s okay to have branches but not to have loops.</text>
        <text start="39" dur="3">If we had branches and we ended up with one goal here</text>
        <text start="42" dur="3">and one goal here in 1, 2, 3, steps,</text>
        <text start="45" dur="3">1, 2, 3, steps, that would be a bounded solution.</text>
        <text start="48" dur="6">But if we have a loop, we might be 1, 2, 3, 4, 5--</text>
        <text start="54" dur="4">we don&amp;#39;t know how many steps it&amp;#39;s going to take.</text>
      </transcript>
    </video>
    <video title="14 Problem Solving via Mathematical Notation" id="SzeJX57N-_I" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="15 Tracking the Predict Update Cycle" id="cfYnEgrVemA" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="16 Classical Planning 1" id="-o9E15BAL3o" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="17 Classical Planning 2" id="HAtsUpBlnf8" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="18 Progression Search" id="V6eHKcZkDtg" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="19 Regression Search" id="Wu3kegFFjgI" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="20 Regression vs Progression" id="qUx66S-B528" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="21 Plan Space Search" id="shcybJnXQz0" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="22 Sliding Puzzle Example" id="mZddP9ytnS4" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="23 Situation Calculus 1" id="Or8cA5xHFbM" length="227">
      <transcript>
        <text start="0" dur="3">[Norvig] Now I want to talk about 1 more representation for planning</text>
        <text start="3" dur="4">called situation calculus.</text>
        <text start="7" dur="5">To motivate this, suppose we wanted to have the goal of moving all the cargo</text>
        <text start="12" dur="5">from airport A to airport B, regardless of how many pieces of cargo there are.</text>
        <text start="17" dur="5">You can&amp;#39;t express the notion of All in propositional languages like classical planning,</text>
        <text start="22" dur="3">but you can in first order logic.</text>
        <text start="25" dur="2">There are several ways to use first order logic for planning.</text>
        <text start="27" dur="3">The best known is situation calculus.</text>
        <text start="30" dur="2">It&amp;#39;s not a new kind of logic;</text>
        <text start="32" dur="4">rather, it&amp;#39;s regular first order logic with a set of conventions</text>
        <text start="36" dur="2">for how to represent states and actions.</text>
        <text start="38" dur="3">I&amp;#39;ll show you what the conventions are.</text>
        <text start="41" dur="8">First, actions are represented as objects in first order logic,</text>
        <text start="49" dur="2">normally by functions.</text>
        <text start="51" dur="5">And so we would have a function like the function Fly</text>
        <text start="56" dur="6">of a plane and a From Airport and a To Airport</text>
        <text start="62" dur="6">which represents an object, which is the action.</text>
        <text start="68" dur="8">Then we have situations, and situations are also objects in the logic,</text>
        <text start="76" dur="6">and they correspond not to states but rather to paths--</text>
        <text start="82" dur="5">the paths of actions that we have in state space search.</text>
        <text start="87" dur="6">So if you arrive at what would be the same world state by 2 different sets of actions,</text>
        <text start="93" dur="4">those would be considered 2 different situations in situation calculus.</text>
        <text start="97" dur="6">We describe the situations by objects, so we usually have an initial situation,</text>
        <text start="103" dur="3">often called S0,</text>
        <text start="106" dur="6">and then we have a function on situations called Result.</text>
        <text start="112" dur="10">So the result of a situation object and an action object is equal to another situation.</text>
        <text start="122" dur="5">And now instead of describing the actions that are applicable</text>
        <text start="127" dur="7">in a situation with a predicate Actions of S,</text>
        <text start="134" dur="3">situation calculus for some reason decided not to do that</text>
        <text start="137" dur="6">and instead we&amp;#39;re going to talk about the actions that are possible in the state,</text>
        <text start="143" dur="3">and we&amp;#39;re going to do that with a predicate.</text>
        <text start="148" dur="9">If we have a predicate Possible of A and S, is an action A possible in a state?</text>
        <text start="157" dur="6">There&amp;#39;s a specific form for describing these predicates,</text>
        <text start="163" dur="9">and in general, it has the form of some precondition of state S</text>
        <text start="172" dur="7">implies that it&amp;#39;s possible to do action A in state S.</text>
        <text start="179" dur="5">I&amp;#39;ll show you the possibility axiom for the Fly action.</text>
        <text start="184" dur="6">We would say if there is some P, which is the plane in state S,</text>
        <text start="190" dur="6">and there is some X, which is an airport in state S,</text>
        <text start="196" dur="5">and there is some Y, which is also an airport in state S,</text>
        <text start="201" dur="7">and P is at location X in state S,</text>
        <text start="208" dur="13">then that implies that it&amp;#39;s possible to fly P from X to Y in state S.</text>
        <text start="221" dur="6">And that&amp;#39;s known as the possibility axiom for the action Fly.</text>
      </transcript>
    </video>
    <video title="24 Situation Calculus 2" id="GM1sxQQ81lg" length="236">
      <transcript>
        <text start="1" dur="6">[Norvig] There&amp;#39;s a convention in situation calculus that predicates like At--</text>
        <text start="7" dur="7">we said plane P was at airport X in situation S--</text>
        <text start="14" dur="5">these types of predicates that can vary from 1 situation to another are called fluents,</text>
        <text start="19" dur="6">from the word fluent, having to do with fluidity or change over time.</text>
        <text start="25" dur="4">And the convention is that they refer to a specific situation,</text>
        <text start="29" dur="6">and we always put that situation argument as the last in the predicate.</text>
        <text start="35" dur="6">Now, the trickiest part about situation calculus is describing what changes</text>
        <text start="41" dur="3">and what doesn&amp;#39;t change as a result of an action.</text>
        <text start="44" dur="4">Remember in classical planning we had action schemas</text>
        <text start="48" dur="5">where we described 1 action at a time and said what changed.</text>
        <text start="53" dur="4">For situation calculus it turns out to be easier to do it the other way around.</text>
        <text start="57" dur="6">Instead of writing 1 action or 1 schema or 1 axiom for each action,</text>
        <text start="63" dur="4">we do 1 for each fluent, for each predicate that can change.</text>
        <text start="67" dur="5">We use the convention called successor state axioms.</text>
        <text start="72" dur="3">These are used to describe what happens in the state</text>
        <text start="75" dur="4">that&amp;#39;s a successor of executing an action.</text>
        <text start="79" dur="7">And in general, a successor state axiom will have the form of saying</text>
        <text start="86" dur="9">for all actions and states, if it&amp;#39;s possible to execute action A in state S,</text>
        <text start="95" dur="7">then--and I&amp;#39;ll show in general what they look like here--</text>
        <text start="102" dur="12">the fluent is true if and only if action A made it true</text>
        <text start="114" dur="6">or action A didn&amp;#39;t undo it.</text>
        <text start="123" dur="5">So that is, either it wasn&amp;#39;t true before and A made it be true,</text>
        <text start="128" dur="6">or it was true before and A didn&amp;#39;t do something to stop it being true.</text>
        <text start="134" dur="4">For example, I&amp;#39;ll show you the successor state axiom for the In predicate.</text>
        <text start="138" dur="5">And just to make it a little bit simpler, I&amp;#39;ll leave out all the For All quantifiers.</text>
        <text start="143" dur="5">So wherever you see a variable without a quantifier, assume that there&amp;#39;s a For All.</text>
        <text start="148" dur="10">What we&amp;#39;ll say is it&amp;#39;s possible to execute A in situation S.</text>
        <text start="158" dur="10">If that&amp;#39;s true, then the In predicate holds between some cargo C</text>
        <text start="168" dur="11">and some plane in the state, which is the result of executing action A in state S.</text>
        <text start="181" dur="11">So that In predicate will hold if and only if either A was a load action--</text>
        <text start="192" dur="7">so if we load the cargo into the plane, then the result of executing that action A</text>
        <text start="199" dur="4">is that the cargo is in the plane--</text>
        <text start="203" dur="7">or it might be that it was already true that the cargo was in the plane in situation S</text>
        <text start="210" dur="8">and A is not equal to an unload action.</text>
        <text start="218" dur="7">So for all A and S for which it&amp;#39;s possible to execute A in situation S,</text>
        <text start="225" dur="5">the In predicate holds if and only if the action was a load</text>
        <text start="230" dur="6">or the In predicate used to hold in the previous state and the action is not an unload.</text>
      </transcript>
    </video>
    <video title="25 Situation Calculus 3" id="5M4q-H1t3Hs" length="186">
      <transcript>
        <text start="0" dur="4">[Norvig] So I&amp;#39;ve talked about the possibility axioms and the successor state axioms.</text>
        <text start="4" dur="3">That&amp;#39;s most of what&amp;#39;s in situation calculus,</text>
        <text start="7" dur="4">and that&amp;#39;s used to describe an entire domain like the airport cargo domain.</text>
        <text start="11" dur="7">And now we describe a particular problem within that domain by describing the initial state.</text>
        <text start="18" dur="5">Typically we call that S0, the initial situation.</text>
        <text start="23" dur="6">And in S0 we can make various types of assertions</text>
        <text start="29" dur="2">of different types of predicates.</text>
        <text start="31" dur="12">So we could say that plane P1 is at airport JFK in S0, so just a simple predicate.</text>
        <text start="43" dur="9">And we could also make larger sentences, so we could say</text>
        <text start="52" dur="15">for all C, if C is cargo, then that C is at JFK in situation S0.</text>
        <text start="67" dur="4">So we have much more flexibility in situation calculus to say almost anything we want.</text>
        <text start="71" dur="7">Anything that&amp;#39;s a valid sentence in first order logic can be asserted about the initial state.</text>
        <text start="78" dur="2">The goal state is similar.</text>
        <text start="80" dur="5">We could have a goal of saying there exists some goal state S</text>
        <text start="85" dur="16">such that for all C, if C is cargo, then we want that cargo to be at SFO in state S.</text>
        <text start="101" dur="4">So this initial state and this goal says move all the cargo--</text>
        <text start="105" dur="5">I don&amp;#39;t care how much there is--from JFK to SFO.</text>
        <text start="110" dur="5">The great thing about situation calculus is that once we&amp;#39;ve described this</text>
        <text start="115" dur="3">in the ordinary language of first order logic,</text>
        <text start="118" dur="5">we don&amp;#39;t need any special programs to manipulate it and come up with the solution</text>
        <text start="123" dur="3">because we already have theorem provers for first order logic</text>
        <text start="126" dur="2">and we can just state this as a problem,</text>
        <text start="128" dur="5">apply the normal theorem prover that we already had for other uses,</text>
        <text start="133" dur="6">and it can come up with an answer of a path that satisfies this goal,</text>
        <text start="139" dur="4">a situation which corresponds to a path which satisfies this</text>
        <text start="143" dur="5">given the initial state and given the descriptions of the actions.</text>
        <text start="148" dur="4">So the advantage of situation calculus is that we have the full power of first order logic.</text>
        <text start="152" dur="2">We can represent anything we want.</text>
        <text start="154" dur="5">Much more flexibility than in problem solving or classical planning.</text>
        <text start="159" dur="3">So all together now, we&amp;#39;ve seen several ways of dealing with planning.</text>
        <text start="162" dur="3">We started in deterministic, fully observable environments</text>
        <text start="165" dur="4">and we moved into stochastic and partially observable environments.</text>
        <text start="169" dur="6">We were able to distinguish between plans that can or cannot solve a problem,</text>
        <text start="175" dur="3">but we had 1 weakness in all these different approaches.</text>
        <text start="178" dur="5">It is that we weren&amp;#39;t able to distinguish between probable and improbable solutions.</text>
        <text start="183" dur="3">And that will be the subject of the next unit.</text>
      </transcript>
    </video>
  </group>
  <group title="Homework 4" count="9">
    <video title="1. Logic " id="WP_97aspqrc" length="110">
      <transcript>
        <text start="0" dur="4">In this exercise, I&amp;#39;m going to write some logical expressions</text>
        <text start="4" dur="3">in propositional logic and ask you</text>
        <text start="7" dur="6">if these expressions are always true or always false</text>
        <text start="13" dur="6">or if their truth value depends on the values of the propositional variables.</text>
        <text start="19" dur="7">The first sentence is smoke implies fire</text>
        <text start="26" dur="6">is equivalent to smoke or not fire.</text>
        <text start="32" dur="7">Is that true or false, or does it depend on the values of smoke and fire?</text>
        <text start="39" dur="6">The second sentence, again, smoke implies fire</text>
        <text start="45" dur="9">is equivalent to not smoke implies not fire.</text>
        <text start="54" dur="6">The third sentence, smoke implies fire</text>
        <text start="60" dur="9">is equivalent to not fire implies not smoke.</text>
        <text start="69" dur="8">The fourth sentence, big or dumb</text>
        <text start="77" dur="5">or big implies dumb.</text>
        <text start="82" dur="9">The final sentence, big and dumb</text>
        <text start="91" dur="8">is equivalent to not, not big or not dumb.</text>
        <text start="99" dur="6">For each of these, tell me if they&amp;#39;re always true regardless of the values of the variables,</text>
        <text start="105" dur="5">always false or sometimes true and sometimes false.</text>
      </transcript>
    </video>
    <video title="2. More Logic" id="P_eu1YFp9Z8" length="199">
      <transcript>
        <text start="0" dur="4">In this exercise, I&amp;#39;m going to give you some English sentences</text>
        <text start="4" dur="3">and then some first-order logic sentences</text>
        <text start="7" dur="3">and ask you does the first-order logic sentence</text>
        <text start="10" dur="5">correctly encode the English sentence, does it incorrectly encode it,</text>
        <text start="15" dur="6">or is it just an error that is not a legitimate sentence</text>
        <text start="21" dur="4">in first-order logic?</text>
        <text start="25" dur="5">The first English sentence is &amp;quot;Paris and Nice are both in France.&amp;quot;</text>
        <text start="30" dur="3">Here&amp;#39;s one possible translation.</text>
        <text start="33" dur="8">Paris and Nice are in France.</text>
        <text start="41" dur="3">Here&amp;#39;s another.</text>
        <text start="44" dur="5">Paris is in France, and Nice is in France.</text>
        <text start="49" dur="5">Tell us if each of these is a correct encoding of English,</text>
        <text start="54" dur="6">incorrect, or if it&amp;#39;s erroneous first-order logic syntax.</text>
        <text start="60" dur="7">The second sentence in English is &amp;quot;There is a country that borders Iran and Syria.&amp;quot;</text>
        <text start="67" dur="2">Here are the possible translations.</text>
        <text start="69" dur="5">There exists a c, and we&amp;#39;re going to use the predicate capital C</text>
        <text start="74" dur="8">to mean C when the argument is a country.</text>
        <text start="82" dur="4">So, there exists a c such that C of c,</text>
        <text start="86" dur="6">and we&amp;#39;re going to use the predicate B to mean 2 objects border each other.</text>
        <text start="92" dur="8">So, c borders Iran, and c borders Syria.</text>
        <text start="100" dur="4">That&amp;#39;s one translation. Here&amp;#39;s the other translation.</text>
        <text start="104" dur="6">There exists a c if C is a country,</text>
        <text start="110" dur="11">then c borders Iran and c borders Syria.</text>
        <text start="121" dur="3">And the final English sentence is no 2 bordering countries</text>
        <text start="124" dur="6">can have the same map color, and we&amp;#39;re going to use the predicate MC for map color.</text>
        <text start="130" dur="4">Here&amp;#39;s one possibility for all x and y.</text>
        <text start="134" dur="7">X is a country, and y is a country.</text>
        <text start="141" dur="5">And x and y border each other.</text>
        <text start="146" dur="6">That implies it&amp;#39;s not the case that the map color</text>
        <text start="152" dur="6">of x equals the map color of y.</text>
        <text start="158" dur="5">And I should say we&amp;#39;re using map color here as a function, not as a predicate.</text>
        <text start="163" dur="3">Here&amp;#39;s another possibility.</text>
        <text start="166" dur="7">For all x and y, it&amp;#39;s not the case that x is a country,</text>
        <text start="173" dur="6">or it&amp;#39;s not the case that y is a country,</text>
        <text start="179" dur="6">or it&amp;#39;s not the case that x and y border,</text>
        <text start="185" dur="6">or it&amp;#39;s not the case that the map color of x</text>
        <text start="191" dur="8">is equal to the map color of y.</text>
      </transcript>
    </video>
    <video title="3. Vacuum World " id="wsfXrIhDhJ0" length="69">
      <transcript>
        <text start="0" dur="4">This problem is about planning in belief space.</text>
        <text start="4" dur="6">We have the 2 room vacuum world, and we&amp;#39;ve represented various belief states here.</text>
        <text start="10" dur="4">Now, in this version, there are no sensors and so no percepts.</text>
        <text start="14" dur="3">The actions are all deterministic.</text>
        <text start="17" dur="5">A right or left or suck action will always do what it&amp;#39;s supposed to do,</text>
        <text start="22" dur="2">and the environment is static.</text>
        <text start="24" dur="4">That is, dirt stays put until it&amp;#39;s cleaned up.</text>
        <text start="28" dur="4">Now, in the start, you know nothing about the environment.</text>
        <text start="32" dur="2">You have no input. You don&amp;#39;t know what location you&amp;#39;re in.</text>
        <text start="34" dur="6">You don&amp;#39;t know where the dirt is, and your goal is to be in the leftmost of the 2 squares</text>
        <text start="40" dur="4">and have both squares cleaned up, and what I want you to do</text>
        <text start="44" dur="5">is click on the sequence of actions, an action like this one or this one or this one</text>
        <text start="49" dur="7">or this one, that constitute a path from the start state to the goal state.</text>
        <text start="56" dur="7">And then I want you to click on yes if that path is guaranteed</text>
        <text start="63" dur="6">to always reach the goal, and no if the path only sometimes reaches the goal.</text>
      </transcript>
    </video>
    <video title="4. More Vacuum World " id="2H4NJg8Iiaw" length="99">
      <transcript>
        <text start="0" dur="6">In this problem, we&amp;#39;re again in the 2-location vacuum world,</text>
        <text start="6" dur="4">but this time around, we have local sensing,</text>
        <text start="10" dur="5">meaning at each turn, we get input of what location we&amp;#39;re at,</text>
        <text start="15" dur="3">the left or the right, and whether there&amp;#39;s dirt in that location.</text>
        <text start="18" dur="3">But we don&amp;#39;t know what&amp;#39;s going on in the other location.</text>
        <text start="21" dur="7">We have a dynamic world where dirt can appear anywhere.</text>
        <text start="28" dur="5">As we move around, dirt can spontaneously appear</text>
        <text start="33" dur="4">in the location we left or in the location we&amp;#39;re going to visit.</text>
        <text start="37" dur="4">However, if we&amp;#39;re sucking, the dirt can&amp;#39;t appear,</text>
        <text start="41" dur="4">because if it did appear there, we would successfully suck it up.</text>
        <text start="45" dur="5">And now in addition, the right and left moves</text>
        <text start="50" dur="4">are stochastic in that they don&amp;#39;t always succeed.</text>
        <text start="54" dur="3">Sometimes when you try to go right, you do successfully go right,</text>
        <text start="57" dur="4">and sometimes you stay in the same location, same for left.</text>
        <text start="61" dur="3">The suck action is always successful.</text>
        <text start="64" dur="3">It will always clean up dirt in the current location.</text>
        <text start="67" dur="3">Now, when we start out, we get the percept</text>
        <text start="70" dur="4">saying that we&amp;#39;re in the leftmost location</text>
        <text start="74" dur="5">and that location is clean, and that means our belief state</text>
        <text start="79" dur="4">is that we&amp;#39;re in either 5 or 7.</text>
        <text start="83" dur="6">Now, the first thing I want you to answer is if we decide to move right,</text>
        <text start="89" dur="4">what do we predict the possible belief state will be,</text>
        <text start="93" dur="3">the possible set of states in our belief state will be</text>
        <text start="96" dur="3">after we execute the right movement?</text>
      </transcript>
    </video>
    <video title="5. More Vacuum World " id="i5XMOLw6CGE" length="19">
      <transcript>
        <text start="0" dur="3">Now we get a percept from the world, and we&amp;#39;ve observed</text>
        <text start="3" dur="4">that we&amp;#39;re in the rightmost square, so the action worked,</text>
        <text start="7" dur="2">and that square is dirty.</text>
        <text start="9" dur="3">Now we want to update our belief state</text>
        <text start="12" dur="3">and click on all the states that belong to the belief state now</text>
        <text start="15" dur="4">as we update due to this percept.</text>
      </transcript>
    </video>
    <video title="6. More Vacuum World " id="x93ewPQhIQc" length="19">
      <transcript>
        <text start="0" dur="4">Now our belief state contains 2 and 6,</text>
        <text start="4" dur="4">and we decide we want to execute the suck action.</text>
        <text start="8" dur="3">Now tell me, by clicking on the appropriate states,</text>
        <text start="11" dur="3">what states belong to the belief state</text>
        <text start="14" dur="5">after we make a prediction for what&amp;#39;s going to happen after the suck action.</text>
      </transcript>
    </video>
    <video title="7. More Vacuum World " id="RW-l7JWDtYQ" length="19">
      <transcript>
        <text start="0" dur="4">Now, we make the observation</text>
        <text start="4" dur="5">right, clean, and I want you to</text>
        <text start="9" dur="3">update our belief state by clicking on the states</text>
        <text start="12" dur="4">that belong to the new belief state now</text>
        <text start="16" dur="3">after taking that observation into account.</text>
      </transcript>
    </video>
    <video title="8. Monkey and Bananas " id="rCGAgc9smZg" length="70">
      <transcript>
        <text start="0" dur="4">This is a famous problem called the monkey and bananas problem,</text>
        <text start="4" dur="4">described in the language of classical planning.</text>
        <text start="8" dur="4">There are six actions. The monkey can go from location x to y.</text>
        <text start="12" dur="7">It can push some object from x to y. It can climb up an object. It can grab something.</text>
        <text start="19" dur="5">It can climb down from an object, and it can un-grab something.</text>
        <text start="24" dur="5">Initially, the monkey is at location A. The bananas are at location B.</text>
        <text start="29" dur="5">The box is at C, and the monkey is at a low height, as is the box,</text>
        <text start="34" dur="3">but the bananas are at a high height,</text>
        <text start="37" dur="3">but the box is pushable and climbable.</text>
        <text start="40" dur="6">Now, assuming that we execute this plan--go from A to C, push the box from C to B,</text>
        <text start="46" dur="5">climb up on the box, grasp the bananas, and climb down from the box.</text>
        <text start="51" dur="6">What I want you to do is look at these definitions of actions,</text>
        <text start="57" dur="6">tell me how the state unfolds from this initial state here to the final state,</text>
        <text start="63" dur="7">and then click off all of these instances that are going to be true in the final state.</text>
      </transcript>
    </video>
    <video title="9. Situation Calculus " id="eeDwEYxWCTA" length="276">
      <transcript>
        <text start="0" dur="5">[Norvig] The final problem involves situation calculus.</text>
        <text start="5" dur="6">In the domain I want to describe, we have a combination lock with 4 digits,</text>
        <text start="11" dur="6">and the correct combination that will open the lock we&amp;#39;ll call X.</text>
        <text start="17" dur="3">There are 2 actions you can perform.</text>
        <text start="20" dur="4">One is to dial any combination on the dial,</text>
        <text start="24" dur="5">and if you dial the correct one, X, then the lock will open.</text>
        <text start="29" dur="5">And the other action you can perform is to press a lock button,</text>
        <text start="34" dur="3">and if you press that button, then the lock will be locked,</text>
        <text start="37" dur="3">whether it was open before or not.</text>
        <text start="40" dur="3">I&amp;#39;m going to describe some axioms,</text>
        <text start="43" dur="5">and I want you to tell me whether these axioms are correct for the domain or not.</text>
        <text start="51" dur="2">First the possibility axioms.</text>
        <text start="53" dur="6">One choice is the possibility axiom that says</text>
        <text start="59" dur="10">if C equals X, then it&amp;#39;s possible to dial C in situation S.</text>
        <text start="69" dur="4">And here I&amp;#39;m assuming that all variables are scoped</text>
        <text start="73" dur="5">so that we say an implicit for all C and for all S here.</text>
        <text start="78" dur="8">And X is not a variable. This is a constant, referring to the correct combination.</text>
        <text start="86" dur="10">The other possible axiom is for all C if C is greater than or equal to 0</text>
        <text start="96" dur="5">and less than or equal to 9999,</text>
        <text start="101" dur="9">then it&amp;#39;s possible to dial C in any situation S.</text>
        <text start="110" dur="10">So tell me which, if any or both, of these axioms you think correctly encode the situation.</text>
        <text start="120" dur="5">Next we&amp;#39;ll look at the possibility axioms for the lock action.</text>
        <text start="125" dur="2">Here&amp;#39;s one.</text>
        <text start="127" dur="5">We can say if the safe is open in situation S,</text>
        <text start="132" dur="6">then it&amp;#39;s possible to execute the lock action in S.</text>
        <text start="138" dur="6">Or maybe we should say if the safe is not open in S,</text>
        <text start="144" dur="6">then it&amp;#39;s possible to execute Lock in S.</text>
        <text start="150" dur="5">Or maybe we should say if true,</text>
        <text start="155" dur="7">then it&amp;#39;s possible to execute the lock action in situation S.</text>
        <text start="162" dur="8">And tell me which, if any, of those represents a correct representation of the problem.</text>
        <text start="170" dur="4">And finally we need successor state axioms for all the fluents,</text>
        <text start="174" dur="5">but there&amp;#39;s really only one fluent, and that&amp;#39;s whether or not the safe is open.</text>
        <text start="179" dur="7">So here&amp;#39;s one example of a successor state axiom.</text>
        <text start="186" dur="7">We could say for any situation and action,</text>
        <text start="193" dur="5">if it&amp;#39;s possible to execute that action in the situation,</text>
        <text start="198" dur="8">then the Open fluent is going to be true in the result of executing that action</text>
        <text start="206" dur="10">if and only if the action is dialing the correct combination, X,</text>
        <text start="216" dur="11">or if the safe was already open in S and the action is not equal to Lock.</text>
        <text start="227" dur="2">That&amp;#39;s one option.</text>
        <text start="229" dur="5">And the other option is the same thing on the left-hand side,</text>
        <text start="234" dur="9">and on the right-hand side it&amp;#39;s open if and only if the action is dialing the correct combination</text>
        <text start="243" dur="6">and the action is not equal to Lock.</text>
        <text start="249" dur="7">So tell me which, if any or all, of these are accurate representations of the problem.</text>
        <text start="256" dur="7">In each case I want you to tell me if each of these axioms are good as they stand alone.</text>
        <text start="263" dur="3">I don&amp;#39;t want you to look at any combinations of axioms</text>
        <text start="266" dur="7">but just go through each one and check the box if you think that the axiom on that line alone</text>
        <text start="273" dur="3">is a correct representation of the problem.</text>
      </transcript>
    </video>
  </group>
  <group title="Unit 9" count="36">
    <video title="01 Introduction" id="DgH6NaJHfVQ" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="02 Planning Under Uncertainty MDP" id="9D35JSWSJAg" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="03 Robot Tour Guide Examples" id="9QMZQkKuYjo" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="04 MDP Grid World" id="YfSBYf9h7qk" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="05 Problems with Conventional Planning 1" id="Ig0ekhtAfkY" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="06 Branching Factor Question" id="Y_WmE98BN7c" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="07 Branching Factor Answer" id="_tpD8n3vpXg" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="08 Problems with Conventional Planning 2" id="V2AvmoBJdU4" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="09 Policy Question 1" id="zOzKPHA-lDQ" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="10 Policy Answer 1" id="_2thYamxwN4" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="11 Policy Question 2" id="jutx0ekYv28" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="12 Policy Answer 2" id="EbWXMMcl1dc" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="13 Policy Question 3" id="Hdm9jCJvesM" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="14 Policy Answer 3 Question 4" id="AAg6KkvTijU" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="15 Policy Answer 4" id="PJKRCDi_fIs" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="16 MDP and Costs" id="WyLEhX3oUZU" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="17 Value Iteration 1" id="oefOCk3koZo" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="18 Value Iteration 2" id="8-pzJXUiXrM" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="19 Value Iteration 3" id="glHKJ359Cnc" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="20 Deterministic Question 1" id="0uBKtlb8QtU" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="21 Deterministic Answer 1" id="cs7eAdklm_4" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="22 Deterministic Question 2" id="ytCyzDAz2Uo" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="23 Deterministic Answer 2" id="Mr3H7QpecRA" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="24 Deterministic Question 3" id="M3AM5huQzlc" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="25 Deterministic Answer 3" id="RzO7U1ZPD54" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="26 Stochastic Question 1" id="_LQAOyxbGiQ" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="27 Stochastic Answer 1" id="wWQO0h_WjT4" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="28 Stochastic Question 2" id="YIR22PaBvCY" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="29 Stochastic Answer 2" id="0ImGXKeKqFU" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="30 Value Iterations and Policy 1" id="CDXaY7cdTYE" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="31 Value Iterations and Policy 2" id="46U-_qzQui0" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="32 MDP Conclusion" id="fCwZN0Ht4Q8" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="33 Partial Observability Introduction" id="y3Rkp3oCzq4" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="34 POMDP vs MDP" id="ynGnvuh0ELQ" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="35 POMDP" id="bVT7QlYC7JQ" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
    <video title="36 Planning Under Uncertainty Conclusion" id="PuoTbYxNJnU" length="?">
      <transcript>
        <text start="0" dur="3">No subtitles...</text>
      </transcript>
    </video>
  </group>
</videos>